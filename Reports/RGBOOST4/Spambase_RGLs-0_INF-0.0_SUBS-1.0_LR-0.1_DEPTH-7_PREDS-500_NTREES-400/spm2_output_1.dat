
 The "USE "../Data/Classification/Spambase/SAMPLES4/data" command: 00:00:01

 Model (target and predictors) reset: SPAM_OR_NOTSPAM

 The KEEP list has 57 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 2301
 Records Kept in Learning sample: 2301

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1150
 Records Kept in Test sample: 1150

    Discrete         N Levels
    Variable         in Model
 ----------------------------
 SPAM_OR_NOTSPAM            2

 ======================
 Target Frequency Table
 ======================

 Variable: SPAM_OR_NOTSPAM
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1394  60.58              1394.00  60.58
                 T         (697  60.61)             (697.00  60.61)
 1               L          907  39.42               907.00  39.42
                 T         (453  39.39)             (453.00  39.39)
 -----------------------------------------------------------------
 Totals
 0                         2091  60.59              2091.00  60.59
 1                         1360  39.41              1360.00  39.41
 -----------------------------------------------------------------
 Total                     3451                     3451.00
 Total Learn               2301                     2301.00
 Total Test                1150                     1150.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.59433      0.60061      0.39418      0.39391      1.00000 |                                               *
      2       0.53280      0.54482      0.10213      0.13043      1.00000 |                                           *
      3       0.48152      0.49931      0.06041      0.09304      1.00000 |                                       *
      4       0.43957      0.46198      0.05476      0.08957      1.00000 |                                    *
      5       0.40183      0.42841      0.05259      0.08522      1.00000 |                                 *
      6       0.36869      0.39954      0.05346      0.08261      1.00000 |                               *
      7       0.34018      0.37405      0.05259      0.08522      1.00000 |                             *
      8       0.31415      0.35095      0.04694      0.08435      1.00000 |                           *
      9       0.29227      0.33199      0.04607      0.08348      1.00000 |                          *
     10       0.27179      0.31406      0.04259      0.08087      1.00000 |                        *
     11       0.25413      0.29884      0.04259      0.07652      1.00000 |                       *
     12       0.23825      0.28472      0.04085      0.07217      1.00000 |                      *
     13       0.22382      0.27157      0.04216      0.07217      1.00000 |                     *
     14       0.21050      0.26063      0.03781      0.06783      1.00000 |                    *
     15       0.19822      0.25024      0.03651      0.06609      1.00000 |                   *
     16       0.18786      0.24220      0.03607      0.06609      1.00000 |                  *
     17       0.17826      0.23448      0.03390      0.06261      1.00000 |                  *
     18       0.16973      0.22753      0.03346      0.06174      1.00000 |                 *
     19       0.16195      0.22108      0.03259      0.06348      1.00000 |                 *
     20       0.15300      0.21483      0.03216      0.06348      1.00000 |                *
     30       0.09799      0.17411      0.02564      0.06087      1.00000 |             *
     40       0.07260      0.15928      0.01738      0.05652      1.00000 |            *
     50       0.05588      0.15232      0.01260      0.05217      1.00000 |           *
     60       0.04538      0.15034      0.01173      0.05304      1.00000 |           *
     70       0.03769      0.14825      0.00652      0.05043      1.00000 |           *
     80       0.03271      0.14878      0.00522      0.04870      1.00000 |           *
     90       0.02840      0.14907      0.00478      0.04783      1.00000 |           *
    100       0.02358      0.14858      0.00304      0.04696      1.00000 |           *
    110       0.02071      0.14984      0.00304      0.04435      1.00000 |           *
    120       0.01827      0.15152      0.00217      0.04609      1.00000 |           *
    130       0.01549      0.15415      0.00130      0.04870      1.00000 |           *
    140       0.01345      0.15662      0.00130      0.04783      1.00000 |            *
    150       0.01160      0.15890      0.00130      0.04783      1.00000 |            *
    160       0.01029      0.15966      0.00130      0.04783      1.00000 |            *
    170       0.00886      0.16081      0.00087      0.04957      1.00000 |            *
    180       0.00760      0.16250      0.00087      0.04957      1.00000 |            *
    190       0.00682      0.16446      0.00087      0.04870      1.00000 |            *
    200       0.00616      0.16703      0.00087      0.04870      1.00000 |            *
    210       0.00532      0.16904      0.00043      0.04783      1.00000 |             *
    220       0.00468      0.17226      0.00043      0.04870      1.00000 |             *
    230       0.00423      0.17532      0.00043      0.04870      1.00000 |             *
    240       0.00362      0.17726      0.00043      0.04696      1.00000 |             *
    250       0.00328      0.17850      0.00043      0.04870      1.00000 |             *
    260       0.00295      0.18021      0.00043      0.04870      1.00000 |             *
    270       0.00259      0.18428      0.00043      0.04609      1.00000 |              *
    280       0.00233      0.18762      0.00043      0.04609      1.00000 |              *
    290       0.00214      0.19263      0.00043      0.04696      1.00000 |              *
    300       0.00193      0.19623      0.00043      0.04783      1.00000 |               *
    310       0.00176      0.19942      0.00043      0.04783      1.00000 |               *
    320       0.00157      0.20300      0.00043      0.04870      1.00000 |               *
    330       0.00142      0.20683      0.00043      0.04783      1.00000 |                *
    340       0.00130      0.20979      0.00043      0.04522      1.00000 |                *
    350       0.00121      0.21318      0.00043      0.04696      1.00000 |                *
    360       0.00114      0.21652      0.00043      0.04696      1.00000 |                *
    370       0.00106      0.22057      0.00043      0.04696      1.00000 |                 *
    380       0.00101      0.22440      0.00043      0.04783      1.00000 |                 *
    390       0.00095      0.22771      0.00043      0.04783      1.00000 |                 *
    400       0.00090      0.23052      0.00043      0.04783      1.00000 |                 *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    390      1    400      1      7      4.20      3.71  CAPITAL_RUN_LENGTH_AVERAGE
    384      1    400      1      7      3.99      3.85  CAPITAL_RUN_LENGTH_TOTAL
    380      2    400      1      7      4.48      3.35  WORD_FREQ_YOU
    360      1    400      1      7      3.94      3.65  CHAR_FREQ_EXCLAMATION
    341      1    400      2      7      4.88      2.66  CAPITAL_RUN_LENGTH_LONGEST
    332      1    400      2      7      4.80      2.66  WORD_FREQ_YOUR
    318      1    400      1      7      4.54      2.75  CHAR_FREQ_BRACKET
    290      1    399      1      7      5.23      2.00  WORD_FREQ_WILL
    265      1    399      1      7      5.30      1.79  WORD_FREQ_OUR
    265      1    400      1      7      4.69      2.19  WORD_FREQ_RE
    261      1    399      1      7      4.84      2.06  WORD_FREQ_HP
    255      1    400      1      7      5.10      1.85  WORD_FREQ_FREE
    237      2    400      2      7      5.57      1.44  WORD_FREQ_ALL
    231      4    397      1      7      5.29      1.56  WORD_FREQ_MAIL
    213      1    398      1      7      4.71      1.75  CHAR_FREQ_DOLLAR
    212      1    399      1      7      4.24      2.00  WORD_FREQ_EDU
    194      1    399      2      7      5.32      1.30  WORD_FREQ_1999
    175      1    400      1      7      4.35      1.60  WORD_FREQ_GEORGE
    172      1    398      1      7      4.60      1.46  WORD_FREQ_REMOVE
    170      1    399      1      7      5.29      1.15  WORD_FREQ_BUSINESS
    164      6    398      1      7      4.82      1.30  WORD_FREQ_MAKE
    161      1    398      1      7      5.08      1.18  CHAR_FREQ_SEMICOLON
    158      6    398      1      7      4.68      1.31  WORD_FREQ_OVER
    136      1    400      1      7      4.77      1.10  WORD_FREQ_DATA
    128     10    395      1      7      4.56      1.10  CHAR_FREQ_BOXBRACKET
    127      8    397      1      7      5.45      0.81  WORD_FREQ_ADDRESS
    126      1    398      1      7      5.35      0.84  WORD_FREQ_EMAIL
    121      6    397      1      7      4.94      0.93  WORD_FREQ_PROJECT
    111      2    398      2      7      5.34      0.74  WORD_FREQ_RECEIVE
    109      1    400      1      7      5.49      0.69  WORD_FREQ_INTERNET
    109      5    397      2      7      5.61      0.65  CHAR_FREQ_HASH
    103     19    399      1      7      5.14      0.74  WORD_FREQ_HPL
    103      1    392      1      7      4.01      1.03  WORD_FREQ_MONEY
     98     26    386      1      7      5.30      0.66  WORD_FREQ_85
     95      6    400      2      7      5.72      0.54  WORD_FREQ_PEOPLE
     93     11    400      1      7      4.25      0.87  WORD_FREQ_000
     90      9    399      1      7      5.47      0.57  WORD_FREQ_TECHNOLOGY
     87      2    400      1      7      3.30      1.02  WORD_FREQ_MEETING
     83      5    399      2      7      5.48      0.52  WORD_FREQ_ORDER
     80      5    396      1      7      4.23      0.76  WORD_FREQ_650
     79      5    399      1      7      3.77      0.84  WORD_FREQ_PM
     78     17    392      1      7      4.09      0.76  WORD_FREQ_REPORT
     73     19    397      1      7      4.38      0.66  WORD_FREQ_CREDIT
     57     14    393      3      7      5.51      0.36  WORD_FREQ_LABS
     50     15    393      1      7      2.72      0.66  WORD_FREQ_CS
     48     23    388      1      7      4.92      0.37  WORD_FREQ_DIRECT
     46     29    372      3      7      5.78      0.26  WORD_FREQ_LAB
     45     12    390      1      7      4.82      0.36  WORD_FREQ_ORIGINAL
     44      4    393      1      7      3.55      0.49  WORD_FREQ_CONFERENCE
     27     60    387      1      7      4.81      0.22  WORD_FREQ_ADDRESSES
     27     27    375      2      7      4.85      0.21  WORD_FREQ_FONT
     15      4    328      4      7      5.80      0.08  WORD_FREQ_TELNET
      8     69    144      4      6      5.00      0.06  WORD_FREQ_PARTS
      7      6    210      5      7      6.14      0.03  WORD_FREQ_3D
      2     68    297      6      7      6.50      0.01  WORD_FREQ_TABLE
      1    279    279      7      7      7.00      0.00  WORD_FREQ_415
      1     34     34      5      5      5.00      0.01  WORD_FREQ_857

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    18 terminal nodes
    Largest :    79 terminal nodes
    Average :     42.23750 terminal nodes

 Reconciling 2301 Learn sample scores across 5 selected models,
 the largest having 192 trees, to compute gains and PS tables.

 Reconciling 1150 Test sample scores across 5 selected models,
 the largest having 192 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 98

 Target: SPAM_OR_NOTSPAM
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     2301      2301.00
 N Test  Obs:     1150      1150.00
 Learn Rate :    0.1000000

 Storage requirements: 33390 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           98      0.14787
                  ROC          192      0.98510
                 Lift           21      2.51656
              KS-stat          266      0.91391
          Class.Error          106      0.04348

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.59433     0.60061     0.97706     0.94314     2.53693     2.27774     0.86076     0.80144     0.39418     0.39391
     10     0.27179     0.31406     0.99069     0.97111     2.53693     2.45243     0.90752     0.84394     0.04259     0.08087
     20     0.15300     0.21483     0.99476     0.97653     2.53693     2.49448     0.93270     0.86822     0.03216     0.06348
     21     0.14496     0.20893     0.99543     0.97824     2.53693     2.51656     0.94203     0.87275     0.03042     0.06261
     30     0.09799     0.17411     0.99764     0.98145     2.53693     2.51656     0.95808     0.90288     0.02564     0.06087
     40     0.07260     0.15928     0.99859     0.98215     2.53693     2.51656     0.96857     0.90144     0.01738     0.05652
     50     0.05588     0.15232     0.99934     0.98345     2.53693     2.51656     0.98257     0.90089     0.01260     0.05217
     60     0.04538     0.15034     0.99956     0.98331     2.53693     2.51656     0.98511     0.89912     0.01173     0.05304
     70     0.03769     0.14825     0.99975     0.98381     2.53693     2.51656     0.98798     0.90210     0.00652     0.05043
     80     0.03271     0.14878     0.99981     0.98384     2.53693     2.51656     0.99195     0.90420     0.00522     0.04870
     90     0.02840     0.14907     0.99989     0.98394     2.53693     2.51656     0.99305     0.90188     0.00478     0.04783
     98     0.02403     0.14787     0.99994     0.98466     2.53693     2.51656     0.99746     0.90387     0.00304     0.04783
    100     0.02358     0.14858     0.99995     0.98453     2.53693     2.51656     0.99746     0.90486     0.00304     0.04696
    106     0.02163     0.14911     0.99996     0.98454     2.53693     2.51656     0.99818     0.90806     0.00304     0.04348
    110     0.02071     0.14984     0.99996     0.98445     2.53693     2.51656     0.99818     0.90873     0.00304     0.04435
    120     0.01827     0.15152     0.99997     0.98449     2.53693     2.51656     0.99818     0.90939     0.00217     0.04609
    130     0.01549     0.15415     0.99999     0.98432     2.53693     2.51656     0.99818     0.90641     0.00130     0.04870
    140     0.01345     0.15662     0.99999     0.98447     2.53693     2.51656     0.99818     0.90652     0.00130     0.04783
    150     0.01160     0.15890     1.00000     0.98442     2.53693     2.51656     0.99857     0.90508     0.00130     0.04783
    155     0.01095     0.15989     1.00000     0.98458     2.53693     2.51656     0.99928     0.90497     0.00130     0.04870
    160     0.01029     0.15966     1.00000     0.98465     2.53693     2.51656     0.99928     0.90652     0.00130     0.04783
    170     0.00886     0.16081     1.00000     0.98479     2.53693     2.51656     0.99928     0.90718     0.00087     0.04957
    180     0.00760     0.16250     1.00000     0.98494     2.53693     2.51656     0.99928     0.91148     0.00087     0.04957
    190     0.00682     0.16446     1.00000     0.98498     2.53693     2.51656     0.99928     0.90939     0.00087     0.04870
    192     0.00671     0.16503     1.00000     0.98510     2.53693     2.51656     0.99928     0.90939     0.00087     0.04870
    200     0.00616     0.16703     1.00000     0.98494     2.53693     2.51656     0.99928     0.90939     0.00087     0.04870
    204     0.00574     0.16751     1.00000     0.98503     2.53693     2.51656     0.99928     0.90917     0.00043     0.04783
    210     0.00532     0.16904     1.00000     0.98503     2.53693     2.51656     0.99928     0.90939     0.00043     0.04783
    220     0.00468     0.17226     1.00000     0.98480     2.53693     2.51656     0.99928     0.91171     0.00043     0.04870
    230     0.00423     0.17532     1.00000     0.98475     2.53693     2.51656     0.99928     0.91171     0.00043     0.04870
    240     0.00362     0.17726     1.00000     0.98474     2.53693     2.51656     0.99928     0.91171     0.00043     0.04696
    250     0.00328     0.17850     1.00000     0.98493     2.53693     2.51656     0.99928     0.91104     0.00043     0.04870
    260     0.00295     0.18021     1.00000     0.98492     2.53693     2.51656     0.99928     0.91182     0.00043     0.04870
    266     0.00268     0.18233     1.00000     0.98485     2.53693     2.51656     0.99928     0.91391     0.00043     0.04609
    270     0.00259     0.18428     1.00000     0.98462     2.53693     2.51656     0.99928     0.91391     0.00043     0.04609
    280     0.00233     0.18762     1.00000     0.98462     2.53693     2.51656     0.99928     0.91248     0.00043     0.04609
    290     0.00214     0.19263     1.00000     0.98449     2.53693     2.51656     0.99928     0.91104     0.00043     0.04696
    300     0.00193     0.19623     1.00000     0.98417     2.53693     2.51656     0.99928     0.91314     0.00043     0.04783
    310     0.00176     0.19942     1.00000     0.98401     2.53693     2.51656     0.99928     0.91314     0.00043     0.04783
    320     0.00157     0.20300     1.00000     0.98402     2.53693     2.51656     0.99928     0.90939     0.00043     0.04870
    330     0.00142     0.20683     1.00000     0.98424     2.53693     2.51656     0.99928     0.90950     0.00043     0.04783
    340     0.00130     0.20979     1.00000     0.98440     2.53693     2.51656     0.99928     0.91237     0.00043     0.04522
    350     0.00121     0.21318     1.00000     0.98435     2.53693     2.51656     0.99928     0.91380     0.00043     0.04696
    360     0.00114     0.21652     1.00000     0.98436     2.53693     2.51656     0.99928     0.91391     0.00043     0.04696
    370     0.00106     0.22057     1.00000     0.98443     2.53693     2.51656     0.99928     0.91314     0.00043     0.04696
    380     0.00101     0.22440     1.00000     0.98443     2.53693     2.51656     0.99928     0.91093     0.00043     0.04783
    390     0.00095     0.22771     1.00000     0.98441     2.53693     2.51656     0.99928     0.91104     0.00043     0.04783
    400     0.00090     0.23052     1.00000     0.98433     2.53693     2.51656     0.99928     0.91082     0.00043     0.04783


 =========================================
 Variable Importance for the 98-tree Model
 =========================================

                                     Abs     Rel

 CHAR_FREQ_EXCLAMATION         100.00000  100.00 |***********|
 WORD_FREQ_REMOVE               58.84032   58.84 |*******    |
 CHAR_FREQ_DOLLAR               57.08238   57.08 |*******    |
 WORD_FREQ_HP                   42.53684   42.54 |*****      |
 CAPITAL_RUN_LENGTH_AVERAGE     40.00717   40.01 |*****      |
 WORD_FREQ_FREE                 33.39640   33.40 |****       |
 CAPITAL_RUN_LENGTH_LONGEST     33.29959   33.30 |****       |
 WORD_FREQ_GEORGE               32.50085   32.50 |****       |
 WORD_FREQ_EDU                  32.31207   32.31 |****       |
 CAPITAL_RUN_LENGTH_TOTAL       30.69166   30.69 |****       |
 WORD_FREQ_MONEY                28.51287   28.51 |****       |
 WORD_FREQ_YOUR                 26.15378   26.15 |****       |
 WORD_FREQ_OUR                  22.96700   22.97 |***        |
 WORD_FREQ_YOU                  22.10412   22.10 |***        |
 WORD_FREQ_RE                   21.31819   21.32 |***        |
 WORD_FREQ_BUSINESS             20.84159   20.84 |***        |
 WORD_FREQ_1999                 16.35218   16.35 |***        |
 WORD_FREQ_WILL                 15.03619   15.04 |**         |
 WORD_FREQ_MEETING              14.55616   14.56 |**         |
 WORD_FREQ_000                  14.16136   14.16 |**         |
 CHAR_FREQ_SEMICOLON            14.15776   14.16 |**         |
 CHAR_FREQ_BRACKET              13.84368   13.84 |**         |
 WORD_FREQ_HPL                  13.20499   13.20 |**         |
 WORD_FREQ_650                  13.06995   13.07 |**         |
 WORD_FREQ_INTERNET             12.03941   12.04 |**         |
 WORD_FREQ_PM                   10.64926   10.65 |**         |
 WORD_FREQ_EMAIL                10.53991   10.54 |**         |
 WORD_FREQ_ALL                  10.46968   10.47 |**         |
 WORD_FREQ_RECEIVE              10.39681   10.40 |**         |
 WORD_FREQ_DATA                  9.84130    9.84 |**         |
 WORD_FREQ_PROJECT               9.37435    9.37 |**         |
 WORD_FREQ_OVER                  9.16645    9.17 |**         |
 CHAR_FREQ_HASH                  8.76790    8.77 |**         |
 WORD_FREQ_MAKE                  8.01780    8.02 |**         |
 WORD_FREQ_MAIL                  7.57592    7.58 |**         |
 WORD_FREQ_CREDIT                7.57528    7.58 |**         |
 WORD_FREQ_PEOPLE                7.46469    7.46 |**         |
 WORD_FREQ_REPORT                7.44580    7.45 |**         |
 WORD_FREQ_ADDRESS               6.44795    6.45 |**         |
 WORD_FREQ_LABS                  5.89155    5.89 |**         |
 WORD_FREQ_FONT                  5.85259    5.85 |**         |
 WORD_FREQ_TECHNOLOGY            5.67176    5.67 |**         |
 WORD_FREQ_CS                    5.55798    5.56 |**         |
 WORD_FREQ_CONFERENCE            4.71469    4.71 |*          |
 WORD_FREQ_TELNET                4.35560    4.36 |*          |
 WORD_FREQ_ORDER                 4.12405    4.12 |*          |
 WORD_FREQ_ORIGINAL              3.64113    3.64 |*          |
 CHAR_FREQ_BOXBRACKET            3.43087    3.43 |*          |
 WORD_FREQ_DIRECT                2.99891    3.00 |*          |
 WORD_FREQ_LAB                   2.04848    2.05 |*          |
 WORD_FREQ_3D                    1.80592    1.81 |*          |
 WORD_FREQ_85                    1.55231    1.55 |*          |
 WORD_FREQ_ADDRESSES             0.67028    0.67 |*          |
 WORD_FREQ_TABLE                 0.19262    0.19 |*          |
 WORD_FREQ_PARTS                 0.00968    0.01 |*          |
 WORD_FREQ_857                   0.00707    0.01 |*          |


 Learn Sample Misclassification by Target Class
 For The 98-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1394.00      1393.00         1.00       0.0007
 1                  907.00       901.00         6.00       0.0066


 Test Sample Misclassification by Target Class
 For The 98-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  697.00       672.00        25.00       0.0359
 1                  453.00       423.00        30.00       0.0662

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.5 MB, 75% compression

 Grove file created containing:
      1 TreeNet

