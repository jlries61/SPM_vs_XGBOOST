
 The "USE "../Data/Classification/Spambase/SAMPLES4/data" command: 00:00:00

 Model (target and predictors) reset: SPAM_OR_NOTSPAM

 The KEEP list has 57 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 2301
 Records Kept in Learning sample: 2301

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1150
 Records Kept in Test sample: 1150

    Discrete         N Levels
    Variable         in Model
 ----------------------------
 SPAM_OR_NOTSPAM            2

 ======================
 Target Frequency Table
 ======================

 Variable: SPAM_OR_NOTSPAM
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1394  60.58              1394.00  60.58
                 T         (697  60.61)             (697.00  60.61)
 1               L          907  39.42               907.00  39.42
                 T         (453  39.39)             (453.00  39.39)
 -----------------------------------------------------------------
 Totals
 0                         2091  60.59              2091.00  60.59
 1                         1360  39.41              1360.00  39.41
 -----------------------------------------------------------------
 Total                     3451                     3451.00
 Total Learn               2301                     2301.00
 Total Test                1150                     1150.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.59232      0.60030      0.39418      0.39391      1.00000 |                                               *
      2       0.52907      0.54457      0.08692      0.12174      1.00000 |                                           *
      3       0.47566      0.49707      0.06215      0.10348      1.00000 |                                       *
      4       0.43011      0.45642      0.04781      0.08609      1.00000 |                                   *
      5       0.39141      0.42309      0.03998      0.08087      1.00000 |                                 *
      6       0.35805      0.39483      0.04042      0.07739      1.00000 |                               *
      7       0.32938      0.36990      0.03564      0.07391      1.00000 |                             *
      8       0.30323      0.34852      0.03433      0.07130      1.00000 |                           *
      9       0.28115      0.33023      0.03390      0.07043      1.00000 |                         *
     10       0.26038      0.31325      0.03129      0.06957      1.00000 |                        *
     11       0.24237      0.29841      0.03216      0.06957      1.00000 |                       *
     12       0.22610      0.28497      0.03173      0.06957      1.00000 |                      *
     13       0.21073      0.27279      0.02999      0.06696      1.00000 |                     *
     14       0.19800      0.26287      0.02912      0.06522      1.00000 |                    *
     15       0.18501      0.25246      0.02694      0.06348      1.00000 |                   *
     16       0.17458      0.24468      0.02651      0.06522      1.00000 |                   *
     17       0.16483      0.23750      0.02564      0.06348      1.00000 |                  *
     18       0.15554      0.22935      0.02521      0.06087      1.00000 |                 *
     19       0.14627      0.22153      0.02477      0.06087      1.00000 |                 *
     20       0.13855      0.21447      0.02303      0.06087      1.00000 |                *
     30       0.08892      0.17205      0.01912      0.05913      1.00000 |             *
     40       0.06330      0.15419      0.01434      0.05391      1.00000 |           *
     50       0.05164      0.14738      0.01130      0.05304      1.00000 |           *
     60       0.04046      0.14558      0.00826      0.04957      1.00000 |           *
     70       0.03449      0.14390      0.00652      0.04522      1.00000 |           *
     80       0.02945      0.14345      0.00565      0.04522      1.00000 |          *
     90       0.02428      0.14440      0.00391      0.04348      1.00000 |           *
    100       0.02067      0.14493      0.00348      0.04261      1.00000 |           *
    110       0.01843      0.14727      0.00348      0.04522      1.00000 |           *
    120       0.01587      0.14868      0.00174      0.04435      1.00000 |           *
    130       0.01303      0.14884      0.00174      0.04435      1.00000 |           *
    140       0.01148      0.15025      0.00174      0.04609      1.00000 |           *
    150       0.01002      0.15199      0.00087      0.04609      1.00000 |           *
    160       0.00843      0.15260      0.00087      0.04609      1.00000 |           *
    170       0.00752      0.15393      0.00087      0.04609      1.00000 |           *
    180       0.00611      0.15584      0.00087      0.04696      1.00000 |           *
    190       0.00558      0.15847      0.00087      0.04435      1.00000 |            *
    200       0.00489      0.15986      0.00087      0.04609      1.00000 |            *
    210       0.00438      0.16032      0.00087      0.04348      1.00000 |            *
    220       0.00400      0.16383      0.00087      0.04522      1.00000 |            *
    230       0.00361      0.16709      0.00087      0.04435      1.00000 |            *
    240       0.00334      0.16883      0.00087      0.04435      1.00000 |            *
    250       0.00309      0.17020      0.00087      0.04348      1.00000 |             *
    260       0.00284      0.17246      0.00087      0.04261      1.00000 |             *
    270       0.00250      0.17431      0.00087      0.04174      1.00000 |             *
    280       0.00237      0.17888      0.00087      0.04174      1.00000 |             *
    290       0.00218      0.18040      0.00087      0.04435      1.00000 |             *
    300       0.00206      0.18372      0.00087      0.04348      1.00000 |              *
    310       0.00189      0.18637      0.00087      0.04000      1.00000 |              *
    320       0.00181      0.18850      0.00087      0.04174      1.00000 |              *
    330       0.00172      0.19233      0.00087      0.04174      1.00000 |              *
    340       0.00164      0.19593      0.00087      0.04261      1.00000 |               *
    350       0.00158      0.20008      0.00087      0.04000      1.00000 |               *
    360       0.00152      0.20176      0.00087      0.04087      1.00000 |               *
    370       0.00147      0.20575      0.00087      0.04174      1.00000 |               *
    380       0.00143      0.20976      0.00087      0.04174      1.00000 |                *
    390       0.00140      0.21271      0.00087      0.04087      1.00000 |                *
    400       0.00137      0.21629      0.00087      0.04174      1.00000 |                *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    384      1    400      1      7      4.19      3.66  CAPITAL_RUN_LENGTH_AVERAGE
    379      1    400      2      7      4.66      3.16  CAPITAL_RUN_LENGTH_TOTAL
    376      1    400      1      7      4.61      3.18  WORD_FREQ_YOU
    357      1    400      1      7      4.22      3.37  CHAR_FREQ_EXCLAMATION
    335      1    400      1      7      4.74      2.73  WORD_FREQ_YOUR
    334      3    400      1      7      4.89      2.60  CHAR_FREQ_BRACKET
    328      1    400      1      7      4.75      2.67  CAPITAL_RUN_LENGTH_LONGEST
    311      1    400      2      7      4.48      2.74  WORD_FREQ_FREE
    294      1    400      2      7      5.09      2.14  WORD_FREQ_OUR
    291      1    397      1      7      4.33      2.67  WORD_FREQ_HP
    280      2    397      2      7      5.23      1.94  WORD_FREQ_WILL
    264      1    400      1      7      4.34      2.41  CHAR_FREQ_DOLLAR
    256      1    400      1      7      4.41      2.30  WORD_FREQ_EDU
    243      1    399      1      7      5.17      1.72  WORD_FREQ_RE
    232      2    400      1      7      5.51      1.45  WORD_FREQ_ALL
    196      2    400      1      7      5.49      1.23  WORD_FREQ_MAIL
    190      5    400      1      7      4.81      1.52  WORD_FREQ_MAKE
    183      1    400      1      7      4.85      1.44  WORD_FREQ_REMOVE
    176      1    400      1      7      3.93      1.79  WORD_FREQ_MONEY
    163      1    396      1      7      3.88      1.68  WORD_FREQ_GEORGE
    160      3    393      2      7      5.45      1.02  WORD_FREQ_EMAIL
    155      1    393      1      7      4.94      1.19  WORD_FREQ_INTERNET
    154      2    398      1      7      4.21      1.46  WORD_FREQ_OVER
    152      3    398      1      7      4.76      1.23  WORD_FREQ_ADDRESS
    138      1    399      1      7      4.81      1.10  CHAR_FREQ_SEMICOLON
    137      1    400      2      7      5.23      0.95  WORD_FREQ_1999
    129      3    399      1      7      4.92      0.99  WORD_FREQ_RECEIVE
    128      1    393      1      7      3.91      1.31  WORD_FREQ_MEETING
    123      1    396      1      7      5.28      0.84  WORD_FREQ_BUSINESS
    121     15    397      1      7      3.75      1.29  WORD_FREQ_CREDIT
    114      1    399      1      7      5.22      0.79  WORD_FREQ_ORDER
    108      9    384      1      7      5.22      0.75  WORD_FREQ_HPL
    108      5    393      3      7      5.28      0.74  WORD_FREQ_TECHNOLOGY
    105      2    400      1      7      4.45      0.93  CHAR_FREQ_HASH
    103      2    399      2      7      5.09      0.75  WORD_FREQ_REPORT
    103      4    397      1      7      4.67      0.86  WORD_FREQ_DATA
    100     14    393      2      7      4.33      0.92  WORD_FREQ_650
     98      6    385      1      7      4.02      0.98  WORD_FREQ_000
     97      1    399      1      7      4.59      0.83  WORD_FREQ_85
     90     10    398      1      7      4.06      0.89  WORD_FREQ_PROJECT
     89     32    398      1      7      4.57      0.76  WORD_FREQ_ORIGINAL
     77      3    400      4      7      6.17      0.35  WORD_FREQ_PEOPLE
     73      5    375      1      7      4.95      0.56  WORD_FREQ_LABS
     68     25    386      3      7      5.04      0.50  WORD_FREQ_ADDRESSES
     64      3    385      1      7      4.52      0.56  WORD_FREQ_PM
     55      6    393      2      7      5.24      0.38  CHAR_FREQ_BOXBRACKET
     54     36    400      1      7      4.37      0.49  WORD_FREQ_DIRECT
     51     44    397      1      7      3.80      0.54  WORD_FREQ_LAB
     49     11    375      1      7      3.90      0.50  WORD_FREQ_CONFERENCE
     33     17    398      1      7      3.55      0.37  WORD_FREQ_TELNET
     30      1    314      2      7      4.17      0.29  WORD_FREQ_FONT
     15     29    362      1      7      4.67      0.13  WORD_FREQ_CS
     14     19    272      6      7      6.71      0.05  WORD_FREQ_857
      9     12    245      1      7      3.89      0.09  WORD_FREQ_3D
      5     17     29      5      6      5.20      0.04  WORD_FREQ_415
      1    247    247      7      7      7.00      0.00  WORD_FREQ_TABLE
      0      0      0      0      0      0.00      0.00  WORD_FREQ_PARTS

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    20 terminal nodes
    Largest :    76 terminal nodes
    Average :     42.73500 terminal nodes

 Reconciling 2301 Learn sample scores across 5 selected models,
 the largest having 384 trees, to compute gains and PS tables.

 Reconciling 1150 Test sample scores across 5 selected models,
 the largest having 384 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 77

 Target: SPAM_OR_NOTSPAM
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     2301      2301.00
 N Test  Obs:     1150      1150.00
 Learn Rate :    0.1000000

 Storage requirements: 33788 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           77      0.14300
                  ROC          268      0.98631
                 Lift           17      2.53863
              KS-stat          210      0.93411
          Class.Error          384      0.03913

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.59232     0.60030     0.97168     0.91617     2.53639     2.33924     0.88734     0.81082     0.39418     0.39391
      3     0.47566     0.49707     0.98546     0.95138     2.53693     2.48231     0.91822     0.82948     0.06215     0.10348
     10     0.26038     0.31325     0.99185     0.96516     2.53693     2.47241     0.92986     0.84813     0.03129     0.06957
     17     0.16483     0.23750     0.99518     0.97349     2.53693     2.53863     0.94558     0.85652     0.02564     0.06348
     20     0.13855     0.21447     0.99607     0.97558     2.53693     2.53863     0.94981     0.86910     0.02303     0.06087
     30     0.08892     0.17205     0.99792     0.98021     2.53693     2.53863     0.96791     0.90277     0.01912     0.05913
     40     0.06330     0.15419     0.99897     0.98184     2.53693     2.51656     0.97701     0.90861     0.01434     0.05391
     50     0.05164     0.14738     0.99931     0.98281     2.53693     2.51656     0.98219     0.91248     0.01130     0.05304
     60     0.04046     0.14558     0.99974     0.98313     2.53693     2.51656     0.98654     0.91468     0.00826     0.04957
     70     0.03449     0.14390     0.99985     0.98358     2.53693     2.53863     0.98941     0.91689     0.00652     0.04522
     77     0.03085     0.14300     0.99990     0.98385     2.53693     2.53863     0.99052     0.91932     0.00608     0.04348
     80     0.02945     0.14345     0.99992     0.98394     2.53693     2.53863     0.99085     0.92075     0.00565     0.04522
     90     0.02428     0.14440     0.99998     0.98414     2.53693     2.53863     0.99531     0.92153     0.00391     0.04348
    100     0.02067     0.14493     0.99999     0.98445     2.53693     2.53863     0.99675     0.91987     0.00348     0.04261
    110     0.01843     0.14727     0.99999     0.98440     2.53693     2.53863     0.99746     0.92075     0.00348     0.04522
    118     0.01621     0.14841     0.99999     0.98449     2.53693     2.53863     0.99857     0.92307     0.00174     0.04435
    120     0.01587     0.14868     0.99999     0.98450     2.53693     2.53863     0.99857     0.92164     0.00174     0.04435
    130     0.01303     0.14884     1.00000     0.98483     2.53693     2.53863     0.99857     0.92451     0.00174     0.04435
    140     0.01148     0.15025     1.00000     0.98511     2.53693     2.53863     0.99857     0.92451     0.00174     0.04609
    146     0.01057     0.15126     1.00000     0.98511     2.53693     2.53863     0.99857     0.92594     0.00087     0.04696
    147     0.01019     0.15142     1.00000     0.98508     2.53693     2.53863     0.99857     0.92451     0.00087     0.04609
    150     0.01002     0.15199     1.00000     0.98510     2.53693     2.53863     0.99857     0.92451     0.00087     0.04609
    160     0.00843     0.15260     1.00000     0.98528     2.53693     2.53863     0.99857     0.92539     0.00087     0.04609
    170     0.00752     0.15393     1.00000     0.98545     2.53693     2.53863     0.99857     0.92683     0.00087     0.04609
    180     0.00611     0.15584     1.00000     0.98574     2.53693     2.53863     0.99857     0.92970     0.00087     0.04696
    190     0.00558     0.15847     1.00000     0.98581     2.53693     2.53863     0.99857     0.93047     0.00087     0.04435
    200     0.00489     0.15986     1.00000     0.98588     2.53693     2.53863     0.99857     0.93190     0.00087     0.04609
    210     0.00438     0.16032     1.00000     0.98616     2.53693     2.53863     0.99857     0.93411     0.00087     0.04348
    220     0.00400     0.16383     1.00000     0.98603     2.53693     2.53863     0.99857     0.93411     0.00087     0.04522
    230     0.00361     0.16709     1.00000     0.98608     2.53693     2.53863     0.99857     0.93411     0.00087     0.04435
    240     0.00334     0.16883     1.00000     0.98617     2.53693     2.53863     0.99857     0.93411     0.00087     0.04435
    250     0.00309     0.17020     1.00000     0.98616     2.53693     2.51656     0.99857     0.93268     0.00087     0.04348
    260     0.00284     0.17246     1.00000     0.98612     2.53693     2.51656     0.99857     0.93268     0.00087     0.04261
    268     0.00254     0.17311     1.00000     0.98631     2.53693     2.51656     0.99857     0.93268     0.00087     0.04174
    270     0.00250     0.17431     1.00000     0.98630     2.53693     2.51656     0.99857     0.93268     0.00087     0.04174
    280     0.00237     0.17888     1.00000     0.98610     2.53693     2.51656     0.99857     0.93268     0.00087     0.04174
    290     0.00218     0.18040     1.00000     0.98624     2.53693     2.51656     0.99857     0.93268     0.00087     0.04435
    300     0.00206     0.18372     1.00000     0.98615     2.53693     2.51656     0.99857     0.92981     0.00087     0.04348
    310     0.00189     0.18637     1.00000     0.98615     2.53693     2.51656     0.99857     0.92903     0.00087     0.04000
    320     0.00181     0.18850     1.00000     0.98620     2.53693     2.53863     0.99857     0.92760     0.00087     0.04174
    330     0.00172     0.19233     1.00000     0.98608     2.53693     2.53863     0.99857     0.92760     0.00087     0.04174
    340     0.00164     0.19593     1.00000     0.98600     2.53693     2.53863     0.99857     0.92749     0.00087     0.04261
    350     0.00158     0.20008     1.00000     0.98590     2.53693     2.51656     0.99857     0.92683     0.00087     0.04000
    360     0.00152     0.20176     1.00000     0.98600     2.53693     2.53863     0.99857     0.92815     0.00087     0.04087
    370     0.00147     0.20575     1.00000     0.98593     2.53693     2.53863     0.99857     0.92749     0.00087     0.04174
    380     0.00143     0.20976     1.00000     0.98592     2.53693     2.51656     0.99857     0.93113     0.00087     0.04174
    384     0.00142     0.21124     1.00000     0.98587     2.53693     2.51656     0.99857     0.93113     0.00087     0.03913
    390     0.00140     0.21271     1.00000     0.98595     2.53693     2.53863     0.99857     0.93113     0.00087     0.04087
    400     0.00137     0.21629     1.00000     0.98580     2.53693     2.53863     0.99857     0.92970     0.00087     0.04174


 =========================================
 Variable Importance for the 77-tree Model
 =========================================

                                     Abs     Rel

 CHAR_FREQ_DOLLAR              100.00000  100.00 |***********|
 CHAR_FREQ_EXCLAMATION          79.27976   79.28 |*********  |
 WORD_FREQ_REMOVE               69.19485   69.19 |********   |
 WORD_FREQ_HP                   52.09794   52.10 |******     |
 CAPITAL_RUN_LENGTH_AVERAGE     46.24156   46.24 |******     |
 WORD_FREQ_FREE                 42.51006   42.51 |*****      |
 WORD_FREQ_YOUR                 42.35919   42.36 |*****      |
 WORD_FREQ_GEORGE               36.93447   36.93 |*****      |
 WORD_FREQ_EDU                  35.59521   35.60 |*****      |
 CAPITAL_RUN_LENGTH_TOTAL       33.75925   33.76 |****       |
 WORD_FREQ_OUR                  27.45073   27.45 |****       |
 CAPITAL_RUN_LENGTH_LONGEST     26.18618   26.19 |****       |
 WORD_FREQ_MEETING              23.97113   23.97 |***        |
 WORD_FREQ_RE                   20.82125   20.82 |***        |
 WORD_FREQ_MONEY                20.70608   20.71 |***        |
 WORD_FREQ_YOU                  20.19076   20.19 |***        |
 WORD_FREQ_INTERNET             17.54712   17.55 |***        |
 CHAR_FREQ_BRACKET              16.72570   16.73 |***        |
 WORD_FREQ_RECEIVE              16.20462   16.20 |***        |
 WORD_FREQ_1999                 14.40350   14.40 |**         |
 WORD_FREQ_WILL                 14.34796   14.35 |**         |
 WORD_FREQ_HPL                  14.04378   14.04 |**         |
 WORD_FREQ_650                  13.67620   13.68 |**         |
 WORD_FREQ_BUSINESS             13.27869   13.28 |**         |
 WORD_FREQ_PM                   12.95232   12.95 |**         |
 CHAR_FREQ_SEMICOLON            12.65743   12.66 |**         |
 WORD_FREQ_ALL                  11.85362   11.85 |**         |
 WORD_FREQ_TECHNOLOGY           11.82123   11.82 |**         |
 WORD_FREQ_000                  11.48863   11.49 |**         |
 WORD_FREQ_MAIL                 11.29848   11.30 |**         |
 WORD_FREQ_85                   11.09972   11.10 |**         |
 WORD_FREQ_OVER                 10.74842   10.75 |**         |
 WORD_FREQ_ADDRESS               9.82029    9.82 |**         |
 WORD_FREQ_CREDIT                9.78715    9.79 |**         |
 WORD_FREQ_REPORT                9.63846    9.64 |**         |
 WORD_FREQ_EMAIL                 9.11108    9.11 |**         |
 WORD_FREQ_ORDER                 8.90214    8.90 |**         |
 WORD_FREQ_FONT                  8.65094    8.65 |**         |
 WORD_FREQ_PEOPLE                7.47672    7.48 |**         |
 WORD_FREQ_MAKE                  7.05849    7.06 |**         |
 WORD_FREQ_PROJECT               6.17144    6.17 |**         |
 WORD_FREQ_CONFERENCE            6.16315    6.16 |**         |
 WORD_FREQ_LAB                   5.75196    5.75 |**         |
 WORD_FREQ_LABS                  4.69285    4.69 |*          |
 WORD_FREQ_ORIGINAL              4.33716    4.34 |*          |
 CHAR_FREQ_HASH                  3.65481    3.65 |*          |
 WORD_FREQ_3D                    3.59211    3.59 |*          |
 CHAR_FREQ_BOXBRACKET            3.51623    3.52 |*          |
 WORD_FREQ_DATA                  3.41964    3.42 |*          |
 WORD_FREQ_DIRECT                3.37263    3.37 |*          |
 WORD_FREQ_ADDRESSES             2.02631    2.03 |*          |
 WORD_FREQ_TELNET                1.87659    1.88 |*          |
 WORD_FREQ_CS                    1.32899    1.33 |*          |
 WORD_FREQ_415                   0.08597    0.09 |*          |
 WORD_FREQ_857                   0.03597    0.04 |*          |


 Learn Sample Misclassification by Target Class
 For The 77-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1394.00      1393.00         1.00       0.0007
 1                  907.00       894.00        13.00       0.0143


 Test Sample Misclassification by Target Class
 For The 77-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  697.00       677.00        20.00       0.0287
 1                  453.00       423.00        30.00       0.0662

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2x_model.grv: 1.5 MB, 75% compression

 Grove file created containing:
      1 TreeNet

