
 The "USE "../Data/Classification/Adult/SAMPLES4/data_tr" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 14 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 24422
 Records Kept in Learning sample: 24422

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 12210
 Records Kept in Test sample: 12210


 ======================================================
 Train/Test Levels Differences in Categorical Variables
 ======================================================


 A discrete variable was discovered that has one or more
 levels not encountered in all data partitions. All levels not
 seen in the training data are mapped to "missing" in test,
 holdout, or any future data to which the model is applied.
 ----------------------------------------------------------------
 NATIVE_COUNTRY$  Test  "Holand-Netherlands"

     Discrete         N Levels
     Variable         in Model
 -----------------------------
 WORKCLASS$                  8
 EDUCATION$                 16
 MARITAL_STATUS$             7
 OCCUPATION$                14
 RELATIONSHIP$               6
 RACE$                       5
 SEX$                        2
 NATIVE_COUNTRY$            41
 CLASS                       2



 ===================
 Cardinality Summary
 ===================

      N  Variable
 ----------------
     41  NATIVE_COUNTRY$
     16  EDUCATION$
     14  OCCUPATION$
      8  WORKCLASS$
      7  MARITAL_STATUS$
      6  RELATIONSHIP$
      5  RACE$
 ----------------

 EXCLUDE NATIVE_COUNTRY$, EDUCATION$, OCCUPATION$, WORKCLASS$, MARITAL_STATUS$, RELATIONSHIP$, RACE$
 Use the above EXCLUDE command to exclude high level categorical variables.

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L        18578  76.07             18578.00  76.07
                 T        (9289  76.08)            (9289.00  76.08)
 1               L         5844  23.93              5844.00  23.93
                 T        (2921  23.92)            (2921.00  23.92)
 -----------------------------------------------------------------
 Totals
 0                        27867  76.07             27867.00  76.07
 1                         8765  23.93              8765.00  23.93
 -----------------------------------------------------------------
 Total                    36632                    36632.00
 Total Learn              24422                    24422.00
 Total Test               12210                    12210.00


 ========================
 Missing Value Prevalence
 ========================

                   Learn
 -----------------------
 OCCUPATION$      0.0585
 WORKCLASS$       0.0582
 NATIVE_COUNTRY$  0.0174

                    Test
 -----------------------
 OCCUPATION$      0.0558
 WORKCLASS$       0.0556
 NATIVE_COUNTRY$  0.0177


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.50558      0.50683      0.23929      0.23923      1.00000 |                                               *
      2       0.47231      0.47480      0.23929      0.23923      1.00000 |                                            *
      3       0.44554      0.44876      0.23929      0.23923      1.00000 |                                          *
      4       0.42328      0.42721      0.18864      0.18690      1.00000 |                                       *
      5       0.40441      0.40970      0.18299      0.18239      1.00000 |                                      *
      6       0.38867      0.39457      0.18012      0.17903      1.00000 |                                    *
      7       0.37496      0.38157      0.14843      0.15225      1.00000 |                                   *
      8       0.36322      0.37041      0.14643      0.15037      1.00000 |                                  *
      9       0.35295      0.36071      0.13942      0.14390      1.00000 |                                 *
     10       0.34375      0.35222      0.13836      0.14373      1.00000 |                                *
     11       0.33584      0.34526      0.13611      0.14185      1.00000 |                                *
     12       0.32858      0.33865      0.13381      0.14087      1.00000 |                               *
     13       0.32220      0.33279      0.13287      0.13997      1.00000 |                               *
     14       0.31629      0.32774      0.13209      0.13907      1.00000 |                              *
     15       0.31095      0.32310      0.13119      0.13825      1.00000 |                              *
     16       0.30632      0.31911      0.12919      0.13702      1.00000 |                             *
     17       0.30182      0.31543      0.12882      0.13645      1.00000 |                             *
     18       0.29811      0.31227      0.12796      0.13620      1.00000 |                             *
     19       0.29457      0.30939      0.12751      0.13571      1.00000 |                            *
     20       0.29137      0.30708      0.12693      0.13554      1.00000 |                            *
     30       0.27001      0.29244      0.12276      0.13186      1.00000 |                           *
     40       0.25491      0.28402      0.11748      0.12916      1.00000 |                          *
     50       0.24381      0.28024      0.11170      0.12760      1.00000 |                          *
     60       0.23491      0.27885      0.10683      0.12760      1.00000 |                         *
     70       0.22832      0.27755      0.10417      0.12719      1.00000 |                         *
     80       0.22223      0.27733      0.10179      0.12711      1.00000 |                         *
     90       0.21683      0.27694      0.09868      0.12776      1.00000 |                         *
    100       0.21314      0.27711      0.09659      0.12760      1.00000 |                         *
    110       0.20785      0.27785      0.09344      0.12752      1.00000 |                         *
    120       0.20086      0.27870      0.08898      0.12670      1.00000 |                         *
    130       0.19681      0.27936      0.08632      0.12654      1.00000 |                         *
    140       0.19351      0.27976      0.08517      0.12645      1.00000 |                         *
    150       0.18961      0.28038      0.08267      0.12662      1.00000 |                          *
    160       0.18569      0.28077      0.08001      0.12621      1.00000 |                          *
    170       0.18027      0.28189      0.07682      0.12785      1.00000 |                          *
    180       0.17753      0.28227      0.07555      0.12834      1.00000 |                          *
    190       0.17335      0.28319      0.07309      0.12826      1.00000 |                          *
    200       0.17049      0.28383      0.07112      0.12883      1.00000 |                          *
    210       0.16730      0.28517      0.06875      0.12924      1.00000 |                          *
    220       0.16258      0.28614      0.06478      0.13014      1.00000 |                          *
    230       0.16005      0.28718      0.06347      0.13104      1.00000 |                          *
    240       0.15710      0.28823      0.06138      0.13071      1.00000 |                          *
    250       0.15291      0.28995      0.05892      0.13194      1.00000 |                          *
    260       0.15138      0.29050      0.05802      0.13161      1.00000 |                           *
    270       0.14963      0.29130      0.05708      0.13178      1.00000 |                           *
    280       0.14653      0.29209      0.05491      0.13227      1.00000 |                           *
    290       0.14408      0.29290      0.05360      0.13170      1.00000 |                           *
    300       0.14267      0.29387      0.05282      0.13194      1.00000 |                           *
    310       0.13965      0.29542      0.05122      0.13284      1.00000 |                           *
    320       0.13753      0.29616      0.04979      0.13333      1.00000 |                           *
    330       0.13386      0.29787      0.04738      0.13415      1.00000 |                           *
    340       0.13238      0.29855      0.04660      0.13382      1.00000 |                           *
    350       0.13046      0.29987      0.04521      0.13415      1.00000 |                           *
    360       0.12648      0.30140      0.04152      0.13481      1.00000 |                            *
    370       0.12421      0.30231      0.04074      0.13407      1.00000 |                            *
    380       0.12197      0.30298      0.03874      0.13358      1.00000 |                            *
    390       0.12048      0.30376      0.03755      0.13325      1.00000 |                            *
    400       0.11829      0.30498      0.03628      0.13317      1.00000 |                            *

 Core TN model building:          8.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      6      3.32      4.68  OCCUPATION$
    398      1    400      1      7      4.07      3.92  WORKCLASS$
    397      1    400      1      7      4.05      3.92  MARITAL_STATUS$
    396      1    400      1      7      3.67      4.29  EDUCATION$
    395      1    400      1      7      3.11      4.83  FNLWGT
    394      1    400      1      7      3.21      4.72  AGE
    390      1    400      1      7      4.28      3.62  RELATIONSHIP$
    380      1    400      1      7      3.91      3.89  HOURS_PER_WEEK
    325      1    399      1      7      4.90      2.52  EDUCATION_NUM
    315      1    399      1      7      5.30      2.13  RACE$
    245      1    400      1      7      4.05      2.42  CAPITAL_GAIN
    222      3    399      2      7      5.74      1.25  SEX$
    214      1    399      1      7      4.64      1.80  NATIVE_COUNTRY$
    198      1    395      1      7      4.25      1.86  CAPITAL_LOSS

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    26 terminal nodes
    Largest :   121 terminal nodes
    Average :     79.81000 terminal nodes

 Reconciling 24422 Learn sample scores across 5 selected models,
 the largest having 181 trees, to compute gains and PS tables.

 Reconciling 12210 Test sample scores across 5 selected models,
 the largest having 181 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 91

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:    24422     24422.00
 N Test  Obs:    12210     12210.00
 Learn Rate :    0.1000000

 Storage requirements: 63448 tree / 54487 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           91      0.27689
                  ROC           91      0.92765
                 Lift          181      3.95070
              KS-stat           54      0.68620
          Class.Error          128      0.12604

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.50558     0.50683     0.90985     0.89908     3.71042     3.62326     0.64560     0.62245     0.23929     0.23923
     10     0.34375     0.35222     0.92782     0.91682     3.86668     3.83086     0.69047     0.66643     0.13836     0.14373
     20     0.29137     0.30708     0.93435     0.91993     3.91461     3.88440     0.70422     0.66836     0.12693     0.13554
     30     0.27001     0.29244     0.93967     0.92213     3.95825     3.88737     0.71956     0.67178     0.12276     0.13186
     40     0.25491     0.28402     0.94588     0.92520     3.97736     3.88908     0.73676     0.68024     0.11748     0.12916
     50     0.24381     0.28024     0.95048     0.92643     4.00103     3.90277     0.75189     0.68579     0.11170     0.12760
     54     0.23952     0.27969     0.95244     0.92655     4.01859     3.90277     0.75690     0.68620     0.10920     0.12867
     60     0.23491     0.27885     0.95435     0.92680     4.03450     3.90620     0.76191     0.68355     0.10683     0.12760
     70     0.22832     0.27755     0.95712     0.92737     4.05236     3.90962     0.77018     0.68505     0.10417     0.12719
     80     0.22223     0.27733     0.95963     0.92747     4.07803     3.89935     0.77710     0.68441     0.10179     0.12711
     90     0.21683     0.27694     0.96188     0.92761     4.09343     3.93358     0.78357     0.68308     0.09868     0.12776
     91     0.21659     0.27689     0.96193     0.92765     4.09343     3.94043     0.78368     0.68289     0.09864     0.12776
    100     0.21314     0.27711     0.96335     0.92753     4.10164     3.93701     0.78824     0.68344     0.09659     0.12760
    110     0.20785     0.27785     0.96566     0.92732     4.11567     3.92674     0.79649     0.68225     0.09344     0.12752
    120     0.20086     0.27870     0.96888     0.92702     4.13792     3.92331     0.80812     0.67975     0.08898     0.12670
    128     0.19775     0.27916     0.97017     0.92689     4.14305     3.92331     0.81386     0.67827     0.08713     0.12604
    130     0.19681     0.27936     0.97060     0.92680     4.14476     3.91989     0.81531     0.67825     0.08632     0.12654
    140     0.19351     0.27976     0.97194     0.92674     4.14476     3.92331     0.82055     0.67880     0.08517     0.12645
    150     0.18961     0.28038     0.97349     0.92656     4.14990     3.92674     0.82589     0.67816     0.08267     0.12662
    160     0.18569     0.28077     0.97502     0.92654     4.15674     3.93358     0.83331     0.67909     0.08001     0.12621
    170     0.18027     0.28189     0.97727     0.92619     4.17043     3.93701     0.84018     0.67805     0.07682     0.12785
    180     0.17753     0.28227     0.97814     0.92616     4.17214     3.94728     0.84286     0.67785     0.07555     0.12834
    181     0.17712     0.28222     0.97831     0.92620     4.17214     3.95070     0.84365     0.67768     0.07546     0.12826
    190     0.17335     0.28319     0.97971     0.92588     4.17385     3.93358     0.84843     0.67529     0.07309     0.12826
    200     0.17049     0.28383     0.98070     0.92576     4.17556     3.94385     0.85301     0.67566     0.07112     0.12883
    210     0.16730     0.28517     0.98176     0.92532     4.17556     3.93701     0.85704     0.67484     0.06875     0.12924
    218     0.16368     0.28596     0.98299     0.92514     4.17899     3.93016     0.86251     0.67380     0.06551     0.12989
    220     0.16258     0.28614     0.98340     0.92511     4.17899     3.92674     0.86490     0.67387     0.06478     0.13014
    230     0.16005     0.28718     0.98412     0.92479     4.17899     3.92331     0.86851     0.67385     0.06347     0.13104
    240     0.15710     0.28823     0.98505     0.92456     4.17899     3.91989     0.87160     0.67430     0.06138     0.13071
    250     0.15291     0.28995     0.98636     0.92400     4.17899     3.92674     0.87873     0.67267     0.05892     0.13194
    260     0.15138     0.29050     0.98674     0.92392     4.17899     3.92331     0.88079     0.67161     0.05802     0.13161
    270     0.14963     0.29130     0.98714     0.92380     4.17899     3.92331     0.88371     0.67176     0.05708     0.13178
    280     0.14653     0.29209     0.98808     0.92360     4.17899     3.93016     0.88800     0.67263     0.05491     0.13227
    290     0.14408     0.29290     0.98874     0.92346     4.17899     3.93016     0.89196     0.67190     0.05360     0.13170
    300     0.14267     0.29387     0.98905     0.92326     4.17899     3.91989     0.89387     0.67221     0.05282     0.13194
    310     0.13965     0.29542     0.98981     0.92281     4.17899     3.92674     0.89909     0.66918     0.05122     0.13284
    320     0.13753     0.29616     0.99036     0.92265     4.17899     3.92331     0.90212     0.66865     0.04979     0.13333
    330     0.13386     0.29787     0.99125     0.92222     4.17899     3.92674     0.90774     0.66716     0.04738     0.13415
    340     0.13238     0.29855     0.99153     0.92214     4.17899     3.91989     0.90912     0.66786     0.04660     0.13382
    350     0.13046     0.29987     0.99189     0.92188     4.17899     3.91989     0.91065     0.66667     0.04521     0.13415
    360     0.12648     0.30140     0.99284     0.92159     4.17899     3.91304     0.91700     0.66674     0.04152     0.13481
    370     0.12421     0.30231     0.99324     0.92147     4.17899     3.91304     0.91965     0.66539     0.04074     0.13407
    380     0.12197     0.30298     0.99370     0.92143     4.17899     3.91304     0.92262     0.66713     0.03874     0.13358
    390     0.12048     0.30376     0.99396     0.92136     4.17899     3.90620     0.92402     0.66628     0.03755     0.13325
    399     0.11836     0.30491     0.99433     0.92117     4.17899     3.90620     0.92706     0.66553     0.03624     0.13317
    400     0.11829     0.30498     0.99434     0.92116     4.17899     3.90620     0.92733     0.66560     0.03628     0.13317


 =========================================
 Variable Importance for the 91-tree Model
 =========================================

                          Abs     Rel

 RELATIONSHIP$      100.00000  100.00 |***********|
 CAPITAL_GAIN        75.62043   75.62 |*********  |
 EDUCATION_NUM       64.79439   64.79 |*******    |
 OCCUPATION$         53.21093   53.21 |******     |
 AGE                 49.78405   49.78 |******     |
 MARITAL_STATUS$     48.46094   48.46 |******     |
 CAPITAL_LOSS        41.80450   41.80 |*****      |
 HOURS_PER_WEEK      36.35936   36.36 |*****      |
 FNLWGT              32.59751   32.60 |****       |
 EDUCATION$          29.32508   29.33 |****       |
 WORKCLASS$          25.75686   25.76 |****       |
 RACE$               14.71488   14.71 |**         |
 NATIVE_COUNTRY$     12.79925   12.80 |**         |
 SEX$                11.24773   11.25 |**         |


 Learn Sample Misclassification by Target Class
 For The 91-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                18578.00     17776.00       802.00       0.0432
 1                 5844.00      4237.00      1607.00       0.2750


 Test Sample Misclassification by Target Class
 For The 91-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 9289.00      8749.00       540.00       0.0581
 1                 2921.00      1901.00      1020.00       0.3492

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                9.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               8.000 sec ( 0.00 hrs,  88.89%)
    Core model:         8.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  11.11%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 3.1 MB, 78% compression

 Grove file created containing:
      1 TreeNet

