
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 15 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172


 ======================================================
 Train/Test Levels Differences in Categorical Variables
 ======================================================


 Discrete variables were discovered that have one or more
 levels not encountered in all data partitions. All levels not
 seen in the training data are mapped to "missing" in test,
 holdout, or any future data to which the model is applied.
 ----------------------------------------------------------------
 A4$  Test  "l"
 A5$  Test  "gg"
 A7$  Test  "o"

 Discrete         N Levels
 Variable         in Model
 -------------------------
 A1$                     2
 A4$                     3
 A5$                     3
 A6$                    14
 A7$                     9
 A9$                     2
 A10$                    2
 A12$                    2
 A13$                    3
 CLASS                   2



 ===================
 Cardinality Summary
 ===================

      N  Variable
 ----------------
     14  A6$
      9  A7$
      3  A5$
      3  A13$
      3  A4$
 ----------------

 EXCLUDE A6$, A7$, A5$, A13$, A4$
 Use the above EXCLUDE command to exclude high level categorical variables.

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A14       0.0231
 A2        0.0202
 A6$       0.0145
 A7$       0.0145
 A1$       0.0145
 A4$       0.0087
 A5$       0.0087

             Test
 ----------------
 A1$       0.0349
 A14       0.0233
 A6$       0.0174
 A2        0.0174
 A7$       0.0174
 A4$       0.0116
 A5$       0.0116


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.60261      0.63140      0.09249      0.20930      1.00000 |                                               *
      2       0.53292      0.58724      0.04046      0.17442      1.00000 |                                            *
      3       0.47327      0.55089      0.02023      0.18605      1.00000 |                                         *
      4       0.42431      0.52725      0.02023      0.18605      1.00000 |                                       *
      5       0.38195      0.50547      0.02023      0.18605      1.00000 |                                     *
      6       0.34498      0.48758      0.01734      0.16860      1.00000 |                                    *
      7       0.31214      0.47350      0.01734      0.18023      1.00000 |                                   *
      8       0.28262      0.45944      0.01445      0.18023      1.00000 |                                  *
      9       0.25631      0.45017      0.01445      0.18605      1.00000 |                                 *
     10       0.23203      0.43703      0.01734      0.17442      1.00000 |                                *
     11       0.21126      0.43059      0.01156      0.18023      1.00000 |                                *
     12       0.19302      0.42587      0.00578      0.19186      1.00000 |                               *
     13       0.17613      0.42136      0.00578      0.19186      1.00000 |                               *
     14       0.16047      0.42101      0.00578      0.18605      1.00000 |                               *
     15       0.14653      0.41883      0.00289      0.18023      1.00000 |                               *
     16       0.13409      0.41524      0.00289      0.17442      1.00000 |                               *
     17       0.12323      0.41260      0.00289      0.19186      1.00000 |                              *
     18       0.11385      0.41106      0.00289      0.19186      1.00000 |                              *
     19       0.10461      0.41445      0.00289      0.18023      1.00000 |                               *
     20       0.09630      0.41660      0.00289      0.18605      1.00000 |                               *
     30       0.04264      0.46679      0.00000      0.17442      1.00000 |                                  *
     40       0.01925      0.52396      0.00000      0.17442      1.00000 |                                       *
     50       0.00954      0.58689      0.00000      0.18023      1.00000 |                                            *
     60       0.00475      0.64395      0.00000      0.16860      1.00000 |                                               *
     70       0.00249      0.68686      0.00000      0.16279      1.00000 |                                               *
     80       0.00123      0.73565      0.00000      0.15698      1.00000 |                                               *
     90       0.00065      0.77767      0.00000      0.15698      1.00000 |                                               *
    100       0.00032      0.84762      0.00000      0.15116      1.00000 |                                               *
    110       0.00016      0.91794      0.00000      0.15116      1.00000 |                                               *
    120       0.00008      0.98102      0.00000      0.15116      1.00000 |                                               *
    130       0.00004      1.04286      0.00000      0.15116      1.00000 |                                               *
    140       0.00003      1.09684      0.00000      0.15116      1.00000 |                                               *
    150       0.00001      1.15412      0.00000      0.15116      1.00000 |                                               *
    160       0.00001      1.18800      0.00000      0.15116      1.00000 |                                               *
    170       0.00000      1.22811      0.00000      0.15116      1.00000 |                                               *
    180       0.00000      1.25938      0.00000      0.15116      1.00000 |                                               *
    190       0.00000      1.30692      0.00000      0.15116      1.00000 |                                               *
    200       0.00000      1.34696      0.00000      0.14535      1.00000 |                                               *
    210       0.00000      1.39330      0.00000      0.14535      1.00000 |                                               *
    220       0.00000      1.43766      0.00000      0.14535      1.00000 |                                               *
    230       0.00000      1.47229      0.00000      0.14535      1.00000 |                                               *
    240       0.00000      1.51056      0.00000      0.14535      1.00000 |                                               *
    250       0.00000      1.55640      0.00000      0.14535      1.00000 |                                               *
    260       0.00000      1.60016      0.00000      0.14535      1.00000 |                                               *
    270       0.00000      1.65570      0.00000      0.15116      1.00000 |                                               *
    280       0.00000      1.71995      0.00000      0.15698      1.00000 |                                               *
    290       0.00000      1.79841      0.00000      0.15698      1.00000 |                                               *
    300       0.00000      1.89068      0.00000      0.15698      1.00000 |                                               *
    310       0.00000      1.95968      0.00000      0.15698      1.00000 |                                               *
    320       0.00000      2.01164      0.00000      0.15698      1.00000 |                                               *
    330       0.00000      2.06462      0.00000      0.15698      1.00000 |                                               *
    340       0.00000      2.11433      0.00000      0.16860      1.00000 |                                               *
    350       0.00000      2.16536      0.00000      0.15698      1.00000 |                                               *
    360       0.00000      2.19800      0.00000      0.15698      1.00000 |                                               *
    370       0.00000      2.23399      0.00000      0.15698      1.00000 |                                               *
    380       0.00000      2.28055      0.00000      0.16279      1.00000 |                                               *
    390       0.00000      2.33940      0.00000      0.15698      1.00000 |                                               *
    400       0.00000      2.39284      0.00000      0.15698      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      7      2.63      5.37  A9$
    398      1    400      1      7      2.87      5.10  A3
    397      1    400      1      7      3.76      4.21  A6$
    393      1    400      1      7      3.60      4.33  A14
    393      1    400      1      7      4.40      3.53  A7$
    391      4    400      1      7      3.29      4.60  A2
    390      1    400      1      7      4.07      3.83  A8
    370      1    400      1      7      3.81      3.88  A15
    368      1    400      2      7      4.37      3.34  A4$
    315      1    400      3      7      5.39      2.06  A1$
    315      1    399      3      7      4.78      2.54  A13$
    297      1    400      1      7      3.81      3.11  A11
    294      3    400      1      7      5.25      2.02  A10$
    284      1    400      2      7      5.30      1.92  A12$
      0      0      0      0      0      0.00      0.00  A5$

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    16 terminal nodes
    Largest :    66 terminal nodes
    Average :     42.07500 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 196 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 196 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 18

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 33260 tree / 18900 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           18      0.41106
                  ROC           74      0.91461
                 Lift           31      2.26316
              KS-stat          294      0.74287
          Class.Error          196      0.14535

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.60261     0.63140     0.99476     0.85629     2.24675     1.91142     0.91930     0.62007     0.09249     0.20930
     10     0.23203     0.43703     0.99932     0.85876     2.24675     2.10526     0.98309     0.66228     0.01734     0.17442
     17     0.12323     0.41260     1.00000     0.88069     2.24675     2.00000     1.00000     0.67818     0.00289     0.19186
     18     0.11385     0.41106     1.00000     0.88247     2.24675     2.00000     1.00000     0.68860     0.00289     0.19186
     20     0.09630     0.41660     1.00000     0.88370     2.24675     2.00000     1.00000     0.68860     0.00289     0.18605
     24     0.06928     0.43494     1.00000     0.88912     2.24675     2.13158     1.00000     0.67544     0.00000     0.17442
     30     0.04264     0.46679     1.00000     0.88816     2.24675     2.00000     1.00000     0.68366     0.00000     0.17442
     31     0.03942     0.46892     1.00000     0.89405     2.24675     2.26316     1.00000     0.68366     0.00000     0.17442
     40     0.01925     0.52396     1.00000     0.89967     2.24675     2.13158     1.00000     0.70450     0.00000     0.17442
     50     0.00954     0.58689     1.00000     0.90419     2.24675     2.26316     1.00000     0.70450     0.00000     0.18023
     60     0.00475     0.64395     1.00000     0.90776     2.24675     2.26316     1.00000     0.69408     0.00000     0.16860
     70     0.00249     0.68686     1.00000     0.91255     2.24675     2.26316     1.00000     0.69408     0.00000     0.16279
     74     0.00195     0.69826     1.00000     0.91461     2.24675     2.26316     1.00000     0.69572     0.00000     0.16279
     80     0.00123     0.73565     1.00000     0.91146     2.24675     2.26316     1.00000     0.70340     0.00000     0.15698
     90     0.00065     0.77767     1.00000     0.91091     2.24675     2.26316     1.00000     0.70450     0.00000     0.15698
    100     0.00032     0.84762     1.00000     0.90707     2.24675     2.26316     1.00000     0.70450     0.00000     0.15116
    110     0.00016     0.91794     1.00000     0.90625     2.24675     2.26316     1.00000     0.70450     0.00000     0.15116
    120     0.00008     0.98102     1.00000     0.90570     2.24675     2.26316     1.00000     0.71491     0.00000     0.15116
    130     0.00004     1.04286     1.00000     0.90748     2.24675     2.26316     1.00000     0.71162     0.00000     0.15116
    140     0.00003     1.09684     1.00000     0.90570     2.24675     2.23684     1.00000     0.71162     0.00000     0.15116
    150     0.00001     1.15412     1.00000     0.90611     2.24675     2.13158     1.00000     0.71656     0.00000     0.15116
    160     0.00001     1.18800     1.00000     0.90694     2.24675     2.13158     1.00000     0.71656     0.00000     0.15116
    170     0.00000     1.22811     1.00000     0.90872     2.24675     2.13158     1.00000     0.71656     0.00000     0.15116
    180     0.00000     1.25938     1.00000     0.91009     2.24675     2.13158     1.00000     0.71656     0.00000     0.15116
    190     0.00000     1.30692     1.00000     0.90954     2.24675     2.13158     1.00000     0.71930     0.00000     0.15116
    196     0.00000     1.32791     1.00000     0.90954     2.24675     2.13158     1.00000     0.72697     0.00000     0.14535
    200     0.00000     1.34696     1.00000     0.90927     2.24675     2.13158     1.00000     0.72971     0.00000     0.14535
    210     0.00000     1.39330     1.00000     0.90954     2.24675     2.13158     1.00000     0.72697     0.00000     0.14535
    220     0.00000     1.43766     1.00000     0.90844     2.24675     2.13158     1.00000     0.72697     0.00000     0.14535
    230     0.00000     1.47229     1.00000     0.90831     2.24675     2.13158     1.00000     0.74013     0.00000     0.14535
    240     0.00000     1.51056     1.00000     0.90803     2.24675     2.13158     1.00000     0.72697     0.00000     0.14535
    250     0.00000     1.55640     1.00000     0.90735     2.24675     2.13158     1.00000     0.72697     0.00000     0.14535
    260     0.00000     1.60016     1.00000     0.90844     2.24675     2.13158     1.00000     0.74013     0.00000     0.14535
    270     0.00000     1.65570     1.00000     0.90776     2.24675     2.13158     1.00000     0.74013     0.00000     0.15116
    280     0.00000     1.71995     1.00000     0.90735     2.24675     2.13158     1.00000     0.74013     0.00000     0.15698
    290     0.00000     1.79841     1.00000     0.90556     2.24675     2.10526     1.00000     0.74013     0.00000     0.15698
    294     0.00000     1.83417     1.00000     0.90556     2.24675     2.13158     1.00000     0.74287     0.00000     0.15698
    300     0.00000     1.89068     1.00000     0.90598     2.24675     2.13158     1.00000     0.74287     0.00000     0.15698
    310     0.00000     1.95968     1.00000     0.90680     2.24675     2.13158     1.00000     0.74287     0.00000     0.15698
    320     0.00000     2.01164     1.00000     0.90515     2.24675     2.10526     1.00000     0.73246     0.00000     0.15698
    330     0.00000     2.06462     1.00000     0.90543     2.24675     2.00000     1.00000     0.74013     0.00000     0.15698
    340     0.00000     2.11433     1.00000     0.90474     2.24675     2.00000     1.00000     0.74013     0.00000     0.16860
    350     0.00000     2.16536     1.00000     0.90406     2.24675     2.00000     1.00000     0.74013     0.00000     0.15698
    360     0.00000     2.19800     1.00000     0.90529     2.24675     2.00000     1.00000     0.74013     0.00000     0.15698
    370     0.00000     2.23399     1.00000     0.90515     2.24675     2.00000     1.00000     0.74013     0.00000     0.15698
    380     0.00000     2.28055     1.00000     0.90584     2.24675     2.00000     1.00000     0.74013     0.00000     0.16279
    390     0.00000     2.33940     1.00000     0.90570     2.24675     2.00000     1.00000     0.74013     0.00000     0.15698
    400     0.00000     2.39284     1.00000     0.90652     2.24675     2.00000     1.00000     0.74013     0.00000     0.15698


 =========================================
 Variable Importance for the 18-tree Model
 =========================================

               Abs     Rel

 A9$     100.00000  100.00 |***********|
 A4$      37.39135   37.39 |*****      |
 A6$      35.95047   35.95 |*****      |
 A11      32.92241   32.92 |****       |
 A14      32.14982   32.15 |****       |
 A15      24.70873   24.71 |***        |
 A3       23.88870   23.89 |***        |
 A7$      22.56930   22.57 |***        |
 A1$      20.90595   20.91 |***        |
 A8       19.82099   19.82 |***        |
 A10$     17.19590   17.20 |***        |
 A13$     17.19221   17.19 |***        |
 A2       16.25720   16.26 |***        |
 A12$     15.48748   15.49 |**         |


 Learn Sample Misclassification by Target Class
 For The 18-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       192.00         0.00       0.0000
 1                  154.00       153.00         1.00       0.0065


 Test Sample Misclassification by Target Class
 For The 18-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        81.00        15.00       0.1563
 1                   76.00        58.00        18.00       0.2368

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.3 MB, 80% compression

 Grove file created containing:
      1 TreeNet

