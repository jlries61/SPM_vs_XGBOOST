
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 15 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172


 ======================================================
 Train/Test Levels Differences in Categorical Variables
 ======================================================


 Discrete variables were discovered that have one or more
 levels not encountered in all data partitions. All levels not
 seen in the training data are mapped to "missing" in test,
 holdout, or any future data to which the model is applied.
 ----------------------------------------------------------------
 A6$  Test  "r"
 A7$  Test  "n", "o"

 Discrete         N Levels
 Variable         in Model
 -------------------------
 A1$                     2
 A4$                     2
 A5$                     2
 A6$                    14
 A7$                     9
 A9$                     2
 A10$                    2
 A12$                    2
 A13$                    3
 CLASS                   2



 ===================
 Cardinality Summary
 ===================

      N  Variable
 ----------------
     14  A6$
      9  A7$
      3  A13$
 ----------------

 EXCLUDE A6$, A7$, A13$
 Use the above EXCLUDE command to exclude high level categorical variables.

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A2        0.0289
 A14       0.0145
 A1$       0.0116
 A6$       0.0087
 A7$       0.0087
 A4$       0.0058
 A5$       0.0058

             Test
 ----------------
 A1$       0.0174
 A14       0.0174
 A4$       0.0174
 A5$       0.0174
 A6$       0.0174
 A7$       0.0174
 A2        0.0058


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.60410      0.63344      0.06647      0.19186      1.00000 |                                               *
      2       0.53693      0.59327      0.04335      0.20349      1.00000 |                                            *
      3       0.47963      0.56175      0.03468      0.18605      1.00000 |                                          *
      4       0.43046      0.53718      0.03468      0.18023      1.00000 |                                        *
      5       0.39072      0.51671      0.03179      0.18605      1.00000 |                                      *
      6       0.35401      0.48976      0.02890      0.19186      1.00000 |                                    *
      7       0.32141      0.47778      0.03179      0.18605      1.00000 |                                   *
      8       0.29264      0.46387      0.02890      0.18605      1.00000 |                                  *
      9       0.26897      0.45740      0.02601      0.18023      1.00000 |                                  *
     10       0.24539      0.44275      0.02023      0.17442      1.00000 |                                 *
     11       0.22437      0.43782      0.01734      0.18605      1.00000 |                                *
     12       0.20670      0.43758      0.01734      0.18605      1.00000 |                                *
     13       0.18911      0.43082      0.01734      0.18023      1.00000 |                                *
     14       0.17422      0.42725      0.01734      0.18605      1.00000 |                               *
     15       0.16027      0.42889      0.01734      0.17442      1.00000 |                               *
     16       0.14825      0.42724      0.01734      0.18023      1.00000 |                               *
     17       0.13632      0.43355      0.01445      0.19186      1.00000 |                                *
     18       0.12657      0.43140      0.01445      0.19186      1.00000 |                                *
     19       0.11685      0.42907      0.01156      0.20349      1.00000 |                                *
     20       0.10885      0.43603      0.00867      0.20349      1.00000 |                                *
     30       0.05337      0.46543      0.00000      0.20349      1.00000 |                                  *
     40       0.02735      0.51893      0.00000      0.16279      1.00000 |                                      *
     50       0.01360      0.56098      0.00000      0.15698      1.00000 |                                          *
     60       0.00644      0.62164      0.00000      0.18023      1.00000 |                                              *
     70       0.00340      0.66725      0.00000      0.17442      1.00000 |                                               *
     80       0.00183      0.72677      0.00000      0.16279      1.00000 |                                               *
     90       0.00103      0.78563      0.00000      0.16279      1.00000 |                                               *
    100       0.00062      0.81645      0.00000      0.16279      1.00000 |                                               *
    110       0.00035      0.85954      0.00000      0.16279      1.00000 |                                               *
    120       0.00019      0.91437      0.00000      0.16860      1.00000 |                                               *
    130       0.00012      0.94985      0.00000      0.16860      1.00000 |                                               *
    140       0.00007      0.99997      0.00000      0.16860      1.00000 |                                               *
    150       0.00005      1.03454      0.00000      0.16860      1.00000 |                                               *
    160       0.00003      1.06564      0.00000      0.16860      1.00000 |                                               *
    170       0.00002      1.09899      0.00000      0.16860      1.00000 |                                               *
    180       0.00001      1.12938      0.00000      0.16860      1.00000 |                                               *
    190       0.00001      1.15129      0.00000      0.16279      1.00000 |                                               *
    200       0.00000      1.19344      0.00000      0.16279      1.00000 |                                               *
    210       0.00000      1.24510      0.00000      0.16279      1.00000 |                                               *
    220       0.00000      1.33408      0.00000      0.16860      1.00000 |                                               *
    230       0.00000      1.39191      0.00000      0.17442      1.00000 |                                               *
    240       0.00000      1.44069      0.00000      0.17442      1.00000 |                                               *
    250       0.00000      1.52333      0.00000      0.18023      1.00000 |                                               *
    260       0.00000      1.57944      0.00000      0.18023      1.00000 |                                               *
    270       0.00000      1.64195      0.00000      0.17442      1.00000 |                                               *
    280       0.00000      1.71159      0.00000      0.18023      1.00000 |                                               *
    290       0.00000      1.74221      0.00000      0.17442      1.00000 |                                               *
    300       0.00000      1.80491      0.00000      0.17442      1.00000 |                                               *
    310       0.00000      1.82997      0.00000      0.17442      1.00000 |                                               *
    320       0.00000      1.86998      0.00000      0.16860      1.00000 |                                               *
    330       0.00000      1.90943      0.00000      0.16860      1.00000 |                                               *
    340       0.00000      1.92536      0.00000      0.16860      1.00000 |                                               *
    350       0.00000      1.95431      0.00000      0.16860      1.00000 |                                               *
    360       0.00000      1.98219      0.00000      0.16860      1.00000 |                                               *
    370       0.00000      2.00626      0.00000      0.16860      1.00000 |                                               *
    380       0.00000      2.03371      0.00000      0.16860      1.00000 |                                               *
    390       0.00000      2.08425      0.00000      0.16860      1.00000 |                                               *
    400       0.00000      2.11385      0.00000      0.16860      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    397      1    400      1      7      3.43      4.54  A6$
    395      1    400      1      7      3.15      4.79  A14
    393      1    399      1      7      3.14      4.77  A2
    388      1    400      1      7      3.57      4.30  A3
    386      1    400      1      7      3.39      4.45  A9$
    364      1    400      1      7      4.43      3.25  A8
    360      1    400      1      7      4.43      3.22  A7$
    342      1    400      1      7      3.64      3.73  A15
    315      1    400      3      7      5.25      2.16  A4$
    285      3    399      2      7      5.28      1.94  A1$
    281      2    400      2      7      4.78      2.27  A10$
    271      1    399      3      7      5.39      1.77  A12$
    250      9    400      3      7      5.62      1.49  A13$
    222      1    400      1      7      4.53      1.93  A11
      0      0      0      0      0      0.00      0.00  A5$

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    14 terminal nodes
    Largest :    75 terminal nodes
    Average :     37.71000 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 115 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 115 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 29768 tree / 16146 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.42724
                  ROC          115      0.90625
                 Lift           12      2.22105
              KS-stat          149      0.70943
          Class.Error           44      0.15698

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.60410     0.63344     0.99280     0.83649     2.24675     1.70991     0.90767     0.63048     0.06647     0.19186
     10     0.24539     0.44275     0.99778     0.87939     2.24675     2.20341     0.96489     0.65186     0.02023     0.17442
     12     0.20670     0.43758     0.99821     0.88041     2.24675     2.22105     0.97531     0.64912     0.01734     0.18605
     16     0.14825     0.42724     0.99944     0.88405     2.24675     2.13158     0.98180     0.65022     0.01734     0.18023
     20     0.10885     0.43603     0.99986     0.89076     2.24675     2.02105     0.98830     0.66667     0.00867     0.20349
     24     0.08196     0.43622     1.00000     0.89762     2.24675     2.03509     1.00000     0.68147     0.00578     0.20349
     30     0.05337     0.46543     1.00000     0.89343     2.24675     2.00000     1.00000     0.67215     0.00000     0.20349
     40     0.02735     0.51893     1.00000     0.89117     2.24675     2.00000     1.00000     0.69134     0.00000     0.16279
     44     0.02134     0.53227     1.00000     0.89515     2.24675     2.13158     1.00000     0.69134     0.00000     0.15698
     50     0.01360     0.56098     1.00000     0.89857     2.24675     2.00000     1.00000     0.69134     0.00000     0.15698
     60     0.00644     0.62164     1.00000     0.89995     2.24675     2.00000     1.00000     0.67818     0.00000     0.18023
     70     0.00340     0.66725     1.00000     0.90132     2.24675     2.13158     1.00000     0.69627     0.00000     0.17442
     80     0.00183     0.72677     1.00000     0.90090     2.24675     2.10526     1.00000     0.67818     0.00000     0.16279
     90     0.00103     0.78563     1.00000     0.90090     2.24675     2.00000     1.00000     0.69134     0.00000     0.16279
    100     0.00062     0.81645     1.00000     0.90269     2.24675     2.13158     1.00000     0.68092     0.00000     0.16279
    110     0.00035     0.85954     1.00000     0.90447     2.24675     2.13158     1.00000     0.69627     0.00000     0.16279
    115     0.00028     0.87424     1.00000     0.90625     2.24675     2.13158     1.00000     0.69627     0.00000     0.16860
    120     0.00019     0.91437     1.00000     0.90474     2.24675     2.13158     1.00000     0.69353     0.00000     0.16860
    130     0.00012     0.94985     1.00000     0.90392     2.24675     2.13158     1.00000     0.68860     0.00000     0.16860
    140     0.00007     0.99997     1.00000     0.90269     2.24675     2.13158     1.00000     0.69901     0.00000     0.16860
    149     0.00005     1.03530     1.00000     0.90474     2.24675     2.13158     1.00000     0.70943     0.00000     0.16860
    150     0.00005     1.03454     1.00000     0.90488     2.24675     2.13158     1.00000     0.70943     0.00000     0.16860
    160     0.00003     1.06564     1.00000     0.90392     2.24675     2.13158     1.00000     0.69901     0.00000     0.16860
    170     0.00002     1.09899     1.00000     0.90323     2.24675     2.13158     1.00000     0.69627     0.00000     0.16860
    180     0.00001     1.12938     1.00000     0.90282     2.24675     2.13158     1.00000     0.69408     0.00000     0.16860
    190     0.00001     1.15129     1.00000     0.90228     2.24675     2.13158     1.00000     0.68586     0.00000     0.16279
    200     0.00000     1.19344     1.00000     0.90186     2.24675     2.13158     1.00000     0.69134     0.00000     0.16279
    210     0.00000     1.24510     1.00000     0.90118     2.24675     2.13158     1.00000     0.69353     0.00000     0.16279
    220     0.00000     1.33408     1.00000     0.89871     2.24675     2.13158     1.00000     0.68092     0.00000     0.16860
    230     0.00000     1.39191     1.00000     0.89940     2.24675     2.13158     1.00000     0.68366     0.00000     0.17442
    240     0.00000     1.44069     1.00000     0.89981     2.24675     2.13158     1.00000     0.68366     0.00000     0.17442
    250     0.00000     1.52333     1.00000     0.89899     2.24675     2.13158     1.00000     0.68366     0.00000     0.18023
    260     0.00000     1.57944     1.00000     0.89830     2.24675     2.13158     1.00000     0.67544     0.00000     0.18023
    270     0.00000     1.64195     1.00000     0.89789     2.24675     2.13158     1.00000     0.68586     0.00000     0.17442
    280     0.00000     1.71159     1.00000     0.89611     2.24675     2.13158     1.00000     0.68366     0.00000     0.18023
    290     0.00000     1.74221     1.00000     0.89638     2.24675     2.13158     1.00000     0.68366     0.00000     0.17442
    300     0.00000     1.80491     1.00000     0.89556     2.24675     2.13158     1.00000     0.68366     0.00000     0.17442
    310     0.00000     1.82997     1.00000     0.89611     2.24675     2.13158     1.00000     0.67325     0.00000     0.17442
    320     0.00000     1.86998     1.00000     0.89597     2.24675     2.13158     1.00000     0.67325     0.00000     0.16860
    330     0.00000     1.90943     1.00000     0.89666     2.24675     2.13158     1.00000     0.67325     0.00000     0.16860
    340     0.00000     1.92536     1.00000     0.89803     2.24675     2.13158     1.00000     0.67325     0.00000     0.16860
    350     0.00000     1.95431     1.00000     0.89816     2.24675     2.13158     1.00000     0.68311     0.00000     0.16860
    360     0.00000     1.98219     1.00000     0.89857     2.24675     2.13158     1.00000     0.68311     0.00000     0.16860
    370     0.00000     2.00626     1.00000     0.89926     2.24675     2.13158     1.00000     0.68311     0.00000     0.16860
    380     0.00000     2.03371     1.00000     0.90077     2.24675     2.13158     1.00000     0.68586     0.00000     0.16860
    390     0.00000     2.08425     1.00000     0.90090     2.24675     2.13158     1.00000     0.68586     0.00000     0.16860
    400     0.00000     2.11385     1.00000     0.90063     2.24675     2.13158     1.00000     0.68311     0.00000     0.16860


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

               Abs     Rel

 A9$     100.00000  100.00 |***********|
 A14      36.99737   37.00 |*****      |
 A3       36.05790   36.06 |*****      |
 A6$      34.01408   34.01 |****       |
 A11      29.21761   29.22 |****       |
 A2       28.14593   28.15 |****       |
 A7$      27.66850   27.67 |****       |
 A10$     26.67064   26.67 |****       |
 A15      14.63523   14.64 |**         |
 A12$     14.05481   14.05 |**         |
 A8       10.64132   10.64 |**         |
 A4$       7.49933    7.50 |**         |
 A13$      6.90392    6.90 |**         |
 A1$       6.47760    6.48 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       191.00         1.00       0.0052
 1                  154.00       149.00         5.00       0.0325


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        77.00        19.00       0.1979
 1                   76.00        64.00        12.00       0.1579

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.2 MB, 80% compression

 Grove file created containing:
      1 TreeNet

