
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 15 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172


 ======================================================
 Train/Test Levels Differences in Categorical Variables
 ======================================================


 Discrete variables were discovered that have one or more
 levels not encountered in all data partitions. All levels not
 seen in the training data are mapped to "missing" in test,
 holdout, or any future data to which the model is applied.
 ----------------------------------------------------------------
 A4$  Test  "l"
 A5$  Test  "gg"
 A6$  Test  "r"
 A7$  Test  "n", "o"

 Discrete         N Levels
 Variable         in Model
 -------------------------
 A1$                     2
 A4$                     3
 A5$                     3
 A6$                    14
 A7$                     9
 A9$                     2
 A10$                    2
 A12$                    2
 A13$                    3
 CLASS                   2



 ===================
 Cardinality Summary
 ===================

      N  Variable
 ----------------
     14  A6$
      9  A7$
      3  A5$
      3  A13$
      3  A4$
 ----------------

 EXCLUDE A6$, A7$, A5$, A13$, A4$
 Use the above EXCLUDE command to exclude high level categorical variables.

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A1$       0.0173
 A14       0.0145
 A2        0.0116
 A6$       0.0087
 A7$       0.0087
 A4$       0.0058
 A5$       0.0058

             Test
 ----------------
 A14       0.0174
 A2        0.0174
 A6$       0.0116
 A7$       0.0116
 A1$       0.0058
 A4$       0.0058
 A5$       0.0058


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.60319      0.62395      0.08671      0.14535      1.00000 |                                               *
      2       0.53553      0.57663      0.04624      0.15116      1.00000 |                                           *
      3       0.47772      0.53381      0.03757      0.15116      1.00000 |                                        *
      4       0.43004      0.50186      0.02890      0.14535      1.00000 |                                      *
      5       0.38804      0.47260      0.02312      0.12209      1.00000 |                                   *
      6       0.35264      0.44783      0.02312      0.12791      1.00000 |                                 *
      7       0.32024      0.42500      0.01445      0.12791      1.00000 |                                *
      8       0.29237      0.40637      0.01156      0.12791      1.00000 |                              *
      9       0.26695      0.39006      0.01156      0.12791      1.00000 |                             *
     10       0.24343      0.38078      0.01156      0.12791      1.00000 |                            *
     11       0.22354      0.36968      0.01156      0.12209      1.00000 |                           *
     12       0.20583      0.35956      0.00867      0.14535      1.00000 |                           *
     13       0.19076      0.35026      0.00578      0.15116      1.00000 |                          *
     14       0.17784      0.33896      0.00578      0.15116      1.00000 |                         *
     15       0.16557      0.33322      0.00578      0.15698      1.00000 |                         *
     16       0.15376      0.32351      0.00578      0.14535      1.00000 |                        *
     17       0.14366      0.31778      0.00578      0.14535      1.00000 |                       *
     18       0.13375      0.31116      0.00289      0.14535      1.00000 |                       *
     19       0.12515      0.30498      0.00289      0.15116      1.00000 |                      *
     20       0.11684      0.30207      0.00289      0.14535      1.00000 |                      *
     30       0.05754      0.29911      0.00000      0.13372      1.00000 |                      *
     40       0.03076      0.33127      0.00000      0.13372      1.00000 |                        *
     50       0.01697      0.36910      0.00000      0.13372      1.00000 |                           *
     60       0.00913      0.39012      0.00000      0.13372      1.00000 |                             *
     70       0.00533      0.39660      0.00000      0.12209      1.00000 |                              *
     80       0.00293      0.41791      0.00000      0.12791      1.00000 |                               *
     90       0.00170      0.43324      0.00000      0.11628      1.00000 |                                *
    100       0.00096      0.46476      0.00000      0.11628      1.00000 |                                   *
    110       0.00054      0.49972      0.00000      0.11628      1.00000 |                                     *
    120       0.00029      0.53819      0.00000      0.12209      1.00000 |                                        *
    130       0.00018      0.55712      0.00000      0.11047      1.00000 |                                          *
    140       0.00012      0.57744      0.00000      0.11047      1.00000 |                                           *
    150       0.00007      0.59242      0.00000      0.11047      1.00000 |                                             *
    160       0.00004      0.61264      0.00000      0.11047      1.00000 |                                              *
    170       0.00002      0.61596      0.00000      0.11047      1.00000 |                                              *
    180       0.00001      0.63202      0.00000      0.11047      1.00000 |                                               *
    190       0.00001      0.65593      0.00000      0.12209      1.00000 |                                               *
    200       0.00001      0.68214      0.00000      0.12209      1.00000 |                                               *
    210       0.00000      0.70742      0.00000      0.12209      1.00000 |                                               *
    220       0.00000      0.73983      0.00000      0.12209      1.00000 |                                               *
    230       0.00000      0.76545      0.00000      0.13372      1.00000 |                                               *
    240       0.00000      0.80957      0.00000      0.13372      1.00000 |                                               *
    250       0.00000      0.85236      0.00000      0.13372      1.00000 |                                               *
    260       0.00000      0.89364      0.00000      0.13372      1.00000 |                                               *
    270       0.00000      0.92913      0.00000      0.13372      1.00000 |                                               *
    280       0.00000      0.95847      0.00000      0.12791      1.00000 |                                               *
    290       0.00000      0.99823      0.00000      0.12791      1.00000 |                                               *
    300       0.00000      1.04631      0.00000      0.12791      1.00000 |                                               *
    310       0.00000      1.09177      0.00000      0.12791      1.00000 |                                               *
    320       0.00000      1.12426      0.00000      0.12791      1.00000 |                                               *
    330       0.00000      1.15137      0.00000      0.13372      1.00000 |                                               *
    340       0.00000      1.18510      0.00000      0.13372      1.00000 |                                               *
    350       0.00000      1.22087      0.00000      0.13372      1.00000 |                                               *
    360       0.00000      1.24313      0.00000      0.12791      1.00000 |                                               *
    370       0.00000      1.25839      0.00000      0.12791      1.00000 |                                               *
    380       0.00000      1.27926      0.00000      0.13372      1.00000 |                                               *
    390       0.00000      1.29434      0.00000      0.12791      1.00000 |                                               *
    400       0.00000      1.32162      0.00000      0.12791      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      7      3.65      4.36  A6$
    398      1    400      1      7      2.76      5.22  A2
    398      1    400      1      7      3.34      4.64  A9$
    397      1    400      2      7      4.16      3.82  A7$
    396      1    400      1      7      3.89      4.07  A8
    390      3    400      1      7      4.13      3.78  A14
    384      1    400      1      7      4.03      3.81  A15
    356      1    400      1      7      3.97      3.59  A3
    330      1    399      2      7      5.10      2.39  A4$
    296      2    400      3      7      5.72      1.69  A1$
    277      3    400      2      7      5.05      2.05  A13$
    269      2    395      2      7      5.36      1.78  A10$
    268      1    400      1      7      4.26      2.51  A11
    266      1    400      2      7      5.59      1.60  A12$
      0      0      0      0      0      0.00      0.00  A5$

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    22 terminal nodes
    Largest :    57 terminal nodes
    Average :     39.61000 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 175 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 175 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 24

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 31288 tree / 18072 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           24      0.29300
                  ROC          175      0.95038
                 Lift           10      2.26316
              KS-stat           17      0.82127
          Class.Error          103      0.10465

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.60319     0.62395     0.99459     0.88569     2.24675     1.93772     0.92066     0.70395     0.08671     0.14535
     10     0.24343     0.38078     0.99944     0.93586     2.24675     2.26316     0.98052     0.76371     0.01156     0.12791
     17     0.14366     0.31778     0.99988     0.94257     2.24675     2.26316     0.98830     0.82127     0.00578     0.14535
     20     0.11684     0.30207     0.99997     0.94291     2.24675     2.26316     0.99479     0.81086     0.00289     0.14535
     21     0.10869     0.29782     1.00000     0.94435     2.24675     2.26316     1.00000     0.82127     0.00289     0.14535
     24     0.08661     0.29300     1.00000     0.94490     2.24675     2.26316     1.00000     0.81086     0.00000     0.13372
     30     0.05754     0.29911     1.00000     0.94360     2.24675     2.26316     1.00000     0.78509     0.00000     0.13372
     40     0.03076     0.33127     1.00000     0.93962     2.24675     2.26316     1.00000     0.78509     0.00000     0.13372
     50     0.01697     0.36910     1.00000     0.94086     2.24675     2.19298     1.00000     0.76425     0.00000     0.13372
     60     0.00913     0.39012     1.00000     0.94243     2.24675     2.13158     1.00000     0.76700     0.00000     0.13372
     70     0.00533     0.39660     1.00000     0.94518     2.24675     2.13158     1.00000     0.76974     0.00000     0.12209
     80     0.00293     0.41791     1.00000     0.94586     2.24675     2.13158     1.00000     0.77522     0.00000     0.12791
     90     0.00170     0.43324     1.00000     0.94778     2.24675     2.13158     1.00000     0.78838     0.00000     0.11628
    100     0.00096     0.46476     1.00000     0.94764     2.24675     2.13158     1.00000     0.78289     0.00000     0.11628
    103     0.00081     0.46836     1.00000     0.94819     2.24675     2.13158     1.00000     0.79605     0.00000     0.10465
    110     0.00054     0.49972     1.00000     0.94737     2.24675     2.13158     1.00000     0.78564     0.00000     0.11628
    120     0.00029     0.53819     1.00000     0.94682     2.24675     2.13158     1.00000     0.78564     0.00000     0.12209
    130     0.00018     0.55712     1.00000     0.94627     2.24675     2.13158     1.00000     0.78289     0.00000     0.11047
    140     0.00012     0.57744     1.00000     0.94627     2.24675     2.13158     1.00000     0.79605     0.00000     0.11047
    150     0.00007     0.59242     1.00000     0.94792     2.24675     2.13158     1.00000     0.79605     0.00000     0.11047
    160     0.00004     0.61264     1.00000     0.94888     2.24675     2.13158     1.00000     0.79331     0.00000     0.11047
    170     0.00002     0.61596     1.00000     0.95011     2.24675     2.13158     1.00000     0.78564     0.00000     0.11047
    175     0.00002     0.61767     1.00000     0.95038     2.24675     2.13158     1.00000     0.78564     0.00000     0.11628
    180     0.00001     0.63202     1.00000     0.94984     2.24675     2.13158     1.00000     0.78289     0.00000     0.11047
    190     0.00001     0.65593     1.00000     0.94792     2.24675     2.13158     1.00000     0.79605     0.00000     0.12209
    200     0.00001     0.68214     1.00000     0.94751     2.24675     2.13158     1.00000     0.78289     0.00000     0.12209
    210     0.00000     0.70742     1.00000     0.94833     2.24675     2.13158     1.00000     0.78235     0.00000     0.12209
    220     0.00000     0.73983     1.00000     0.94682     2.24675     2.13158     1.00000     0.78235     0.00000     0.12209
    230     0.00000     0.76545     1.00000     0.94627     2.24675     2.13158     1.00000     0.78235     0.00000     0.13372
    240     0.00000     0.80957     1.00000     0.94435     2.24675     2.13158     1.00000     0.77193     0.00000     0.13372
    250     0.00000     0.85236     1.00000     0.94326     2.24675     2.13158     1.00000     0.77193     0.00000     0.13372
    260     0.00000     0.89364     1.00000     0.94339     2.24675     2.13158     1.00000     0.78509     0.00000     0.13372
    270     0.00000     0.92913     1.00000     0.94243     2.24675     2.13158     1.00000     0.77467     0.00000     0.13372
    280     0.00000     0.95847     1.00000     0.94189     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791
    290     0.00000     0.99823     1.00000     0.94202     2.24675     2.13158     1.00000     0.78509     0.00000     0.12791
    300     0.00000     1.04631     1.00000     0.94120     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791
    310     0.00000     1.09177     1.00000     0.94010     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791
    320     0.00000     1.12426     1.00000     0.93983     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791
    330     0.00000     1.15137     1.00000     0.93887     2.24675     2.13158     1.00000     0.77467     0.00000     0.13372
    340     0.00000     1.18510     1.00000     0.93873     2.24675     2.13158     1.00000     0.77467     0.00000     0.13372
    350     0.00000     1.22087     1.00000     0.93860     2.24675     2.13158     1.00000     0.77467     0.00000     0.13372
    360     0.00000     1.24313     1.00000     0.93887     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791
    370     0.00000     1.25839     1.00000     0.93969     2.24675     2.13158     1.00000     0.78509     0.00000     0.12791
    380     0.00000     1.27926     1.00000     0.94010     2.24675     2.13158     1.00000     0.78509     0.00000     0.13372
    390     0.00000     1.29434     1.00000     0.94010     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791
    400     0.00000     1.32162     1.00000     0.93969     2.24675     2.13158     1.00000     0.77467     0.00000     0.12791


 =========================================
 Variable Importance for the 24-tree Model
 =========================================

               Abs     Rel

 A9$     100.00000  100.00 |***********|
 A6$      40.60029   40.60 |*****      |
 A15      36.76151   36.76 |*****      |
 A2       30.04872   30.05 |****       |
 A3       29.91574   29.92 |****       |
 A4$      26.22198   26.22 |****       |
 A8       25.86587   25.87 |****       |
 A11      25.42046   25.42 |***        |
 A7$      20.98772   20.99 |***        |
 A14      19.53518   19.54 |***        |
 A12$     17.03387   17.03 |***        |
 A10$     14.36258   14.36 |**         |
 A13$      9.86220    9.86 |**         |
 A1$       9.26558    9.27 |**         |


 Learn Sample Misclassification by Target Class
 For The 24-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       192.00         0.00       0.0000
 1                  154.00       154.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 24-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        82.00        14.00       0.1458
 1                   76.00        67.00         9.00       0.1184

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.2 MB, 80% compression

 Grove file created containing:
      1 TreeNet

