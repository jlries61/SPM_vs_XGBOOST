
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 51 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A2        0.0202
 A14       0.0173

             Test
 ----------------
 A2        0.0174
 A14       0.0116

 No learn sample variance for: A7_O.
 No test sample variance for: A4_L.
 No test sample variance for: A7_N.
 No test sample variance for: A5_GG.



 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.62051      0.62454      0.23699      0.25581      1.00000 |                                               *
      2       0.56612      0.57663      0.13584      0.14535      1.00000 |                                           *
      3       0.52058      0.53657      0.12139      0.16279      1.00000 |                                        *
      4       0.48136      0.50176      0.09249      0.15698      1.00000 |                                      *
      5       0.44673      0.47324      0.08382      0.12791      1.00000 |                                   *
      6       0.41601      0.44768      0.08382      0.11047      1.00000 |                                 *
      7       0.39022      0.42888      0.08382      0.12209      1.00000 |                                *
      8       0.36607      0.41006      0.07803      0.11628      1.00000 |                               *
      9       0.34584      0.39753      0.07803      0.12209      1.00000 |                              *
     10       0.32847      0.38299      0.07803      0.12209      1.00000 |                            *
     11       0.31231      0.36937      0.07225      0.12209      1.00000 |                           *
     12       0.29715      0.36105      0.06936      0.12791      1.00000 |                           *
     13       0.28322      0.35393      0.07514      0.12209      1.00000 |                          *
     14       0.26803      0.34348      0.06936      0.11047      1.00000 |                         *
     15       0.25750      0.33934      0.06647      0.11047      1.00000 |                         *
     16       0.24623      0.33200      0.06936      0.11047      1.00000 |                         *
     17       0.23652      0.32806      0.06936      0.12791      1.00000 |                        *
     18       0.22673      0.32220      0.06358      0.12209      1.00000 |                        *
     19       0.21850      0.31632      0.06358      0.10465      1.00000 |                       *
     20       0.21077      0.31283      0.06069      0.10465      1.00000 |                       *
     30       0.14252      0.30264      0.02312      0.12209      1.00000 |                      *
     40       0.10251      0.31010      0.01445      0.11047      1.00000 |                       *
     50       0.07753      0.31776      0.00289      0.10465      1.00000 |                       *
     60       0.06127      0.32515      0.00289      0.09884      1.00000 |                        *
     70       0.04622      0.33262      0.00000      0.11628      1.00000 |                         *
     80       0.03653      0.33681      0.00000      0.11047      1.00000 |                         *
     90       0.02887      0.34191      0.00000      0.11047      1.00000 |                         *
    100       0.02245      0.35332      0.00000      0.11628      1.00000 |                          *
    110       0.01802      0.36889      0.00000      0.11628      1.00000 |                           *
    120       0.01324      0.37442      0.00000      0.11628      1.00000 |                            *
    130       0.01066      0.38913      0.00000      0.12209      1.00000 |                             *
    140       0.00799      0.39348      0.00000      0.11628      1.00000 |                             *
    150       0.00595      0.40531      0.00000      0.11628      1.00000 |                              *
    160       0.00470      0.41857      0.00000      0.11628      1.00000 |                               *
    170       0.00359      0.43345      0.00000      0.12209      1.00000 |                                *
    180       0.00268      0.44806      0.00000      0.12209      1.00000 |                                 *
    190       0.00220      0.46629      0.00000      0.12209      1.00000 |                                   *
    200       0.00184      0.47943      0.00000      0.12209      1.00000 |                                    *
    210       0.00147      0.48879      0.00000      0.12791      1.00000 |                                     *
    220       0.00117      0.49900      0.00000      0.12791      1.00000 |                                     *
    230       0.00090      0.51407      0.00000      0.11628      1.00000 |                                       *
    240       0.00069      0.52397      0.00000      0.12209      1.00000 |                                       *
    250       0.00054      0.53347      0.00000      0.12209      1.00000 |                                        *
    260       0.00040      0.55305      0.00000      0.12209      1.00000 |                                          *
    270       0.00031      0.57324      0.00000      0.12209      1.00000 |                                           *
    280       0.00024      0.58953      0.00000      0.11047      1.00000 |                                            *
    290       0.00019      0.60801      0.00000      0.11047      1.00000 |                                              *
    300       0.00014      0.62247      0.00000      0.11047      1.00000 |                                               *
    310       0.00011      0.64672      0.00000      0.11047      1.00000 |                                               *
    320       0.00008      0.65300      0.00000      0.11628      1.00000 |                                               *
    330       0.00007      0.67735      0.00000      0.12209      1.00000 |                                               *
    340       0.00005      0.69264      0.00000      0.12209      1.00000 |                                               *
    350       0.00004      0.70529      0.00000      0.12791      1.00000 |                                               *
    360       0.00003      0.72945      0.00000      0.12209      1.00000 |                                               *
    370       0.00003      0.74409      0.00000      0.12209      1.00000 |                                               *
    380       0.00002      0.76404      0.00000      0.13372      1.00000 |                                               *
    390       0.00001      0.78701      0.00000      0.12791      1.00000 |                                               *
    400       0.00001      0.81325      0.00000      0.13372      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    385      1    400      1      7      2.92      4.89  A14
    362      1    399      1      7      3.74      3.86  A2
    354      1    400      1      7      3.63      3.87  A3
    315      1    400      1      7      4.18      3.01  A8
    310      1    400      1      7      3.53      3.47  A15
    210      1    400      1      7      3.90      2.15  A11
    127      3    399      1      7      3.19      1.53  A9_T
    109      1    399      1      7      3.03      1.36  A9_F
     80     10    393      2      7      5.43      0.52  A4_Y
     58     35    396      1      6      2.91      0.74  A6_X
     56      2    400      2      7      4.75      0.46  A1_A
     53     22    400      3      7      5.15      0.38  A4_U
     52     28    396      1      7      3.92      0.53  A6_CC
     49     23    400      4      7      5.82      0.27  A7_V
     43     19    398      3      7      4.40      0.39  A6_C
     41     44    368      1      7      2.61      0.55  A6_FF
     41     13    385      2      7      4.22      0.39  A6_K
     40      4    394      1      7      3.15      0.49  A7_H
     38      2    335      1      7      3.45      0.43  A10_F
     37     14    400      3      7      5.62      0.22  A12_T
     36      7    400      2      7      3.94      0.37  A6_Q
     35     16    400      3      7      5.34      0.23  A12_F
     31     14    391      3      7      4.77      0.25  A1_B
     28     79    397      3      7      4.50      0.25  A13_G
     25     38    391      2      7      3.52      0.28  A6_M
     18     48    302      3      7      5.17      0.13  A6_W
     14     92    384      4      7      5.36      0.09  A7_BB
     10    104    331      1      4      2.30      0.14  A6_AA
      8     42    384      3      5      3.25      0.10  A6_I
      5     30    274      3      6      4.40      0.05  A13_S
      2    311    390      3      3      3.00      0.03  A6_D
      1    251    251      6      6      6.00      0.01  A7_FF
      0      0      0      0      0      0.00      0.00  A4_L
      0      0      0      0      0      0.00      0.00  A4_MISS
      0      0      0      0      0      0.00      0.00  A1_MISS
      0      0      0      0      0      0.00      0.00  A6_R
      0      0      0      0      0      0.00      0.00  A5_MISS
      0      0      0      0      0      0.00      0.00  A5_P
      0      0      0      0      0      0.00      0.00  A5_G
      0      0      0      0      0      0.00      0.00  A10_T
      0      0      0      0      0      0.00      0.00  A7_N
      0      0      0      0      0      0.00      0.00  A7_DD
      0      0      0      0      0      0.00      0.00  A7_O
      0      0      0      0      0      0.00      0.00  A7_MISS
      0      0      0      0      0      0.00      0.00  A5_GG
      0      0      0      0      0      0.00      0.00  A6_J
      0      0      0      0      0      0.00      0.00  A6_MISS
      0      0      0      0      0      0.00      0.00  A13_P
      0      0      0      0      0      0.00      0.00  A7_Z
      0      0      0      0      0      0.00      0.00  A7_J
      0      0      0      0      0      0.00      0.00  A6_E

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    28 terminal nodes
    Average :     17.89000 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 57 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 57 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 27

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 13912 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           27      0.30157
                  ROC           27      0.94312
                 Lift           22      2.26316
              KS-stat           51      0.80647
          Class.Error           57      0.09884

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.62051     0.62454     0.96571     0.94189     2.24675     2.16029     0.79322     0.79002     0.23699     0.25581
     10     0.32847     0.38299     0.98045     0.93750     2.24675     2.13158     0.85694     0.77029     0.07803     0.12209
     20     0.21077     0.31283     0.98852     0.94024     2.24675     2.13158     0.89347     0.80373     0.06069     0.10465
     22     0.19314     0.30767     0.99087     0.94154     2.24675     2.26316     0.91416     0.79331     0.04913     0.11628
     27     0.16174     0.30157     0.99401     0.94312     2.24675     2.26316     0.93628     0.79605     0.03179     0.11047
     30     0.14252     0.30264     0.99604     0.93805     2.24675     2.26316     0.95191     0.78838     0.02312     0.12209
     40     0.10251     0.31010     0.99946     0.93476     2.24675     2.26316     0.98438     0.78783     0.01445     0.11047
     50     0.07753     0.31776     0.99980     0.93462     2.24675     2.26316     0.99479     0.79605     0.00289     0.10465
     51     0.07571     0.31897     0.99986     0.93448     2.24675     2.26316     0.99479     0.80647     0.00289     0.10465
     56     0.06694     0.32297     1.00000     0.93476     2.24675     2.26316     1.00000     0.80647     0.00289     0.10465
     57     0.06506     0.32351     0.99997     0.93517     2.24675     2.26316     0.99479     0.80647     0.00289     0.09884
     60     0.06127     0.32515     1.00000     0.93558     2.24675     2.26316     1.00000     0.80647     0.00289     0.09884
     63     0.05686     0.32674     1.00000     0.93572     2.24675     2.26316     1.00000     0.80099     0.00000     0.11047
     70     0.04622     0.33262     1.00000     0.93476     2.24675     2.26316     1.00000     0.79605     0.00000     0.11628
     80     0.03653     0.33681     1.00000     0.93654     2.24675     2.26316     1.00000     0.79605     0.00000     0.11047
     90     0.02887     0.34191     1.00000     0.93668     2.24675     2.26316     1.00000     0.78289     0.00000     0.11047
    100     0.02245     0.35332     1.00000     0.93750     2.24675     2.26316     1.00000     0.78564     0.00000     0.11628
    110     0.01802     0.36889     1.00000     0.93640     2.24675     2.26316     1.00000     0.78289     0.00000     0.11628
    120     0.01324     0.37442     1.00000     0.93736     2.24675     2.26316     1.00000     0.77248     0.00000     0.11628
    130     0.01066     0.38913     1.00000     0.93709     2.24675     2.26316     1.00000     0.77796     0.00000     0.12209
    140     0.00799     0.39348     1.00000     0.93750     2.24675     2.26316     1.00000     0.77796     0.00000     0.11628
    150     0.00595     0.40531     1.00000     0.93777     2.24675     2.26316     1.00000     0.78070     0.00000     0.11628
    160     0.00470     0.41857     1.00000     0.93914     2.24675     2.26316     1.00000     0.79112     0.00000     0.11628
    170     0.00359     0.43345     1.00000     0.93860     2.24675     2.26316     1.00000     0.79112     0.00000     0.12209
    180     0.00268     0.44806     1.00000     0.93723     2.24675     2.26316     1.00000     0.79112     0.00000     0.12209
    190     0.00220     0.46629     1.00000     0.93586     2.24675     2.26316     1.00000     0.78070     0.00000     0.12209
    200     0.00184     0.47943     1.00000     0.93572     2.24675     2.26316     1.00000     0.79112     0.00000     0.12209
    210     0.00147     0.48879     1.00000     0.93627     2.24675     2.26316     1.00000     0.78070     0.00000     0.12791
    220     0.00117     0.49900     1.00000     0.93558     2.24675     2.26316     1.00000     0.77796     0.00000     0.12791
    230     0.00090     0.51407     1.00000     0.93572     2.24675     2.26316     1.00000     0.77522     0.00000     0.11628
    240     0.00069     0.52397     1.00000     0.93681     2.24675     2.26316     1.00000     0.78015     0.00000     0.12209
    250     0.00054     0.53347     1.00000     0.93764     2.24675     2.26316     1.00000     0.78564     0.00000     0.12209
    260     0.00040     0.55305     1.00000     0.93750     2.24675     2.26316     1.00000     0.78564     0.00000     0.12209
    270     0.00031     0.57324     1.00000     0.93613     2.24675     2.26316     1.00000     0.78564     0.00000     0.12209
    280     0.00024     0.58953     1.00000     0.93627     2.24675     2.26316     1.00000     0.78564     0.00000     0.11047
    290     0.00019     0.60801     1.00000     0.93572     2.24675     2.26316     1.00000     0.78289     0.00000     0.11047
    300     0.00014     0.62247     1.00000     0.93613     2.24675     2.26316     1.00000     0.78289     0.00000     0.11047
    310     0.00011     0.64672     1.00000     0.93517     2.24675     2.26316     1.00000     0.78289     0.00000     0.11047
    320     0.00008     0.65300     1.00000     0.93544     2.24675     2.26316     1.00000     0.78289     0.00000     0.11628
    330     0.00007     0.67735     1.00000     0.93448     2.24675     2.26316     1.00000     0.78070     0.00000     0.12209
    340     0.00005     0.69264     1.00000     0.93435     2.24675     2.26316     1.00000     0.77741     0.00000     0.12209
    350     0.00004     0.70529     1.00000     0.93448     2.24675     2.26316     1.00000     0.77741     0.00000     0.12791
    360     0.00003     0.72945     1.00000     0.93421     2.24675     2.26316     1.00000     0.77796     0.00000     0.12209
    370     0.00003     0.74409     1.00000     0.93380     2.24675     2.26316     1.00000     0.77741     0.00000     0.12209
    380     0.00002     0.76404     1.00000     0.93270     2.24675     2.26316     1.00000     0.77522     0.00000     0.13372
    390     0.00001     0.78701     1.00000     0.93202     2.24675     2.26316     1.00000     0.77522     0.00000     0.12791
    400     0.00001     0.81325     1.00000     0.93161     2.24675     2.26316     1.00000     0.77522     0.00000     0.13372


 =========================================
 Variable Importance for the 27-tree Model
 =========================================

                  Abs     Rel

 A9_F       100.00000  100.00 |***********|
 A9_T        66.13703   66.14 |********   |
 A14         37.80138   37.80 |*****      |
 A15         37.72916   37.73 |*****      |
 A11         36.28132   36.28 |*****      |
 A8          31.87938   31.88 |****       |
 A3          31.16701   31.17 |****       |
 A2          28.58469   28.58 |****       |
 A10_F       18.63067   18.63 |***        |
 A7_H        16.45546   16.46 |***        |
 A12_T        9.77118    9.77 |**         |
 A4_U         9.21464    9.21 |**         |
 A7_V         7.69718    7.70 |**         |
 A6_C         7.39491    7.39 |**         |
 A4_Y         6.84763    6.85 |**         |
 A6_Q         5.45019    5.45 |*          |
 A1_A         4.78918    4.79 |*          |
 A6_K         3.45909    3.46 |*          |
 A1_B         2.59439    2.59 |*          |
 A12_F        0.02109    0.02 |*          |


 Learn Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       186.00         6.00       0.0313
 1                  154.00       149.00         5.00       0.0325


 Test Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        85.00        11.00       0.1146
 1                   76.00        68.00         8.00       0.1053

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenetx_model.grv: 589 kb , 79% compression

 Grove file created containing:
      1 TreeNet

