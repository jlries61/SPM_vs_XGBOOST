
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11042      0.12071      0.02910      0.02898      1.00000 |                                               *
      2       0.10319      0.11588      0.02910      0.02898      1.00000 |                                             *
      3       0.09755      0.11323      0.02910      0.02898      1.00000 |                                            *
      4       0.09279      0.11145      0.02910      0.02898      1.00000 |                                           *
      5       0.08776      0.11065      0.02910      0.02924      1.00000 |                                           *
      6       0.08462      0.10968      0.02858      0.02977      1.00000 |                                           *
      7       0.08176      0.10859      0.02779      0.02950      1.00000 |                                          *
      8       0.07848      0.10840      0.02752      0.02898      1.00000 |                                          *
      9       0.07607      0.10790      0.02726      0.02950      1.00000 |                                          *
     10       0.07378      0.10754      0.02660      0.02898      1.00000 |                                          *
     11       0.07204      0.10758      0.02647      0.02871      1.00000 |                                          *
     12       0.07029      0.10723      0.02634      0.02871      1.00000 |                                          *
     13       0.06881      0.10712      0.02594      0.02871      1.00000 |                                          *
     14       0.06749      0.10706      0.02541      0.02898      1.00000 |                                          *
     15       0.06587      0.10728      0.02449      0.02819      1.00000 |                                          *
     16       0.06443      0.10738      0.02449      0.02871      1.00000 |                                          *
     17       0.06323      0.10714      0.02462      0.02819      1.00000 |                                          *
     18       0.06185      0.10762      0.02436      0.02871      1.00000 |                                          *
     19       0.06094      0.10733      0.02423      0.02871      1.00000 |                                          *
     20       0.05984      0.10728      0.02423      0.02871      1.00000 |                                          *
     30       0.05178      0.10952      0.02291      0.02871      1.00000 |                                           *
     40       0.04734      0.11078      0.02067      0.03082      1.00000 |                                           *
     50       0.04182      0.11285      0.01725      0.03030      1.00000 |                                            *
     60       0.03906      0.11437      0.01528      0.03056      1.00000 |                                            *
     70       0.03742      0.11544      0.01422      0.03030      1.00000 |                                             *
     80       0.03545      0.11662      0.01343      0.03109      1.00000 |                                             *
     90       0.03294      0.11859      0.01225      0.03109      1.00000 |                                              *
    100       0.03147      0.11987      0.01106      0.03135      1.00000 |                                               *
    110       0.03018      0.12081      0.00948      0.03135      1.00000 |                                               *
    120       0.02897      0.12202      0.00843      0.03109      1.00000 |                                               *
    130       0.02833      0.12269      0.00830      0.03109      1.00000 |                                               *
    140       0.02720      0.12352      0.00751      0.03109      1.00000 |                                               *
    150       0.02547      0.12498      0.00685      0.03109      1.00000 |                                               *
    160       0.02477      0.12543      0.00658      0.03135      1.00000 |                                               *
    170       0.02376      0.12610      0.00593      0.03161      1.00000 |                                               *
    180       0.02300      0.12706      0.00566      0.03161      1.00000 |                                               *
    190       0.02207      0.12797      0.00487      0.03109      1.00000 |                                               *
    200       0.02092      0.12911      0.00382      0.03161      1.00000 |                                               *
    210       0.02011      0.12945      0.00382      0.03161      1.00000 |                                               *
    220       0.01923      0.13051      0.00303      0.03214      1.00000 |                                               *
    230       0.01814      0.13115      0.00277      0.03161      1.00000 |                                               *
    240       0.01764      0.13202      0.00250      0.03161      1.00000 |                                               *
    250       0.01697      0.13303      0.00171      0.03214      1.00000 |                                               *
    260       0.01676      0.13384      0.00171      0.03188      1.00000 |                                               *
    270       0.01623      0.13497      0.00132      0.03240      1.00000 |                                               *
    280       0.01562      0.13576      0.00105      0.03214      1.00000 |                                               *
    290       0.01454      0.13783      0.00040      0.03240      1.00000 |                                               *
    300       0.01377      0.13917      0.00040      0.03214      1.00000 |                                               *
    310       0.01307      0.14060      0.00013      0.03214      1.00000 |                                               *
    320       0.01226      0.14214      0.00013      0.03214      1.00000 |                                               *
    330       0.01175      0.14288      0.00000      0.03214      1.00000 |                                               *
    340       0.01103      0.14435      0.00000      0.03188      1.00000 |                                               *
    350       0.01064      0.14572      0.00000      0.03161      1.00000 |                                               *
    360       0.00987      0.14769      0.00000      0.03240      1.00000 |                                               *
    370       0.00950      0.14888      0.00000      0.03214      1.00000 |                                               *
    380       0.00931      0.14981      0.00000      0.03214      1.00000 |                                               *
    390       0.00886      0.15128      0.00000      0.03214      1.00000 |                                               *
    400       0.00862      0.15180      0.00000      0.03214      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.34      6.66  CHILDYRS
    290      1    400      1      7      3.82      3.03  AGE_MOM
    267      1    399      1      7      3.62      2.92  AGE
    252      1    399      1      7      4.34      2.31  INCOME
    240      1    399      1      7      4.23      2.26  OTH_CHLD
    220      1    399      1      7      4.14      2.13  EDUC_MOM
    199      2    400      2      7      5.35      1.32  ILLEGIT
    162      1    399      2      7      5.22      1.13  RACE_MOM
    140      3    398      2      7      5.34      0.93  LBW
    137      1    400      1      7      5.50      0.86  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    92 terminal nodes
    Average :     33.03250 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 77 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 77 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 14

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 26026 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           14      0.10706
                  ROC            4      0.84940
                 Lift           77      5.23636
              KS-stat            5      0.58799
          Class.Error           24      0.02792

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11042     0.12071     0.92493     0.80159     7.33937     4.00000     0.69979     0.48071     0.02910     0.02898
      4     0.09279     0.11145     0.95068     0.84940     8.16652     4.96364     0.75697     0.57130     0.02910     0.02898
      5     0.08776     0.11065     0.96225     0.84583     8.60090     4.81818     0.80827     0.58799     0.02910     0.02924
     10     0.07378     0.10754     0.97461     0.83537     9.29412     4.78182     0.85952     0.56507     0.02660     0.02898
     14     0.06749     0.10706     0.97958     0.83129     9.41176     5.07273     0.87241     0.56533     0.02541     0.02898
     20     0.05984     0.10728     0.98578     0.83168     9.63801     4.90909     0.90285     0.56045     0.02423     0.02871
     24     0.05585     0.10824     0.98891     0.82906     9.72851     4.90909     0.91014     0.55692     0.02410     0.02792
     30     0.05178     0.10952     0.99136     0.83136     9.90950     4.90909     0.92503     0.54592     0.02291     0.02871
     40     0.04734     0.11078     0.99375     0.83367     9.90950     4.90909     0.93606     0.55379     0.02067     0.03082
     50     0.04182     0.11285     0.99627     0.83315     9.90950     4.90909     0.96006     0.53887     0.01725     0.03030
     60     0.03906     0.11437     0.99703     0.83353     9.90950     4.90909     0.96608     0.53670     0.01528     0.03056
     70     0.03742     0.11544     0.99747     0.83135     9.95475     5.00000     0.96879     0.54036     0.01422     0.03030
     75     0.03621     0.11635     0.99782     0.83048    10.00000     5.18182     0.96966     0.54118     0.01356     0.03082
     77     0.03574     0.11647     0.99799     0.83118    10.00000     5.23636     0.97300     0.54579     0.01356     0.03030
     80     0.03545     0.11662     0.99804     0.83204    10.00000     5.18182     0.97313     0.54064     0.01343     0.03109
     90     0.03294     0.11859     0.99861     0.83080    10.00000     4.90909     0.97712     0.53956     0.01225     0.03109
    100     0.03147     0.11987     0.99886     0.83009    10.00000     4.81818     0.97784     0.53331     0.01106     0.03135
    110     0.03018     0.12081     0.99910     0.82989    10.00000     4.72727     0.98096     0.53358     0.00948     0.03135
    120     0.02897     0.12202     0.99931     0.82723    10.00000     4.90909     0.98210     0.53169     0.00843     0.03109
    130     0.02833     0.12269     0.99940     0.82682    10.00000     4.90909     0.98395     0.53332     0.00830     0.03109
    140     0.02720     0.12352     0.99954     0.82582    10.00000     4.81818     0.98774     0.52884     0.00751     0.03109
    150     0.02547     0.12498     0.99973     0.82403    10.00000     4.60000     0.99105     0.53820     0.00685     0.03109
    160     0.02477     0.12543     0.99978     0.82440    10.00000     4.72727     0.99281     0.52992     0.00658     0.03135
    170     0.02376     0.12610     0.99985     0.82433    10.00000     4.54545     0.99390     0.52544     0.00593     0.03161
    180     0.02300     0.12706     0.99989     0.82279    10.00000     4.63636     0.99756     0.53033     0.00566     0.03161
    190     0.02207     0.12797     0.99993     0.82408    10.00000     4.63636     0.99864     0.53304     0.00487     0.03109
    200     0.02092     0.12911     0.99995     0.82462    10.00000     4.54545     0.99905     0.53481     0.00382     0.03161
    210     0.02011     0.12945     0.99996     0.82562    10.00000     4.54545     0.99946     0.53262     0.00382     0.03161
    220     0.01923     0.13051     0.99997     0.82571    10.00000     4.45455     0.99946     0.53005     0.00303     0.03214
    230     0.01814     0.13115     0.99998     0.82771    10.00000     4.45455     0.99959     0.52382     0.00277     0.03161
    240     0.01764     0.13202     0.99999     0.82890    10.00000     4.63636     0.99986     0.53074     0.00250     0.03161
    250     0.01697     0.13303     0.99999     0.82736    10.00000     4.63636     0.99986     0.52803     0.00171     0.03214
    260     0.01676     0.13384     0.99999     0.82650    10.00000     4.72727     0.99986     0.52979     0.00171     0.03188
    270     0.01623     0.13497     0.99999     0.82705    10.00000     4.63636     0.99986     0.53196     0.00132     0.03240
    280     0.01562     0.13576     1.00000     0.82619    10.00000     4.72727     0.99986     0.53521     0.00105     0.03214
    290     0.01454     0.13783     1.00000     0.82525    10.00000     4.72727     0.99986     0.53182     0.00040     0.03240
    298     0.01378     0.13911     1.00000     0.82526    10.00000     4.63636     1.00000     0.53386     0.00040     0.03214
    300     0.01377     0.13917     1.00000     0.82520    10.00000     4.63636     1.00000     0.53386     0.00040     0.03214
    310     0.01307     0.14060     1.00000     0.82548    10.00000     4.63636     1.00000     0.54064     0.00013     0.03214
    320     0.01226     0.14214     1.00000     0.82532    10.00000     4.45455     1.00000     0.53576     0.00013     0.03214
    326     0.01202     0.14261     1.00000     0.82538    10.00000     4.54545     1.00000     0.52762     0.00000     0.03214
    330     0.01175     0.14288     1.00000     0.82586    10.00000     4.63636     1.00000     0.53005     0.00000     0.03214
    340     0.01103     0.14435     1.00000     0.82570    10.00000     4.54545     1.00000     0.52951     0.00000     0.03188
    350     0.01064     0.14572     1.00000     0.82713    10.00000     4.63636     1.00000     0.53060     0.00000     0.03161
    360     0.00987     0.14769     1.00000     0.82581    10.00000     4.45455     1.00000     0.53358     0.00000     0.03240
    370     0.00950     0.14888     1.00000     0.82473    10.00000     4.45455     1.00000     0.53060     0.00000     0.03214
    380     0.00931     0.14981     1.00000     0.82428    10.00000     4.45455     1.00000     0.52259     0.00000     0.03214
    390     0.00886     0.15128     1.00000     0.82258    10.00000     4.54545     1.00000     0.52381     0.00000     0.03214
    400     0.00862     0.15180     1.00000     0.82288    10.00000     4.54545     1.00000     0.52653     0.00000     0.03214


 =========================================
 Variable Importance for the 14-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      33.14819   33.15 |****       |
 AGE          32.78415   32.78 |****       |
 OTH_CHLD     32.76179   32.76 |****       |
 INCOME       28.79687   28.80 |****       |
 EDUC_MOM     26.19820   26.20 |****       |
 RACE_MOM     16.92103   16.92 |***        |
 LBW          14.32208   14.32 |**         |
 ILLEGIT      13.60779   13.61 |**         |
 PNCLATE      13.44061   13.44 |**         |


 Learn Sample Misclassification by Target Class
 For The 14-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7370.00         3.00       0.0004
 1                  221.00        31.00       190.00       0.8597


 Test Sample Misclassification by Target Class
 For The 14-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3681.00         5.00       0.0014
 1                  110.00         5.00       105.00       0.9545

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenetx_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

