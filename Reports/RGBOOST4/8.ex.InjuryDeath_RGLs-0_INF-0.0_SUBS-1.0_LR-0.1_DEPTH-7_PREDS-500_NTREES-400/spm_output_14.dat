
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10920      0.12221      0.02910      0.02898      1.00000 |                                               *
      2       0.10064      0.11852      0.02897      0.02871      1.00000 |                                              *
      3       0.09432      0.11714      0.02871      0.02898      1.00000 |                                             *
      4       0.08941      0.11495      0.02779      0.02898      1.00000 |                                            *
      5       0.08585      0.11390      0.02699      0.02871      1.00000 |                                            *
      6       0.08279      0.11246      0.02673      0.02871      1.00000 |                                           *
      7       0.07981      0.11189      0.02634      0.02898      1.00000 |                                           *
      8       0.07756      0.11150      0.02620      0.02898      1.00000 |                                           *
      9       0.07574      0.11105      0.02541      0.02950      1.00000 |                                           *
     10       0.07340      0.11068      0.02476      0.02977      1.00000 |                                          *
     11       0.07181      0.11055      0.02449      0.03003      1.00000 |                                          *
     12       0.07013      0.11041      0.02423      0.03003      1.00000 |                                          *
     13       0.06871      0.11006      0.02410      0.03056      1.00000 |                                          *
     14       0.06741      0.10996      0.02383      0.03056      1.00000 |                                          *
     15       0.06594      0.10982      0.02370      0.03056      1.00000 |                                          *
     16       0.06480      0.10979      0.02344      0.03056      1.00000 |                                          *
     17       0.06362      0.11010      0.02318      0.03030      1.00000 |                                          *
     18       0.06231      0.11012      0.02291      0.03003      1.00000 |                                          *
     19       0.06117      0.11016      0.02252      0.03003      1.00000 |                                          *
     20       0.05956      0.11031      0.02239      0.03003      1.00000 |                                          *
     30       0.05023      0.11190      0.02094      0.03109      1.00000 |                                           *
     40       0.04598      0.11375      0.01975      0.03109      1.00000 |                                            *
     50       0.04128      0.11566      0.01725      0.03109      1.00000 |                                            *
     60       0.03656      0.11825      0.01501      0.03267      1.00000 |                                             *
     70       0.03263      0.12162      0.01172      0.03267      1.00000 |                                               *
     80       0.03049      0.12375      0.01001      0.03214      1.00000 |                                               *
     90       0.02802      0.12685      0.00803      0.03240      1.00000 |                                               *
    100       0.02552      0.12942      0.00672      0.03267      1.00000 |                                               *
    110       0.02415      0.13133      0.00566      0.03240      1.00000 |                                               *
    120       0.02281      0.13333      0.00487      0.03319      1.00000 |                                               *
    130       0.02166      0.13538      0.00448      0.03346      1.00000 |                                               *
    140       0.02062      0.13665      0.00408      0.03372      1.00000 |                                               *
    150       0.01896      0.13912      0.00316      0.03346      1.00000 |                                               *
    160       0.01744      0.14085      0.00237      0.03346      1.00000 |                                               *
    170       0.01629      0.14322      0.00211      0.03346      1.00000 |                                               *
    180       0.01540      0.14575      0.00184      0.03372      1.00000 |                                               *
    190       0.01475      0.14755      0.00119      0.03425      1.00000 |                                               *
    200       0.01407      0.14874      0.00092      0.03398      1.00000 |                                               *
    210       0.01372      0.14972      0.00092      0.03319      1.00000 |                                               *
    220       0.01335      0.15109      0.00053      0.03346      1.00000 |                                               *
    230       0.01289      0.15217      0.00053      0.03372      1.00000 |                                               *
    240       0.01245      0.15372      0.00040      0.03372      1.00000 |                                               *
    250       0.01199      0.15505      0.00040      0.03372      1.00000 |                                               *
    260       0.01150      0.15702      0.00040      0.03372      1.00000 |                                               *
    270       0.01097      0.15832      0.00040      0.03372      1.00000 |                                               *
    280       0.01058      0.15992      0.00026      0.03372      1.00000 |                                               *
    290       0.01025      0.16125      0.00026      0.03372      1.00000 |                                               *
    300       0.00981      0.16283      0.00026      0.03372      1.00000 |                                               *
    310       0.00898      0.16448      0.00013      0.03398      1.00000 |                                               *
    320       0.00855      0.16656      0.00000      0.03398      1.00000 |                                               *
    330       0.00814      0.16841      0.00000      0.03319      1.00000 |                                               *
    340       0.00766      0.16985      0.00000      0.03319      1.00000 |                                               *
    350       0.00700      0.17194      0.00000      0.03346      1.00000 |                                               *
    360       0.00676      0.17338      0.00000      0.03346      1.00000 |                                               *
    370       0.00638      0.17514      0.00000      0.03346      1.00000 |                                               *
    380       0.00614      0.17680      0.00000      0.03346      1.00000 |                                               *
    390       0.00596      0.17821      0.00000      0.03372      1.00000 |                                               *
    400       0.00555      0.17991      0.00000      0.03398      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.40      6.60  CHILDYRS
    331      1    400      1      7      4.42      2.96  INCOME
    325      1    400      1      7      3.83      3.39  AGE
    321      1    400      1      7      4.33      2.95  AGE_MOM
    307      1    400      1      7      4.54      2.66  OTH_CHLD
    275      1    400      1      7      4.31      2.54  EDUC_MOM
    240      1    400      2      7      5.18      1.69  ILLEGIT
    187      2    400      2      7      5.43      1.20  PNCLATE
    185      1    400      2      7      5.37      1.22  RACE_MOM
    167      4    400      1      7      5.24      1.15  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    88 terminal nodes
    Average :     36.55750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 16 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 16 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 28846 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.10979
                  ROC            6      0.84523
                 Lift            2      5.00000
              KS-stat           27      0.56018
          Class.Error            2      0.02871

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10920     0.12221     0.92148     0.73431     7.60070     4.34949     0.69852     0.40970     0.02910     0.02898
      2     0.10064     0.11852     0.93849     0.79777     7.91855     5.00000     0.72985     0.49639     0.02897     0.02871
      6     0.08279     0.11246     0.95850     0.84523     8.50679     4.81818     0.78552     0.54117     0.02673     0.02871
     10     0.07340     0.11068     0.96665     0.83955     8.77828     4.50909     0.82346     0.54581     0.02476     0.02977
     16     0.06480     0.10979     0.97459     0.83993     9.14027     4.63636     0.85176     0.53615     0.02344     0.03056
     20     0.05956     0.11031     0.98194     0.83715     9.41176     4.54545     0.87351     0.54470     0.02239     0.03003
     27     0.05307     0.11125     0.99023     0.83758     9.77376     4.72727     0.92623     0.56018     0.02160     0.03082
     30     0.05023     0.11190     0.99309     0.83830     9.95475     4.72727     0.94926     0.55421     0.02094     0.03109
     40     0.04598     0.11375     0.99479     0.83737     9.95475     4.54545     0.95492     0.52302     0.01975     0.03109
     50     0.04128     0.11566     0.99629     0.83537     9.95475     4.54545     0.96274     0.52301     0.01725     0.03109
     60     0.03656     0.11825     0.99787     0.83044     9.95475     4.54545     0.97337     0.52153     0.01501     0.03267
     70     0.03263     0.12162     0.99859     0.82402     9.95475     4.63636     0.97725     0.50417     0.01172     0.03267
     79     0.03057     0.12364     0.99893     0.81887    10.00000     4.54545     0.97847     0.49929     0.01001     0.03214
     80     0.03049     0.12375     0.99894     0.81878    10.00000     4.54545     0.97847     0.50037     0.01001     0.03214
     90     0.02802     0.12685     0.99918     0.81416    10.00000     4.54545     0.98159     0.48651     0.00803     0.03240
    100     0.02552     0.12942     0.99970     0.81089    10.00000     4.45455     0.99019     0.49195     0.00672     0.03267
    110     0.02415     0.13133     0.99977     0.80769    10.00000     4.54545     0.99059     0.48541     0.00566     0.03240
    120     0.02281     0.13333     0.99985     0.80455    10.00000     4.45455     0.99403     0.48147     0.00487     0.03319
    130     0.02166     0.13538     0.99991     0.80181    10.00000     4.27273     0.99742     0.47008     0.00448     0.03346
    140     0.02062     0.13665     0.99993     0.80293    10.00000     4.27273     0.99742     0.47157     0.00408     0.03372
    150     0.01896     0.13912     0.99996     0.80081    10.00000     4.36364     0.99797     0.46004     0.00316     0.03346
    160     0.01744     0.14085     0.99998     0.80181    10.00000     4.27273     0.99851     0.46370     0.00237     0.03346
    170     0.01629     0.14322     0.99999     0.79850    10.00000     4.18182     0.99919     0.46669     0.00211     0.03346
    180     0.01540     0.14575     1.00000     0.79425    10.00000     4.00000     0.99973     0.44755     0.00184     0.03372
    190     0.01475     0.14755     1.00000     0.79137    10.00000     3.90909     0.99986     0.45583     0.00119     0.03425
    191     0.01453     0.14793     1.00000     0.79105    10.00000     3.90909     1.00000     0.44973     0.00119     0.03372
    200     0.01407     0.14874     1.00000     0.79135    10.00000     4.00000     1.00000     0.45055     0.00092     0.03398
    210     0.01372     0.14972     1.00000     0.79026    10.00000     4.09091     1.00000     0.44010     0.00092     0.03319
    220     0.01335     0.15109     1.00000     0.78693    10.00000     4.00000     1.00000     0.44837     0.00053     0.03346
    230     0.01289     0.15217     1.00000     0.78447    10.00000     3.90909     1.00000     0.44431     0.00053     0.03372
    240     0.01245     0.15372     1.00000     0.78097    10.00000     3.90909     1.00000     0.43617     0.00040     0.03372
    250     0.01199     0.15505     1.00000     0.77935    10.00000     3.90909     1.00000     0.42528     0.00040     0.03372
    260     0.01150     0.15702     1.00000     0.78029    10.00000     4.00000     1.00000     0.42651     0.00040     0.03372
    270     0.01097     0.15832     1.00000     0.78073    10.00000     3.90909     1.00000     0.43167     0.00040     0.03372
    280     0.01058     0.15992     1.00000     0.78073    10.00000     3.96364     1.00000     0.43492     0.00026     0.03372
    290     0.01025     0.16125     1.00000     0.78017    10.00000     4.05455     1.00000     0.43642     0.00026     0.03372
    300     0.00981     0.16283     1.00000     0.77977    10.00000     3.96364     1.00000     0.44062     0.00026     0.03372
    310     0.00898     0.16448     1.00000     0.78030    10.00000     4.00000     1.00000     0.44239     0.00013     0.03398
    314     0.00879     0.16519     1.00000     0.78031    10.00000     4.09091     1.00000     0.44727     0.00000     0.03398
    320     0.00855     0.16656     1.00000     0.77776    10.00000     4.09091     1.00000     0.44388     0.00000     0.03398
    330     0.00814     0.16841     1.00000     0.77490    10.00000     4.09091     1.00000     0.43832     0.00000     0.03319
    340     0.00766     0.16985     1.00000     0.77505    10.00000     4.00000     1.00000     0.43642     0.00000     0.03319
    350     0.00700     0.17194     1.00000     0.77410    10.00000     4.00000     1.00000     0.44185     0.00000     0.03346
    360     0.00676     0.17338     1.00000     0.77491    10.00000     4.00000     1.00000     0.44890     0.00000     0.03346
    370     0.00638     0.17514     1.00000     0.77502    10.00000     4.09091     1.00000     0.44171     0.00000     0.03346
    380     0.00614     0.17680     1.00000     0.77217    10.00000     4.09091     1.00000     0.43683     0.00000     0.03346
    390     0.00596     0.17821     1.00000     0.77104    10.00000     4.14545     1.00000     0.42951     0.00000     0.03372
    400     0.00555     0.17991     1.00000     0.77507    10.00000     4.09091     1.00000     0.43547     0.00000     0.03398


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      42.90343   42.90 |*****      |
 AGE          37.89761   37.90 |*****      |
 INCOME       30.94021   30.94 |****       |
 OTH_CHLD     28.89289   28.89 |****       |
 EDUC_MOM     24.98017   24.98 |***        |
 ILLEGIT      17.66205   17.66 |***        |
 RACE_MOM     15.99980   16.00 |***        |
 PNCLATE      12.66385   12.66 |**         |
 LBW           8.01077    8.01 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7370.00         3.00       0.0004
 1                  221.00        46.00       175.00       0.7919


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3676.00        10.00       0.0027
 1                  110.00         4.00       106.00       0.9636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs,  50.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  50.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.3 MB, 75% compression

 Grove file created containing:
      1 TreeNet

