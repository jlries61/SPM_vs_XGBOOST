
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10356      0.12272      0.02910      0.02898      1.00000 |                                               *
      2       0.09463      0.12084      0.02660      0.02845      1.00000 |                                              *
      3       0.08898      0.11928      0.02634      0.02950      1.00000 |                                              *
      4       0.08252      0.11761      0.02634      0.02950      1.00000 |                                             *
      5       0.07797      0.11675      0.02607      0.02977      1.00000 |                                             *
      6       0.07408      0.11626      0.02528      0.02977      1.00000 |                                            *
      7       0.07124      0.11548      0.02502      0.03003      1.00000 |                                            *
      8       0.06855      0.11437      0.02462      0.02950      1.00000 |                                            *
      9       0.06654      0.11400      0.02436      0.02924      1.00000 |                                            *
     10       0.06479      0.11348      0.02344      0.02924      1.00000 |                                           *
     11       0.06270      0.11330      0.02318      0.02950      1.00000 |                                           *
     12       0.06059      0.11354      0.02265      0.02950      1.00000 |                                           *
     13       0.05905      0.11354      0.02199      0.02977      1.00000 |                                           *
     14       0.05740      0.11355      0.02160      0.02977      1.00000 |                                           *
     15       0.05609      0.11407      0.02146      0.02977      1.00000 |                                            *
     16       0.05451      0.11434      0.02081      0.03003      1.00000 |                                            *
     17       0.05301      0.11433      0.02002      0.03003      1.00000 |                                            *
     18       0.05211      0.11433      0.01936      0.03003      1.00000 |                                            *
     19       0.05111      0.11449      0.01909      0.03003      1.00000 |                                            *
     20       0.04975      0.11474      0.01883      0.03003      1.00000 |                                            *
     30       0.04243      0.11720      0.01725      0.03056      1.00000 |                                             *
     40       0.03747      0.11982      0.01475      0.03056      1.00000 |                                              *
     50       0.03230      0.12256      0.01146      0.03082      1.00000 |                                               *
     60       0.02745      0.12597      0.00843      0.03135      1.00000 |                                               *
     70       0.02484      0.12818      0.00593      0.03135      1.00000 |                                               *
     80       0.02268      0.13035      0.00500      0.03161      1.00000 |                                               *
     90       0.02063      0.13280      0.00382      0.03135      1.00000 |                                               *
    100       0.01902      0.13448      0.00198      0.03214      1.00000 |                                               *
    110       0.01687      0.13699      0.00132      0.03293      1.00000 |                                               *
    120       0.01516      0.13922      0.00092      0.03267      1.00000 |                                               *
    130       0.01369      0.14191      0.00079      0.03267      1.00000 |                                               *
    140       0.01275      0.14377      0.00040      0.03240      1.00000 |                                               *
    150       0.01150      0.14609      0.00000      0.03267      1.00000 |                                               *
    160       0.01064      0.14884      0.00000      0.03240      1.00000 |                                               *
    170       0.00975      0.15136      0.00000      0.03267      1.00000 |                                               *
    180       0.00892      0.15363      0.00000      0.03188      1.00000 |                                               *
    190       0.00816      0.15571      0.00000      0.03240      1.00000 |                                               *
    200       0.00727      0.15839      0.00000      0.03240      1.00000 |                                               *
    210       0.00656      0.16140      0.00000      0.03293      1.00000 |                                               *
    220       0.00627      0.16268      0.00000      0.03319      1.00000 |                                               *
    230       0.00564      0.16508      0.00000      0.03293      1.00000 |                                               *
    240       0.00509      0.16710      0.00000      0.03293      1.00000 |                                               *
    250       0.00473      0.16895      0.00000      0.03267      1.00000 |                                               *
    260       0.00429      0.17108      0.00000      0.03267      1.00000 |                                               *
    270       0.00399      0.17351      0.00000      0.03267      1.00000 |                                               *
    280       0.00365      0.17619      0.00000      0.03293      1.00000 |                                               *
    290       0.00336      0.17838      0.00000      0.03346      1.00000 |                                               *
    300       0.00300      0.18175      0.00000      0.03372      1.00000 |                                               *
    310       0.00275      0.18498      0.00000      0.03319      1.00000 |                                               *
    320       0.00241      0.18823      0.00000      0.03319      1.00000 |                                               *
    330       0.00223      0.19094      0.00000      0.03319      1.00000 |                                               *
    340       0.00201      0.19399      0.00000      0.03319      1.00000 |                                               *
    350       0.00184      0.19746      0.00000      0.03267      1.00000 |                                               *
    360       0.00172      0.20045      0.00000      0.03293      1.00000 |                                               *
    370       0.00159      0.20334      0.00000      0.03240      1.00000 |                                               *
    380       0.00146      0.20689      0.00000      0.03293      1.00000 |                                               *
    390       0.00130      0.21008      0.00000      0.03346      1.00000 |                                               *
    400       0.00115      0.21308      0.00000      0.03346      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      7      3.31      4.69  AGE
    400      1    400      1      3      1.58      6.42  CHILDYRS
    386      1    400      1      7      3.94      3.92  AGE_MOM
    382      1    400      1      7      4.03      3.79  INCOME
    375      1    400      1      7      4.34      3.44  OTH_CHLD
    366      1    400      1      7      4.31      3.37  EDUC_MOM
    299      1    400      2      7      5.20      2.10  ILLEGIT
    291      1    400      2      7      5.25      2.00  RACE_MOM
    265      1    400      1      7      5.22      1.84  PNCLATE
    231      3    400      2      7      5.06      1.70  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    13 terminal nodes
    Largest :   103 terminal nodes
    Average :     58.04750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 34 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 34 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 11

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 46038 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           11      0.11330
                  ROC           34      0.81562
                 Lift           21      5.00000
              KS-stat          106      0.51649
          Class.Error            2      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10356     0.12272     0.93393     0.73145     7.95278     4.33697     0.71649     0.42367     0.02910     0.02898
      2     0.09463     0.12084     0.94293     0.76070     8.13739     4.21581     0.74271     0.45992     0.02660     0.02845
     10     0.06479     0.11348     0.97844     0.80497     9.14027     4.63636     0.85638     0.50346     0.02344     0.02924
     11     0.06270     0.11330     0.98045     0.80593     9.23077     4.63636     0.86751     0.50238     0.02318     0.02950
     20     0.04975     0.11474     0.98958     0.80962     9.50226     4.81818     0.90763     0.48530     0.01883     0.03003
     21     0.04858     0.11477     0.99041     0.81078     9.54751     5.00000     0.91573     0.47620     0.01857     0.03030
     30     0.04243     0.11720     0.99528     0.81253     9.81900     4.81818     0.94409     0.48584     0.01725     0.03056
     34     0.04031     0.11814     0.99581     0.81562     9.81900     5.00000     0.95037     0.49983     0.01593     0.03030
     40     0.03747     0.11982     0.99654     0.81445     9.86425     4.81818     0.95246     0.49793     0.01475     0.03056
     46     0.03452     0.12125     0.99840     0.81287    10.00000     4.96364     0.96829     0.49982     0.01356     0.03109
     50     0.03230     0.12256     0.99879     0.81108    10.00000     4.81818     0.97005     0.49290     0.01146     0.03082
     60     0.02745     0.12597     0.99958     0.80899    10.00000     4.81818     0.98395     0.49573     0.00843     0.03135
     70     0.02484     0.12818     0.99981     0.80854    10.00000     4.54545     0.99118     0.50170     0.00593     0.03135
     80     0.02268     0.13035     0.99991     0.80834    10.00000     4.63636     0.99240     0.51377     0.00500     0.03161
     90     0.02063     0.13280     0.99994     0.80692    10.00000     4.54545     0.99349     0.50442     0.00382     0.03135
    100     0.01902     0.13448     0.99996     0.80564    10.00000     4.45455     0.99403     0.51446     0.00198     0.03214
    106     0.01764     0.13611     0.99999     0.80491    10.00000     4.36364     0.99919     0.51649     0.00171     0.03240
    110     0.01687     0.13699     1.00000     0.80399    10.00000     4.36364     0.99946     0.51581     0.00132     0.03293
    112     0.01634     0.13749     1.00000     0.80379    10.00000     4.36364     1.00000     0.50781     0.00119     0.03240
    120     0.01516     0.13922     1.00000     0.80315    10.00000     4.45455     1.00000     0.50591     0.00092     0.03267
    130     0.01369     0.14191     1.00000     0.79983    10.00000     4.50909     1.00000     0.49967     0.00079     0.03267
    140     0.01275     0.14377     1.00000     0.80079    10.00000     4.27273     1.00000     0.49411     0.00040     0.03240
    146     0.01191     0.14557     1.00000     0.80000    10.00000     4.45455     1.00000     0.48923     0.00000     0.03240
    150     0.01150     0.14609     1.00000     0.80052    10.00000     4.45455     1.00000     0.48693     0.00000     0.03267
    160     0.01064     0.14884     1.00000     0.79716    10.00000     4.27273     1.00000     0.49492     0.00000     0.03240
    170     0.00975     0.15136     1.00000     0.79484    10.00000     4.23636     1.00000     0.48705     0.00000     0.03267
    180     0.00892     0.15363     1.00000     0.79397    10.00000     4.18182     1.00000     0.47104     0.00000     0.03188
    190     0.00816     0.15571     1.00000     0.79479    10.00000     4.00000     1.00000     0.47485     0.00000     0.03240
    200     0.00727     0.15839     1.00000     0.79342    10.00000     3.90909     1.00000     0.46264     0.00000     0.03240
    210     0.00656     0.16140     1.00000     0.79390    10.00000     4.05455     1.00000     0.47160     0.00000     0.03293
    220     0.00627     0.16268     1.00000     0.79582    10.00000     3.96364     1.00000     0.46984     0.00000     0.03319
    230     0.00564     0.16508     1.00000     0.79675    10.00000     4.05455     1.00000     0.48191     0.00000     0.03293
    240     0.00509     0.16710     1.00000     0.79636    10.00000     4.09091     1.00000     0.48680     0.00000     0.03293
    250     0.00473     0.16895     1.00000     0.79659    10.00000     4.09091     1.00000     0.47798     0.00000     0.03267
    260     0.00429     0.17108     1.00000     0.79532    10.00000     4.00000     1.00000     0.47865     0.00000     0.03267
    270     0.00399     0.17351     1.00000     0.79464    10.00000     3.90909     1.00000     0.46658     0.00000     0.03267
    280     0.00365     0.17619     1.00000     0.79570    10.00000     4.09091     1.00000     0.47716     0.00000     0.03293
    290     0.00336     0.17838     1.00000     0.79730    10.00000     4.09091     1.00000     0.46981     0.00000     0.03346
    300     0.00300     0.18175     1.00000     0.79717    10.00000     4.18182     1.00000     0.47673     0.00000     0.03372
    310     0.00275     0.18498     1.00000     0.79413    10.00000     4.18182     1.00000     0.47130     0.00000     0.03319
    320     0.00241     0.18823     1.00000     0.79584    10.00000     4.18182     1.00000     0.47646     0.00000     0.03319
    330     0.00223     0.19094     1.00000     0.79601    10.00000     4.09091     1.00000     0.47768     0.00000     0.03319
    340     0.00201     0.19399     1.00000     0.79461    10.00000     4.09091     1.00000     0.47228     0.00000     0.03319
    350     0.00184     0.19746     1.00000     0.79470    10.00000     4.09091     1.00000     0.46958     0.00000     0.03267
    360     0.00172     0.20045     1.00000     0.79405    10.00000     4.18182     1.00000     0.46645     0.00000     0.03293
    370     0.00159     0.20334     1.00000     0.79386    10.00000     4.09091     1.00000     0.46101     0.00000     0.03240
    380     0.00146     0.20689     1.00000     0.79411    10.00000     4.09091     1.00000     0.46696     0.00000     0.03293
    390     0.00130     0.21008     1.00000     0.79289    10.00000     4.18182     1.00000     0.46072     0.00000     0.03346
    400     0.00115     0.21308     1.00000     0.79256    10.00000     4.18182     1.00000     0.45949     0.00000     0.03346


 =========================================
 Variable Importance for the 11-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          36.31894   36.32 |*****      |
 AGE_MOM      34.37174   34.37 |****       |
 EDUC_MOM     27.32944   27.33 |****       |
 INCOME       26.88331   26.88 |****       |
 ILLEGIT      23.12300   23.12 |***        |
 OTH_CHLD     23.11655   23.12 |***        |
 PNCLATE      13.37155   13.37 |**         |
 RACE_MOM     10.82431   10.82 |**         |
 LBW           6.99796    7.00 |**         |


 Learn Sample Misclassification by Target Class
 For The 11-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        47.00       174.00       0.7873


 Test Sample Misclassification by Target Class
 For The 11-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3679.00         7.00       0.0019
 1                  110.00         5.00       105.00       0.9545

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

