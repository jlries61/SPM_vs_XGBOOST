
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11330      0.12134      0.02910      0.02898      1.00000 |                                               *
      2       0.10597      0.11787      0.02910      0.02898      1.00000 |                                              *
      3       0.10011      0.11591      0.02792      0.02845      1.00000 |                                             *
      4       0.09555      0.11482      0.02792      0.02845      1.00000 |                                            *
      5       0.09120      0.11355      0.02792      0.02845      1.00000 |                                            *
      6       0.08731      0.11234      0.02792      0.02845      1.00000 |                                           *
      7       0.08445      0.11163      0.02792      0.02845      1.00000 |                                           *
      8       0.08143      0.11087      0.02779      0.02845      1.00000 |                                           *
      9       0.07885      0.11060      0.02779      0.02845      1.00000 |                                           *
     10       0.07678      0.11000      0.02779      0.02845      1.00000 |                                           *
     11       0.07442      0.10977      0.02765      0.02845      1.00000 |                                          *
     12       0.07278      0.10965      0.02726      0.02845      1.00000 |                                          *
     13       0.07092      0.10955      0.02686      0.02792      1.00000 |                                          *
     14       0.06980      0.10930      0.02634      0.02792      1.00000 |                                          *
     15       0.06887      0.10922      0.02620      0.02819      1.00000 |                                          *
     16       0.06773      0.10919      0.02594      0.02819      1.00000 |                                          *
     17       0.06631      0.10938      0.02568      0.02845      1.00000 |                                          *
     18       0.06534      0.10922      0.02541      0.02845      1.00000 |                                          *
     19       0.06432      0.10928      0.02528      0.02845      1.00000 |                                          *
     20       0.06341      0.10940      0.02489      0.02924      1.00000 |                                          *
     30       0.05596      0.11036      0.02344      0.02950      1.00000 |                                           *
     40       0.05033      0.11179      0.02212      0.03003      1.00000 |                                           *
     50       0.04738      0.11348      0.02081      0.02977      1.00000 |                                            *
     60       0.04503      0.11532      0.01936      0.03030      1.00000 |                                             *
     70       0.04239      0.11677      0.01817      0.03082      1.00000 |                                             *
     80       0.04036      0.11826      0.01712      0.03135      1.00000 |                                              *
     90       0.03778      0.12017      0.01580      0.03082      1.00000 |                                               *
    100       0.03464      0.12239      0.01383      0.03188      1.00000 |                                               *
    110       0.03324      0.12399      0.01317      0.03161      1.00000 |                                               *
    120       0.03161      0.12535      0.01225      0.03161      1.00000 |                                               *
    130       0.02965      0.12745      0.01014      0.03135      1.00000 |                                               *
    140       0.02780      0.12865      0.00935      0.03161      1.00000 |                                               *
    150       0.02669      0.12996      0.00803      0.03188      1.00000 |                                               *
    160       0.02614      0.13096      0.00764      0.03188      1.00000 |                                               *
    170       0.02521      0.13195      0.00685      0.03188      1.00000 |                                               *
    180       0.02379      0.13392      0.00593      0.03188      1.00000 |                                               *
    190       0.02142      0.13576      0.00395      0.03161      1.00000 |                                               *
    200       0.01995      0.13787      0.00290      0.03214      1.00000 |                                               *
    210       0.01913      0.13944      0.00250      0.03214      1.00000 |                                               *
    220       0.01870      0.14042      0.00250      0.03188      1.00000 |                                               *
    230       0.01701      0.14244      0.00105      0.03267      1.00000 |                                               *
    240       0.01592      0.14342      0.00066      0.03293      1.00000 |                                               *
    250       0.01551      0.14493      0.00053      0.03293      1.00000 |                                               *
    260       0.01505      0.14588      0.00053      0.03267      1.00000 |                                               *
    270       0.01459      0.14700      0.00040      0.03267      1.00000 |                                               *
    280       0.01440      0.14776      0.00040      0.03293      1.00000 |                                               *
    290       0.01401      0.14935      0.00040      0.03267      1.00000 |                                               *
    300       0.01374      0.15075      0.00040      0.03240      1.00000 |                                               *
    310       0.01312      0.15221      0.00026      0.03240      1.00000 |                                               *
    320       0.01233      0.15348      0.00026      0.03214      1.00000 |                                               *
    330       0.01161      0.15516      0.00013      0.03214      1.00000 |                                               *
    340       0.01116      0.15601      0.00000      0.03214      1.00000 |                                               *
    350       0.01023      0.15838      0.00000      0.03214      1.00000 |                                               *
    360       0.00948      0.15964      0.00000      0.03214      1.00000 |                                               *
    370       0.00886      0.16155      0.00000      0.03214      1.00000 |                                               *
    380       0.00833      0.16314      0.00000      0.03188      1.00000 |                                               *
    390       0.00782      0.16564      0.00000      0.03214      1.00000 |                                               *
    400       0.00744      0.16717      0.00000      0.03214      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.52      6.48  CHILDYRS
    340      1    399      1      7      4.75      2.77  AGE_MOM
    328      1    400      1      7      3.33      3.83  AGE
    319      1    399      1      7      4.43      2.85  INCOME
    315      1    400      1      7      3.30      3.70  EDUC_MOM
    300      1    400      1      7      4.32      2.76  OTH_CHLD
    230      1    400      1      7      4.99      1.73  ILLEGIT
    219      1    399      2      7      5.64      1.29  RACE_MOM
    213      1    399      2      7      5.57      1.30  LBW
    151      3    399      1      7      5.72      0.86  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   108 terminal nodes
    Average :     40.22500 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 16 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 16 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 31780 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.10919
                  ROC            2      0.83375
                 Lift            1      5.42539
              KS-stat            2      0.54647
          Class.Error           13      0.02792

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11330     0.12134     0.90581     0.78939     6.70548     5.42539     0.64484     0.48768     0.02910     0.02898
      2     0.10597     0.11787     0.92521     0.83375     7.54299     4.64416     0.69913     0.54647     0.02910     0.02898
     10     0.07678     0.11000     0.97136     0.82244     9.23077     4.72727     0.85106     0.52179     0.02779     0.02845
     13     0.07092     0.10955     0.97966     0.82681     9.36652     4.54545     0.87342     0.53318     0.02686     0.02792
     16     0.06773     0.10919     0.98118     0.82931     9.54751     4.45455     0.88395     0.52640     0.02594     0.02819
     20     0.06341     0.10940     0.98530     0.82929     9.63801     4.63636     0.89747     0.53902     0.02489     0.02924
     30     0.05596     0.11036     0.99036     0.83274     9.77376     4.45455     0.91945     0.53685     0.02344     0.02950
     40     0.05033     0.11179     0.99320     0.83245     9.90950     4.36364     0.92976     0.53752     0.02212     0.03003
     50     0.04738     0.11348     0.99473     0.83019     9.95475     4.36364     0.94533     0.53440     0.02081     0.02977
     60     0.04503     0.11532     0.99574     0.82769     9.95475     4.09091     0.95740     0.53602     0.01936     0.03030
     70     0.04239     0.11677     0.99699     0.82619     9.97285     4.09091     0.96038     0.52381     0.01817     0.03082
     71     0.04230     0.11682     0.99700     0.82623    10.00000     4.09091     0.96038     0.52409     0.01817     0.03082
     80     0.04036     0.11826     0.99760     0.82524    10.00000     4.00000     0.96337     0.51840     0.01712     0.03135
     90     0.03778     0.12017     0.99831     0.82178    10.00000     4.09091     0.97169     0.50552     0.01580     0.03082
    100     0.03464     0.12239     0.99892     0.81917    10.00000     4.18182     0.97888     0.51055     0.01383     0.03188
    110     0.03324     0.12399     0.99911     0.81779    10.00000     4.27273     0.98322     0.50608     0.01317     0.03161
    120     0.03161     0.12535     0.99938     0.81798    10.00000     4.27273     0.98444     0.49657     0.01225     0.03161
    130     0.02965     0.12745     0.99958     0.81639    10.00000     4.18182     0.98978     0.51354     0.01014     0.03135
    140     0.02780     0.12865     0.99965     0.81714    10.00000     4.18182     0.99141     0.50350     0.00935     0.03161
    150     0.02669     0.12996     0.99973     0.81641    10.00000     4.27273     0.99263     0.50011     0.00803     0.03188
    160     0.02614     0.13096     0.99977     0.81571    10.00000     4.23636     0.99371     0.50078     0.00764     0.03188
    170     0.02521     0.13195     0.99983     0.81689    10.00000     4.54545     0.99498     0.50648     0.00685     0.03188
    180     0.02379     0.13392     0.99989     0.81495    10.00000     4.45455     0.99810     0.49889     0.00593     0.03188
    190     0.02142     0.13576     0.99997     0.81365    10.00000     4.54545     0.99851     0.49156     0.00395     0.03161
    200     0.01995     0.13787     0.99998     0.81218    10.00000     4.45455     0.99864     0.51394     0.00290     0.03214
    210     0.01913     0.13944     0.99999     0.81079    10.00000     4.54545     0.99932     0.50770     0.00250     0.03214
    220     0.01870     0.14042     0.99999     0.81082    10.00000     4.45455     0.99959     0.50363     0.00250     0.03188
    230     0.01701     0.14244     1.00000     0.80932    10.00000     4.36364     0.99986     0.49236     0.00105     0.03267
    232     0.01655     0.14276     1.00000     0.81046    10.00000     4.36364     1.00000     0.49467     0.00092     0.03267
    240     0.01592     0.14342     1.00000     0.81065    10.00000     4.41818     1.00000     0.49291     0.00066     0.03293
    250     0.01551     0.14493     1.00000     0.80949    10.00000     4.27273     1.00000     0.49657     0.00053     0.03293
    260     0.01505     0.14588     1.00000     0.80941    10.00000     4.41818     1.00000     0.49752     0.00053     0.03267
    270     0.01459     0.14700     1.00000     0.80806    10.00000     4.36364     1.00000     0.49087     0.00040     0.03267
    280     0.01440     0.14776     1.00000     0.80710    10.00000     4.45455     1.00000     0.49115     0.00040     0.03293
    290     0.01401     0.14935     1.00000     0.80538    10.00000     4.45455     1.00000     0.47812     0.00040     0.03267
    300     0.01374     0.15075     1.00000     0.80662    10.00000     4.36364     1.00000     0.48097     0.00040     0.03240
    310     0.01312     0.15221     1.00000     0.80772    10.00000     4.45455     1.00000     0.48260     0.00026     0.03240
    320     0.01233     0.15348     1.00000     0.80895    10.00000     4.27273     1.00000     0.48571     0.00026     0.03214
    330     0.01161     0.15516     1.00000     0.80970    10.00000     4.27273     1.00000     0.48762     0.00013     0.03214
    335     0.01143     0.15554     1.00000     0.80985    10.00000     4.27273     1.00000     0.48843     0.00000     0.03214
    340     0.01116     0.15601     1.00000     0.80943    10.00000     4.36364     1.00000     0.48274     0.00000     0.03214
    350     0.01023     0.15838     1.00000     0.80877    10.00000     4.27273     1.00000     0.49156     0.00000     0.03214
    360     0.00948     0.15964     1.00000     0.80878    10.00000     4.27273     1.00000     0.49250     0.00000     0.03214
    370     0.00886     0.16155     1.00000     0.80743    10.00000     4.27273     1.00000     0.48708     0.00000     0.03214
    380     0.00833     0.16314     1.00000     0.80635    10.00000     4.09091     1.00000     0.48789     0.00000     0.03188
    390     0.00782     0.16564     1.00000     0.80505    10.00000     4.09091     1.00000     0.47839     0.00000     0.03214
    400     0.00744     0.16717     1.00000     0.80574    10.00000     4.09091     1.00000     0.46944     0.00000     0.03214


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     33.76628   33.77 |****       |
 AGE          28.80793   28.81 |****       |
 AGE_MOM      27.32151   27.32 |****       |
 INCOME       25.55056   25.55 |****       |
 OTH_CHLD     23.93055   23.93 |***        |
 PNCLATE      16.00095   16.00 |***        |
 LBW          12.47384   12.47 |**         |
 ILLEGIT      11.91054   11.91 |**         |
 RACE_MOM      9.87481    9.87 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        26.00       195.00       0.8824


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3684.00         2.00       0.0005
 1                  110.00         5.00       105.00       0.9545

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs,  50.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  50.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000278 hrs 50.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.4 MB, 75% compression

 Grove file created containing:
      1 TreeNet

