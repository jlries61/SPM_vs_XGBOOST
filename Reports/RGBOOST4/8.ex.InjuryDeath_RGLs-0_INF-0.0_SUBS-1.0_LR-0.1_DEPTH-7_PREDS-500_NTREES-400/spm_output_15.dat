
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10938      0.11939      0.02910      0.02898      1.00000 |                                               *
      2       0.10158      0.11601      0.02910      0.02898      1.00000 |                                              *
      3       0.09595      0.11392      0.02884      0.02924      1.00000 |                                             *
      4       0.09163      0.11226      0.02792      0.02977      1.00000 |                                            *
      5       0.08787      0.11102      0.02765      0.02977      1.00000 |                                            *
      6       0.08492      0.10941      0.02765      0.02977      1.00000 |                                           *
      7       0.08239      0.10830      0.02726      0.03003      1.00000 |                                           *
      8       0.08006      0.10730      0.02673      0.03030      1.00000 |                                          *
      9       0.07788      0.10666      0.02594      0.03056      1.00000 |                                          *
     10       0.07576      0.10605      0.02555      0.03003      1.00000 |                                          *
     11       0.07374      0.10564      0.02541      0.03003      1.00000 |                                         *
     12       0.07195      0.10575      0.02515      0.03030      1.00000 |                                          *
     13       0.07040      0.10538      0.02489      0.03056      1.00000 |                                         *
     14       0.06897      0.10509      0.02476      0.03056      1.00000 |                                         *
     15       0.06790      0.10476      0.02410      0.03056      1.00000 |                                         *
     16       0.06687      0.10442      0.02383      0.03056      1.00000 |                                         *
     17       0.06583      0.10437      0.02370      0.03056      1.00000 |                                         *
     18       0.06477      0.10414      0.02383      0.03056      1.00000 |                                         *
     19       0.06395      0.10405      0.02370      0.03056      1.00000 |                                         *
     20       0.06301      0.10375      0.02357      0.03030      1.00000 |                                         *
     30       0.05650      0.10393      0.02265      0.03135      1.00000 |                                         *
     40       0.05231      0.10408      0.02133      0.03082      1.00000 |                                         *
     50       0.04643      0.10539      0.01962      0.03030      1.00000 |                                         *
     60       0.04373      0.10673      0.01844      0.03188      1.00000 |                                          *
     70       0.04176      0.10792      0.01751      0.03214      1.00000 |                                          *
     80       0.04071      0.10883      0.01686      0.03188      1.00000 |                                           *
     90       0.03767      0.10997      0.01528      0.03188      1.00000 |                                           *
    100       0.03609      0.11096      0.01422      0.03214      1.00000 |                                            *
    110       0.03363      0.11234      0.01290      0.03267      1.00000 |                                            *
    120       0.03266      0.11277      0.01251      0.03267      1.00000 |                                            *
    130       0.03082      0.11336      0.01172      0.03267      1.00000 |                                             *
    140       0.02897      0.11400      0.01040      0.03293      1.00000 |                                             *
    150       0.02726      0.11462      0.00895      0.03240      1.00000 |                                             *
    160       0.02674      0.11559      0.00830      0.03267      1.00000 |                                             *
    170       0.02620      0.11628      0.00803      0.03319      1.00000 |                                              *
    180       0.02492      0.11691      0.00685      0.03293      1.00000 |                                              *
    190       0.02405      0.11745      0.00632      0.03267      1.00000 |                                              *
    200       0.02328      0.11785      0.00540      0.03267      1.00000 |                                              *
    210       0.02235      0.11877      0.00514      0.03240      1.00000 |                                               *
    220       0.02220      0.11920      0.00514      0.03240      1.00000 |                                               *
    230       0.02135      0.11980      0.00448      0.03214      1.00000 |                                               *
    240       0.02110      0.12002      0.00435      0.03214      1.00000 |                                               *
    250       0.02040      0.12069      0.00342      0.03214      1.00000 |                                               *
    260       0.01973      0.12153      0.00316      0.03240      1.00000 |                                               *
    270       0.01934      0.12206      0.00303      0.03214      1.00000 |                                               *
    280       0.01869      0.12226      0.00277      0.03240      1.00000 |                                               *
    290       0.01826      0.12255      0.00263      0.03240      1.00000 |                                               *
    300       0.01738      0.12373      0.00211      0.03214      1.00000 |                                               *
    310       0.01663      0.12460      0.00158      0.03188      1.00000 |                                               *
    320       0.01622      0.12515      0.00158      0.03214      1.00000 |                                               *
    330       0.01578      0.12612      0.00132      0.03214      1.00000 |                                               *
    340       0.01526      0.12663      0.00119      0.03214      1.00000 |                                               *
    350       0.01492      0.12721      0.00119      0.03240      1.00000 |                                               *
    360       0.01426      0.12818      0.00092      0.03267      1.00000 |                                               *
    370       0.01356      0.12943      0.00066      0.03240      1.00000 |                                               *
    380       0.01305      0.13005      0.00066      0.03293      1.00000 |                                               *
    390       0.01270      0.13108      0.00053      0.03319      1.00000 |                                               *
    400       0.01189      0.13200      0.00040      0.03319      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.27      6.73  CHILDYRS
    254      1    399      1      7      3.97      2.56  AGE
    240      1    400      1      7      4.70      1.98  OTH_CHLD
    235      1    398      1      7      4.51      2.05  INCOME
    227      1    398      1      7      4.20      2.16  EDUC_MOM
    218      1    398      1      7      4.25      2.05  AGE_MOM
    168      1    398      1      7      4.52      1.46  ILLEGIT
    124      1    398      2      7      5.27      0.85  LBW
    116      2    397      3      7      5.41      0.75  RACE_MOM
    116      1    398      2      7      5.47      0.74  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   105 terminal nodes
    Average :     29.38250 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 43 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 43 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 20

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 23106 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           20      0.10375
                  ROC           43      0.86697
                 Lift           14      5.72727
              KS-stat           48      0.60279
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10938     0.11939     0.93194     0.79775     7.50528     4.68951     0.70361     0.52242     0.02910     0.02898
     10     0.07576     0.10605     0.97024     0.85105     9.04977     5.45455     0.83323     0.56670     0.02555     0.03003
     14     0.06897     0.10509     0.97665     0.85524     9.23077     5.72727     0.85781     0.57212     0.02476     0.03056
     20     0.06301     0.10375     0.98235     0.86204     9.54751     5.72727     0.88427     0.58704     0.02357     0.03030
     30     0.05650     0.10393     0.98889     0.86534     9.77376     5.54545     0.90690     0.58067     0.02265     0.03135
     40     0.05231     0.10408     0.99199     0.86650     9.95475     5.63636     0.93498     0.58705     0.02133     0.03082
     43     0.05111     0.10435     0.99268     0.86697     9.95475     5.72727     0.93526     0.59166     0.02094     0.03056
     48     0.04809     0.10517     0.99436     0.86527     9.95475     5.72727     0.94366     0.60279     0.02002     0.03030
     50     0.04643     0.10539     0.99524     0.86557     9.95475     5.54545     0.95180     0.59330     0.01962     0.03030
     60     0.04373     0.10673     0.99610     0.86427     9.95475     5.54545     0.95818     0.59424     0.01844     0.03188
     70     0.04176     0.10792     0.99667     0.86273     9.95475     5.36364     0.95967     0.58284     0.01751     0.03214
     80     0.04071     0.10883     0.99691     0.86053     9.95475     5.36364     0.96103     0.56847     0.01686     0.03188
     83     0.03920     0.10943     0.99755     0.86009    10.00000     5.36364     0.96355     0.56438     0.01593     0.03214
     90     0.03767     0.10997     0.99804     0.85913    10.00000     5.27273     0.96848     0.55935     0.01528     0.03188
    100     0.03609     0.11096     0.99846     0.85763    10.00000     5.27273     0.97459     0.56559     0.01422     0.03214
    110     0.03363     0.11234     0.99894     0.85637    10.00000     5.18182     0.97816     0.56683     0.01290     0.03267
    120     0.03266     0.11277     0.99911     0.85604    10.00000     5.09091     0.97974     0.56169     0.01251     0.03267
    130     0.03082     0.11336     0.99940     0.85612    10.00000     5.09091     0.98712     0.56005     0.01172     0.03267
    140     0.02897     0.11400     0.99964     0.85655    10.00000     5.18182     0.98983     0.56316     0.01040     0.03293
    150     0.02726     0.11462     0.99975     0.85676    10.00000     5.18182     0.99295     0.56615     0.00895     0.03240
    160     0.02674     0.11559     0.99978     0.85473    10.00000     5.09091     0.99335     0.56723     0.00830     0.03267
    170     0.02620     0.11628     0.99979     0.85378    10.00000     5.09091     0.99363     0.56085     0.00803     0.03319
    180     0.02492     0.11691     0.99986     0.85424    10.00000     5.00000     0.99525     0.56179     0.00685     0.03293
    190     0.02405     0.11745     0.99990     0.85424    10.00000     5.00000     0.99647     0.55894     0.00632     0.03267
    200     0.02328     0.11785     0.99992     0.85432    10.00000     5.09091     0.99756     0.55964     0.00540     0.03267
    210     0.02235     0.11877     0.99994     0.85418    10.00000     4.81818     0.99824     0.56615     0.00514     0.03240
    220     0.02220     0.11920     0.99994     0.85312    10.00000     4.81818     0.99851     0.56588     0.00514     0.03240
    230     0.02135     0.11980     0.99996     0.85297    10.00000     4.72727     0.99878     0.55885     0.00448     0.03214
    240     0.02110     0.12002     0.99996     0.85263    10.00000     4.72727     0.99878     0.55777     0.00435     0.03214
    250     0.02040     0.12069     0.99998     0.85210    10.00000     4.81818     0.99891     0.56184     0.00342     0.03214
    260     0.01973     0.12153     0.99998     0.85087    10.00000     4.72727     0.99891     0.56061     0.00316     0.03240
    270     0.01934     0.12206     0.99998     0.85006    10.00000     4.81818     0.99905     0.55544     0.00303     0.03214
    280     0.01869     0.12226     0.99998     0.85161    10.00000     4.90909     0.99905     0.55325     0.00277     0.03240
    290     0.01826     0.12255     0.99999     0.85111    10.00000     5.00000     0.99919     0.55245     0.00263     0.03240
    300     0.01738     0.12373     0.99999     0.85003    10.00000     5.00000     0.99932     0.55259     0.00211     0.03214
    310     0.01663     0.12460     1.00000     0.85025    10.00000     5.00000     0.99959     0.55166     0.00158     0.03188
    320     0.01622     0.12515     1.00000     0.85014    10.00000     4.90909     0.99973     0.55434     0.00158     0.03214
    330     0.01578     0.12612     1.00000     0.84952    10.00000     4.90909     0.99973     0.55911     0.00132     0.03214
    340     0.01526     0.12663     1.00000     0.84992    10.00000     4.96364     0.99986     0.56535     0.00119     0.03214
    345     0.01495     0.12716     1.00000     0.85005    10.00000     5.05455     1.00000     0.56696     0.00119     0.03240
    350     0.01492     0.12721     1.00000     0.84996    10.00000     5.05455     1.00000     0.56696     0.00119     0.03240
    360     0.01426     0.12818     1.00000     0.84944    10.00000     5.05455     1.00000     0.56359     0.00092     0.03267
    370     0.01356     0.12943     1.00000     0.84862    10.00000     4.90909     1.00000     0.56438     0.00066     0.03240
    380     0.01305     0.13005     1.00000     0.84894    10.00000     4.90909     1.00000     0.56520     0.00066     0.03293
    390     0.01270     0.13108     1.00000     0.84777    10.00000     4.90909     1.00000     0.56033     0.00053     0.03319
    397     0.01196     0.13201     1.00000     0.84805    10.00000     4.81818     1.00000     0.56074     0.00040     0.03319
    400     0.01189     0.13200     1.00000     0.84865    10.00000     4.81818     1.00000     0.56237     0.00040     0.03319


 =========================================
 Variable Importance for the 20-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     38.68449   38.68 |*****      |
 AGE          32.23908   32.24 |****       |
 OTH_CHLD     31.04230   31.04 |****       |
 INCOME       26.54451   26.54 |****       |
 ILLEGIT      24.86661   24.87 |***        |
 AGE_MOM      22.86370   22.86 |***        |
 PNCLATE      15.86800   15.87 |***        |
 LBW          11.23443   11.23 |**         |
 RACE_MOM     10.97922   10.98 |**         |


 Learn Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7368.00         5.00       0.0007
 1                  221.00        47.00       174.00       0.7873


 Test Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3675.00        11.00       0.0030
 1                  110.00         6.00       104.00       0.9455

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1 MB, 75% compression

 Grove file created containing:
      1 TreeNet

