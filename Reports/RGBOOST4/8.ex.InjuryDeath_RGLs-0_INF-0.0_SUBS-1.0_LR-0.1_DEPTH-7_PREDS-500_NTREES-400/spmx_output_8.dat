
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11109      0.11745      0.02910      0.02898      1.00000 |                                               *
      2       0.10441      0.11383      0.02910      0.02898      1.00000 |                                              *
      3       0.09936      0.11154      0.02792      0.02792      1.00000 |                                             *
      4       0.09488      0.10923      0.02792      0.02792      1.00000 |                                            *
      5       0.09102      0.10717      0.02792      0.02792      1.00000 |                                           *
      6       0.08772      0.10608      0.02792      0.02792      1.00000 |                                          *
      7       0.08525      0.10513      0.02792      0.02792      1.00000 |                                          *
      8       0.08254      0.10450      0.02792      0.02792      1.00000 |                                          *
      9       0.08048      0.10377      0.02779      0.02792      1.00000 |                                         *
     10       0.07844      0.10307      0.02752      0.02766      1.00000 |                                         *
     11       0.07662      0.10259      0.02739      0.02766      1.00000 |                                         *
     12       0.07540      0.10231      0.02673      0.02792      1.00000 |                                         *
     13       0.07339      0.10208      0.02647      0.02766      1.00000 |                                         *
     14       0.07169      0.10159      0.02647      0.02766      1.00000 |                                         *
     15       0.07020      0.10179      0.02607      0.02740      1.00000 |                                         *
     16       0.06883      0.10161      0.02555      0.02766      1.00000 |                                         *
     17       0.06738      0.10154      0.02555      0.02740      1.00000 |                                        *
     18       0.06536      0.10164      0.02476      0.02740      1.00000 |                                         *
     19       0.06417      0.10159      0.02476      0.02713      1.00000 |                                         *
     20       0.06303      0.10140      0.02489      0.02740      1.00000 |                                        *
     30       0.05566      0.10209      0.02304      0.02713      1.00000 |                                         *
     40       0.05076      0.10292      0.02186      0.02740      1.00000 |                                         *
     50       0.04663      0.10335      0.02015      0.02766      1.00000 |                                         *
     60       0.04303      0.10402      0.01791      0.02713      1.00000 |                                          *
     70       0.03885      0.10551      0.01633      0.02687      1.00000 |                                          *
     80       0.03604      0.10628      0.01383      0.02661      1.00000 |                                          *
     90       0.03317      0.10764      0.01225      0.02713      1.00000 |                                           *
    100       0.03142      0.10859      0.01106      0.02766      1.00000 |                                           *
    110       0.02902      0.11002      0.00909      0.02845      1.00000 |                                            *
    120       0.02664      0.11173      0.00777      0.02898      1.00000 |                                             *
    130       0.02498      0.11323      0.00619      0.02924      1.00000 |                                             *
    140       0.02364      0.11467      0.00527      0.02898      1.00000 |                                              *
    150       0.02232      0.11585      0.00435      0.02871      1.00000 |                                              *
    160       0.02083      0.11801      0.00290      0.02871      1.00000 |                                               *
    170       0.01965      0.11950      0.00211      0.02871      1.00000 |                                               *
    180       0.01936      0.12019      0.00211      0.02898      1.00000 |                                               *
    190       0.01851      0.12117      0.00171      0.02898      1.00000 |                                               *
    200       0.01757      0.12303      0.00158      0.02950      1.00000 |                                               *
    210       0.01666      0.12460      0.00105      0.02898      1.00000 |                                               *
    220       0.01635      0.12533      0.00079      0.02950      1.00000 |                                               *
    230       0.01521      0.12718      0.00066      0.02950      1.00000 |                                               *
    240       0.01413      0.12913      0.00026      0.02977      1.00000 |                                               *
    250       0.01381      0.12968      0.00026      0.03003      1.00000 |                                               *
    260       0.01327      0.13061      0.00026      0.03056      1.00000 |                                               *
    270       0.01283      0.13171      0.00026      0.03030      1.00000 |                                               *
    280       0.01219      0.13233      0.00013      0.03030      1.00000 |                                               *
    290       0.01160      0.13336      0.00013      0.03030      1.00000 |                                               *
    300       0.01120      0.13439      0.00000      0.03082      1.00000 |                                               *
    310       0.01083      0.13536      0.00000      0.03082      1.00000 |                                               *
    320       0.00998      0.13686      0.00000      0.03082      1.00000 |                                               *
    330       0.00946      0.13797      0.00000      0.03109      1.00000 |                                               *
    340       0.00893      0.13938      0.00000      0.03109      1.00000 |                                               *
    350       0.00862      0.14100      0.00000      0.03109      1.00000 |                                               *
    360       0.00844      0.14197      0.00000      0.03109      1.00000 |                                               *
    370       0.00774      0.14412      0.00000      0.03109      1.00000 |                                               *
    380       0.00722      0.14537      0.00000      0.03161      1.00000 |                                               *
    390       0.00684      0.14648      0.00000      0.03082      1.00000 |                                               *
    400       0.00637      0.14774      0.00000      0.03056      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.46      6.54  CHILDYRS
    296      1    400      1      7      3.46      3.36  AGE
    295      1    400      1      7      3.86      3.06  INCOME
    266      1    400      1      7      4.46      2.36  AGE_MOM
    263      1    400      1      7      4.05      2.60  OTH_CHLD
    242      1    399      1      7      4.24      2.28  EDUC_MOM
    206      1    399      1      7      4.85      1.62  ILLEGIT
    179      3    400      2      7      5.35      1.19  RACE_MOM
    174      1    399      1      7      4.93      1.34  PNCLATE
    138      1    398      2      7      5.61      0.83  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    97 terminal nodes
    Average :     36.76750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 73 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 73 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 20

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 29014 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           20      0.10140
                  ROC            5      0.87301
                 Lift            6      5.54545
              KS-stat            5      0.63101
          Class.Error           73      0.02634

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11109     0.11745     0.92115     0.80961     7.19954     4.55636     0.68901     0.56341     0.02910     0.02898
      5     0.09102     0.10717     0.95211     0.87301     8.36035     5.45455     0.77352     0.63101     0.02792     0.02792
      6     0.08772     0.10608     0.95609     0.87080     8.41629     5.54545     0.78601     0.60739     0.02792     0.02792
     10     0.07844     0.10307     0.96400     0.86796     8.68778     5.45455     0.80265     0.60250     0.02752     0.02766
     20     0.06303     0.10140     0.98444     0.86540     9.59276     5.45455     0.89252     0.59572     0.02489     0.02740
     30     0.05566     0.10209     0.99082     0.86120     9.95475     5.45455     0.93266     0.58743     0.02304     0.02713
     40     0.05076     0.10292     0.99311     0.86094     9.95475     5.36364     0.94383     0.59206     0.02186     0.02740
     50     0.04663     0.10335     0.99468     0.86293     9.95475     5.54545     0.95079     0.58934     0.02015     0.02766
     54     0.04459     0.10374     0.99572     0.86298    10.00000     5.18182     0.96106     0.59138     0.01909     0.02713
     60     0.04303     0.10402     0.99624     0.86310    10.00000     5.00000     0.96238     0.60292     0.01791     0.02713
     70     0.03885     0.10551     0.99764     0.86087    10.00000     4.96364     0.97405     0.58786     0.01633     0.02687
     73     0.03820     0.10561     0.99777     0.86126    10.00000     5.00000     0.97472     0.58500     0.01607     0.02634
     80     0.03604     0.10628     0.99839     0.86114    10.00000     5.00000     0.98042     0.59951     0.01383     0.02661
     90     0.03317     0.10764     0.99894     0.85856    10.00000     5.00000     0.98557     0.58052     0.01225     0.02713
    100     0.03142     0.10859     0.99916     0.85792    10.00000     4.90909     0.98842     0.58133     0.01106     0.02766
    110     0.02902     0.11002     0.99941     0.85518    10.00000     4.81818     0.98991     0.57495     0.00909     0.02845
    120     0.02664     0.11173     0.99963     0.85518    10.00000     4.63636     0.99322     0.56912     0.00777     0.02898
    130     0.02498     0.11323     0.99975     0.85380    10.00000     4.69091     0.99607     0.56817     0.00619     0.02924
    140     0.02364     0.11467     0.99982     0.85245    10.00000     4.72727     0.99634     0.56695     0.00527     0.02898
    150     0.02232     0.11585     0.99990     0.85206    10.00000     4.90909     0.99729     0.57129     0.00435     0.02871
    160     0.02083     0.11801     0.99993     0.84950    10.00000     4.81818     0.99756     0.57252     0.00290     0.02871
    170     0.01965     0.11950     0.99996     0.84827    10.00000     5.00000     0.99797     0.56790     0.00211     0.02871
    180     0.01936     0.12019     0.99997     0.84721    10.00000     5.00000     0.99797     0.56057     0.00211     0.02898
    190     0.01851     0.12117     0.99998     0.84685    10.00000     4.96364     0.99824     0.56234     0.00171     0.02898
    200     0.01757     0.12303     0.99998     0.84455    10.00000     5.27273     0.99864     0.56004     0.00158     0.02950
    210     0.01666     0.12460     0.99999     0.84293    10.00000     5.27273     0.99919     0.56017     0.00105     0.02898
    220     0.01635     0.12533     0.99999     0.84206    10.00000     5.00000     0.99932     0.55935     0.00079     0.02950
    230     0.01521     0.12718     1.00000     0.84068    10.00000     5.00000     0.99946     0.54472     0.00066     0.02950
    235     0.01476     0.12796     1.00000     0.84009    10.00000     5.09091     1.00000     0.55189     0.00053     0.02950
    240     0.01413     0.12913     1.00000     0.83939    10.00000     4.90909     1.00000     0.54863     0.00026     0.02977
    250     0.01381     0.12968     1.00000     0.83888    10.00000     4.81818     1.00000     0.54945     0.00026     0.03003
    260     0.01327     0.13061     1.00000     0.83857    10.00000     4.81818     1.00000     0.54741     0.00026     0.03056
    270     0.01283     0.13171     1.00000     0.83747    10.00000     4.90909     1.00000     0.54375     0.00026     0.03030
    280     0.01219     0.13233     1.00000     0.83877    10.00000     4.90909     1.00000     0.54429     0.00013     0.03030
    290     0.01160     0.13336     1.00000     0.83758    10.00000     5.00000     1.00000     0.54374     0.00013     0.03030
    293     0.01148     0.13369     1.00000     0.83741    10.00000     5.00000     1.00000     0.54483     0.00000     0.03056
    300     0.01120     0.13439     1.00000     0.83653    10.00000     5.00000     1.00000     0.53859     0.00000     0.03082
    310     0.01083     0.13536     1.00000     0.83639    10.00000     5.00000     1.00000     0.54062     0.00000     0.03082
    320     0.00998     0.13686     1.00000     0.83607    10.00000     4.90909     1.00000     0.53873     0.00000     0.03082
    330     0.00946     0.13797     1.00000     0.83541    10.00000     5.00000     1.00000     0.53888     0.00000     0.03109
    340     0.00893     0.13938     1.00000     0.83490    10.00000     4.81818     1.00000     0.53617     0.00000     0.03109
    350     0.00862     0.14100     1.00000     0.83408    10.00000     4.81818     1.00000     0.54607     0.00000     0.03109
    360     0.00844     0.14197     1.00000     0.83343    10.00000     4.63636     1.00000     0.55123     0.00000     0.03109
    370     0.00774     0.14412     1.00000     0.83240    10.00000     4.54545     1.00000     0.53617     0.00000     0.03109
    380     0.00722     0.14537     1.00000     0.83359    10.00000     4.54545     1.00000     0.54552     0.00000     0.03161
    390     0.00684     0.14648     1.00000     0.83407    10.00000     4.72727     1.00000     0.53684     0.00000     0.03082
    400     0.00637     0.14774     1.00000     0.83384    10.00000     4.63636     1.00000     0.54444     0.00000     0.03056


 =========================================
 Variable Importance for the 20-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     31.87742   31.88 |****       |
 AGE_MOM      31.80972   31.81 |****       |
 OTH_CHLD     30.68843   30.69 |****       |
 AGE          30.65946   30.66 |****       |
 INCOME       30.21100   30.21 |****       |
 ILLEGIT      22.38388   22.38 |***        |
 RACE_MOM     12.96152   12.96 |**         |
 PNCLATE      12.00362   12.00 |**         |
 LBW          11.67722   11.68 |**         |


 Learn Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7369.00         4.00       0.0005
 1                  221.00        36.00       185.00       0.8371


 Test Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3681.00         5.00       0.0014
 1                  110.00        11.00        99.00       0.9000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenetx_model.grv: 1.3 MB, 75% compression

 Grove file created containing:
      1 TreeNet

