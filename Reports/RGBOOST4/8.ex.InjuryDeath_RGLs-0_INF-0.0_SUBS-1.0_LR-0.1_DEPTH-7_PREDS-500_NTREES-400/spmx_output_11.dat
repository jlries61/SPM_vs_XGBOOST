
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11361      0.11775      0.02910      0.02898      1.00000 |                                               *
      2       0.10617      0.11363      0.02910      0.02898      1.00000 |                                             *
      3       0.09957      0.11073      0.02871      0.02845      1.00000 |                                            *
      4       0.09505      0.10854      0.02858      0.02766      1.00000 |                                           *
      5       0.09140      0.10725      0.02805      0.02792      1.00000 |                                           *
      6       0.08737      0.10652      0.02792      0.02792      1.00000 |                                          *
      7       0.08403      0.10552      0.02792      0.02819      1.00000 |                                          *
      8       0.08116      0.10540      0.02779      0.02792      1.00000 |                                          *
      9       0.07868      0.10463      0.02779      0.02792      1.00000 |                                          *
     10       0.07652      0.10415      0.02726      0.02766      1.00000 |                                         *
     11       0.07431      0.10383      0.02647      0.02766      1.00000 |                                         *
     12       0.07290      0.10344      0.02647      0.02792      1.00000 |                                         *
     13       0.07136      0.10336      0.02634      0.02792      1.00000 |                                         *
     14       0.07008      0.10295      0.02607      0.02766      1.00000 |                                         *
     15       0.06888      0.10307      0.02607      0.02792      1.00000 |                                         *
     16       0.06732      0.10306      0.02581      0.02766      1.00000 |                                         *
     17       0.06592      0.10298      0.02555      0.02792      1.00000 |                                         *
     18       0.06485      0.10309      0.02528      0.02792      1.00000 |                                         *
     19       0.06383      0.10319      0.02568      0.02792      1.00000 |                                         *
     20       0.06248      0.10344      0.02555      0.02792      1.00000 |                                         *
     30       0.05527      0.10440      0.02318      0.02924      1.00000 |                                          *
     40       0.04832      0.10740      0.02054      0.03003      1.00000 |                                           *
     50       0.04300      0.10953      0.01672      0.03056      1.00000 |                                            *
     60       0.03894      0.11134      0.01449      0.03030      1.00000 |                                            *
     70       0.03547      0.11307      0.01225      0.03030      1.00000 |                                             *
     80       0.03290      0.11562      0.01080      0.03030      1.00000 |                                              *
     90       0.03133      0.11729      0.01001      0.03030      1.00000 |                                               *
    100       0.02932      0.11926      0.00856      0.03030      1.00000 |                                               *
    110       0.02762      0.12059      0.00790      0.03030      1.00000 |                                               *
    120       0.02636      0.12216      0.00685      0.03082      1.00000 |                                               *
    130       0.02511      0.12293      0.00593      0.03109      1.00000 |                                               *
    140       0.02406      0.12394      0.00527      0.03135      1.00000 |                                               *
    150       0.02179      0.12610      0.00408      0.03135      1.00000 |                                               *
    160       0.02014      0.12841      0.00342      0.03161      1.00000 |                                               *
    170       0.01867      0.13008      0.00263      0.03214      1.00000 |                                               *
    180       0.01759      0.13167      0.00198      0.03214      1.00000 |                                               *
    190       0.01650      0.13332      0.00171      0.03240      1.00000 |                                               *
    200       0.01586      0.13520      0.00158      0.03214      1.00000 |                                               *
    210       0.01498      0.13665      0.00105      0.03293      1.00000 |                                               *
    220       0.01435      0.13847      0.00105      0.03267      1.00000 |                                               *
    230       0.01356      0.13997      0.00092      0.03293      1.00000 |                                               *
    240       0.01262      0.14176      0.00053      0.03319      1.00000 |                                               *
    250       0.01192      0.14301      0.00040      0.03346      1.00000 |                                               *
    260       0.01134      0.14443      0.00040      0.03346      1.00000 |                                               *
    270       0.01086      0.14606      0.00013      0.03293      1.00000 |                                               *
    280       0.01041      0.14749      0.00000      0.03319      1.00000 |                                               *
    290       0.00960      0.14942      0.00000      0.03372      1.00000 |                                               *
    300       0.00899      0.15136      0.00000      0.03372      1.00000 |                                               *
    310       0.00834      0.15345      0.00000      0.03372      1.00000 |                                               *
    320       0.00785      0.15537      0.00000      0.03346      1.00000 |                                               *
    330       0.00745      0.15664      0.00000      0.03346      1.00000 |                                               *
    340       0.00709      0.15800      0.00000      0.03346      1.00000 |                                               *
    350       0.00668      0.15989      0.00000      0.03346      1.00000 |                                               *
    360       0.00635      0.16168      0.00000      0.03346      1.00000 |                                               *
    370       0.00591      0.16354      0.00000      0.03372      1.00000 |                                               *
    380       0.00545      0.16612      0.00000      0.03346      1.00000 |                                               *
    390       0.00519      0.16776      0.00000      0.03346      1.00000 |                                               *
    400       0.00490      0.16979      0.00000      0.03346      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.53      6.47  CHILDYRS
    337      1    400      1      7      3.60      3.71  AGE
    337      1    400      1      7      4.13      3.26  INCOME
    323      1    400      2      7      4.14      3.12  OTH_CHLD
    300      1    400      1      7      4.24      2.82  AGE_MOM
    288      1    400      1      7      4.30      2.66  EDUC_MOM
    218      1    400      1      7      4.51      1.90  ILLEGIT
    206      2    400      1      7      5.25      1.42  PNCLATE
    199      1    400      2      7      5.23      1.38  RACE_MOM
    184      2    400      2      7      5.32      1.23  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    99 terminal nodes
    Average :     40.53750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 14

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 32030 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           14      0.10295
                  ROC           28      0.85736
                 Lift           11      5.72727
              KS-stat           17      0.59626
          Class.Error            4      0.02766

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11361     0.11775     0.91185     0.78691     7.02167     4.90909     0.65239     0.48257     0.02910     0.02898
      4     0.09505     0.10854     0.95013     0.85600     8.00905     5.18182     0.76053     0.58282     0.02858     0.02766
     10     0.07652     0.10415     0.97346     0.85181     8.95928     5.54545     0.84739     0.57292     0.02726     0.02766
     11     0.07431     0.10383     0.97610     0.85101     9.04977     5.72727     0.85919     0.56424     0.02647     0.02766
     14     0.07008     0.10295     0.97864     0.85670     9.27602     5.54545     0.87288     0.57455     0.02607     0.02766
     17     0.06592     0.10298     0.98258     0.85729     9.45701     5.63636     0.87811     0.59626     0.02555     0.02792
     20     0.06248     0.10344     0.98507     0.85566     9.68326     5.41818     0.89902     0.58228     0.02555     0.02792
     28     0.05598     0.10427     0.98935     0.85736     9.72851     5.27273     0.91155     0.57891     0.02318     0.02977
     30     0.05527     0.10440     0.98968     0.85683     9.72851     5.27273     0.91277     0.57619     0.02318     0.02924
     40     0.04832     0.10740     0.99303     0.85263     9.81900     5.09091     0.92533     0.59423     0.02054     0.03003
     50     0.04300     0.10953     0.99535     0.85012     9.90950     5.18182     0.94433     0.58094     0.01672     0.03056
     60     0.03894     0.11134     0.99691     0.84804    10.00000     5.27273     0.95636     0.56005     0.01449     0.03030
     70     0.03547     0.11307     0.99795     0.84695    10.00000     4.81818     0.97156     0.56099     0.01225     0.03030
     80     0.03290     0.11562     0.99865     0.84121    10.00000     4.90909     0.97784     0.54390     0.01080     0.03030
     90     0.03133     0.11729     0.99887     0.83912    10.00000     4.69091     0.97906     0.53738     0.01001     0.03030
    100     0.02932     0.11926     0.99927     0.83635    10.00000     4.63636     0.98712     0.54201     0.00856     0.03030
    110     0.02762     0.12059     0.99948     0.83528    10.00000     4.72727     0.99019     0.52978     0.00790     0.03030
    120     0.02636     0.12216     0.99959     0.83310    10.00000     4.87273     0.99417     0.53670     0.00685     0.03082
    130     0.02511     0.12293     0.99971     0.83307    10.00000     4.90909     0.99512     0.53888     0.00593     0.03109
    140     0.02406     0.12394     0.99979     0.83237    10.00000     4.90909     0.99593     0.53888     0.00527     0.03135
    150     0.02179     0.12610     0.99990     0.83107    10.00000     4.72727     0.99824     0.54784     0.00408     0.03135
    160     0.02014     0.12841     0.99993     0.82926    10.00000     4.72727     0.99878     0.54431     0.00342     0.03161
    170     0.01867     0.13008     0.99996     0.82783    10.00000     4.63636     0.99891     0.53481     0.00263     0.03214
    180     0.01759     0.13167     0.99998     0.82613    10.00000     4.72727     0.99919     0.52139     0.00198     0.03214
    190     0.01650     0.13332     0.99999     0.82545    10.00000     4.63636     0.99946     0.51582     0.00171     0.03240
    200     0.01586     0.13520     0.99999     0.82315    10.00000     4.60000     0.99946     0.50985     0.00158     0.03214
    210     0.01498     0.13665     0.99999     0.82243    10.00000     4.45455     0.99959     0.50985     0.00105     0.03293
    220     0.01435     0.13847     1.00000     0.82052    10.00000     4.36364     0.99973     0.51392     0.00105     0.03267
    230     0.01356     0.13997     1.00000     0.82053    10.00000     4.18182     0.99986     0.50415     0.00092     0.03293
    234     0.01303     0.14082     1.00000     0.81926    10.00000     4.36364     1.00000     0.50564     0.00066     0.03319
    240     0.01262     0.14176     1.00000     0.81853    10.00000     4.36364     1.00000     0.50877     0.00053     0.03319
    250     0.01192     0.14301     1.00000     0.81966    10.00000     4.45455     1.00000     0.50022     0.00040     0.03346
    260     0.01134     0.14443     1.00000     0.81778    10.00000     4.45455     1.00000     0.49303     0.00040     0.03346
    270     0.01086     0.14606     1.00000     0.81632    10.00000     4.54545     1.00000     0.50063     0.00013     0.03293
    280     0.01041     0.14749     1.00000     0.81508    10.00000     4.72727     1.00000     0.49439     0.00000     0.03319
    290     0.00960     0.14942     1.00000     0.81618    10.00000     4.72727     1.00000     0.49669     0.00000     0.03372
    300     0.00899     0.15136     1.00000     0.81615    10.00000     4.72727     1.00000     0.49832     0.00000     0.03372
    310     0.00834     0.15345     1.00000     0.81713    10.00000     4.63636     1.00000     0.49126     0.00000     0.03372
    320     0.00785     0.15537     1.00000     0.81701    10.00000     4.63636     1.00000     0.48150     0.00000     0.03346
    330     0.00745     0.15664     1.00000     0.81717    10.00000     4.63636     1.00000     0.47729     0.00000     0.03346
    340     0.00709     0.15800     1.00000     0.81698    10.00000     4.63636     1.00000     0.47580     0.00000     0.03346
    350     0.00668     0.15989     1.00000     0.81627    10.00000     4.63636     1.00000     0.47294     0.00000     0.03346
    360     0.00635     0.16168     1.00000     0.81525    10.00000     4.54545     1.00000     0.46916     0.00000     0.03346
    370     0.00591     0.16354     1.00000     0.81455    10.00000     4.54545     1.00000     0.47810     0.00000     0.03372
    380     0.00545     0.16612     1.00000     0.81323    10.00000     4.45455     1.00000     0.47186     0.00000     0.03346
    390     0.00519     0.16776     1.00000     0.81190    10.00000     4.54545     1.00000     0.47064     0.00000     0.03346
    400     0.00490     0.16979     1.00000     0.81136    10.00000     4.50909     1.00000     0.46834     0.00000     0.03346


 =========================================
 Variable Importance for the 14-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          37.40353   37.40 |*****      |
 AGE_MOM      32.43782   32.44 |****       |
 EDUC_MOM     29.73128   29.73 |****       |
 OTH_CHLD     28.69602   28.70 |****       |
 INCOME       28.67100   28.67 |****       |
 ILLEGIT      18.22090   18.22 |***        |
 LBW          16.50952   16.51 |***        |
 RACE_MOM     16.44476   16.44 |***        |
 PNCLATE      12.04509   12.05 |**         |


 Learn Sample Misclassification by Target Class
 For The 14-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        25.00       196.00       0.8869


 Test Sample Misclassification by Target Class
 For The 14-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3681.00         5.00       0.0014
 1                  110.00        10.00       100.00       0.9091

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenetx_model.grv: 1.4 MB, 74% compression

 Grove file created containing:
      1 TreeNet

