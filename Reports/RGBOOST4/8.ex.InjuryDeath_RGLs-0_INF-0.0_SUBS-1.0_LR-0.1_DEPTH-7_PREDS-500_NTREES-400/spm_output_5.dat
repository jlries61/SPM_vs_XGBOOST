
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10925      0.11777      0.02910      0.02898      1.00000 |                                               *
      2       0.10174      0.11394      0.02910      0.02898      1.00000 |                                             *
      3       0.09678      0.11120      0.02910      0.02898      1.00000 |                                            *
      4       0.09209      0.10956      0.02831      0.02819      1.00000 |                                            *
      5       0.08880      0.10772      0.02779      0.02740      1.00000 |                                           *
      6       0.08574      0.10649      0.02752      0.02713      1.00000 |                                          *
      7       0.08289      0.10548      0.02752      0.02687      1.00000 |                                          *
      8       0.08085      0.10456      0.02673      0.02687      1.00000 |                                          *
      9       0.07839      0.10387      0.02660      0.02713      1.00000 |                                         *
     10       0.07654      0.10329      0.02594      0.02740      1.00000 |                                         *
     11       0.07492      0.10299      0.02568      0.02792      1.00000 |                                         *
     12       0.07370      0.10269      0.02541      0.02713      1.00000 |                                         *
     13       0.07235      0.10243      0.02541      0.02740      1.00000 |                                         *
     14       0.07080      0.10196      0.02555      0.02740      1.00000 |                                         *
     15       0.06970      0.10187      0.02541      0.02740      1.00000 |                                         *
     16       0.06794      0.10140      0.02515      0.02740      1.00000 |                                        *
     17       0.06705      0.10163      0.02489      0.02713      1.00000 |                                        *
     18       0.06556      0.10149      0.02476      0.02740      1.00000 |                                        *
     19       0.06412      0.10167      0.02436      0.02766      1.00000 |                                        *
     20       0.06277      0.10199      0.02436      0.02766      1.00000 |                                         *
     30       0.05430      0.10243      0.02278      0.02766      1.00000 |                                         *
     40       0.04954      0.10358      0.02120      0.02819      1.00000 |                                         *
     50       0.04533      0.10515      0.01896      0.02871      1.00000 |                                          *
     60       0.04124      0.10615      0.01646      0.02950      1.00000 |                                          *
     70       0.03926      0.10687      0.01501      0.02924      1.00000 |                                           *
     80       0.03884      0.10730      0.01514      0.02924      1.00000 |                                           *
     90       0.03693      0.10804      0.01462      0.02924      1.00000 |                                           *
    100       0.03536      0.10876      0.01383      0.02898      1.00000 |                                           *
    110       0.03396      0.10963      0.01264      0.02950      1.00000 |                                            *
    120       0.03245      0.11129      0.01132      0.03056      1.00000 |                                            *
    130       0.03114      0.11213      0.01093      0.03056      1.00000 |                                             *
    140       0.03007      0.11282      0.00974      0.03056      1.00000 |                                             *
    150       0.02857      0.11403      0.00777      0.03135      1.00000 |                                             *
    160       0.02705      0.11574      0.00672      0.03082      1.00000 |                                              *
    170       0.02598      0.11674      0.00619      0.03188      1.00000 |                                               *
    180       0.02497      0.11816      0.00566      0.03161      1.00000 |                                               *
    190       0.02454      0.11869      0.00540      0.03188      1.00000 |                                               *
    200       0.02319      0.11984      0.00474      0.03214      1.00000 |                                               *
    210       0.02198      0.12062      0.00448      0.03240      1.00000 |                                               *
    220       0.02065      0.12176      0.00408      0.03188      1.00000 |                                               *
    230       0.01955      0.12254      0.00356      0.03240      1.00000 |                                               *
    240       0.01825      0.12410      0.00290      0.03240      1.00000 |                                               *
    250       0.01692      0.12574      0.00171      0.03214      1.00000 |                                               *
    260       0.01590      0.12728      0.00132      0.03267      1.00000 |                                               *
    270       0.01489      0.12935      0.00105      0.03240      1.00000 |                                               *
    280       0.01433      0.13076      0.00105      0.03267      1.00000 |                                               *
    290       0.01362      0.13225      0.00105      0.03267      1.00000 |                                               *
    300       0.01312      0.13266      0.00092      0.03240      1.00000 |                                               *
    310       0.01222      0.13441      0.00066      0.03214      1.00000 |                                               *
    320       0.01121      0.13592      0.00026      0.03293      1.00000 |                                               *
    330       0.01053      0.13700      0.00026      0.03319      1.00000 |                                               *
    340       0.01001      0.13806      0.00013      0.03319      1.00000 |                                               *
    350       0.00927      0.14019      0.00000      0.03293      1.00000 |                                               *
    360       0.00872      0.14171      0.00000      0.03267      1.00000 |                                               *
    370       0.00810      0.14331      0.00000      0.03319      1.00000 |                                               *
    380       0.00780      0.14418      0.00000      0.03319      1.00000 |                                               *
    390       0.00731      0.14554      0.00000      0.03293      1.00000 |                                               *
    400       0.00694      0.14721      0.00000      0.03293      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.40      6.60  CHILDYRS
    312      1    400      1      7      3.43      3.57  AGE
    309      1    400      1      7      4.31      2.85  INCOME
    299      1    399      1      7      4.20      2.84  AGE_MOM
    274      1    400      1      7      4.11      2.67  OTH_CHLD
    266      1    398      1      7      4.25      2.49  EDUC_MOM
    200      1    399      2      7      5.17      1.42  ILLEGIT
    184      1    400      1      7      4.97      1.39  RACE_MOM
    158      2    399      2      7      5.47      1.00  PNCLATE
    151      1    399      2      7      5.52      0.94  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   103 terminal nodes
    Average :     35.51750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 18 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 18 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 28014 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.10140
                  ROC           18      0.85867
                 Lift           18      6.09091
              KS-stat           80      0.58268
          Class.Error            7      0.02687

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10925     0.11777     0.92687     0.78949     7.25212     4.94443     0.67944     0.45568     0.02910     0.02898
      7     0.08289     0.10548     0.95550     0.84923     8.37104     5.81818     0.76406     0.56234     0.02752     0.02687
     10     0.07654     0.10329     0.96099     0.85127     8.59729     5.72727     0.78694     0.55990     0.02594     0.02740
     16     0.06794     0.10140     0.97087     0.85354     8.91403     5.90909     0.82692     0.56639     0.02515     0.02740
     18     0.06556     0.10149     0.97358     0.85867     9.14027     6.09091     0.84219     0.56381     0.02476     0.02740
     20     0.06277     0.10199     0.97953     0.85591     9.32127     5.90909     0.85813     0.56571     0.02436     0.02766
     30     0.05430     0.10243     0.98889     0.85600     9.63801     5.81818     0.90624     0.57522     0.02278     0.02766
     40     0.04954     0.10358     0.99201     0.85276     9.77376     5.72727     0.92451     0.56492     0.02120     0.02819
     50     0.04533     0.10515     0.99479     0.84772     9.90950     5.81818     0.94764     0.56193     0.01896     0.02871
     60     0.04124     0.10615     0.99643     0.84965     9.95475     5.72727     0.96120     0.57278     0.01646     0.02950
     61     0.04037     0.10625     0.99675     0.84900    10.00000     5.78182     0.96269     0.57454     0.01580     0.02924
     70     0.03926     0.10687     0.99697     0.84819    10.00000     5.72727     0.96283     0.57943     0.01501     0.02924
     80     0.03884     0.10730     0.99708     0.84750    10.00000     5.72727     0.96355     0.58268     0.01514     0.02924
     90     0.03693     0.10804     0.99757     0.84750    10.00000     5.72727     0.96599     0.56884     0.01462     0.02924
    100     0.03536     0.10876     0.99799     0.84759    10.00000     5.72727     0.96857     0.56789     0.01383     0.02898
    110     0.03396     0.10963     0.99835     0.84649    10.00000     5.90909     0.97061     0.56952     0.01264     0.02950
    120     0.03245     0.11129     0.99862     0.84363    10.00000     6.00000     0.97549     0.56830     0.01132     0.03056
    130     0.03114     0.11213     0.99882     0.84207    10.00000     6.09091     0.97549     0.56667     0.01093     0.03056
    140     0.03007     0.11282     0.99900     0.84267    10.00000     6.00000     0.97657     0.55921     0.00974     0.03056
    150     0.02857     0.11403     0.99921     0.84221    10.00000     5.90909     0.97947     0.57251     0.00777     0.03135
    160     0.02705     0.11574     0.99939     0.83992    10.00000     5.90909     0.98295     0.57196     0.00672     0.03082
    170     0.02598     0.11674     0.99949     0.83847    10.00000     5.90909     0.98557     0.57251     0.00619     0.03188
    180     0.02497     0.11816     0.99956     0.83588    10.00000     5.81818     0.98625     0.57495     0.00566     0.03161
    190     0.02454     0.11869     0.99958     0.83681    10.00000     5.72727     0.98625     0.57291     0.00540     0.03188
    200     0.02319     0.11984     0.99972     0.83617    10.00000     5.54545     0.98707     0.56667     0.00474     0.03214
    210     0.02198     0.12062     0.99983     0.83569    10.00000     5.63636     0.99078     0.57318     0.00448     0.03240
    220     0.02065     0.12176     0.99988     0.83602    10.00000     5.72727     0.99295     0.57372     0.00408     0.03188
    230     0.01955     0.12254     0.99993     0.83627    10.00000     5.72727     0.99580     0.57454     0.00356     0.03240
    240     0.01825     0.12410     0.99995     0.83533    10.00000     5.63636     0.99688     0.57210     0.00290     0.03240
    250     0.01692     0.12574     0.99997     0.83367    10.00000     5.72727     0.99824     0.57169     0.00171     0.03214
    260     0.01590     0.12728     0.99999     0.83249    10.00000     5.72727     0.99878     0.57521     0.00132     0.03267
    270     0.01489     0.12935     0.99999     0.82957    10.00000     5.81818     0.99905     0.57020     0.00105     0.03240
    280     0.01433     0.13076     0.99999     0.82823    10.00000     5.81818     0.99905     0.56518     0.00105     0.03267
    290     0.01362     0.13225     1.00000     0.82882    10.00000     5.72727     0.99986     0.55962     0.00105     0.03267
    300     0.01312     0.13266     1.00000     0.82812    10.00000     5.72727     0.99986     0.56111     0.00092     0.03240
    303     0.01289     0.13314     1.00000     0.82736    10.00000     5.63636     1.00000     0.55650     0.00066     0.03214
    310     0.01222     0.13441     1.00000     0.82612    10.00000     5.63636     1.00000     0.55948     0.00066     0.03214
    320     0.01121     0.13592     1.00000     0.82706    10.00000     5.63636     1.00000     0.56761     0.00026     0.03293
    330     0.01053     0.13700     1.00000     0.82916    10.00000     5.63636     1.00000     0.56490     0.00026     0.03319
    340     0.01001     0.13806     1.00000     0.82976    10.00000     5.54545     1.00000     0.55839     0.00013     0.03319
    349     0.00930     0.14001     1.00000     0.82742    10.00000     5.63636     1.00000     0.55690     0.00000     0.03293
    350     0.00927     0.14019     1.00000     0.82812    10.00000     5.63636     1.00000     0.55798     0.00000     0.03293
    360     0.00872     0.14171     1.00000     0.82932    10.00000     5.63636     1.00000     0.55527     0.00000     0.03267
    370     0.00810     0.14331     1.00000     0.82740    10.00000     5.72727     1.00000     0.56219     0.00000     0.03319
    380     0.00780     0.14418     1.00000     0.82854    10.00000     5.63636     1.00000     0.56449     0.00000     0.03319
    390     0.00731     0.14554     1.00000     0.82873    10.00000     5.63636     1.00000     0.56748     0.00000     0.03293
    400     0.00694     0.14721     1.00000     0.82773    10.00000     5.72727     1.00000     0.57006     0.00000     0.03293


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          36.99714   37.00 |*****      |
 EDUC_MOM     32.29904   32.30 |****       |
 AGE_MOM      29.08253   29.08 |****       |
 INCOME       27.90793   27.91 |****       |
 OTH_CHLD     23.18265   23.18 |***        |
 ILLEGIT      17.70413   17.70 |***        |
 RACE_MOM     13.45716   13.46 |**         |
 PNCLATE      11.85853   11.86 |**         |
 LBW          10.40156   10.40 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7368.00         5.00       0.0007
 1                  221.00        35.00       186.00       0.8416


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3678.00         8.00       0.0022
 1                  110.00        14.00        96.00       0.8727

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.3 MB, 75% compression

 Grove file created containing:
      1 TreeNet

