
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:01

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10621      0.12111      0.02910      0.02898      1.00000 |                                               *
      2       0.09668      0.11793      0.02713      0.03030      1.00000 |                                              *
      3       0.09105      0.11598      0.02699      0.03030      1.00000 |                                             *
      4       0.08661      0.11365      0.02686      0.03030      1.00000 |                                            *
      5       0.08203      0.11263      0.02620      0.03056      1.00000 |                                            *
      6       0.07877      0.11182      0.02568      0.03056      1.00000 |                                           *
      7       0.07601      0.11065      0.02541      0.03030      1.00000 |                                           *
      8       0.07294      0.11008      0.02476      0.03003      1.00000 |                                           *
      9       0.07037      0.10930      0.02462      0.03003      1.00000 |                                          *
     10       0.06827      0.10890      0.02397      0.03056      1.00000 |                                          *
     11       0.06613      0.10875      0.02344      0.03030      1.00000 |                                          *
     12       0.06450      0.10863      0.02304      0.03030      1.00000 |                                          *
     13       0.06301      0.10848      0.02265      0.03082      1.00000 |                                          *
     14       0.06191      0.10825      0.02212      0.03135      1.00000 |                                          *
     15       0.06035      0.10806      0.02212      0.03161      1.00000 |                                          *
     16       0.05847      0.10817      0.02199      0.03161      1.00000 |                                          *
     17       0.05714      0.10813      0.02186      0.03188      1.00000 |                                          *
     18       0.05638      0.10809      0.02146      0.03214      1.00000 |                                          *
     19       0.05532      0.10795      0.02146      0.03214      1.00000 |                                          *
     20       0.05444      0.10781      0.02146      0.03214      1.00000 |                                          *
     30       0.04679      0.10821      0.01909      0.03240      1.00000 |                                          *
     40       0.04338      0.10877      0.01751      0.03267      1.00000 |                                          *
     50       0.03926      0.10920      0.01620      0.03161      1.00000 |                                          *
     60       0.03477      0.11000      0.01238      0.03240      1.00000 |                                           *
     70       0.03202      0.11161      0.01067      0.03293      1.00000 |                                           *
     80       0.02873      0.11374      0.00895      0.03346      1.00000 |                                            *
     90       0.02588      0.11533      0.00764      0.03372      1.00000 |                                             *
    100       0.02326      0.11712      0.00645      0.03398      1.00000 |                                             *
    110       0.02155      0.11828      0.00474      0.03372      1.00000 |                                              *
    120       0.01987      0.12017      0.00408      0.03372      1.00000 |                                               *
    130       0.01806      0.12175      0.00316      0.03398      1.00000 |                                               *
    140       0.01674      0.12363      0.00263      0.03398      1.00000 |                                               *
    150       0.01580      0.12534      0.00198      0.03477      1.00000 |                                               *
    160       0.01482      0.12689      0.00171      0.03477      1.00000 |                                               *
    170       0.01367      0.12906      0.00092      0.03425      1.00000 |                                               *
    180       0.01229      0.13100      0.00053      0.03451      1.00000 |                                               *
    190       0.01100      0.13319      0.00040      0.03372      1.00000 |                                               *
    200       0.01030      0.13496      0.00026      0.03477      1.00000 |                                               *
    210       0.00920      0.13740      0.00013      0.03504      1.00000 |                                               *
    220       0.00825      0.13892      0.00000      0.03372      1.00000 |                                               *
    230       0.00774      0.14017      0.00000      0.03346      1.00000 |                                               *
    240       0.00713      0.14207      0.00000      0.03319      1.00000 |                                               *
    250       0.00660      0.14371      0.00000      0.03372      1.00000 |                                               *
    260       0.00618      0.14495      0.00000      0.03398      1.00000 |                                               *
    270       0.00546      0.14739      0.00000      0.03398      1.00000 |                                               *
    280       0.00478      0.14979      0.00000      0.03346      1.00000 |                                               *
    290       0.00442      0.15231      0.00000      0.03346      1.00000 |                                               *
    300       0.00395      0.15435      0.00000      0.03398      1.00000 |                                               *
    310       0.00364      0.15642      0.00000      0.03372      1.00000 |                                               *
    320       0.00335      0.15851      0.00000      0.03372      1.00000 |                                               *
    330       0.00313      0.16080      0.00000      0.03372      1.00000 |                                               *
    340       0.00284      0.16348      0.00000      0.03372      1.00000 |                                               *
    350       0.00240      0.16769      0.00000      0.03346      1.00000 |                                               *
    360       0.00221      0.16976      0.00000      0.03372      1.00000 |                                               *
    370       0.00200      0.17214      0.00000      0.03319      1.00000 |                                               *
    380       0.00179      0.17528      0.00000      0.03346      1.00000 |                                               *
    390       0.00161      0.17787      0.00000      0.03346      1.00000 |                                               *
    400       0.00141      0.18067      0.00000      0.03425      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.56      6.44  CHILDYRS
    377      1    400      1      7      3.42      4.32  AGE
    364      1    400      1      7      4.30      3.36  INCOME
    354      1    400      1      7      4.04      3.50  OTH_CHLD
    351      1    400      2      7      4.33      3.22  AGE_MOM
    336      1    400      1      7      4.35      3.07  EDUC_MOM
    287      1    400      1      7      4.60      2.44  ILLEGIT
    254      2    399      1      7      5.19      1.78  RACE_MOM
    245      1    400      2      7      5.32      1.64  PNCLATE
    230      1    399      3      7      5.29      1.56  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   112 terminal nodes
    Average :     56.64000 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 63 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 63 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 20

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 44912 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           20      0.10781
                  ROC           63      0.86625
                 Lift           60      5.72727
              KS-stat            7      0.62245
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10621     0.12111     0.92628     0.78897     7.43849     4.76862     0.69975     0.51116     0.02910     0.02898
      7     0.07601     0.11065     0.96913     0.85440     8.95928     5.27273     0.83480     0.62245     0.02541     0.03030
     10     0.06827     0.10890     0.97661     0.85495     9.27602     5.27273     0.86625     0.60305     0.02397     0.03056
     20     0.05444     0.10781     0.98793     0.85152     9.54751     5.60000     0.89832     0.59748     0.02146     0.03214
     30     0.04679     0.10821     0.99387     0.85713     9.81900     5.45455     0.92044     0.59830     0.01909     0.03240
     40     0.04338     0.10877     0.99536     0.85989     9.81900     5.63636     0.93676     0.60373     0.01751     0.03267
     49     0.03943     0.10933     0.99710     0.86236    10.00000     5.63636     0.95084     0.60346     0.01659     0.03161
     50     0.03926     0.10920     0.99714     0.86294    10.00000     5.63636     0.95111     0.60509     0.01620     0.03161
     60     0.03477     0.11000     0.99853     0.86580    10.00000     5.72727     0.96816     0.61242     0.01238     0.03240
     63     0.03381     0.11016     0.99876     0.86625    10.00000     5.63636     0.96993     0.61567     0.01132     0.03267
     70     0.03202     0.11161     0.99903     0.86521    10.00000     5.27273     0.97617     0.60916     0.01067     0.03293
     80     0.02873     0.11374     0.99953     0.86289    10.00000     4.90909     0.98363     0.59762     0.00895     0.03346
     90     0.02588     0.11533     0.99983     0.86113    10.00000     4.90909     0.99168     0.60209     0.00764     0.03372
    100     0.02326     0.11712     0.99994     0.85997    10.00000     4.90909     0.99783     0.60739     0.00645     0.03398
    110     0.02155     0.11828     0.99997     0.85970    10.00000     4.81818     0.99824     0.60698     0.00474     0.03372
    120     0.01987     0.12017     0.99998     0.85737    10.00000     4.81818     0.99837     0.60468     0.00408     0.03372
    130     0.01806     0.12175     0.99999     0.85728    10.00000     4.81818     0.99905     0.59736     0.00316     0.03398
    140     0.01674     0.12363     1.00000     0.85719    10.00000     4.96364     0.99946     0.59695     0.00263     0.03398
    150     0.01580     0.12534     1.00000     0.85531    10.00000     5.00000     0.99973     0.59709     0.00198     0.03477
    160     0.01482     0.12689     1.00000     0.85568    10.00000     5.09091     0.99973     0.58868     0.00171     0.03477
    170     0.01367     0.12906     1.00000     0.85530    10.00000     5.00000     0.99986     0.58474     0.00092     0.03425
    171     0.01332     0.12917     1.00000     0.85576    10.00000     5.00000     1.00000     0.58501     0.00092     0.03425
    180     0.01229     0.13100     1.00000     0.85351    10.00000     5.09091     1.00000     0.58366     0.00053     0.03451
    190     0.01100     0.13319     1.00000     0.85308    10.00000     5.00000     1.00000     0.59573     0.00040     0.03372
    200     0.01030     0.13496     1.00000     0.85369    10.00000     5.09091     1.00000     0.59383     0.00026     0.03477
    210     0.00920     0.13740     1.00000     0.85241    10.00000     5.00000     1.00000     0.58799     0.00013     0.03504
    212     0.00885     0.13763     1.00000     0.85319    10.00000     5.09091     1.00000     0.58501     0.00000     0.03477
    220     0.00825     0.13892     1.00000     0.85330    10.00000     5.27273     1.00000     0.57673     0.00000     0.03372
    230     0.00774     0.14017     1.00000     0.85273    10.00000     5.36364     1.00000     0.57239     0.00000     0.03346
    240     0.00713     0.14207     1.00000     0.85105    10.00000     5.23636     1.00000     0.56384     0.00000     0.03319
    250     0.00660     0.14371     1.00000     0.84987    10.00000     5.18182     1.00000     0.56223     0.00000     0.03372
    260     0.00618     0.14495     1.00000     0.85052    10.00000     5.27273     1.00000     0.56385     0.00000     0.03398
    270     0.00546     0.14739     1.00000     0.84979    10.00000     5.18182     1.00000     0.57089     0.00000     0.03398
    280     0.00478     0.14979     1.00000     0.84904    10.00000     5.18182     1.00000     0.56548     0.00000     0.03346
    290     0.00442     0.15231     1.00000     0.84636    10.00000     5.09091     1.00000     0.56615     0.00000     0.03346
    300     0.00395     0.15435     1.00000     0.84655    10.00000     5.09091     1.00000     0.56670     0.00000     0.03398
    310     0.00364     0.15642     1.00000     0.84694    10.00000     5.00000     1.00000     0.56385     0.00000     0.03372
    320     0.00335     0.15851     1.00000     0.84619    10.00000     5.09091     1.00000     0.56343     0.00000     0.03372
    330     0.00313     0.16080     1.00000     0.84562    10.00000     5.09091     1.00000     0.56154     0.00000     0.03372
    340     0.00284     0.16348     1.00000     0.84383    10.00000     5.09091     1.00000     0.55299     0.00000     0.03372
    350     0.00240     0.16769     1.00000     0.84262    10.00000     4.90909     1.00000     0.55055     0.00000     0.03346
    360     0.00221     0.16976     1.00000     0.84283    10.00000     5.09091     1.00000     0.54975     0.00000     0.03372
    370     0.00200     0.17214     1.00000     0.84192    10.00000     5.18182     1.00000     0.54147     0.00000     0.03319
    380     0.00179     0.17528     1.00000     0.84057    10.00000     5.18182     1.00000     0.54551     0.00000     0.03346
    390     0.00161     0.17787     1.00000     0.84085    10.00000     4.96364     1.00000     0.54876     0.00000     0.03346
    400     0.00141     0.18067     1.00000     0.84029    10.00000     5.18182     1.00000     0.54432     0.00000     0.03425


 =========================================
 Variable Importance for the 20-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     37.79443   37.79 |*****      |
 AGE          35.89298   35.89 |*****      |
 OTH_CHLD     28.65999   28.66 |****       |
 INCOME       26.21849   26.22 |****       |
 AGE_MOM      23.49050   23.49 |***        |
 ILLEGIT      22.45570   22.46 |***        |
 PNCLATE      16.21728   16.22 |***        |
 LBW          14.95823   14.96 |**         |
 RACE_MOM     14.14258   14.14 |**         |


 Learn Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7372.00         1.00       0.0001
 1                  221.00        59.00       162.00       0.7330


 Test Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3667.00        19.00       0.0052
 1                  110.00         7.00       103.00       0.9364

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.9 MB, 75% compression

 Grove file created containing:
      1 TreeNet

