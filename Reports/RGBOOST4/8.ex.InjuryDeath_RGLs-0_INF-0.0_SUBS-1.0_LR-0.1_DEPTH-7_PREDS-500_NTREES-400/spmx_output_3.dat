
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11117      0.11963      0.02910      0.02898      1.00000 |                                               *
      2       0.10372      0.11600      0.02910      0.02898      1.00000 |                                              *
      3       0.09708      0.11438      0.02910      0.02898      1.00000 |                                             *
      4       0.09296      0.11261      0.02910      0.02898      1.00000 |                                            *
      5       0.08986      0.11125      0.02910      0.02898      1.00000 |                                            *
      6       0.08708      0.11041      0.02910      0.02898      1.00000 |                                           *
      7       0.08450      0.10972      0.02884      0.02898      1.00000 |                                           *
      8       0.08221      0.10910      0.02884      0.02924      1.00000 |                                           *
      9       0.07988      0.10845      0.02884      0.02924      1.00000 |                                           *
     10       0.07714      0.10806      0.02844      0.02924      1.00000 |                                          *
     11       0.07552      0.10777      0.02831      0.02924      1.00000 |                                          *
     12       0.07368      0.10741      0.02818      0.02924      1.00000 |                                          *
     13       0.07203      0.10748      0.02818      0.02924      1.00000 |                                          *
     14       0.06992      0.10709      0.02765      0.02950      1.00000 |                                          *
     15       0.06844      0.10678      0.02752      0.02950      1.00000 |                                          *
     16       0.06716      0.10663      0.02699      0.02950      1.00000 |                                          *
     17       0.06594      0.10655      0.02620      0.02977      1.00000 |                                          *
     18       0.06442      0.10652      0.02634      0.02977      1.00000 |                                          *
     19       0.06319      0.10631      0.02607      0.02924      1.00000 |                                          *
     20       0.06199      0.10636      0.02607      0.02950      1.00000 |                                          *
     30       0.05420      0.10615      0.02357      0.02977      1.00000 |                                          *
     40       0.04862      0.10692      0.02212      0.03056      1.00000 |                                          *
     50       0.04478      0.10784      0.01923      0.03109      1.00000 |                                          *
     60       0.04242      0.10929      0.01791      0.03030      1.00000 |                                           *
     70       0.04050      0.11048      0.01672      0.03056      1.00000 |                                           *
     80       0.03768      0.11189      0.01501      0.03030      1.00000 |                                            *
     90       0.03631      0.11332      0.01435      0.03161      1.00000 |                                            *
    100       0.03516      0.11426      0.01435      0.03135      1.00000 |                                             *
    110       0.03363      0.11515      0.01277      0.03161      1.00000 |                                             *
    120       0.03236      0.11602      0.01172      0.03188      1.00000 |                                              *
    130       0.03071      0.11666      0.01093      0.03135      1.00000 |                                              *
    140       0.02697      0.11847      0.00672      0.03188      1.00000 |                                               *
    150       0.02494      0.11981      0.00566      0.03267      1.00000 |                                               *
    160       0.02407      0.12094      0.00500      0.03293      1.00000 |                                               *
    170       0.02286      0.12215      0.00448      0.03372      1.00000 |                                               *
    180       0.02136      0.12367      0.00356      0.03319      1.00000 |                                               *
    190       0.01963      0.12493      0.00263      0.03293      1.00000 |                                               *
    200       0.01830      0.12663      0.00184      0.03346      1.00000 |                                               *
    210       0.01720      0.12837      0.00132      0.03293      1.00000 |                                               *
    220       0.01590      0.12969      0.00079      0.03346      1.00000 |                                               *
    230       0.01489      0.13141      0.00079      0.03398      1.00000 |                                               *
    240       0.01436      0.13232      0.00066      0.03398      1.00000 |                                               *
    250       0.01367      0.13342      0.00053      0.03293      1.00000 |                                               *
    260       0.01297      0.13466      0.00026      0.03293      1.00000 |                                               *
    270       0.01201      0.13702      0.00013      0.03293      1.00000 |                                               *
    280       0.01144      0.13902      0.00013      0.03319      1.00000 |                                               *
    290       0.01077      0.14045      0.00000      0.03319      1.00000 |                                               *
    300       0.01028      0.14231      0.00000      0.03372      1.00000 |                                               *
    310       0.00975      0.14321      0.00000      0.03293      1.00000 |                                               *
    320       0.00931      0.14454      0.00000      0.03319      1.00000 |                                               *
    330       0.00879      0.14588      0.00000      0.03346      1.00000 |                                               *
    340       0.00841      0.14740      0.00000      0.03372      1.00000 |                                               *
    350       0.00791      0.14910      0.00000      0.03372      1.00000 |                                               *
    360       0.00768      0.15011      0.00000      0.03398      1.00000 |                                               *
    370       0.00730      0.15173      0.00000      0.03425      1.00000 |                                               *
    380       0.00704      0.15250      0.00000      0.03425      1.00000 |                                               *
    390       0.00673      0.15408      0.00000      0.03425      1.00000 |                                               *
    400       0.00634      0.15555      0.00000      0.03425      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.41      6.59  CHILDYRS
    337      1    400      1      7      3.83      3.51  AGE
    310      1    400      1      7      3.85      3.22  INCOME
    295      1    400      1      7      3.83      3.07  AGE_MOM
    282      1    400      1      7      4.16      2.71  OTH_CHLD
    254      1    400      2      7      4.16      2.44  EDUC_MOM
    237      1    400      1      7      4.79      1.90  ILLEGIT
    207      1    400      1      7      5.12      1.49  RACE_MOM
    186      1    400      2      7      5.01      1.39  PNCLATE
    170      1    400      2      7      5.35      1.13  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   103 terminal nodes
    Average :     37.57750 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 36 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 36 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 24

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 29662 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           24      0.10599
                  ROC           36      0.84692
                 Lift           30      5.63636
              KS-stat           29      0.56182
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11117     0.11963     0.92475     0.75269     7.47059     4.86942     0.69372     0.45053     0.02910     0.02898
     10     0.07714     0.10806     0.96553     0.83285     8.73303     5.00000     0.80885     0.52922     0.02844     0.02924
     20     0.06199     0.10636     0.98484     0.83575     9.50226     5.14545     0.88303     0.54362     0.02607     0.02950
     24     0.05862     0.10599     0.98895     0.83980     9.77376     5.36364     0.91507     0.55096     0.02528     0.02950
     29     0.05495     0.10624     0.99152     0.84156    10.00000     5.54545     0.93670     0.56182     0.02383     0.03003
     30     0.05420     0.10615     0.99186     0.84280    10.00000     5.63636     0.93904     0.55707     0.02357     0.02977
     36     0.05079     0.10611     0.99363     0.84692    10.00000     5.36364     0.95379     0.56072     0.02331     0.03003
     40     0.04862     0.10692     0.99439     0.84668    10.00000     5.36364     0.96003     0.55992     0.02212     0.03056
     50     0.04478     0.10784     0.99567     0.84580    10.00000     5.36364     0.96405     0.55542     0.01923     0.03109
     60     0.04242     0.10929     0.99650     0.84359    10.00000     5.36364     0.96906     0.53981     0.01791     0.03030
     70     0.04050     0.11048     0.99701     0.84156    10.00000     5.45455     0.97001     0.54768     0.01672     0.03056
     80     0.03768     0.11189     0.99773     0.83978    10.00000     5.36364     0.97218     0.55257     0.01501     0.03030
     90     0.03631     0.11332     0.99797     0.83758    10.00000     5.36364     0.97246     0.54524     0.01435     0.03161
    100     0.03516     0.11426     0.99818     0.83805    10.00000     5.27273     0.97273     0.54402     0.01435     0.03135
    110     0.03363     0.11515     0.99847     0.83846    10.00000     5.36364     0.97562     0.54375     0.01277     0.03161
    120     0.03236     0.11602     0.99869     0.83986    10.00000     5.27273     0.97644     0.54564     0.01172     0.03188
    130     0.03071     0.11666     0.99903     0.84002    10.00000     5.27273     0.97901     0.54537     0.01093     0.03135
    140     0.02697     0.11847     0.99963     0.84024    10.00000     5.54545     0.98937     0.53642     0.00672     0.03188
    150     0.02494     0.11981     0.99979     0.84063    10.00000     5.54545     0.99363     0.53221     0.00566     0.03267
    160     0.02407     0.12094     0.99983     0.84114    10.00000     5.54545     0.99566     0.53684     0.00500     0.03293
    170     0.02286     0.12215     0.99989     0.84110    10.00000     5.54545     0.99620     0.53628     0.00448     0.03372
    180     0.02136     0.12367     0.99993     0.84133    10.00000     5.45455     0.99647     0.53723     0.00356     0.03319
    190     0.01963     0.12493     0.99996     0.84210    10.00000     5.45455     0.99634     0.53534     0.00263     0.03293
    200     0.01830     0.12663     0.99997     0.84175    10.00000     5.45455     0.99688     0.53548     0.00184     0.03346
    210     0.01720     0.12837     0.99998     0.84139    10.00000     5.27273     0.99715     0.54104     0.00132     0.03293
    220     0.01590     0.12969     1.00000     0.84021    10.00000     5.18182     0.99959     0.53846     0.00079     0.03346
    230     0.01489     0.13141     1.00000     0.83920    10.00000     4.90909     0.99986     0.53684     0.00079     0.03398
    236     0.01466     0.13200     1.00000     0.83845    10.00000     5.00000     1.00000     0.53874     0.00066     0.03398
    240     0.01436     0.13232     1.00000     0.83811    10.00000     5.09091     1.00000     0.54064     0.00066     0.03398
    250     0.01367     0.13342     1.00000     0.83717    10.00000     5.18182     1.00000     0.54172     0.00053     0.03293
    260     0.01297     0.13466     1.00000     0.83678    10.00000     5.09091     1.00000     0.53941     0.00026     0.03293
    270     0.01201     0.13702     1.00000     0.83467    10.00000     4.81818     1.00000     0.55284     0.00013     0.03293
    280     0.01144     0.13902     1.00000     0.83262    10.00000     4.81818     1.00000     0.54457     0.00013     0.03319
    290     0.01077     0.14045     1.00000     0.83275    10.00000     4.81818     1.00000     0.54647     0.00000     0.03319
    300     0.01028     0.14231     1.00000     0.83077    10.00000     4.81818     1.00000     0.54104     0.00000     0.03372
    310     0.00975     0.14321     1.00000     0.83112    10.00000     4.72727     1.00000     0.53508     0.00000     0.03293
    320     0.00931     0.14454     1.00000     0.83060    10.00000     4.72727     1.00000     0.53534     0.00000     0.03319
    330     0.00879     0.14588     1.00000     0.83008    10.00000     4.87273     1.00000     0.53778     0.00000     0.03346
    340     0.00841     0.14740     1.00000     0.82889    10.00000     4.81818     1.00000     0.53426     0.00000     0.03372
    350     0.00791     0.14910     1.00000     0.82963    10.00000     5.00000     1.00000     0.53508     0.00000     0.03372
    360     0.00768     0.15011     1.00000     0.82902    10.00000     5.00000     1.00000     0.52897     0.00000     0.03398
    370     0.00730     0.15173     1.00000     0.82812    10.00000     5.00000     1.00000     0.52707     0.00000     0.03425
    380     0.00704     0.15250     1.00000     0.82844    10.00000     5.00000     1.00000     0.52476     0.00000     0.03425
    390     0.00673     0.15408     1.00000     0.82847    10.00000     4.81818     1.00000     0.51852     0.00000     0.03425
    400     0.00634     0.15555     1.00000     0.82925    10.00000     4.81818     1.00000     0.51784     0.00000     0.03425


 =========================================
 Variable Importance for the 24-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      34.87136   34.87 |****       |
 OTH_CHLD     29.75812   29.76 |****       |
 AGE          29.53345   29.53 |****       |
 EDUC_MOM     28.76864   28.77 |****       |
 INCOME       25.70371   25.70 |****       |
 ILLEGIT      17.82421   17.82 |***        |
 PNCLATE      13.73177   13.73 |**         |
 RACE_MOM     13.68629   13.69 |**         |
 LBW          13.29758   13.30 |**         |


 Learn Sample Misclassification by Target Class
 For The 24-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        31.00       190.00       0.8597


 Test Sample Misclassification by Target Class
 For The 24-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3681.00         5.00       0.0014
 1                  110.00         3.00       107.00       0.9727

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenetx_model.grv: 1.3 MB, 75% compression

 Grove file created containing:
      1 TreeNet

