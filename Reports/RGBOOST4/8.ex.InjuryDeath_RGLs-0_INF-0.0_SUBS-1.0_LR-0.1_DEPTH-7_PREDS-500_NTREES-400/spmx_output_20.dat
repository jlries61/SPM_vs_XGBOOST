
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10868      0.12228      0.02910      0.02898      1.00000 |                                               *
      2       0.10017      0.11964      0.02910      0.02898      1.00000 |                                              *
      3       0.09489      0.11776      0.02910      0.02898      1.00000 |                                             *
      4       0.09076      0.11587      0.02858      0.02871      1.00000 |                                            *
      5       0.08657      0.11444      0.02818      0.02871      1.00000 |                                            *
      6       0.08283      0.11394      0.02779      0.02871      1.00000 |                                            *
      7       0.08000      0.11325      0.02792      0.02871      1.00000 |                                           *
      8       0.07755      0.11291      0.02779      0.02871      1.00000 |                                           *
      9       0.07541      0.11212      0.02752      0.02898      1.00000 |                                           *
     10       0.07348      0.11189      0.02726      0.02845      1.00000 |                                           *
     11       0.07182      0.11150      0.02673      0.02845      1.00000 |                                           *
     12       0.07034      0.11127      0.02660      0.02845      1.00000 |                                           *
     13       0.06857      0.11143      0.02528      0.02871      1.00000 |                                           *
     14       0.06730      0.11155      0.02515      0.02871      1.00000 |                                           *
     15       0.06567      0.11172      0.02410      0.02898      1.00000 |                                           *
     16       0.06446      0.11154      0.02410      0.02924      1.00000 |                                           *
     17       0.06313      0.11193      0.02383      0.02898      1.00000 |                                           *
     18       0.06215      0.11211      0.02383      0.02871      1.00000 |                                           *
     19       0.06143      0.11213      0.02370      0.02845      1.00000 |                                           *
     20       0.06044      0.11233      0.02344      0.02845      1.00000 |                                           *
     30       0.05410      0.11349      0.02278      0.03003      1.00000 |                                            *
     40       0.04964      0.11609      0.02054      0.02977      1.00000 |                                             *
     50       0.04575      0.11825      0.01817      0.03003      1.00000 |                                             *
     60       0.04127      0.12078      0.01633      0.03056      1.00000 |                                              *
     70       0.03748      0.12312      0.01449      0.03056      1.00000 |                                               *
     80       0.03416      0.12515      0.01225      0.03056      1.00000 |                                               *
     90       0.03213      0.12679      0.01080      0.03056      1.00000 |                                               *
    100       0.02974      0.12814      0.00816      0.03030      1.00000 |                                               *
    110       0.02665      0.13108      0.00658      0.03056      1.00000 |                                               *
    120       0.02520      0.13345      0.00593      0.03082      1.00000 |                                               *
    130       0.02368      0.13549      0.00553      0.03109      1.00000 |                                               *
    140       0.02097      0.13841      0.00316      0.03214      1.00000 |                                               *
    150       0.01977      0.14072      0.00250      0.03188      1.00000 |                                               *
    160       0.01842      0.14256      0.00237      0.03214      1.00000 |                                               *
    170       0.01707      0.14574      0.00158      0.03214      1.00000 |                                               *
    180       0.01621      0.14678      0.00119      0.03161      1.00000 |                                               *
    190       0.01494      0.14971      0.00066      0.03161      1.00000 |                                               *
    200       0.01362      0.15267      0.00053      0.03161      1.00000 |                                               *
    210       0.01254      0.15493      0.00000      0.03135      1.00000 |                                               *
    220       0.01173      0.15709      0.00000      0.03135      1.00000 |                                               *
    230       0.01092      0.15953      0.00000      0.03188      1.00000 |                                               *
    240       0.01013      0.16130      0.00000      0.03214      1.00000 |                                               *
    250       0.00938      0.16263      0.00000      0.03240      1.00000 |                                               *
    260       0.00879      0.16450      0.00000      0.03214      1.00000 |                                               *
    270       0.00830      0.16727      0.00000      0.03267      1.00000 |                                               *
    280       0.00783      0.16944      0.00000      0.03267      1.00000 |                                               *
    290       0.00726      0.17119      0.00000      0.03267      1.00000 |                                               *
    300       0.00675      0.17357      0.00000      0.03240      1.00000 |                                               *
    310       0.00637      0.17512      0.00000      0.03293      1.00000 |                                               *
    320       0.00604      0.17631      0.00000      0.03267      1.00000 |                                               *
    330       0.00571      0.17835      0.00000      0.03214      1.00000 |                                               *
    340       0.00521      0.18075      0.00000      0.03267      1.00000 |                                               *
    350       0.00488      0.18251      0.00000      0.03240      1.00000 |                                               *
    360       0.00451      0.18466      0.00000      0.03240      1.00000 |                                               *
    370       0.00417      0.18656      0.00000      0.03240      1.00000 |                                               *
    380       0.00389      0.18900      0.00000      0.03293      1.00000 |                                               *
    390       0.00367      0.19124      0.00000      0.03319      1.00000 |                                               *
    400       0.00337      0.19352      0.00000      0.03319      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.60      6.41  CHILDYRS
    352      1    400      1      7      3.29      4.15  AGE
    341      1    400      1      7      4.10      3.32  INCOME
    317      1    400      1      7      4.11      3.08  AGE_MOM
    311      1    400      1      7      4.12      3.02  OTH_CHLD
    304      1    400      1      7      3.98      3.05  EDUC_MOM
    251      1    400      2      7      5.19      1.76  ILLEGIT
    234      2    400      2      7      5.40      1.52  RACE_MOM
    214      2    400      2      7      5.54      1.32  PNCLATE
    183      2    400      3      7      5.58      1.11  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    96 terminal nodes
    Average :     43.35500 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 53 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 53 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 12

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 34284 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           12      0.11127
                  ROC           23      0.82257
                 Lift           53      4.63636
              KS-stat           23      0.55341
          Class.Error           10      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10868     0.12228     0.93519     0.72378     7.83348     4.00000     0.71670     0.42179     0.02910     0.02898
     10     0.07348     0.11189     0.97007     0.81531     9.00452     4.36364     0.82531     0.51188     0.02726     0.02845
     12     0.07034     0.11127     0.97259     0.81855     9.04977     4.36364     0.83540     0.51677     0.02660     0.02845
     20     0.06044     0.11233     0.98239     0.82045     9.41176     4.36364     0.88294     0.53632     0.02344     0.02845
     23     0.05857     0.11247     0.98410     0.82257     9.50226     4.36364     0.89416     0.55341     0.02318     0.02898
     30     0.05410     0.11349     0.98846     0.82062     9.68326     4.36364     0.90210     0.52790     0.02278     0.03003
     40     0.04964     0.11609     0.99127     0.81793     9.86425     4.54545     0.92389     0.52613     0.02054     0.02977
     50     0.04575     0.11825     0.99324     0.81664     9.90950     4.45455     0.93374     0.52044     0.01817     0.03003
     53     0.04484     0.11873     0.99375     0.81630     9.90950     4.63636     0.93704     0.51867     0.01791     0.03030
     60     0.04127     0.12078     0.99580     0.81369     9.95475     4.54545     0.95152     0.53196     0.01633     0.03056
     70     0.03748     0.12312     0.99721     0.81227    10.00000     4.36364     0.95916     0.54160     0.01449     0.03056
     80     0.03416     0.12515     0.99817     0.81256    10.00000     4.27273     0.97120     0.53997     0.01225     0.03056
     90     0.03213     0.12679     0.99862     0.81298    10.00000     4.36364     0.97337     0.52938     0.01080     0.03056
    100     0.02974     0.12814     0.99914     0.81432    10.00000     4.50909     0.98359     0.52532     0.00816     0.03030
    110     0.02665     0.13108     0.99965     0.81034    10.00000     4.36364     0.99023     0.51717     0.00658     0.03056
    120     0.02520     0.13345     0.99975     0.80682    10.00000     4.18182     0.99363     0.51540     0.00593     0.03082
    130     0.02368     0.13549     0.99983     0.80412    10.00000     4.18182     0.99430     0.50074     0.00553     0.03109
    140     0.02097     0.13841     0.99995     0.80286    10.00000     4.00000     0.99783     0.48881     0.00316     0.03214
    150     0.01977     0.14072     0.99996     0.80265    10.00000     4.00000     0.99851     0.48433     0.00250     0.03188
    160     0.01842     0.14256     0.99998     0.80212    10.00000     4.09091     0.99919     0.48786     0.00237     0.03214
    170     0.01707     0.14574     0.99999     0.80029    10.00000     4.09091     0.99932     0.47917     0.00158     0.03214
    180     0.01621     0.14678     0.99999     0.79861    10.00000     4.09091     0.99959     0.48203     0.00119     0.03161
    190     0.01494     0.14971     1.00000     0.79832    10.00000     4.18182     0.99973     0.47430     0.00066     0.03161
    193     0.01438     0.15068     1.00000     0.79818    10.00000     4.18182     1.00000     0.47294     0.00066     0.03188
    200     0.01362     0.15267     1.00000     0.79809    10.00000     4.18182     1.00000     0.48406     0.00053     0.03161
    210     0.01254     0.15493     1.00000     0.79682    10.00000     4.09091     1.00000     0.47932     0.00000     0.03135
    220     0.01173     0.15709     1.00000     0.79598    10.00000     4.00000     1.00000     0.47510     0.00000     0.03135
    230     0.01092     0.15953     1.00000     0.79625    10.00000     4.09091     1.00000     0.47743     0.00000     0.03188
    240     0.01013     0.16130     1.00000     0.79666    10.00000     4.18182     1.00000     0.47783     0.00000     0.03214
    250     0.00938     0.16263     1.00000     0.79775    10.00000     4.18182     1.00000     0.47824     0.00000     0.03240
    260     0.00879     0.16450     1.00000     0.79709    10.00000     4.27273     1.00000     0.48353     0.00000     0.03214
    270     0.00830     0.16727     1.00000     0.79504    10.00000     4.27273     1.00000     0.47567     0.00000     0.03267
    280     0.00783     0.16944     1.00000     0.79517    10.00000     4.27273     1.00000     0.47472     0.00000     0.03267
    290     0.00726     0.17119     1.00000     0.79443    10.00000     4.18182     1.00000     0.47445     0.00000     0.03267
    300     0.00675     0.17357     1.00000     0.79542    10.00000     4.18182     1.00000     0.47295     0.00000     0.03240
    310     0.00637     0.17512     1.00000     0.79539    10.00000     4.27273     1.00000     0.46766     0.00000     0.03293
    320     0.00604     0.17631     1.00000     0.79560    10.00000     4.23636     1.00000     0.46781     0.00000     0.03267
    330     0.00571     0.17835     1.00000     0.79615    10.00000     4.00000     1.00000     0.46588     0.00000     0.03214
    340     0.00521     0.18075     1.00000     0.79729    10.00000     4.18182     1.00000     0.47282     0.00000     0.03267
    350     0.00488     0.18251     1.00000     0.79760    10.00000     4.18182     1.00000     0.46983     0.00000     0.03240
    360     0.00451     0.18466     1.00000     0.79812    10.00000     4.18182     1.00000     0.47103     0.00000     0.03240
    370     0.00417     0.18656     1.00000     0.79835    10.00000     4.27273     1.00000     0.47876     0.00000     0.03240
    380     0.00389     0.18900     1.00000     0.79815    10.00000     4.36364     1.00000     0.47591     0.00000     0.03293
    390     0.00367     0.19124     1.00000     0.79741    10.00000     4.27273     1.00000     0.47578     0.00000     0.03319
    400     0.00337     0.19352     1.00000     0.79859    10.00000     4.32727     1.00000     0.47930     0.00000     0.03319


 =========================================
 Variable Importance for the 12-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          34.92742   34.93 |****       |
 AGE_MOM      34.80965   34.81 |****       |
 EDUC_MOM     29.40096   29.40 |****       |
 INCOME       26.70854   26.71 |****       |
 ILLEGIT      24.38103   24.38 |***        |
 OTH_CHLD     24.22074   24.22 |***        |
 RACE_MOM     13.93640   13.94 |**         |
 PNCLATE       7.59504    7.60 |**         |
 LBW           6.19870    6.20 |**         |


 Learn Sample Misclassification by Target Class
 For The 12-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7370.00         3.00       0.0004
 1                  221.00        22.00       199.00       0.9005


 Test Sample Misclassification by Target Class
 For The 12-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3685.00         1.00       0.0003
 1                  110.00         3.00       107.00       0.9727

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenetx_model.grv: 1.5 MB, 74% compression

 Grove file created containing:
      1 TreeNet

