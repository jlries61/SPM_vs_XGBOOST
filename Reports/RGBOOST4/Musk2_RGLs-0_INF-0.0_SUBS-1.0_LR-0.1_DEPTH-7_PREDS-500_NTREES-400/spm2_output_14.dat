
 The "USE "../Data/Classification/Musk2/SAMPLES4/data_tr" command: 00:00:01

 Model (target and predictors) reset: CLASS

 The KEEP list has 166 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 3300
 Records Kept in Learning sample: 3300

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1649
 Records Kept in Test sample: 1649

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         2791  84.58              2791.00  84.58
                 T        (1395  84.60)            (1395.00  84.60)
 1               L          509  15.42               509.00  15.42
                 T         (254  15.40)             (254.00  15.40)
 -----------------------------------------------------------------
 Totals
 0                         4186  84.58              4186.00  84.58
 1                          763  15.42               763.00  15.42
 -----------------------------------------------------------------
 Total                     4949                     4949.00
 Total Learn               3300                     3300.00
 Total Test                1649                     1649.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.35032      0.35982      0.15424      0.15403      1.00000 |                                               *
      2       0.30147      0.31724      0.15424      0.15403      1.00000 |                                         *
      3       0.26553      0.28642      0.15424      0.15403      1.00000 |                                     *
      4       0.23600      0.26235      0.15394      0.15403      1.00000 |                                  *
      5       0.21167      0.24145      0.04273      0.06246      1.00000 |                               *
      6       0.19143      0.22411      0.03273      0.05822      1.00000 |                             *
      7       0.17434      0.20983      0.02727      0.05397      1.00000 |                           *
      8       0.15870      0.19739      0.01970      0.04791      1.00000 |                         *
      9       0.14563      0.18767      0.01939      0.04851      1.00000 |                        *
     10       0.13359      0.17807      0.01485      0.04306      1.00000 |                       *
     11       0.12217      0.16817      0.01333      0.04245      1.00000 |                     *
     12       0.11223      0.15970      0.01303      0.04245      1.00000 |                    *
     13       0.10406      0.15338      0.01152      0.04063      1.00000 |                   *
     14       0.09583      0.14669      0.01061      0.03942      1.00000 |                   *
     15       0.08903      0.14137      0.00939      0.03639      1.00000 |                  *
     16       0.08287      0.13623      0.00879      0.03699      1.00000 |                 *
     17       0.07667      0.13194      0.00848      0.03578      1.00000 |                 *
     18       0.07133      0.12832      0.00818      0.03639      1.00000 |                *
     19       0.06662      0.12399      0.00697      0.03639      1.00000 |                *
     20       0.06184      0.12029      0.00576      0.03760      1.00000 |               *
     30       0.02943      0.09439      0.00091      0.03214      1.00000 |            *
     40       0.01704      0.08123      0.00000      0.02850      1.00000 |          *
     50       0.01072      0.07775      0.00000      0.02790      1.00000 |         *
     60       0.00705      0.07479      0.00000      0.02547      1.00000 |         *
     70       0.00473      0.07356      0.00000      0.02486      1.00000 |         *
     80       0.00328      0.07239      0.00000      0.02244      1.00000 |         *
     90       0.00228      0.07088      0.00000      0.02062      1.00000 |        *
    100       0.00156      0.06942      0.00000      0.02062      1.00000 |        *
    110       0.00114      0.06859      0.00000      0.02122      1.00000 |        *
    120       0.00078      0.06785      0.00000      0.02122      1.00000 |        *
    130       0.00055      0.06785      0.00000      0.02122      1.00000 |        *
    140       0.00040      0.06891      0.00000      0.02001      1.00000 |        *
    150       0.00029      0.06815      0.00000      0.02001      1.00000 |        *
    160       0.00021      0.06837      0.00000      0.01880      1.00000 |        *
    170       0.00015      0.06833      0.00000      0.01880      1.00000 |        *
    180       0.00011      0.06910      0.00000      0.01819      1.00000 |        *
    190       0.00008      0.06930      0.00000      0.01759      1.00000 |        *
    200       0.00006      0.06995      0.00000      0.01698      1.00000 |        *
    210       0.00004      0.07085      0.00000      0.01698      1.00000 |        *
    220       0.00003      0.07057      0.00000      0.01637      1.00000 |        *
    230       0.00002      0.07111      0.00000      0.01637      1.00000 |        *
    240       0.00001      0.07243      0.00000      0.01637      1.00000 |         *
    250       0.00001      0.07459      0.00000      0.01637      1.00000 |         *
    260       0.00001      0.07508      0.00000      0.01637      1.00000 |         *
    270       0.00000      0.07677      0.00000      0.01637      1.00000 |         *
    280       0.00000      0.07798      0.00000      0.01637      1.00000 |         *
    290       0.00000      0.08101      0.00000      0.01637      1.00000 |          *
    300       0.00000      0.08236      0.00000      0.01637      1.00000 |          *
    310       0.00000      0.08356      0.00000      0.01637      1.00000 |          *
    320       0.00000      0.08482      0.00000      0.01637      1.00000 |          *
    330       0.00000      0.08484      0.00000      0.01637      1.00000 |          *
    340       0.00000      0.08612      0.00000      0.01698      1.00000 |          *
    350       0.00000      0.08639      0.00000      0.01698      1.00000 |           *
    360       0.00000      0.08777      0.00000      0.01698      1.00000 |           *
    370       0.00000      0.08959      0.00000      0.01698      1.00000 |           *
    380       0.00000      0.09028      0.00000      0.01698      1.00000 |           *
    390       0.00000      0.09170      0.00000      0.01698      1.00000 |           *
    400       0.00000      0.09275      0.00000      0.01698      1.00000 |           *

 Core TN model building:          5.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    220      2    399      1      7      4.71      1.81  F160
    216      2    400      2      7      5.52      1.34  F8
    214      1    399      1      7      5.46      1.36  F1
    214      1    400      1      7      5.03      1.59  F36
    213      1    399      2      7      5.00      1.60  F4
    205      1    399      2      7      5.20      1.44  F50
    201      1    396      1      7      4.91      1.55  F163
    199      1    400      2      7      5.35      1.32  F22
    198      1    399      1      7      4.63      1.67  F151
    196      2    400      2      7      5.67      1.14  F10
    192      1    396      1      7      4.70      1.58  F66
    191      1    399      1      7      5.02      1.42  F88
    187      4    399      1      7      5.17      1.32  F117
    187      2    400      2      7      4.97      1.42  F109
    186      1    397      2      7      5.75      1.05  F6
    181      1    399      1      7      4.46      1.60  F116
    181      4    400      2      7      4.69      1.50  F126
    179      1    400      1      7      4.84      1.42  F63
    178     15    400      2      7      5.41      1.15  F165
    175      4    397      1      7      5.10      1.27  F111
    173      1    394      2      7      5.47      1.09  F55
    170      2    400      3      7      5.55      1.04  F15
    164      3    396      1      7      5.00      1.23  F84
    162      3    399      3      7      5.75      0.91  F7
    162      5    400      2      7      5.21      1.13  F86
    162      1    400      2      7      5.03      1.20  F132
    159      8    400      2      7      4.79      1.28  F162
    159      1    397      2      7      5.23      1.10  F92
    158      2    395      3      7      5.64      0.93  F25
    157     13    400      1      7      4.11      1.53  F49
    156      1    397      2      7      5.31      1.05  F42
    156      2    400      1      7      5.40      1.02  F29
    156     11    400      2      7      5.10      1.13  F110
    156      4    399      1      7      4.61      1.32  F58
    156      1    400      2      7      5.20      1.09  F9
    155      8    396      1      7      3.86      1.61  F146
    154      1    399      1      7      5.49      0.97  F24
    154      2    397      1      7      4.77      1.24  F68
    153      6    400      2      7      4.97      1.16  F21
    150      1    393      3      7      5.70      0.86  F38
    150      6    394      1      7      5.28      1.02  F59
    149      1    400      2      7      5.77      0.83  F140
    147      5    393      3      7      5.20      1.03  F52
    147      9    400      2      7      5.79      0.81  F83
    146      3    398      2      7      5.41      0.95  F43
    146      1    397      2      7      5.36      0.96  F80
    145      3    399      3      7      5.79      0.80  F20
    144      1    400      2      7      5.28      0.98  F166
    144      8    400      1      7      5.72      0.82  F18
    142      4    395      2      7      5.63      0.84  F23
    142      3    400      2      7      5.47      0.90  F61
    137      2    399      2      7      5.19      0.96  F102
    135      1    396      1      7      5.47      0.86  F54
    134      1    399      2      7      5.75      0.76  F30
    133      2    399      2      7      5.25      0.92  F89
    131      1    398      2      7      5.34      0.87  F14
    130     11    399      3      7      5.55      0.80  F161
    130      3    400      2      7      5.89      0.69  F95
    130      2    389      1      7      5.34      0.87  F106
    129      2    400      2      7      5.81      0.71  F3
    127      2    400      2      7      5.82      0.69  F32
    126      2    400      1      7      5.41      0.82  F96
    125      3    400      2      7      5.37      0.82  F44
    125      2    400      2      7      5.63      0.74  F13
    125      2    396      2      7      5.96      0.64  F19
    125     13    391      1      7      4.26      1.17  F130
    124      6    390      1      7      4.67      1.03  F133
    123      6    400      1      7      5.15      0.88  F77
    123      3    398      3      7      5.98      0.62  F11
    122      5    400      1      7      5.53      0.75  F34
    120      2    400      3      7      5.73      0.68  F33
    120      1    399      3      7      5.60      0.72  F56
    120      5    400      1      7      5.29      0.81  F131
    119      1    399      1      7      4.71      0.98  F124
    117     11    378      1      7      5.43      0.75  F97
    117      2    392      2      7      5.57      0.71  F35
    117      1    392      3      7      6.11      0.55  F2
    116      1    399      1      7      4.16      1.12  F129
    115     14    400      1      7      5.41      0.75  F123
    114      1    398      2      7      5.58      0.69  F122
    114      3    400      2      7      5.70      0.66  F121
    113      2    387      2      7      5.58      0.69  F16
    113      2    400      2      7      5.87      0.60  F17
    113     13    392      3      7      5.58      0.68  F79
    112      1    397      2      7      5.38      0.74  F28
    112     10    399      3      7      5.59      0.68  F53
    110      4    394      1      7      5.71      0.63  F157
    110      3    398      2      7      5.58      0.67  F72
    109      3    400      2      7      5.61      0.65  F144
    109      2    395      1      7      5.83      0.59  F115
    109      8    399      1      7      5.41      0.71  F104
    108     16    393      2      7      5.19      0.76  F137
    107     13    394      2      7      5.83      0.58  F155
    106     17    397      2      7      5.26      0.73  F51
    106      1    394      2      7      5.45      0.68  F48
    106      4    388      1      7      3.55      1.18  F67
    105      2    399      1      7      5.08      0.77  F108
    105      1    376      2      7      5.10      0.76  F103
    105      4    398      1      7      5.66      0.62  F107
    103     17    400      2      7      6.06      0.50  F141
    103      5    400      1      7      4.75      0.84  F31
    103      1    397      2      7      5.80      0.57  F99
    103     13    392      3      7      5.54      0.63  F105
    102      4    394      2      7      5.41      0.66  F70
    100      3    400      3      7      5.71      0.57  F47
    100      5    400      3      7      5.61      0.60  F154
    100      5    400      4      7      6.01      0.50  F12
    100      1    396      2      7      5.56      0.61  F46
     99     12    392      2      7      5.51      0.62  F138
     99      3    400      1      7      4.75      0.81  F91
     95      6    397      1      7      5.18      0.67  F37
     93      1    400      2      7      5.38      0.61  F112
     93      5    388      2      7      5.31      0.63  F75
     91      4    397      4      7      5.89      0.48  F60
     91     18    396      1      7      5.30      0.62  F90
     91      7    400      2      7      5.20      0.64  F87
     90      5    395      2      7      5.59      0.54  F158
     88      8    381      3      7      5.89      0.47  F93
     87      1    392      1      7      5.10      0.63  F136
     86      4    392      1      7      5.99      0.43  F27
     85      3    400      3      7      5.98      0.43  F39
     84      4    397      2      7      4.90      0.65  F5
     83      3    392      2      7      6.08      0.40  F26
     82     41    379      2      7      5.54      0.51  F81
     80      1    399      1      7      5.75      0.45  F85
     79     12    398      2      7      5.56      0.48  F147
     77     10    390      3      7      5.90      0.41  F74
     77      7    392      3      7      5.73      0.44  F134
     76      2    386      2      7      5.84      0.41  F69
     75      4    394      2      7      5.80      0.41  F45
     75     13    398      2      7      5.72      0.43  F135
     74     18    395      2      7      5.84      0.40  F118
     73     31    400      1      7      5.58      0.44  F120
     73      1    395      2      7      6.05      0.36  F73
     73     11    400      1      7      4.52      0.64  F57
     70      2    394      3      7      5.80      0.39  F62
     70      1    389      2      7      6.09      0.34  F94
     70      8    398      1      7      5.74      0.40  F78
     70     19    394      3      7      5.76      0.39  F143
     68      4    383      2      7      5.31      0.46  F64
     67      4    400      2      7      5.96      0.34  F40
     67      8    400      3      7      5.82      0.37  F159
     66     17    391      1      7      5.02      0.49  F152
     66      1    392      3      7      5.56      0.40  F145
     65      3    399      2      7      5.75      0.37  F113
     65     12    385      2      7      5.62      0.39  F41
     65      8    393      3      7      5.37      0.43  F128
     64      3    392      2      7      5.58      0.39  F156
     63     11    400      3      7      6.13      0.30  F65
     62      2    400      2      7      5.56      0.38  F139
     62      1    392      1      7      5.21      0.43  F148
     61     11    396      1      7      5.61      0.37  F119
     61      3    397      3      7      6.00      0.31  F127
     60      4    398      2      7      5.28      0.41  F76
     57     17    399      3      7      5.77      0.32  F164
     57      1    380      4      7      5.86      0.31  F153
     57      3    337      3      7      5.89      0.30  F125
     53     17    379      2      7      5.43      0.34  F101
     52      4    393      2      7      6.46      0.20  F100
     50      6    400      2      7      5.80      0.28  F149
     48      3    317      1      7      4.92      0.37  F71
     47      8    395      3      7      5.94      0.24  F82
     41     14    389      3      7      6.12      0.19  F98
     36     11    381      3      7      6.19      0.16  F142
     31     17    371      3      7      5.58      0.19  F150
     27     47    389      3      7      5.96      0.14  F114

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    34 terminal nodes
    Largest :    86 terminal nodes
    Average :     60.41750 terminal nodes

 Reconciling 3300 Learn sample scores across 5 selected models,
 the largest having 392 trees, to compute gains and PS tables.

 Reconciling 1649 Test sample scores across 5 selected models,
 the largest having 392 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 165

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     3300      3300.00
 N Test  Obs:     1649      1649.00
 Learn Rate :    0.1000000

 Storage requirements: 47934 tree / 1 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL          165      0.06688
                  ROC          392      0.99811
                 Lift          147      6.49213
              KS-stat          353      0.96167
          Class.Error          244      0.01516

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.35032     0.35982     0.97886     0.91091     6.44486     5.93636     0.89101     0.79020     0.15424     0.15403
      2     0.30147     0.31724     0.98154     0.93439     6.48330     6.21654     0.91507     0.82027     0.15424     0.15403
     10     0.13359     0.17807     0.99518     0.97406     6.48330     6.37795     0.97570     0.87715     0.01485     0.04306
     20     0.06184     0.12029     0.99995     0.98496     6.48330     6.41339     0.99196     0.89473     0.00576     0.03760
     26     0.03904     0.10219     1.00000     0.98727     6.48330     6.41339     1.00000     0.90616     0.00182     0.03153
     30     0.02943     0.09439     1.00000     0.98756     6.48330     6.41339     1.00000     0.90761     0.00091     0.03214
     40     0.01704     0.08123     1.00000     0.98806     6.48330     6.41339     1.00000     0.92335     0.00000     0.02850
     50     0.01072     0.07775     1.00000     0.98880     6.48330     6.41339     1.00000     0.92549     0.00000     0.02790
     60     0.00705     0.07479     1.00000     0.98932     6.48330     6.41339     1.00000     0.93232     0.00000     0.02547
     70     0.00473     0.07356     1.00000     0.99048     6.48330     6.41339     1.00000     0.93696     0.00000     0.02486
     80     0.00328     0.07239     1.00000     0.99203     6.48330     6.41339     1.00000     0.94125     0.00000     0.02244
     90     0.00228     0.07088     1.00000     0.99293     6.48330     6.45276     1.00000     0.94556     0.00000     0.02062
    100     0.00156     0.06942     1.00000     0.99396     6.48330     6.41339     1.00000     0.94913     0.00000     0.02062
    110     0.00114     0.06859     1.00000     0.99489     6.48330     6.45276     1.00000     0.94841     0.00000     0.02122
    120     0.00078     0.06785     1.00000     0.99542     6.48330     6.45276     1.00000     0.94914     0.00000     0.02122
    130     0.00055     0.06785     1.00000     0.99602     6.48330     6.41732     1.00000     0.95021     0.00000     0.02122
    140     0.00040     0.06891     1.00000     0.99619     6.48330     6.45276     1.00000     0.95164     0.00000     0.02001
    147     0.00033     0.06862     1.00000     0.99641     6.48330     6.49213     1.00000     0.95092     0.00000     0.02062
    150     0.00029     0.06815     1.00000     0.99654     6.48330     6.49213     1.00000     0.95236     0.00000     0.02001
    160     0.00021     0.06837     1.00000     0.99664     6.48330     6.49213     1.00000     0.95057     0.00000     0.01880
    165     0.00018     0.06688     1.00000     0.99679     6.48330     6.49213     1.00000     0.95344     0.00000     0.01819
    170     0.00015     0.06833     1.00000     0.99686     6.48330     6.49213     1.00000     0.95344     0.00000     0.01880
    180     0.00011     0.06910     1.00000     0.99694     6.48330     6.49213     1.00000     0.95309     0.00000     0.01819
    190     0.00008     0.06930     1.00000     0.99710     6.48330     6.49213     1.00000     0.95452     0.00000     0.01759
    200     0.00006     0.06995     1.00000     0.99716     6.48330     6.49213     1.00000     0.95452     0.00000     0.01698
    210     0.00004     0.07085     1.00000     0.99735     6.48330     6.49213     1.00000     0.95307     0.00000     0.01698
    220     0.00003     0.07057     1.00000     0.99762     6.48330     6.49213     1.00000     0.95631     0.00000     0.01637
    230     0.00002     0.07111     1.00000     0.99770     6.48330     6.49213     1.00000     0.95702     0.00000     0.01637
    240     0.00001     0.07243     1.00000     0.99772     6.48330     6.49213     1.00000     0.95485     0.00000     0.01637
    244     0.00001     0.07301     1.00000     0.99775     6.48330     6.49213     1.00000     0.95521     0.00000     0.01516
    250     0.00001     0.07459     1.00000     0.99769     6.48330     6.49213     1.00000     0.95843     0.00000     0.01637
    260     0.00001     0.07508     1.00000     0.99782     6.48330     6.49213     1.00000     0.95915     0.00000     0.01637
    270     0.00000     0.07677     1.00000     0.99783     6.48330     6.49213     1.00000     0.95987     0.00000     0.01637
    280     0.00000     0.07798     1.00000     0.99787     6.48330     6.49213     1.00000     0.95628     0.00000     0.01637
    290     0.00000     0.08101     1.00000     0.99785     6.48330     6.49213     1.00000     0.95700     0.00000     0.01637
    300     0.00000     0.08236     1.00000     0.99787     6.48330     6.49213     1.00000     0.95700     0.00000     0.01637
    310     0.00000     0.08356     1.00000     0.99791     6.48330     6.49213     1.00000     0.95628     0.00000     0.01637
    320     0.00000     0.08482     1.00000     0.99793     6.48330     6.49213     1.00000     0.95736     0.00000     0.01637
    330     0.00000     0.08484     1.00000     0.99797     6.48330     6.49213     1.00000     0.95880     0.00000     0.01637
    340     0.00000     0.08612     1.00000     0.99798     6.48330     6.49213     1.00000     0.95880     0.00000     0.01698
    350     0.00000     0.08639     1.00000     0.99805     6.48330     6.49213     1.00000     0.96023     0.00000     0.01698
    353     0.00000     0.08684     1.00000     0.99804     6.48330     6.49213     1.00000     0.96167     0.00000     0.01698
    360     0.00000     0.08777     1.00000     0.99805     6.48330     6.49213     1.00000     0.96167     0.00000     0.01698
    370     0.00000     0.08959     1.00000     0.99804     6.48330     6.49213     1.00000     0.96095     0.00000     0.01698
    380     0.00000     0.09028     1.00000     0.99804     6.48330     6.49213     1.00000     0.96023     0.00000     0.01698
    390     0.00000     0.09170     1.00000     0.99808     6.48330     6.49213     1.00000     0.96167     0.00000     0.01698
    392     0.00000     0.09147     1.00000     0.99811     6.48330     6.49213     1.00000     0.96167     0.00000     0.01698
    400     0.00000     0.09275     1.00000     0.99809     6.48330     6.49213     1.00000     0.96095     0.00000     0.01698


 ==========================================
 Variable Importance for the 165-tree Model
 ==========================================

               Abs     Rel

 F36     100.00000  100.00 |***********|
 F132     64.42947   64.43 |*******    |
 F151     44.04112   44.04 |*****      |
 F35      42.88574   42.89 |*****      |
 F122     41.94873   41.95 |*****      |
 F1       41.88697   41.89 |*****      |
 F163     40.62533   40.63 |*****      |
 F124     40.08968   40.09 |*****      |
 F31      38.01453   38.01 |*****      |
 F33      36.16240   36.16 |*****      |
 F112     31.93092   31.93 |****       |
 F22      31.87929   31.88 |****       |
 F50      31.84306   31.84 |****       |
 F145     31.03774   31.04 |****       |
 F140     30.89291   30.89 |****       |
 F80      30.76875   30.77 |****       |
 F102     30.70919   30.71 |****       |
 F109     28.20778   28.21 |****       |
 F55      27.35564   27.36 |****       |
 F162     26.52241   26.52 |****       |
 F160     25.93444   25.93 |****       |
 F66      25.87049   25.87 |****       |
 F43      25.07166   25.07 |***        |
 F17      23.19021   23.19 |***        |
 F9       22.67791   22.68 |***        |
 F10      22.46228   22.46 |***        |
 F61      22.09037   22.09 |***        |
 F110     21.95976   21.96 |***        |
 F92      21.85016   21.85 |***        |
 F29      21.65725   21.66 |***        |
 F88      21.44327   21.44 |***        |
 F4       20.80077   20.80 |***        |
 F148     20.67751   20.68 |***        |
 F63      20.59719   20.60 |***        |
 F126     20.54439   20.54 |***        |
 F25      20.47876   20.48 |***        |
 F153     20.32773   20.33 |***        |
 F99      20.18865   20.19 |***        |
 F116     19.89144   19.89 |***        |
 F38      19.61053   19.61 |***        |
 F42      19.03847   19.04 |***        |
 F67      19.01727   19.02 |***        |
 F91      18.95038   18.95 |***        |
 F136     17.97241   17.97 |***        |
 F6       17.03547   17.04 |***        |
 F56      16.69909   16.70 |***        |
 F154     16.44759   16.45 |***        |
 F111     15.93418   15.93 |***        |
 F117     15.67693   15.68 |***        |
 F62      15.57919   15.58 |***        |
 F85      15.50540   15.51 |***        |
 F54      15.42310   15.42 |**         |
 F144     15.16299   15.16 |**         |
 F52      15.14724   15.15 |**         |
 F21      14.87300   14.87 |**         |
 F72      14.44919   14.45 |**         |
 F30      14.32967   14.33 |**         |
 F24      14.28200   14.28 |**         |
 F129     14.23759   14.24 |**         |
 F58      14.05418   14.05 |**         |
 F46      13.86902   13.87 |**         |
 F68      13.86285   13.86 |**         |
 F79      13.53396   13.53 |**         |
 F157     13.48382   13.48 |**         |
 F104     13.47942   13.48 |**         |
 F8       13.44803   13.45 |**         |
 F89      13.43062   13.43 |**         |
 F7       13.17137   13.17 |**         |
 F133     13.10987   13.11 |**         |
 F14      13.08833   13.09 |**         |
 F70      13.05502   13.06 |**         |
 F47      13.02534   13.03 |**         |
 F95      12.99592   13.00 |**         |
 F69      12.91463   12.91 |**         |
 F77      12.70488   12.70 |**         |
 F5       12.54300   12.54 |**         |
 F105     12.34044   12.34 |**         |
 F96      12.21330   12.21 |**         |
 F166     12.20516   12.21 |**         |
 F94      12.18241   12.18 |**         |
 F73      11.82586   11.83 |**         |
 F115     11.42750   11.43 |**         |
 F131     11.23794   11.24 |**         |
 F108     11.16806   11.17 |**         |
 F125     10.96742   10.97 |**         |
 F83      10.91802   10.92 |**         |
 F121     10.91164   10.91 |**         |
 F146     10.83160   10.83 |**         |
 F59      10.80030   10.80 |**         |
 F142     10.79036   10.79 |**         |
 F32      10.75139   10.75 |**         |
 F44      10.43134   10.43 |**         |
 F71      10.36934   10.37 |**         |
 F64      10.24230   10.24 |**         |
 F106     10.13018   10.13 |**         |
 F86      10.03849   10.04 |**         |
 F45       9.86029    9.86 |**         |
 F103      9.72885    9.73 |**         |
 F2        9.60526    9.61 |**         |
 F20       9.50870    9.51 |**         |
 F16       9.23670    9.24 |**         |
 F60       9.21388    9.21 |**         |
 F53       9.17142    9.17 |**         |
 F15       9.11250    9.11 |**         |
 F48       9.05602    9.06 |**         |
 F130      9.03116    9.03 |**         |
 F155      9.00228    9.00 |**         |
 F49       8.97595    8.98 |**         |
 F84       8.84101    8.84 |**         |
 F158      8.82096    8.82 |**         |
 F34       8.81551    8.82 |**         |
 F19       8.51110    8.51 |**         |
 F141      8.25299    8.25 |**         |
 F3        8.18727    8.19 |**         |
 F40       8.15064    8.15 |**         |
 F39       8.09272    8.09 |**         |
 F78       7.96100    7.96 |**         |
 F156      7.94487    7.94 |**         |
 F93       7.82430    7.82 |**         |
 F161      7.77706    7.78 |**         |
 F11       7.76333    7.76 |**         |
 F18       7.60835    7.61 |**         |
 F165      7.55431    7.55 |**         |
 F139      7.45844    7.46 |**         |
 F100      7.08494    7.08 |**         |
 F119      6.92836    6.93 |**         |
 F27       6.85661    6.86 |**         |
 F138      6.85402    6.85 |**         |
 F128      6.79277    6.79 |**         |
 F28       6.76973    6.77 |**         |
 F123      6.67526    6.68 |**         |
 F75       6.50816    6.51 |**         |
 F137      6.44834    6.45 |**         |
 F13       6.27914    6.28 |**         |
 F159      6.17785    6.18 |**         |
 F76       6.15736    6.16 |**         |
 F147      5.88307    5.88 |**         |
 F118      5.86629    5.87 |**         |
 F12       5.80949    5.81 |**         |
 F134      5.61567    5.62 |**         |
 F90       5.59543    5.60 |**         |
 F37       5.58595    5.59 |**         |
 F101      5.49881    5.50 |*          |
 F135      5.10929    5.11 |*          |
 F26       5.05113    5.05 |*          |
 F98       4.97196    4.97 |*          |
 F164      4.71324    4.71 |*          |
 F23       4.56946    4.57 |*          |
 F107      4.55923    4.56 |*          |
 F97       4.42081    4.42 |*          |
 F51       4.35601    4.36 |*          |
 F113      4.34837    4.35 |*          |
 F57       3.93220    3.93 |*          |
 F65       3.61323    3.61 |*          |
 F152      3.38477    3.38 |*          |
 F143      3.37197    3.37 |*          |
 F127      3.31775    3.32 |*          |
 F150      3.27652    3.28 |*          |
 F81       2.55688    2.56 |*          |
 F120      2.52601    2.53 |*          |
 F149      2.26401    2.26 |*          |
 F74       2.10165    2.10 |*          |
 F82       1.87034    1.87 |*          |
 F114      1.85637    1.86 |*          |
 F41       0.89047    0.89 |*          |
 F87       0.85552    0.86 |*          |


 Learn Sample Misclassification by Target Class
 For The 165-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 2791.00      2791.00         0.00       0.0000
 1                  509.00       509.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 165-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1395.00      1391.00         4.00       0.0029
 1                  254.00       228.00        26.00       0.1024

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                5.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               5.000 sec ( 0.00 hrs, 100.00%)
    Core model:         5.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 2.1 MB, 75% compression

 Grove file created containing:
      1 TreeNet

