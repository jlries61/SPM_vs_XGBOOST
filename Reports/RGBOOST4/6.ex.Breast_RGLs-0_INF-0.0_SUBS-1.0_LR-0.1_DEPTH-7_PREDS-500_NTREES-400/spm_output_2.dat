
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14643      0.16312      0.04116      0.04116      1.00000 |                                               *
      2       0.13697      0.16065      0.04116      0.04116      1.00000 |                                              *
      3       0.12880      0.15818      0.04116      0.04116      1.00000 |                                              *
      4       0.12164      0.15725      0.04116      0.04116      1.00000 |                                             *
      5       0.11683      0.15673      0.04116      0.04116      1.00000 |                                             *
      6       0.11322      0.15680      0.04116      0.04116      1.00000 |                                             *
      7       0.10999      0.15674      0.04116      0.04116      1.00000 |                                             *
      8       0.10681      0.15576      0.04056      0.04116      1.00000 |                                             *
      9       0.10411      0.15587      0.03995      0.04116      1.00000 |                                             *
     10       0.10195      0.15621      0.03814      0.04479      1.00000 |                                             *
     11       0.09940      0.15623      0.03632      0.04479      1.00000 |                                             *
     12       0.09780      0.15643      0.03511      0.04358      1.00000 |                                             *
     13       0.09608      0.15604      0.03511      0.04358      1.00000 |                                             *
     14       0.09372      0.15562      0.03390      0.04358      1.00000 |                                             *
     15       0.09161      0.15581      0.03390      0.04358      1.00000 |                                             *
     16       0.08988      0.15599      0.03390      0.04479      1.00000 |                                             *
     17       0.08760      0.15592      0.03390      0.04479      1.00000 |                                             *
     18       0.08578      0.15607      0.03208      0.04237      1.00000 |                                             *
     19       0.08467      0.15711      0.03208      0.04358      1.00000 |                                             *
     20       0.08353      0.15735      0.03208      0.04237      1.00000 |                                             *
     30       0.07489      0.16224      0.02663      0.04600      1.00000 |                                               *
     40       0.06791      0.16511      0.02421      0.04843      1.00000 |                                               *
     50       0.06333      0.16903      0.02361      0.04722      1.00000 |                                               *
     60       0.05461      0.17084      0.02119      0.05085      1.00000 |                                               *
     70       0.04907      0.17675      0.01816      0.04843      1.00000 |                                               *
     80       0.04493      0.17944      0.01574      0.04964      1.00000 |                                               *
     90       0.04103      0.18394      0.01392      0.05085      1.00000 |                                               *
    100       0.03680      0.18636      0.01211      0.05327      1.00000 |                                               *
    110       0.03407      0.18989      0.01090      0.05206      1.00000 |                                               *
    120       0.03124      0.19303      0.00969      0.05448      1.00000 |                                               *
    130       0.02927      0.19596      0.00847      0.05327      1.00000 |                                               *
    140       0.02723      0.19878      0.00787      0.05327      1.00000 |                                               *
    150       0.02511      0.20031      0.00666      0.05206      1.00000 |                                               *
    160       0.02319      0.20405      0.00545      0.05085      1.00000 |                                               *
    170       0.02177      0.20699      0.00545      0.05085      1.00000 |                                               *
    180       0.01931      0.21288      0.00363      0.05206      1.00000 |                                               *
    190       0.01745      0.21761      0.00303      0.05327      1.00000 |                                               *
    200       0.01543      0.22326      0.00121      0.05327      1.00000 |                                               *
    210       0.01418      0.22632      0.00121      0.05448      1.00000 |                                               *
    220       0.01315      0.23147      0.00121      0.05569      1.00000 |                                               *
    230       0.01194      0.23797      0.00121      0.05811      1.00000 |                                               *
    240       0.01088      0.24513      0.00121      0.05811      1.00000 |                                               *
    250       0.00995      0.25198      0.00121      0.05811      1.00000 |                                               *
    260       0.00895      0.25731      0.00121      0.05811      1.00000 |                                               *
    270       0.00828      0.26275      0.00121      0.05811      1.00000 |                                               *
    280       0.00769      0.26908      0.00121      0.05811      1.00000 |                                               *
    290       0.00706      0.27520      0.00121      0.05932      1.00000 |                                               *
    300       0.00659      0.28341      0.00121      0.05932      1.00000 |                                               *
    310       0.00611      0.28951      0.00121      0.05932      1.00000 |                                               *
    320       0.00573      0.29472      0.00121      0.06174      1.00000 |                                               *
    330       0.00535      0.30080      0.00121      0.06053      1.00000 |                                               *
    340       0.00500      0.30561      0.00121      0.06174      1.00000 |                                               *
    350       0.00454      0.31373      0.00121      0.06174      1.00000 |                                               *
    360       0.00426      0.31953      0.00121      0.06174      1.00000 |                                               *
    370       0.00404      0.32569      0.00121      0.06295      1.00000 |                                               *
    380       0.00386      0.33122      0.00121      0.06295      1.00000 |                                               *
    390       0.00374      0.33594      0.00121      0.06295      1.00000 |                                               *
    400       0.00361      0.34199      0.00121      0.06174      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.72      6.28  FOLLOW
    399      1    400      1      6      2.38      5.60  ENTAGE
    352      1    400      1      7      4.19      3.35  PD
    138      1    396      1      7      3.22      1.65  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    59 terminal nodes
    Average :     26.83250 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 205 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 205 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 14

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 21066 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           14      0.15562
                  ROC          205      0.76253
                 Lift            7      4.41176
              KS-stat           63      0.50386
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14643     0.16312     0.93844     0.48997     7.35686     3.55709     0.74239     0.27503     0.04116     0.04116
      7     0.10999     0.15674     0.95362     0.66128     8.09559     4.41176     0.79453     0.35658     0.04116     0.04116
     10     0.10195     0.15621     0.95655     0.69775     7.94118     4.11765     0.80689     0.38295     0.03814     0.04479
     14     0.09372     0.15562     0.96652     0.74803     8.38235     3.82353     0.80418     0.41964     0.03390     0.04358
     20     0.08353     0.15735     0.97741     0.75401     8.82353     3.82353     0.85424     0.42395     0.03208     0.04237
     30     0.07489     0.16224     0.98252     0.75238     9.55882     4.11765     0.89988     0.45425     0.02663     0.04600
     40     0.06791     0.16511     0.98939     0.75384     9.70588     4.11765     0.92071     0.46168     0.02421     0.04843
     50     0.06333     0.16903     0.99072     0.75451     9.70588     3.82353     0.92198     0.43390     0.02361     0.04722
     57     0.05679     0.16993     0.99476     0.76045    10.00000     3.82353     0.94823     0.45425     0.02240     0.04843
     60     0.05461     0.17084     0.99547     0.75819    10.00000     3.82353     0.94823     0.48997     0.02119     0.05085
     63     0.05213     0.17207     0.99653     0.76064    10.00000     3.82353     0.96383     0.50386     0.01998     0.05085
     70     0.04907     0.17675     0.99716     0.75072    10.00000     3.82353     0.96446     0.48871     0.01816     0.04843
     80     0.04493     0.17944     0.99812     0.74961    10.00000     3.82353     0.97141     0.47356     0.01574     0.04964
     90     0.04103     0.18394     0.99865     0.74768    10.00000     3.82353     0.97727     0.46687     0.01392     0.05085
    100     0.03680     0.18636     0.99923     0.74998    10.00000     4.00000     0.98927     0.48745     0.01211     0.05327
    110     0.03407     0.18989     0.99944     0.74931    10.00000     3.82353     0.99369     0.49250     0.01090     0.05206
    120     0.03124     0.19303     0.99960     0.75512    10.00000     3.82353     0.99684     0.49250     0.00969     0.05448
    130     0.02927     0.19596     0.99966     0.75724    10.00000     3.82353     0.99684     0.49124     0.00847     0.05327
    140     0.02723     0.19878     0.99972     0.75680    10.00000     3.82353     0.99811     0.48619     0.00787     0.05327
    150     0.02511     0.20031     0.99979     0.75960    10.00000     3.52941     0.99811     0.49250     0.00666     0.05206
    160     0.02319     0.20405     0.99983     0.75808    10.00000     3.70588     0.99811     0.48871     0.00545     0.05085
    170     0.02177     0.20699     0.99983     0.75798    10.00000     3.52941     0.99811     0.49502     0.00545     0.05085
    180     0.01931     0.21288     0.99991     0.75704    10.00000     3.52941     0.99811     0.48997     0.00363     0.05206
    183     0.01864     0.21414     0.99994     0.75711    10.00000     3.52941     0.99874     0.49086     0.00303     0.05206
    190     0.01745     0.21761     0.99994     0.75938    10.00000     3.52941     0.99874     0.49124     0.00303     0.05327
    196     0.01593     0.22171     0.99998     0.75685    10.00000     3.52941     0.99874     0.48745     0.00121     0.05448
    200     0.01543     0.22326     0.99998     0.75771    10.00000     3.52941     0.99874     0.47935     0.00121     0.05327
    205     0.01481     0.22426     0.99998     0.76253    10.00000     3.52941     0.99874     0.48945     0.00121     0.05327
    210     0.01418     0.22632     0.99998     0.76120    10.00000     3.52941     0.99874     0.48819     0.00121     0.05448
    220     0.01315     0.23147     0.99998     0.75951    10.00000     3.52941     0.99874     0.48693     0.00121     0.05569
    230     0.01194     0.23797     0.99998     0.75720    10.00000     3.52941     0.99874     0.46546     0.00121     0.05811
    240     0.01088     0.24513     0.99998     0.75160    10.00000     3.52941     0.99874     0.46145     0.00121     0.05811
    250     0.00995     0.25198     0.99998     0.74792    10.00000     3.52941     0.99874     0.46272     0.00121     0.05811
    260     0.00895     0.25731     0.99998     0.74967    10.00000     3.52941     0.99874     0.45261     0.00121     0.05811
    270     0.00828     0.26275     0.99998     0.74963    10.00000     3.52941     0.99874     0.45514     0.00121     0.05811
    280     0.00769     0.26908     0.99998     0.74851    10.00000     3.52941     0.99874     0.46019     0.00121     0.05811
    290     0.00706     0.27520     0.99998     0.74647    10.00000     3.52941     0.99874     0.45640     0.00121     0.05932
    300     0.00659     0.28341     0.99998     0.73971    10.00000     3.52941     0.99874     0.42825     0.00121     0.05932
    310     0.00611     0.28951     0.99998     0.73916    10.00000     3.52941     0.99874     0.42231     0.00121     0.05932
    320     0.00573     0.29472     0.99998     0.73953    10.00000     3.52941     0.99874     0.43457     0.00121     0.06174
    330     0.00535     0.30080     0.99998     0.73823    10.00000     3.52941     0.99874     0.43204     0.00121     0.06053
    340     0.00500     0.30561     0.99998     0.73730    10.00000     3.52941     0.99874     0.42825     0.00121     0.06174
    350     0.00454     0.31373     0.99998     0.73388    10.00000     3.52941     0.99874     0.43457     0.00121     0.06174
    360     0.00426     0.31953     0.99998     0.73459    10.00000     3.52941     0.99874     0.43962     0.00121     0.06174
    370     0.00404     0.32569     0.99998     0.73184    10.00000     3.52941     0.99874     0.42952     0.00121     0.06295
    380     0.00386     0.33122     0.99998     0.73377    10.00000     3.52941     0.99874     0.43583     0.00121     0.06295
    390     0.00374     0.33594     0.99998     0.73258    10.00000     3.70588     0.99874     0.44972     0.00121     0.06295
    400     0.00361     0.34199     0.99998     0.72984    10.00000     3.52941     0.99874     0.44467     0.00121     0.06174


 =========================================
 Variable Importance for the 14-tree Model
 =========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     56.31009   56.31 |*******    |
 PD         37.54141   37.54 |*****      |
 FH         14.65207   14.65 |**         |


 Learn Sample Misclassification by Target Class
 For The 14-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1583.00         1.00       0.0006
 1                   68.00        13.00        55.00       0.8088


 Test Sample Misclassification by Target Class
 For The 14-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       787.00         5.00       0.0063
 1                   34.00         3.00        31.00       0.9118

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 907 kb , 77% compression

 Grove file created containing:
      1 TreeNet

