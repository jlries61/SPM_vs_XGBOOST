
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14816      0.16161      0.04116      0.04116      1.00000 |                                               *
      2       0.13811      0.15690      0.04116      0.04116      1.00000 |                                              *
      3       0.12896      0.15547      0.04116      0.04116      1.00000 |                                             *
      4       0.12331      0.15279      0.04116      0.04116      1.00000 |                                            *
      5       0.11815      0.15079      0.04116      0.04116      1.00000 |                                            *
      6       0.11296      0.14980      0.04116      0.04116      1.00000 |                                           *
      7       0.10759      0.14863      0.03995      0.04358      1.00000 |                                           *
      8       0.10361      0.14793      0.03935      0.04358      1.00000 |                                           *
      9       0.09998      0.14802      0.03814      0.04479      1.00000 |                                           *
     10       0.09710      0.14799      0.03753      0.04479      1.00000 |                                           *
     11       0.09459      0.14820      0.03753      0.04479      1.00000 |                                           *
     12       0.09127      0.14827      0.03632      0.04843      1.00000 |                                           *
     13       0.08936      0.14821      0.03632      0.04843      1.00000 |                                           *
     14       0.08631      0.14863      0.03511      0.04722      1.00000 |                                           *
     15       0.08413      0.14847      0.03390      0.04722      1.00000 |                                           *
     16       0.08238      0.14874      0.03329      0.04722      1.00000 |                                           *
     17       0.08074      0.14892      0.03390      0.04722      1.00000 |                                           *
     18       0.07883      0.14960      0.03329      0.04722      1.00000 |                                           *
     19       0.07726      0.15041      0.03329      0.04843      1.00000 |                                            *
     20       0.07623      0.15054      0.03269      0.04843      1.00000 |                                            *
     30       0.06684      0.15387      0.02845      0.04600      1.00000 |                                             *
     40       0.06188      0.15654      0.02482      0.04722      1.00000 |                                             *
     50       0.05774      0.15811      0.02179      0.04600      1.00000 |                                              *
     60       0.05288      0.16011      0.02119      0.04479      1.00000 |                                               *
     70       0.04814      0.16356      0.01755      0.04479      1.00000 |                                               *
     80       0.04491      0.16647      0.01392      0.04479      1.00000 |                                               *
     90       0.04268      0.16856      0.01211      0.04237      1.00000 |                                               *
    100       0.03912      0.17187      0.00908      0.04358      1.00000 |                                               *
    110       0.03642      0.17629      0.00787      0.04479      1.00000 |                                               *
    120       0.03431      0.17847      0.00666      0.04964      1.00000 |                                               *
    130       0.03242      0.17977      0.00605      0.05085      1.00000 |                                               *
    140       0.03023      0.18238      0.00545      0.05206      1.00000 |                                               *
    150       0.02726      0.18609      0.00484      0.05206      1.00000 |                                               *
    160       0.02484      0.19203      0.00424      0.05085      1.00000 |                                               *
    170       0.02238      0.19677      0.00303      0.04964      1.00000 |                                               *
    180       0.02050      0.20283      0.00182      0.05085      1.00000 |                                               *
    190       0.01870      0.20825      0.00121      0.05206      1.00000 |                                               *
    200       0.01726      0.21209      0.00121      0.05206      1.00000 |                                               *
    210       0.01601      0.21689      0.00061      0.05206      1.00000 |                                               *
    220       0.01471      0.21928      0.00061      0.04964      1.00000 |                                               *
    230       0.01388      0.22102      0.00061      0.04964      1.00000 |                                               *
    240       0.01303      0.22509      0.00061      0.04964      1.00000 |                                               *
    250       0.01204      0.22779      0.00061      0.04843      1.00000 |                                               *
    260       0.01087      0.23230      0.00061      0.04843      1.00000 |                                               *
    270       0.00986      0.23650      0.00061      0.04964      1.00000 |                                               *
    280       0.00930      0.23969      0.00061      0.04964      1.00000 |                                               *
    290       0.00841      0.24441      0.00061      0.04964      1.00000 |                                               *
    300       0.00779      0.24848      0.00061      0.04964      1.00000 |                                               *
    310       0.00741      0.25238      0.00061      0.04964      1.00000 |                                               *
    320       0.00684      0.25835      0.00061      0.04964      1.00000 |                                               *
    330       0.00632      0.26418      0.00061      0.04964      1.00000 |                                               *
    340       0.00581      0.26920      0.00061      0.04964      1.00000 |                                               *
    350       0.00543      0.27399      0.00061      0.04964      1.00000 |                                               *
    360       0.00510      0.27730      0.00061      0.04964      1.00000 |                                               *
    370       0.00478      0.28138      0.00061      0.04964      1.00000 |                                               *
    380       0.00446      0.28471      0.00061      0.04843      1.00000 |                                               *
    390       0.00421      0.29117      0.00061      0.04964      1.00000 |                                               *
    400       0.00388      0.29596      0.00061      0.04722      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.81      6.19  FOLLOW
    399      1    400      1      7      2.18      5.80  ENTAGE
    291      1    400      1      7      4.04      2.88  PD
    166      1    397      1      7      3.28      1.96  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    54 terminal nodes
    Average :     24.47000 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 66 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 66 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 19176 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.14793
                  ROC           62      0.77867
                 Lift           66      5.88235
              KS-stat          216      0.52206
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14816     0.16161     0.91592     0.69103     7.16078     4.38107     0.71305     0.43887     0.04116     0.04116
      8     0.10361     0.14793     0.96995     0.72963     8.52941     5.00000     0.83567     0.49228     0.03935     0.04358
     10     0.09710     0.14799     0.97439     0.72547     8.73529     5.00000     0.84080     0.48470     0.03753     0.04479
     20     0.07623     0.15054     0.98723     0.75221     9.70588     5.29412     0.91667     0.49228     0.03269     0.04843
     30     0.06684     0.15387     0.99174     0.75084     9.85294     5.29412     0.94363     0.50238     0.02845     0.04600
     40     0.06188     0.15654     0.99337     0.76404     9.85294     5.29412     0.94489     0.49733     0.02482     0.04722
     43     0.06040     0.15658     0.99407     0.77150    10.00000     5.29412     0.94552     0.50111     0.02421     0.04600
     50     0.05774     0.15811     0.99468     0.76916    10.00000     5.76471     0.95013     0.50869     0.02179     0.04600
     60     0.05288     0.16011     0.99650     0.77618    10.00000     5.58824     0.96023     0.49985     0.02119     0.04479
     62     0.05192     0.16003     0.99692     0.77867    10.00000     5.58824     0.96023     0.49859     0.01937     0.04479
     66     0.04976     0.16164     0.99740     0.77388    10.00000     5.88235     0.96970     0.50995     0.01816     0.04479
     70     0.04814     0.16356     0.99770     0.77028    10.00000     5.88235     0.97159     0.51500     0.01755     0.04479
     80     0.04491     0.16647     0.99820     0.77081    10.00000     5.88235     0.97096     0.51374     0.01392     0.04479
     90     0.04268     0.16856     0.99847     0.76924    10.00000     5.88235     0.97222     0.51374     0.01211     0.04237
    100     0.03912     0.17187     0.99903     0.77035    10.00000     5.88235     0.97917     0.51627     0.00908     0.04358
    110     0.03642     0.17629     0.99922     0.76519    10.00000     5.88235     0.98106     0.51159     0.00787     0.04479
    120     0.03431     0.17847     0.99936     0.76367    10.00000     5.29412     0.98422     0.51285     0.00666     0.04964
    130     0.03242     0.17977     0.99949     0.76385    10.00000     5.29412     0.98674     0.50275     0.00605     0.05085
    140     0.03023     0.18238     0.99969     0.76352    10.00000     5.29412     0.99306     0.49807     0.00545     0.05206
    150     0.02726     0.18609     0.99986     0.76051    10.00000     5.29412     0.99684     0.49733     0.00484     0.05206
    160     0.02484     0.19203     0.99991     0.76003    10.00000     5.29412     0.99747     0.49428     0.00424     0.05085
    170     0.02238     0.19677     0.99997     0.75847    10.00000     5.17647     0.99874     0.50438     0.00303     0.04964
    180     0.02050     0.20283     0.99998     0.75553    10.00000     4.70588     0.99874     0.49176     0.00182     0.05085
    181     0.02041     0.20273     0.99999     0.75550    10.00000     4.70588     0.99937     0.49176     0.00182     0.05085
    182     0.02004     0.20433     1.00000     0.75412    10.00000     4.70588     0.99937     0.48923     0.00121     0.05206
    190     0.01870     0.20825     0.99999     0.75100    10.00000     4.88235     0.99937     0.50186     0.00121     0.05206
    200     0.01726     0.21209     1.00000     0.75071    10.00000     5.00000     0.99937     0.51575     0.00121     0.05206
    209     0.01615     0.21672     1.00000     0.75123    10.00000     4.88235     0.99937     0.51448     0.00061     0.05206
    210     0.01601     0.21689     1.00000     0.75082    10.00000     4.70588     0.99937     0.51322     0.00061     0.05206
    216     0.01523     0.21799     1.00000     0.75097    10.00000     5.00000     0.99937     0.52206     0.00061     0.05085
    220     0.01471     0.21928     1.00000     0.75119    10.00000     4.88235     0.99937     0.51953     0.00061     0.04964
    230     0.01388     0.22102     1.00000     0.75245    10.00000     4.88235     0.99937     0.50691     0.00061     0.04964
    240     0.01303     0.22509     1.00000     0.75219    10.00000     4.70588     0.99937     0.49807     0.00061     0.04964
    250     0.01204     0.22779     1.00000     0.75383    10.00000     4.41176     0.99937     0.50312     0.00061     0.04843
    260     0.01087     0.23230     1.00000     0.75026    10.00000     4.70588     0.99937     0.50817     0.00061     0.04843
    270     0.00986     0.23650     1.00000     0.75249    10.00000     4.70588     0.99937     0.51448     0.00061     0.04964
    280     0.00930     0.23969     1.00000     0.75319    10.00000     4.41176     0.99937     0.50312     0.00061     0.04964
    290     0.00841     0.24441     1.00000     0.75271    10.00000     4.41176     0.99937     0.51196     0.00061     0.04964
    300     0.00779     0.24848     1.00000     0.75305    10.00000     4.29412     0.99937     0.50943     0.00061     0.04964
    310     0.00741     0.25238     1.00000     0.75505    10.00000     4.41176     0.99937     0.51070     0.00061     0.04964
    320     0.00684     0.25835     1.00000     0.75408    10.00000     4.41176     0.99937     0.51196     0.00061     0.04964
    330     0.00632     0.26418     1.00000     0.75373    10.00000     4.41176     0.99937     0.51070     0.00061     0.04964
    340     0.00581     0.26920     1.00000     0.75098    10.00000     4.41176     0.99937     0.50564     0.00061     0.04964
    350     0.00543     0.27399     1.00000     0.75050    10.00000     4.41176     0.99937     0.49933     0.00061     0.04964
    360     0.00510     0.27730     1.00000     0.75017    10.00000     4.41176     0.99937     0.50438     0.00061     0.04964
    370     0.00478     0.28138     1.00000     0.74887    10.00000     4.17647     0.99937     0.48671     0.00061     0.04964
    380     0.00446     0.28471     1.00000     0.74928    10.00000     4.37255     0.99937     0.48671     0.00061     0.04843
    390     0.00421     0.29117     1.00000     0.74987    10.00000     4.41176     0.99937     0.48165     0.00061     0.04964
    400     0.00388     0.29596     1.00000     0.75117    10.00000     4.41176     0.99937     0.48418     0.00061     0.04722


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     53.64080   53.64 |******     |
 PD         34.70676   34.71 |****       |
 FH         16.45541   16.46 |***        |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         3.00        65.00       0.9559


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       790.00         2.00       0.0025
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 831 kb , 77% compression

 Grove file created containing:
      1 TreeNet

