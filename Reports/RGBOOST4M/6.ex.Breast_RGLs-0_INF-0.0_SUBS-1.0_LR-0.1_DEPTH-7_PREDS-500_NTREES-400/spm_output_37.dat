
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14940      0.16318      0.04116      0.04116      1.00000 |                                               *
      2       0.13906      0.15767      0.04116      0.04116      1.00000 |                                             *
      3       0.13129      0.15347      0.04116      0.04116      1.00000 |                                            *
      4       0.12542      0.15012      0.04116      0.04116      1.00000 |                                           *
      5       0.12053      0.14796      0.04056      0.04116      1.00000 |                                           *
      6       0.11661      0.14680      0.04056      0.04116      1.00000 |                                          *
      7       0.11251      0.14534      0.03935      0.03995      1.00000 |                                          *
      8       0.10896      0.14451      0.03874      0.03995      1.00000 |                                          *
      9       0.10521      0.14473      0.03814      0.03995      1.00000 |                                          *
     10       0.10275      0.14446      0.03753      0.03995      1.00000 |                                         *
     11       0.09892      0.14408      0.03692      0.03874      1.00000 |                                         *
     12       0.09524      0.14441      0.03571      0.03874      1.00000 |                                         *
     13       0.09265      0.14418      0.03511      0.03874      1.00000 |                                         *
     14       0.09033      0.14364      0.03511      0.03874      1.00000 |                                         *
     15       0.08837      0.14298      0.03511      0.03874      1.00000 |                                         *
     16       0.08671      0.14342      0.03390      0.03753      1.00000 |                                         *
     17       0.08408      0.14382      0.03148      0.03995      1.00000 |                                         *
     18       0.08208      0.14445      0.03148      0.03995      1.00000 |                                         *
     19       0.08016      0.14469      0.03148      0.03874      1.00000 |                                          *
     20       0.07851      0.14399      0.03148      0.03874      1.00000 |                                         *
     30       0.06777      0.14548      0.02724      0.04116      1.00000 |                                          *
     40       0.06186      0.14616      0.02361      0.04358      1.00000 |                                          *
     50       0.05672      0.14815      0.02119      0.04358      1.00000 |                                           *
     60       0.05160      0.15062      0.01877      0.04358      1.00000 |                                           *
     70       0.04812      0.15287      0.01695      0.04358      1.00000 |                                            *
     80       0.04463      0.15468      0.01513      0.04358      1.00000 |                                            *
     90       0.04199      0.15573      0.01453      0.04358      1.00000 |                                             *
    100       0.03791      0.15903      0.01211      0.04358      1.00000 |                                              *
    110       0.03579      0.16149      0.01150      0.04358      1.00000 |                                               *
    120       0.03271      0.16398      0.00969      0.04358      1.00000 |                                               *
    130       0.02953      0.16803      0.00484      0.04479      1.00000 |                                               *
    140       0.02764      0.17066      0.00484      0.04479      1.00000 |                                               *
    150       0.02634      0.17233      0.00484      0.04600      1.00000 |                                               *
    160       0.02468      0.17470      0.00424      0.04600      1.00000 |                                               *
    170       0.02256      0.17870      0.00363      0.04722      1.00000 |                                               *
    180       0.02034      0.18252      0.00303      0.04722      1.00000 |                                               *
    190       0.01829      0.18694      0.00182      0.04600      1.00000 |                                               *
    200       0.01738      0.19033      0.00182      0.04600      1.00000 |                                               *
    210       0.01613      0.19178      0.00182      0.04600      1.00000 |                                               *
    220       0.01506      0.19550      0.00121      0.04358      1.00000 |                                               *
    230       0.01406      0.19889      0.00121      0.04479      1.00000 |                                               *
    240       0.01280      0.20237      0.00121      0.04358      1.00000 |                                               *
    250       0.01208      0.20726      0.00121      0.04358      1.00000 |                                               *
    260       0.01130      0.20965      0.00121      0.04358      1.00000 |                                               *
    270       0.01032      0.21384      0.00121      0.04358      1.00000 |                                               *
    280       0.00964      0.21793      0.00121      0.04358      1.00000 |                                               *
    290       0.00910      0.22203      0.00121      0.04237      1.00000 |                                               *
    300       0.00858      0.22553      0.00121      0.04237      1.00000 |                                               *
    310       0.00819      0.22867      0.00121      0.04237      1.00000 |                                               *
    320       0.00769      0.23187      0.00121      0.04237      1.00000 |                                               *
    330       0.00698      0.23595      0.00121      0.04237      1.00000 |                                               *
    340       0.00643      0.24197      0.00121      0.03995      1.00000 |                                               *
    350       0.00601      0.24712      0.00121      0.04237      1.00000 |                                               *
    360       0.00566      0.25224      0.00121      0.04237      1.00000 |                                               *
    370       0.00530      0.25713      0.00121      0.04358      1.00000 |                                               *
    380       0.00500      0.26151      0.00121      0.04358      1.00000 |                                               *
    390       0.00473      0.26507      0.00121      0.04358      1.00000 |                                               *
    400       0.00448      0.26843      0.00121      0.04237      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.82      6.18  FOLLOW
    399      1    400      1      6      2.04      5.95  ENTAGE
    299      1    400      1      7      3.47      3.39  PD
    112      1    394      2      7      4.39      1.01  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    67 terminal nodes
    Average :     24.07750 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 124 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 124 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 15

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 18862 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           15      0.14298
                  ROC          124      0.81532
                 Lift           27      5.29412
              KS-stat          344      0.57516
          Class.Error           16      0.03753

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14940     0.16318     0.92706     0.57711     6.86765     3.52941     0.71713     0.27718     0.04116     0.04116
     10     0.10275     0.14446     0.95579     0.78296     8.23529     4.29412     0.77577     0.49213     0.03753     0.03995
     15     0.08837     0.14298     0.97601     0.79980     8.82353     4.41176     0.84061     0.49703     0.03511     0.03874
     16     0.08671     0.14342     0.97722     0.79822     8.82353     4.29412     0.84072     0.50067     0.03390     0.03753
     20     0.07851     0.14399     0.98469     0.80195     9.41176     4.88235     0.88310     0.51166     0.03148     0.03874
     27     0.07056     0.14511     0.98970     0.79664     9.79412     5.29412     0.92279     0.49265     0.02906     0.04116
     30     0.06777     0.14548     0.99104     0.79564     9.70588     4.70588     0.92740     0.49391     0.02724     0.04116
     35     0.06500     0.14496     0.99287     0.80219    10.00000     5.29412     0.94300     0.51070     0.02542     0.04237
     40     0.06186     0.14616     0.99425     0.80450    10.00000     4.88235     0.95644     0.49896     0.02361     0.04358
     50     0.05672     0.14815     0.99617     0.80751    10.00000     4.41176     0.97285     0.51070     0.02119     0.04358
     60     0.05160     0.15062     0.99780     0.81120    10.00000     4.41176     0.97854     0.49592     0.01877     0.04358
     70     0.04812     0.15287     0.99833     0.80997    10.00000     4.11765     0.97917     0.50223     0.01695     0.04358
     80     0.04463     0.15468     0.99889     0.80804    10.00000     4.11765     0.98422     0.48329     0.01513     0.04358
     90     0.04199     0.15573     0.99922     0.81209    10.00000     4.70588     0.98611     0.50535     0.01453     0.04358
    100     0.03791     0.15903     0.99950     0.81235    10.00000     4.41176     0.99495     0.50572     0.01211     0.04358
    110     0.03579     0.16149     0.99955     0.81384    10.00000     4.41176     0.99558     0.51129     0.01150     0.04358
    120     0.03271     0.16398     0.99975     0.81451    10.00000     4.58824     0.99495     0.50082     0.00969     0.04358
    124     0.03158     0.16503     0.99977     0.81532    10.00000     4.41176     0.99495     0.50460     0.00666     0.04358
    130     0.02953     0.16803     0.99984     0.81296    10.00000     4.41176     0.99684     0.51671     0.00484     0.04479
    140     0.02764     0.17066     0.99985     0.81070    10.00000     4.11765     0.99684     0.50787     0.00484     0.04479
    150     0.02634     0.17233     0.99991     0.80936    10.00000     4.11765     0.99811     0.51419     0.00484     0.04600
    160     0.02468     0.17470     0.99993     0.80884    10.00000     4.11765     0.99811     0.53186     0.00424     0.04600
    165     0.02356     0.17741     0.99994     0.80728    10.00000     4.11765     0.99874     0.54070     0.00363     0.04722
    170     0.02256     0.17870     0.99994     0.80877    10.00000     4.11765     0.99874     0.53818     0.00363     0.04722
    180     0.02034     0.18252     0.99996     0.80840    10.00000     4.11765     0.99874     0.52429     0.00303     0.04722
    190     0.01829     0.18694     0.99997     0.80331    10.00000     4.41176     0.99874     0.49703     0.00182     0.04600
    200     0.01738     0.19033     0.99997     0.80078    10.00000     4.11765     0.99874     0.50030     0.00182     0.04600
    205     0.01695     0.19090     0.99998     0.80075    10.00000     4.11765     0.99874     0.50661     0.00182     0.04600
    210     0.01613     0.19178     0.99998     0.80208    10.00000     4.11765     0.99874     0.50787     0.00182     0.04600
    211     0.01603     0.19240     0.99998     0.80127    10.00000     4.11765     0.99874     0.50787     0.00121     0.04600
    220     0.01506     0.19550     0.99998     0.79974    10.00000     4.11765     0.99874     0.51545     0.00121     0.04358
    230     0.01406     0.19889     0.99998     0.79696    10.00000     4.11765     0.99874     0.51797     0.00121     0.04479
    240     0.01280     0.20237     0.99998     0.79629    10.00000     4.11765     0.99874     0.47594     0.00121     0.04358
    250     0.01208     0.20726     0.99998     0.79269    10.00000     4.11765     0.99874     0.46494     0.00121     0.04358
    260     0.01130     0.20965     0.99998     0.79492    10.00000     4.11765     0.99874     0.45611     0.00121     0.04358
    270     0.01032     0.21384     0.99998     0.79755    10.00000     4.11765     0.99874     0.48061     0.00121     0.04358
    280     0.00964     0.21793     0.99998     0.79685    10.00000     4.11765     0.99874     0.47378     0.00121     0.04358
    290     0.00910     0.22203     0.99998     0.79488    10.00000     4.11765     0.99874     0.48515     0.00121     0.04237
    300     0.00858     0.22553     0.99998     0.79547    10.00000     3.82353     0.99874     0.49777     0.00121     0.04237
    310     0.00819     0.22867     0.99998     0.79618    10.00000     3.82353     0.99874     0.52302     0.00121     0.04237
    320     0.00769     0.23187     0.99998     0.79986    10.00000     3.82353     0.99874     0.53476     0.00121     0.04237
    330     0.00698     0.23595     0.99998     0.80314    10.00000     3.82353     0.99874     0.55875     0.00121     0.04237
    340     0.00643     0.24197     0.99998     0.80192    10.00000     3.82353     0.99874     0.57011     0.00121     0.03995
    344     0.00635     0.24356     0.99998     0.80266    10.00000     3.82353     0.99874     0.57516     0.00121     0.03995
    350     0.00601     0.24712     0.99998     0.80032    10.00000     3.82353     0.99874     0.56380     0.00121     0.04237
    360     0.00566     0.25224     0.99998     0.79921    10.00000     4.11765     0.99874     0.54612     0.00121     0.04237
    370     0.00530     0.25713     0.99998     0.79857    10.00000     3.82353     0.99874     0.53476     0.00121     0.04358
    380     0.00500     0.26151     0.99998     0.79731    10.00000     4.11765     0.99874     0.52340     0.00121     0.04358
    390     0.00473     0.26507     0.99998     0.79596    10.00000     4.11765     0.99874     0.52176     0.00121     0.04358
    400     0.00448     0.26843     0.99998     0.79462    10.00000     4.11765     0.99874     0.51419     0.00121     0.04237


 =========================================
 Variable Importance for the 15-tree Model
 =========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     60.48225   60.48 |*******    |
 PD         26.05188   26.05 |****       |
 FH         14.75425   14.75 |**         |


 Learn Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00        10.00        58.00       0.8529


 Test Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       791.00         1.00       0.0013
 1                   34.00         3.00        31.00       0.9118

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 836 kb , 76% compression

 Grove file created containing:
      1 TreeNet

