
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14643      0.16312      0.04116      0.04116      1.00000 |                                               *
      2       0.13668      0.16053      0.04116      0.04116      1.00000 |                                              *
      3       0.13074      0.15947      0.04116      0.04116      1.00000 |                                              *
      4       0.12425      0.15997      0.04116      0.04116      1.00000 |                                              *
      5       0.11963      0.15921      0.04116      0.04116      1.00000 |                                              *
      6       0.11508      0.15870      0.04116      0.04116      1.00000 |                                              *
      7       0.11128      0.15807      0.03995      0.04116      1.00000 |                                              *
      8       0.10850      0.15749      0.03935      0.04116      1.00000 |                                             *
      9       0.10570      0.15787      0.03935      0.04116      1.00000 |                                             *
     10       0.10344      0.15749      0.03935      0.04116      1.00000 |                                             *
     11       0.10109      0.15898      0.03874      0.04358      1.00000 |                                              *
     12       0.09924      0.15924      0.03753      0.04600      1.00000 |                                              *
     13       0.09731      0.15821      0.03511      0.04600      1.00000 |                                              *
     14       0.09555      0.15871      0.03329      0.04479      1.00000 |                                              *
     15       0.09426      0.15965      0.03269      0.04479      1.00000 |                                              *
     16       0.09295      0.15929      0.03148      0.04600      1.00000 |                                              *
     17       0.09167      0.15993      0.03148      0.04722      1.00000 |                                              *
     18       0.09064      0.15977      0.03148      0.04722      1.00000 |                                              *
     19       0.08978      0.15983      0.03027      0.04843      1.00000 |                                              *
     20       0.08926      0.16022      0.03027      0.04722      1.00000 |                                              *
     30       0.08312      0.16248      0.02724      0.04964      1.00000 |                                               *
     40       0.07786      0.16464      0.02421      0.05206      1.00000 |                                               *
     50       0.07201      0.16936      0.02119      0.05206      1.00000 |                                               *
     60       0.06649      0.17101      0.02058      0.05327      1.00000 |                                               *
     70       0.06048      0.17495      0.01937      0.05690      1.00000 |                                               *
     80       0.05613      0.17779      0.01755      0.05690      1.00000 |                                               *
     90       0.05222      0.18321      0.01513      0.05690      1.00000 |                                               *
    100       0.04806      0.18573      0.01513      0.05690      1.00000 |                                               *
    110       0.04269      0.18879      0.01332      0.05690      1.00000 |                                               *
    120       0.03948      0.19359      0.01271      0.05811      1.00000 |                                               *
    130       0.03608      0.19835      0.01211      0.05690      1.00000 |                                               *
    140       0.03275      0.20239      0.01090      0.05690      1.00000 |                                               *
    150       0.03019      0.20582      0.01090      0.05690      1.00000 |                                               *
    160       0.02726      0.20752      0.00787      0.05690      1.00000 |                                               *
    170       0.02555      0.20963      0.00726      0.05569      1.00000 |                                               *
    180       0.02321      0.21408      0.00363      0.05569      1.00000 |                                               *
    190       0.02105      0.21872      0.00363      0.05811      1.00000 |                                               *
    200       0.01978      0.22318      0.00303      0.05811      1.00000 |                                               *
    210       0.01881      0.22703      0.00303      0.05811      1.00000 |                                               *
    220       0.01770      0.23151      0.00303      0.05690      1.00000 |                                               *
    230       0.01638      0.23555      0.00242      0.05690      1.00000 |                                               *
    240       0.01536      0.23860      0.00242      0.05690      1.00000 |                                               *
    250       0.01466      0.24059      0.00182      0.05811      1.00000 |                                               *
    260       0.01374      0.24402      0.00121      0.05811      1.00000 |                                               *
    270       0.01261      0.24775      0.00121      0.05690      1.00000 |                                               *
    280       0.01163      0.25124      0.00121      0.05811      1.00000 |                                               *
    290       0.01113      0.25393      0.00121      0.05690      1.00000 |                                               *
    300       0.01063      0.25571      0.00121      0.05690      1.00000 |                                               *
    310       0.01015      0.25948      0.00121      0.05811      1.00000 |                                               *
    320       0.00981      0.26298      0.00121      0.05690      1.00000 |                                               *
    330       0.00946      0.26577      0.00121      0.05448      1.00000 |                                               *
    340       0.00868      0.27102      0.00121      0.05448      1.00000 |                                               *
    350       0.00828      0.27459      0.00121      0.05448      1.00000 |                                               *
    360       0.00770      0.27990      0.00121      0.05448      1.00000 |                                               *
    370       0.00732      0.28416      0.00121      0.05448      1.00000 |                                               *
    380       0.00673      0.28737      0.00121      0.05569      1.00000 |                                               *
    390       0.00637      0.29000      0.00121      0.05690      1.00000 |                                               *
    400       0.00606      0.29453      0.00121      0.05690      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.55      6.45  FOLLOW
    383      1    400      1      7      2.64      5.13  ENTAGE
    280      1    400      1      7      4.06      2.76  PD
    111      1    399      1      7      3.41      1.27  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    48 terminal nodes
    Average :     20.29500 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 42 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 42 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 15836 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.15749
                  ROC           42      0.74265
                 Lift           22      4.41176
              KS-stat           46      0.44504
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14643     0.16312     0.93844     0.54362     7.35686     3.55709     0.74239     0.27503     0.04116     0.04116
      8     0.10850     0.15749     0.95915     0.67965     8.38235     3.52941     0.79363     0.33749     0.03935     0.04116
     10     0.10344     0.15749     0.96074     0.68878     8.08824     3.52941     0.79371     0.36312     0.03935     0.04116
     20     0.08926     0.16022     0.96312     0.72033     7.94118     4.11765     0.79453     0.42952     0.03027     0.04722
     22     0.08805     0.16023     0.96340     0.72683     7.94118     4.41176     0.79074     0.44467     0.02966     0.04722
     30     0.08312     0.16248     0.96584     0.73216     7.94118     4.41176     0.79479     0.44214     0.02724     0.04964
     40     0.07786     0.16464     0.96977     0.73611     8.41176     4.41176     0.79757     0.43167     0.02421     0.05206
     42     0.07649     0.16568     0.97041     0.74265     8.52941     4.11765     0.79731     0.42914     0.02300     0.05206
     46     0.07421     0.16722     0.97169     0.73856     8.67647     4.11765     0.81309     0.44504     0.02240     0.05206
     50     0.07201     0.16936     0.97358     0.73515     8.67647     4.11765     0.81707     0.43746     0.02119     0.05206
     60     0.06649     0.17101     0.97941     0.73336     9.11765     4.41176     0.84674     0.40211     0.02058     0.05327
     70     0.06048     0.17495     0.98632     0.72727     9.26471     3.82353     0.87849     0.38332     0.01937     0.05690
     80     0.05613     0.17779     0.98976     0.71719     9.41176     3.82353     0.88499     0.37069     0.01755     0.05690
     90     0.05222     0.18321     0.99155     0.70429     9.55882     3.82353     0.89654     0.36438     0.01513     0.05690
    100     0.04806     0.18573     0.99415     0.70752     9.85294     3.82353     0.92848     0.37069     0.01513     0.05690
    104     0.04415     0.18685     0.99704     0.71091    10.00000     3.82353     0.95013     0.39127     0.01392     0.05569
    110     0.04269     0.18879     0.99727     0.70594    10.00000     4.11765     0.94931     0.38495     0.01332     0.05690
    120     0.03948     0.19359     0.99819     0.69157    10.00000     4.11765     0.96717     0.34997     0.01271     0.05811
    130     0.03608     0.19835     0.99899     0.68555    10.00000     4.00000     0.98359     0.35755     0.01211     0.05690
    140     0.03275     0.20239     0.99938     0.69294    10.00000     3.82353     0.98422     0.34745     0.01090     0.05690
    150     0.03019     0.20582     0.99951     0.69231    10.00000     3.82353     0.98927     0.35146     0.01090     0.05690
    160     0.02726     0.20752     0.99971     0.69851    10.00000     3.82353     0.99558     0.36223     0.00787     0.05690
    170     0.02555     0.20963     0.99977     0.70052    10.00000     3.82353     0.99621     0.37485     0.00726     0.05569
    180     0.02321     0.21408     0.99989     0.69792    10.00000     3.82353     0.99811     0.36475     0.00363     0.05569
    188     0.02158     0.21783     0.99992     0.69680    10.00000     3.82353     0.99874     0.35250     0.00363     0.05811
    190     0.02105     0.21872     0.99992     0.69981    10.00000     3.82353     0.99874     0.37381     0.00363     0.05811
    200     0.01978     0.22318     0.99993     0.69435    10.00000     3.82353     0.99874     0.36081     0.00303     0.05811
    210     0.01881     0.22703     0.99993     0.68975    10.00000     3.82353     0.99874     0.35198     0.00303     0.05811
    220     0.01770     0.23151     0.99993     0.68614    10.00000     3.52941     0.99874     0.33051     0.00303     0.05690
    230     0.01638     0.23555     0.99994     0.68605    10.00000     3.70588     0.99874     0.33266     0.00242     0.05690
    240     0.01536     0.23860     0.99994     0.68705    10.00000     3.82353     0.99874     0.32108     0.00242     0.05690
    250     0.01466     0.24059     0.99997     0.68665    10.00000     3.82353     0.99874     0.33051     0.00182     0.05811
    259     0.01394     0.24307     0.99998     0.68327    10.00000     3.82353     0.99874     0.32925     0.00121     0.05811
    260     0.01374     0.24402     0.99998     0.68486    10.00000     3.82353     0.99874     0.33935     0.00121     0.05811
    270     0.01261     0.24775     0.99998     0.68542    10.00000     3.82353     0.99874     0.33861     0.00121     0.05690
    280     0.01163     0.25124     0.99998     0.68728    10.00000     3.82353     0.99874     0.33229     0.00121     0.05811
    290     0.01113     0.25393     0.99998     0.68497    10.00000     3.82353     0.99874     0.33103     0.00121     0.05690
    300     0.01063     0.25571     0.99998     0.68817    10.00000     3.82353     0.99874     0.32635     0.00121     0.05690
    310     0.01015     0.25948     0.99998     0.68327    10.00000     3.52941     0.99874     0.32888     0.00121     0.05811
    320     0.00981     0.26298     0.99998     0.68048    10.00000     3.52941     0.99874     0.32635     0.00121     0.05690
    330     0.00946     0.26577     0.99998     0.68026    10.00000     3.52941     0.99874     0.31878     0.00121     0.05448
    340     0.00868     0.27102     0.99998     0.68000    10.00000     3.52941     0.99874     0.32583     0.00121     0.05448
    350     0.00828     0.27459     0.99998     0.67851    10.00000     3.52941     0.99874     0.32204     0.00121     0.05448
    360     0.00770     0.27990     0.99998     0.67525    10.00000     3.52941     0.99874     0.33467     0.00121     0.05448
    370     0.00732     0.28416     0.99998     0.67547    10.00000     3.52941     0.99874     0.32836     0.00121     0.05448
    380     0.00673     0.28737     0.99998     0.67829    10.00000     3.41176     0.99874     0.33341     0.00121     0.05569
    390     0.00637     0.29000     0.99998     0.67810    10.00000     3.52941     0.99874     0.32836     0.00121     0.05690
    400     0.00606     0.29453     0.99998     0.67305    10.00000     2.94118     0.99874     0.30184     0.00121     0.05690


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     56.79722   56.80 |*******    |
 PD         40.28154   40.28 |*****      |
 FH         16.47538   16.48 |***        |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         3.00        65.00       0.9559


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 689 kb , 77% compression

 Grove file created containing:
      1 TreeNet

