
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14909      0.16037      0.04116      0.04116      1.00000 |                                               *
      2       0.13818      0.15652      0.04116      0.04116      1.00000 |                                              *
      3       0.13125      0.15492      0.04116      0.04116      1.00000 |                                             *
      4       0.12584      0.15353      0.04116      0.04116      1.00000 |                                             *
      5       0.12098      0.15248      0.04116      0.04116      1.00000 |                                             *
      6       0.11702      0.15122      0.04116      0.04116      1.00000 |                                            *
      7       0.11363      0.15077      0.04116      0.04116      1.00000 |                                            *
      8       0.11046      0.15031      0.04116      0.04116      1.00000 |                                            *
      9       0.10817      0.15123      0.03995      0.04116      1.00000 |                                            *
     10       0.10599      0.15160      0.03995      0.04237      1.00000 |                                            *
     11       0.10423      0.15228      0.03692      0.04479      1.00000 |                                             *
     12       0.10242      0.15240      0.03632      0.04358      1.00000 |                                             *
     13       0.09998      0.15247      0.03208      0.04358      1.00000 |                                             *
     14       0.09855      0.15299      0.03027      0.04358      1.00000 |                                             *
     15       0.09736      0.15318      0.03027      0.04358      1.00000 |                                             *
     16       0.09600      0.15251      0.02966      0.04600      1.00000 |                                             *
     17       0.09409      0.15232      0.02906      0.04600      1.00000 |                                             *
     18       0.09285      0.15221      0.03087      0.04479      1.00000 |                                             *
     19       0.09175      0.15185      0.02966      0.04358      1.00000 |                                            *
     20       0.09101      0.15189      0.02906      0.04358      1.00000 |                                            *
     30       0.08474      0.15445      0.02542      0.04722      1.00000 |                                             *
     40       0.07485      0.15532      0.02300      0.04358      1.00000 |                                             *
     50       0.06738      0.15580      0.02058      0.04358      1.00000 |                                              *
     60       0.06292      0.15589      0.01877      0.04358      1.00000 |                                              *
     70       0.05989      0.15717      0.01816      0.04479      1.00000 |                                              *
     80       0.05552      0.15905      0.01755      0.04237      1.00000 |                                               *
     90       0.05405      0.15937      0.01755      0.03995      1.00000 |                                               *
    100       0.04936      0.16231      0.01755      0.03874      1.00000 |                                               *
    110       0.04714      0.16457      0.01574      0.04237      1.00000 |                                               *
    120       0.04281      0.16747      0.01453      0.04237      1.00000 |                                               *
    130       0.03997      0.17053      0.01332      0.04358      1.00000 |                                               *
    140       0.03779      0.17210      0.01211      0.04358      1.00000 |                                               *
    150       0.03392      0.17632      0.01029      0.04237      1.00000 |                                               *
    160       0.03106      0.17866      0.01029      0.04479      1.00000 |                                               *
    170       0.02962      0.18062      0.00969      0.04358      1.00000 |                                               *
    180       0.02802      0.18231      0.00847      0.04358      1.00000 |                                               *
    190       0.02617      0.18556      0.00605      0.04358      1.00000 |                                               *
    200       0.02523      0.18729      0.00545      0.04358      1.00000 |                                               *
    210       0.02393      0.18814      0.00424      0.04358      1.00000 |                                               *
    220       0.02257      0.19202      0.00303      0.04479      1.00000 |                                               *
    230       0.02129      0.19533      0.00242      0.04479      1.00000 |                                               *
    240       0.01969      0.20003      0.00242      0.04600      1.00000 |                                               *
    250       0.01885      0.20237      0.00242      0.04722      1.00000 |                                               *
    260       0.01771      0.20369      0.00182      0.04722      1.00000 |                                               *
    270       0.01698      0.20499      0.00182      0.04722      1.00000 |                                               *
    280       0.01564      0.20903      0.00182      0.04722      1.00000 |                                               *
    290       0.01528      0.20991      0.00182      0.04722      1.00000 |                                               *
    300       0.01426      0.21214      0.00182      0.04600      1.00000 |                                               *
    310       0.01377      0.21299      0.00182      0.04600      1.00000 |                                               *
    320       0.01316      0.21454      0.00182      0.04600      1.00000 |                                               *
    330       0.01244      0.21766      0.00182      0.04722      1.00000 |                                               *
    340       0.01199      0.21907      0.00182      0.04722      1.00000 |                                               *
    350       0.01140      0.22168      0.00182      0.04722      1.00000 |                                               *
    360       0.01051      0.22588      0.00182      0.04722      1.00000 |                                               *
    370       0.00983      0.22903      0.00182      0.04722      1.00000 |                                               *
    380       0.00929      0.23262      0.00121      0.04722      1.00000 |                                               *
    390       0.00860      0.23692      0.00121      0.04722      1.00000 |                                               *
    400       0.00805      0.23919      0.00121      0.04722      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.45      6.55  FOLLOW
    371      1    400      1      7      2.58      5.02  ENTAGE
    220      1    400      1      7      4.03      2.19  PD
    112      3    397      2      7      4.13      1.08  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    46 terminal nodes
    Average :     20.13500 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 86 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 86 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 15708 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.15031
                  ROC           43      0.75577
                 Lift            1      4.79085
              KS-stat           74      0.48091
          Class.Error           86      0.03874

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14909     0.16037     0.91070     0.70462     7.08824     4.79085     0.69474     0.41110     0.04116     0.04116
      8     0.11046     0.15031     0.93898     0.71669     8.08824     4.00000     0.74759     0.43835     0.04116     0.04116
     10     0.10599     0.15160     0.93724     0.71075     8.08824     4.11765     0.74885     0.42952     0.03995     0.04237
     20     0.09101     0.15189     0.94652     0.75223     7.94118     4.41176     0.74788     0.45224     0.02906     0.04358
     30     0.08474     0.15445     0.95234     0.75349     7.94118     4.41176     0.75100     0.44883     0.02542     0.04722
     40     0.07485     0.15532     0.97310     0.75158     8.38235     4.41176     0.82483     0.46450     0.02300     0.04358
     43     0.07117     0.15572     0.97815     0.75577     8.82353     4.41176     0.84819     0.46197     0.02240     0.04479
     50     0.06738     0.15580     0.98153     0.75327     9.26471     4.58824     0.87697     0.46576     0.02058     0.04358
     60     0.06292     0.15589     0.98524     0.75071     9.50000     4.58824     0.89609     0.46576     0.01877     0.04358
     70     0.05989     0.15717     0.98671     0.75056     9.55882     4.70588     0.90051     0.47965     0.01816     0.04479
     74     0.05879     0.15680     0.98739     0.75457     9.55882     4.70588     0.90285     0.48091     0.01816     0.04479
     80     0.05552     0.15905     0.98953     0.75030     9.55882     4.41176     0.91169     0.47712     0.01755     0.04237
     86     0.05448     0.15918     0.98993     0.75033     9.70588     4.41176     0.91422     0.47460     0.01755     0.03874
     90     0.05405     0.15937     0.99007     0.75019     9.70588     4.41176     0.91737     0.46955     0.01755     0.03995
    100     0.04936     0.16231     0.99463     0.74358     9.70588     4.11765     0.94155     0.45945     0.01755     0.03874
    110     0.04714     0.16457     0.99528     0.73869     9.70588     4.11765     0.94534     0.46487     0.01574     0.04237
    118     0.04382     0.16674     0.99695     0.73364    10.00000     4.41176     0.95354     0.46739     0.01453     0.04237
    120     0.04281     0.16747     0.99747     0.73342    10.00000     4.41176     0.96383     0.46361     0.01453     0.04237
    130     0.03997     0.17053     0.99844     0.73180    10.00000     4.11765     0.97664     0.44846     0.01332     0.04358
    140     0.03779     0.17210     0.99881     0.73149    10.00000     4.11765     0.97727     0.46992     0.01211     0.04358
    150     0.03392     0.17632     0.99946     0.72434    10.00000     4.41176     0.98737     0.47029     0.01029     0.04237
    160     0.03106     0.17866     0.99971     0.72337    10.00000     4.41176     0.99369     0.46398     0.01029     0.04479
    170     0.02962     0.18062     0.99976     0.71903    10.00000     4.41176     0.99558     0.44251     0.00969     0.04358
    180     0.02802     0.18231     0.99981     0.71858    10.00000     4.41176     0.99684     0.47029     0.00847     0.04358
    190     0.02617     0.18556     0.99989     0.71907    10.00000     4.41176     0.99747     0.45856     0.00605     0.04358
    200     0.02523     0.18729     0.99989     0.71736    10.00000     4.41176     0.99747     0.45477     0.00545     0.04358
    207     0.02432     0.18795     0.99993     0.71855    10.00000     4.41176     0.99874     0.45514     0.00424     0.04358
    210     0.02393     0.18814     0.99993     0.71817    10.00000     4.41176     0.99874     0.45603     0.00424     0.04358
    220     0.02257     0.19202     0.99994     0.71452    10.00000     4.41176     0.99874     0.45766     0.00303     0.04479
    230     0.02129     0.19533     0.99994     0.71140    10.00000     4.41176     0.99874     0.45261     0.00242     0.04479
    240     0.01969     0.20003     0.99995     0.70861    10.00000     4.11765     0.99874     0.42157     0.00242     0.04600
    250     0.01885     0.20237     0.99995     0.70538    10.00000     4.41176     0.99874     0.41741     0.00242     0.04722
    260     0.01771     0.20369     0.99996     0.70371    10.00000     4.29412     0.99874     0.41993     0.00182     0.04722
    270     0.01698     0.20499     0.99996     0.70557    10.00000     4.41176     0.99874     0.41526     0.00182     0.04722
    280     0.01564     0.20903     0.99996     0.70475    10.00000     4.41176     0.99874     0.42283     0.00182     0.04722
    290     0.01528     0.20991     0.99996     0.70445    10.00000     4.41176     0.99874     0.41993     0.00182     0.04722
    300     0.01426     0.21214     0.99996     0.70553    10.00000     4.41176     0.99874     0.41615     0.00182     0.04600
    310     0.01377     0.21299     0.99996     0.70657    10.00000     4.11765     0.99874     0.41020     0.00182     0.04600
    320     0.01316     0.21454     0.99996     0.70598    10.00000     4.11765     0.99874     0.41778     0.00182     0.04600
    330     0.01244     0.21766     0.99996     0.70360    10.00000     4.11765     0.99874     0.41488     0.00182     0.04722
    340     0.01199     0.21907     0.99996     0.70367    10.00000     4.11765     0.99874     0.41399     0.00182     0.04722
    350     0.01140     0.22168     0.99996     0.70211    10.00000     4.11765     0.99874     0.42157     0.00182     0.04722
    360     0.01051     0.22588     0.99997     0.70300    10.00000     4.11765     0.99874     0.42283     0.00182     0.04722
    367     0.00996     0.22842     0.99998     0.70271    10.00000     4.11765     0.99874     0.41904     0.00182     0.04722
    370     0.00983     0.22903     0.99998     0.70245    10.00000     4.11765     0.99874     0.41399     0.00182     0.04722
    371     0.00971     0.22927     0.99998     0.70219    10.00000     4.11765     0.99874     0.41399     0.00121     0.04722
    380     0.00929     0.23262     0.99998     0.70141    10.00000     4.11765     0.99874     0.41399     0.00121     0.04722
    390     0.00860     0.23692     0.99998     0.70185    10.00000     4.11765     0.99874     0.40768     0.00121     0.04722
    400     0.00805     0.23919     0.99998     0.70460    10.00000     4.11765     0.99874     0.41184     0.00121     0.04722


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     61.34208   61.34 |*******    |
 PD         49.51579   49.52 |******     |
 FH         19.79340   19.79 |***        |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         0.00        68.00       1.0000


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 683 kb , 77% compression

 Grove file created containing:
      1 TreeNet

