
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14651      0.15889      0.04116      0.04116      1.00000 |                                               *
      2       0.13589      0.15469      0.04116      0.04116      1.00000 |                                              *
      3       0.12868      0.15172      0.04116      0.04116      1.00000 |                                             *
      4       0.12315      0.15012      0.04116      0.04116      1.00000 |                                            *
      5       0.11809      0.14949      0.04116      0.04116      1.00000 |                                            *
      6       0.11417      0.14959      0.04056      0.04116      1.00000 |                                            *
      7       0.11082      0.14893      0.03571      0.04600      1.00000 |                                            *
      8       0.10682      0.14746      0.03571      0.04600      1.00000 |                                            *
      9       0.10418      0.14829      0.03571      0.04600      1.00000 |                                            *
     10       0.10131      0.14799      0.03511      0.04600      1.00000 |                                            *
     11       0.09969      0.14852      0.03511      0.04600      1.00000 |                                            *
     12       0.09735      0.14893      0.03511      0.04479      1.00000 |                                            *
     13       0.09541      0.15060      0.03450      0.04358      1.00000 |                                            *
     14       0.09358      0.15140      0.03450      0.04358      1.00000 |                                             *
     15       0.09248      0.15186      0.03269      0.04358      1.00000 |                                             *
     16       0.09149      0.15247      0.03269      0.04358      1.00000 |                                             *
     17       0.09011      0.15288      0.03087      0.04479      1.00000 |                                             *
     18       0.08732      0.15427      0.03027      0.04600      1.00000 |                                              *
     19       0.08634      0.15430      0.02966      0.04722      1.00000 |                                              *
     20       0.08521      0.15450      0.02966      0.04358      1.00000 |                                              *
     30       0.07421      0.15825      0.02542      0.04600      1.00000 |                                               *
     40       0.06639      0.16065      0.02361      0.04600      1.00000 |                                               *
     50       0.06103      0.16508      0.02240      0.04722      1.00000 |                                               *
     60       0.05577      0.16805      0.02119      0.04722      1.00000 |                                               *
     70       0.05196      0.17447      0.01816      0.04964      1.00000 |                                               *
     80       0.04769      0.17781      0.01695      0.05085      1.00000 |                                               *
     90       0.04473      0.18181      0.01574      0.05085      1.00000 |                                               *
    100       0.04116      0.18389      0.01332      0.05085      1.00000 |                                               *
    110       0.03844      0.18536      0.01392      0.05206      1.00000 |                                               *
    120       0.03436      0.18933      0.01211      0.05569      1.00000 |                                               *
    130       0.03151      0.19392      0.00908      0.05690      1.00000 |                                               *
    140       0.02808      0.19637      0.00908      0.05569      1.00000 |                                               *
    150       0.02579      0.19717      0.00666      0.05569      1.00000 |                                               *
    160       0.02372      0.19843      0.00484      0.05448      1.00000 |                                               *
    170       0.02136      0.20071      0.00303      0.05448      1.00000 |                                               *
    180       0.01989      0.20379      0.00242      0.05327      1.00000 |                                               *
    190       0.01823      0.20539      0.00121      0.05448      1.00000 |                                               *
    200       0.01726      0.20900      0.00121      0.05448      1.00000 |                                               *
    210       0.01572      0.21271      0.00000      0.05569      1.00000 |                                               *
    220       0.01463      0.21499      0.00000      0.05569      1.00000 |                                               *
    230       0.01346      0.21858      0.00000      0.05448      1.00000 |                                               *
    240       0.01266      0.22298      0.00000      0.05448      1.00000 |                                               *
    250       0.01166      0.22616      0.00000      0.05569      1.00000 |                                               *
    260       0.01088      0.22889      0.00000      0.05569      1.00000 |                                               *
    270       0.01005      0.23431      0.00000      0.05569      1.00000 |                                               *
    280       0.00921      0.23937      0.00000      0.05690      1.00000 |                                               *
    290       0.00865      0.24262      0.00000      0.05569      1.00000 |                                               *
    300       0.00840      0.24556      0.00000      0.05569      1.00000 |                                               *
    310       0.00769      0.25174      0.00000      0.05569      1.00000 |                                               *
    320       0.00703      0.25612      0.00000      0.05569      1.00000 |                                               *
    330       0.00641      0.26001      0.00000      0.05690      1.00000 |                                               *
    340       0.00617      0.26186      0.00000      0.05690      1.00000 |                                               *
    350       0.00570      0.26430      0.00000      0.05932      1.00000 |                                               *
    360       0.00533      0.26756      0.00000      0.06053      1.00000 |                                               *
    370       0.00515      0.27065      0.00000      0.06053      1.00000 |                                               *
    380       0.00489      0.27315      0.00000      0.06053      1.00000 |                                               *
    390       0.00460      0.27713      0.00000      0.06053      1.00000 |                                               *
    400       0.00443      0.27966      0.00000      0.05932      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.45      6.55  FOLLOW
    352      1    400      1      7      2.88      4.50  ENTAGE
    231      1    395      1      7      4.26      2.16  PD
     95      2    395      1      7      5.03      0.71  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    53 terminal nodes
    Average :     18.91500 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 30 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 30 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 14732 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.14746
                  ROC           11      0.83137
                 Lift           30      4.41176
              KS-stat            9      0.59915
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14651     0.15889     0.93542     0.73988     7.01307     4.01548     0.72761     0.43226     0.04116     0.04116
      8     0.10682     0.14746     0.95702     0.82574     8.08824     3.76471     0.76745     0.55801     0.03571     0.04600
      9     0.10418     0.14829     0.95788     0.82568     8.08824     3.82353     0.77711     0.59915     0.03571     0.04600
     10     0.10131     0.14799     0.96171     0.83020     8.08824     3.82353     0.79705     0.59663     0.03511     0.04600
     11     0.09969     0.14852     0.96180     0.83137     8.23529     4.07843     0.79579     0.59789     0.03511     0.04600
     20     0.08521     0.15450     0.97112     0.78727     8.52941     4.11765     0.82635     0.50260     0.02966     0.04358
     30     0.07421     0.15825     0.98207     0.76894     9.26471     4.41176     0.87671     0.44808     0.02542     0.04600
     40     0.06639     0.16065     0.98696     0.77081     9.55882     4.11765     0.89528     0.47029     0.02361     0.04600
     50     0.06103     0.16508     0.98997     0.74540     9.55882     4.00000     0.90638     0.44593     0.02240     0.04722
     60     0.05577     0.16805     0.99380     0.74213     9.70588     4.41176     0.92298     0.44430     0.02119     0.04722
     65     0.05380     0.17051     0.99485     0.73318    10.00000     4.41176     0.94318     0.42788     0.01998     0.04964
     70     0.05196     0.17447     0.99554     0.72263    10.00000     4.11765     0.94697     0.42283     0.01816     0.04964
     80     0.04769     0.17781     0.99690     0.72322    10.00000     3.82353     0.95310     0.42409     0.01695     0.05085
     90     0.04473     0.18181     0.99762     0.71524    10.00000     3.82353     0.96194     0.43546     0.01574     0.05085
    100     0.04116     0.18389     0.99833     0.71855    10.00000     3.70588     0.96572     0.44682     0.01332     0.05085
    110     0.03844     0.18536     0.99897     0.72033    10.00000     3.82353     0.97790     0.44935     0.01392     0.05206
    120     0.03436     0.18933     0.99973     0.72371    10.00000     3.82353     0.99179     0.44808     0.01211     0.05569
    130     0.03151     0.19392     0.99982     0.71936    10.00000     3.82353     0.99116     0.42499     0.00908     0.05690
    140     0.02808     0.19637     0.99994     0.72653    10.00000     3.82353     0.99621     0.42499     0.00908     0.05569
    142     0.02771     0.19764     1.00000     0.72408    10.00000     3.82353     1.00000     0.42625     0.00847     0.05569
    150     0.02579     0.19717     1.00000     0.72997    10.00000     3.82353     1.00000     0.43330     0.00666     0.05569
    160     0.02372     0.19843     1.00000     0.73444    10.00000     3.82353     1.00000     0.43962     0.00484     0.05448
    170     0.02136     0.20071     1.00000     0.73522    10.00000     3.82353     1.00000     0.44682     0.00303     0.05448
    180     0.01989     0.20379     1.00000     0.73269    10.00000     3.82353     1.00000     0.45440     0.00242     0.05327
    190     0.01823     0.20539     1.00000     0.73429    10.00000     3.82353     1.00000     0.44808     0.00121     0.05448
    200     0.01726     0.20900     1.00000     0.72872    10.00000     3.82353     1.00000     0.44935     0.00121     0.05448
    206     0.01637     0.21068     1.00000     0.72883    10.00000     3.82353     1.00000     0.43672     0.00000     0.05448
    210     0.01572     0.21271     1.00000     0.72761    10.00000     3.52941     1.00000     0.43419     0.00000     0.05569
    220     0.01463     0.21499     1.00000     0.72894    10.00000     3.70588     1.00000     0.42536     0.00000     0.05569
    230     0.01346     0.21858     1.00000     0.72148    10.00000     4.00000     1.00000     0.42409     0.00000     0.05448
    240     0.01266     0.22298     1.00000     0.71364    10.00000     3.82353     1.00000     0.43546     0.00000     0.05448
    250     0.01166     0.22616     1.00000     0.71346    10.00000     3.82353     1.00000     0.42409     0.00000     0.05569
    260     0.01088     0.22889     1.00000     0.71041    10.00000     4.00000     1.00000     0.42536     0.00000     0.05569
    270     0.01005     0.23431     1.00000     0.70826    10.00000     3.82353     1.00000     0.42788     0.00000     0.05569
    280     0.00921     0.23937     1.00000     0.70629    10.00000     4.11765     1.00000     0.43167     0.00000     0.05690
    290     0.00865     0.24262     1.00000     0.70395    10.00000     4.11765     1.00000     0.41399     0.00000     0.05569
    300     0.00840     0.24556     1.00000     0.69797    10.00000     4.11765     1.00000     0.40263     0.00000     0.05569
    310     0.00769     0.25174     1.00000     0.69192    10.00000     4.11765     1.00000     0.39379     0.00000     0.05569
    320     0.00703     0.25612     1.00000     0.69121    10.00000     4.11765     1.00000     0.39884     0.00000     0.05569
    330     0.00641     0.26001     1.00000     0.69411    10.00000     3.82353     1.00000     0.38622     0.00000     0.05690
    340     0.00617     0.26186     1.00000     0.69270    10.00000     3.82353     1.00000     0.39000     0.00000     0.05690
    350     0.00570     0.26430     1.00000     0.69664    10.00000     3.82353     1.00000     0.38748     0.00000     0.05932
    360     0.00533     0.26756     1.00000     0.69396    10.00000     3.82353     1.00000     0.38874     0.00000     0.06053
    370     0.00515     0.27065     1.00000     0.69162    10.00000     3.82353     1.00000     0.38243     0.00000     0.06053
    380     0.00489     0.27315     1.00000     0.69452    10.00000     3.82353     1.00000     0.38369     0.00000     0.06053
    390     0.00460     0.27713     1.00000     0.69081    10.00000     3.82353     1.00000     0.36980     0.00000     0.06053
    400     0.00443     0.27966     1.00000     0.68694    10.00000     3.82353     1.00000     0.36854     0.00000     0.05932


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     64.29077   64.29 |*******    |
 PD         39.80266   39.80 |*****      |
 FH         33.01238   33.01 |****       |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         9.00        59.00       0.8676


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       787.00         5.00       0.0063
 1                   34.00         1.00        33.00       0.9706

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 645 kb , 77% compression

 Grove file created containing:
      1 TreeNet

