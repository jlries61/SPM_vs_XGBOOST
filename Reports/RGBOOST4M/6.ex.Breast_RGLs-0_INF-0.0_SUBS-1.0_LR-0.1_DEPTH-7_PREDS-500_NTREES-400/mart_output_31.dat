
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.15068      0.16011      0.04116      0.04116      1.00000 |                                               *
      2       0.13872      0.15486      0.04116      0.04116      1.00000 |                                             *
      3       0.13105      0.15036      0.04116      0.04116      1.00000 |                                            *
      4       0.12456      0.14836      0.04116      0.04116      1.00000 |                                           *
      5       0.11806      0.14861      0.04116      0.04116      1.00000 |                                            *
      6       0.11387      0.14737      0.04116      0.04116      1.00000 |                                           *
      7       0.10978      0.14634      0.04116      0.04116      1.00000 |                                           *
      8       0.10521      0.14568      0.04056      0.04116      1.00000 |                                           *
      9       0.10204      0.14498      0.03935      0.04116      1.00000 |                                          *
     10       0.09923      0.14562      0.03935      0.04116      1.00000 |                                           *
     11       0.09602      0.14567      0.03874      0.04116      1.00000 |                                           *
     12       0.09423      0.14566      0.03632      0.04116      1.00000 |                                           *
     13       0.09278      0.14585      0.03632      0.04237      1.00000 |                                           *
     14       0.08961      0.14646      0.03450      0.04237      1.00000 |                                           *
     15       0.08734      0.14707      0.03329      0.04237      1.00000 |                                           *
     16       0.08576      0.14653      0.03148      0.04116      1.00000 |                                           *
     17       0.08368      0.14745      0.03087      0.04116      1.00000 |                                           *
     18       0.08254      0.14790      0.02966      0.04116      1.00000 |                                           *
     19       0.08164      0.14823      0.02785      0.04116      1.00000 |                                           *
     20       0.08002      0.14968      0.02663      0.04116      1.00000 |                                            *
     30       0.07198      0.15240      0.02300      0.04237      1.00000 |                                             *
     40       0.06131      0.15702      0.02058      0.04237      1.00000 |                                              *
     50       0.05236      0.16341      0.01998      0.04116      1.00000 |                                               *
     60       0.04826      0.16838      0.01877      0.04116      1.00000 |                                               *
     70       0.04256      0.17391      0.01513      0.04237      1.00000 |                                               *
     80       0.04091      0.17684      0.01513      0.04116      1.00000 |                                               *
     90       0.03874      0.17903      0.01271      0.04116      1.00000 |                                               *
    100       0.03605      0.18364      0.01271      0.04116      1.00000 |                                               *
    110       0.03380      0.18698      0.01090      0.04237      1.00000 |                                               *
    120       0.03185      0.19134      0.00847      0.04358      1.00000 |                                               *
    130       0.02904      0.19529      0.00787      0.04237      1.00000 |                                               *
    140       0.02642      0.19895      0.00484      0.04237      1.00000 |                                               *
    150       0.02415      0.20199      0.00363      0.04237      1.00000 |                                               *
    160       0.02242      0.20456      0.00303      0.04237      1.00000 |                                               *
    170       0.02075      0.20784      0.00242      0.04116      1.00000 |                                               *
    180       0.01996      0.20869      0.00242      0.04116      1.00000 |                                               *
    190       0.01829      0.21317      0.00242      0.04237      1.00000 |                                               *
    200       0.01687      0.21715      0.00182      0.04237      1.00000 |                                               *
    210       0.01579      0.22067      0.00182      0.04358      1.00000 |                                               *
    220       0.01445      0.22458      0.00061      0.04358      1.00000 |                                               *
    230       0.01324      0.22892      0.00061      0.04358      1.00000 |                                               *
    240       0.01242      0.23152      0.00061      0.04358      1.00000 |                                               *
    250       0.01191      0.23415      0.00061      0.04358      1.00000 |                                               *
    260       0.01086      0.23929      0.00061      0.04358      1.00000 |                                               *
    270       0.01036      0.24268      0.00061      0.04358      1.00000 |                                               *
    280       0.00938      0.24616      0.00061      0.04237      1.00000 |                                               *
    290       0.00898      0.24851      0.00061      0.04237      1.00000 |                                               *
    300       0.00828      0.25331      0.00061      0.04600      1.00000 |                                               *
    310       0.00781      0.25584      0.00061      0.04600      1.00000 |                                               *
    320       0.00731      0.25994      0.00061      0.04479      1.00000 |                                               *
    330       0.00669      0.26553      0.00061      0.04479      1.00000 |                                               *
    340       0.00624      0.26904      0.00061      0.04479      1.00000 |                                               *
    350       0.00588      0.27340      0.00061      0.04479      1.00000 |                                               *
    360       0.00553      0.27951      0.00061      0.04600      1.00000 |                                               *
    370       0.00509      0.28472      0.00061      0.04964      1.00000 |                                               *
    380       0.00475      0.29103      0.00061      0.05085      1.00000 |                                               *
    390       0.00450      0.29479      0.00061      0.04843      1.00000 |                                               *
    400       0.00414      0.29912      0.00061      0.04843      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.37      6.63  FOLLOW
    379      1    400      1      7      2.83      4.90  ENTAGE
    234      1    400      1      7      4.29      2.17  PD
    138      1    397      1      7      3.74      1.47  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    59 terminal nodes
    Average :     20.65500 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 22 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 22 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 9

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 16124 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            9      0.14498
                  ROC            9      0.75433
                 Lift            3      5.58824
              KS-stat            5      0.49354
          Class.Error           22      0.03995

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.15068     0.16011     0.93129     0.74458     6.93294     5.11111     0.73273     0.49228     0.04116     0.04116
      3     0.13105     0.15036     0.94873     0.72477     7.65074     5.58824     0.78071     0.48685     0.04116     0.04116
      5     0.11806     0.14861     0.95780     0.70581     8.08824     5.45098     0.80236     0.49354     0.04116     0.04116
      9     0.10204     0.14498     0.96758     0.75433     8.97059     5.00000     0.83266     0.46108     0.03935     0.04116
     10     0.09923     0.14562     0.96858     0.73956     8.97059     5.00000     0.83645     0.46272     0.03935     0.04116
     20     0.08002     0.14968     0.97711     0.73561     8.85294     5.00000     0.86921     0.43509     0.02663     0.04116
     22     0.07818     0.15019     0.97692     0.72911     8.97059     5.00000     0.86479     0.44771     0.02542     0.03995
     30     0.07198     0.15240     0.98016     0.72829     8.97059     5.00000     0.86416     0.44392     0.02300     0.04237
     40     0.06131     0.15702     0.98923     0.73013     9.55882     5.00000     0.92116     0.42172     0.02058     0.04237
     50     0.05236     0.16341     0.99449     0.73435     9.70588     4.11765     0.94281     0.36742     0.01998     0.04116
     60     0.04826     0.16838     0.99553     0.71888     9.70588     4.11765     0.95102     0.38384     0.01877     0.04116
     70     0.04256     0.17391     0.99695     0.70286     9.85294     4.11765     0.96428     0.36237     0.01513     0.04237
     80     0.04091     0.17684     0.99713     0.69469     9.85294     4.11765     0.96491     0.36453     0.01513     0.04116
     90     0.03874     0.17903     0.99788     0.69145     9.85294     4.00000     0.96554     0.37589     0.01271     0.04116
     93     0.03771     0.18008     0.99857     0.69042    10.00000     3.82353     0.96554     0.37210     0.01271     0.04116
    100     0.03605     0.18364     0.99870     0.68343    10.00000     3.52941     0.96680     0.35569     0.01271     0.04116
    110     0.03380     0.18698     0.99917     0.67667    10.00000     3.52941     0.97285     0.34685     0.01090     0.04237
    120     0.03185     0.19134     0.99939     0.67129    10.00000     3.52941     0.97709     0.32917     0.00847     0.04358
    130     0.02904     0.19529     0.99967     0.66767    10.00000     3.52941     0.98801     0.31239     0.00787     0.04237
    140     0.02642     0.19895     0.99991     0.66644    10.00000     3.52941     0.99811     0.30608     0.00484     0.04237
    150     0.02415     0.20199     0.99994     0.66585    10.00000     3.52941     0.99874     0.30608     0.00363     0.04237
    160     0.02242     0.20456     0.99996     0.67049    10.00000     3.52941     0.99874     0.31618     0.00303     0.04237
    168     0.02116     0.20677     0.99997     0.66797    10.00000     3.52941     0.99937     0.30608     0.00242     0.04116
    170     0.02075     0.20784     0.99997     0.66826    10.00000     3.52941     0.99937     0.30734     0.00242     0.04116
    180     0.01996     0.20869     0.99997     0.67149    10.00000     3.52941     0.99937     0.30860     0.00242     0.04116
    190     0.01829     0.21317     0.99998     0.66802    10.00000     3.52941     0.99937     0.30318     0.00242     0.04237
    199     0.01708     0.21685     1.00000     0.66869    10.00000     3.82353     0.99937     0.30823     0.00182     0.04237
    200     0.01687     0.21715     1.00000     0.66821    10.00000     3.82353     0.99937     0.30407     0.00182     0.04237
    210     0.01579     0.22067     1.00000     0.66212    10.00000     3.82353     0.99937     0.30281     0.00182     0.04358
    218     0.01468     0.22393     1.00000     0.66175    10.00000     3.82353     0.99937     0.31387     0.00061     0.04358
    220     0.01445     0.22458     1.00000     0.66163    10.00000     3.82353     0.99937     0.31766     0.00061     0.04358
    230     0.01324     0.22892     1.00000     0.66201    10.00000     3.82353     0.99937     0.30533     0.00061     0.04358
    240     0.01242     0.23152     1.00000     0.66457    10.00000     3.82353     0.99937     0.31766     0.00061     0.04358
    250     0.01191     0.23415     1.00000     0.66319    10.00000     3.82353     0.99937     0.30912     0.00061     0.04358
    260     0.01086     0.23929     1.00000     0.66371    10.00000     3.82353     0.99937     0.30154     0.00061     0.04358
    270     0.01036     0.24268     1.00000     0.66071    10.00000     3.82353     0.99937     0.29776     0.00061     0.04358
    280     0.00938     0.24616     1.00000     0.66282    10.00000     3.82353     0.99937     0.30154     0.00061     0.04237
    290     0.00898     0.24851     1.00000     0.66331    10.00000     3.82353     0.99937     0.30912     0.00061     0.04237
    300     0.00828     0.25331     1.00000     0.66405    10.00000     3.82353     0.99937     0.30786     0.00061     0.04600
    310     0.00781     0.25584     1.00000     0.66605    10.00000     3.82353     0.99937     0.30660     0.00061     0.04600
    320     0.00731     0.25994     1.00000     0.66605    10.00000     3.82353     0.99937     0.30919     0.00061     0.04479
    330     0.00669     0.26553     1.00000     0.66379    10.00000     3.82353     0.99937     0.31046     0.00061     0.04479
    340     0.00624     0.26904     1.00000     0.66579    10.00000     3.82353     0.99937     0.30786     0.00061     0.04479
    350     0.00588     0.27340     1.00000     0.66431    10.00000     3.82353     0.99937     0.30660     0.00061     0.04479
    360     0.00553     0.27951     1.00000     0.66201    10.00000     3.82353     0.99937     0.30660     0.00061     0.04600
    370     0.00509     0.28472     1.00000     0.66182    10.00000     3.82353     0.99937     0.30533     0.00061     0.04964
    380     0.00475     0.29103     1.00000     0.65837    10.00000     3.82353     0.99937     0.30028     0.00061     0.05085
    390     0.00450     0.29479     1.00000     0.65796    10.00000     3.52941     0.99937     0.29716     0.00061     0.04843
    400     0.00414     0.29912     1.00000     0.66056    10.00000     3.52941     0.99937     0.32242     0.00061     0.04843


 ========================================
 Variable Importance for the 9-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     59.20745   59.21 |*******    |
 PD         47.57512   47.58 |******     |
 FH         28.59898   28.60 |****       |


 Learn Sample Misclassification by Target Class
 For The 9-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         3.00        65.00       0.9559


 Test Sample Misclassification by Target Class
 For The 9-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 694 kb , 77% compression

 Grove file created containing:
      1 TreeNet

