
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14622      0.15822      0.04116      0.04116      1.00000 |                                               *
      2       0.13673      0.15280      0.04116      0.04116      1.00000 |                                             *
      3       0.13056      0.14867      0.04116      0.04116      1.00000 |                                            *
      4       0.12244      0.14560      0.04116      0.04116      1.00000 |                                           *
      5       0.11675      0.14229      0.04116      0.04116      1.00000 |                                          *
      6       0.11213      0.14024      0.04116      0.04116      1.00000 |                                          *
      7       0.10716      0.13867      0.03874      0.04116      1.00000 |                                         *
      8       0.10366      0.13724      0.03753      0.04237      1.00000 |                                         *
      9       0.10068      0.13686      0.03450      0.03995      1.00000 |                                         *
     10       0.09774      0.13650      0.03269      0.04116      1.00000 |                                        *
     11       0.09580      0.13561      0.03148      0.04116      1.00000 |                                        *
     12       0.09343      0.13471      0.03087      0.04116      1.00000 |                                        *
     13       0.09112      0.13407      0.03027      0.04116      1.00000 |                                        *
     14       0.08878      0.13395      0.02966      0.04116      1.00000 |                                        *
     15       0.08697      0.13391      0.03027      0.03995      1.00000 |                                        *
     16       0.08555      0.13384      0.03027      0.03995      1.00000 |                                        *
     17       0.08404      0.13353      0.02966      0.03874      1.00000 |                                        *
     18       0.08265      0.13363      0.02966      0.03995      1.00000 |                                        *
     19       0.08123      0.13366      0.02906      0.03874      1.00000 |                                        *
     20       0.08031      0.13366      0.02845      0.03753      1.00000 |                                        *
     30       0.07295      0.13706      0.02542      0.03995      1.00000 |                                         *
     40       0.06229      0.14110      0.02240      0.04237      1.00000 |                                          *
     50       0.05354      0.14578      0.01877      0.04237      1.00000 |                                           *
     60       0.04889      0.14753      0.01574      0.04116      1.00000 |                                            *
     70       0.04501      0.14980      0.01453      0.04358      1.00000 |                                            *
     80       0.04221      0.15335      0.01332      0.04358      1.00000 |                                              *
     90       0.03874      0.15552      0.01211      0.04358      1.00000 |                                              *
    100       0.03559      0.15817      0.00969      0.04237      1.00000 |                                               *
    110       0.03284      0.16015      0.00969      0.04237      1.00000 |                                               *
    120       0.03116      0.16235      0.00847      0.04237      1.00000 |                                               *
    130       0.02961      0.16344      0.00847      0.04358      1.00000 |                                               *
    140       0.02719      0.16592      0.00726      0.04358      1.00000 |                                               *
    150       0.02609      0.16808      0.00666      0.04358      1.00000 |                                               *
    160       0.02450      0.17045      0.00666      0.04358      1.00000 |                                               *
    170       0.02270      0.17295      0.00484      0.04358      1.00000 |                                               *
    180       0.02131      0.17581      0.00363      0.04237      1.00000 |                                               *
    190       0.02011      0.17827      0.00303      0.04237      1.00000 |                                               *
    200       0.01903      0.18179      0.00303      0.04358      1.00000 |                                               *
    210       0.01808      0.18376      0.00303      0.04479      1.00000 |                                               *
    220       0.01670      0.18595      0.00303      0.04479      1.00000 |                                               *
    230       0.01501      0.19085      0.00061      0.04479      1.00000 |                                               *
    240       0.01397      0.19404      0.00061      0.04479      1.00000 |                                               *
    250       0.01277      0.19711      0.00061      0.04600      1.00000 |                                               *
    260       0.01195      0.19894      0.00061      0.04358      1.00000 |                                               *
    270       0.01130      0.20269      0.00061      0.04479      1.00000 |                                               *
    280       0.01034      0.20706      0.00061      0.04600      1.00000 |                                               *
    290       0.00962      0.21118      0.00061      0.04600      1.00000 |                                               *
    300       0.00893      0.21482      0.00061      0.04600      1.00000 |                                               *
    310       0.00843      0.21724      0.00061      0.04722      1.00000 |                                               *
    320       0.00786      0.21995      0.00061      0.04722      1.00000 |                                               *
    330       0.00738      0.22342      0.00061      0.04722      1.00000 |                                               *
    340       0.00702      0.22638      0.00061      0.04843      1.00000 |                                               *
    350       0.00664      0.22879      0.00061      0.04843      1.00000 |                                               *
    360       0.00628      0.23156      0.00061      0.04843      1.00000 |                                               *
    370       0.00598      0.23471      0.00061      0.04964      1.00000 |                                               *
    380       0.00569      0.23771      0.00061      0.04843      1.00000 |                                               *
    390       0.00539      0.23952      0.00061      0.04964      1.00000 |                                               *
    400       0.00499      0.24302      0.00061      0.04964      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.48      6.52  FOLLOW
    374      1    400      1      7      2.33      5.30  ENTAGE
    230      1    400      1      7      4.10      2.25  PD
     99      1    400      2      7      4.23      0.93  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    43 terminal nodes
    Average :     19.43000 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 21 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 21 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 17

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 15144 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           17      0.13353
                  ROC            8      0.85641
                 Lift            5      5.29412
              KS-stat           11      0.63904
          Class.Error           21      0.03632

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14622     0.15822     0.91161     0.75999     7.09477     4.70588     0.68717     0.43427     0.04116     0.04116
      5     0.11675     0.14229     0.95317     0.81074     7.64706     5.29412     0.78235     0.53818     0.04116     0.04116
      8     0.10366     0.13724     0.96068     0.85641     8.23529     5.00000     0.79037     0.59410     0.03753     0.04237
     10     0.09774     0.13650     0.96470     0.83562     8.82353     5.00000     0.81607     0.58653     0.03269     0.04116
     11     0.09580     0.13561     0.96507     0.84230     8.82353     5.00000     0.81607     0.63904     0.03148     0.04116
     17     0.08404     0.13353     0.97180     0.84122     8.82353     5.00000     0.84440     0.60584     0.02966     0.03874
     20     0.08031     0.13366     0.97446     0.83762     9.11765     5.00000     0.85784     0.61378     0.02845     0.03753
     21     0.07938     0.13396     0.97540     0.84033     9.26471     5.00000     0.86668     0.61757     0.02724     0.03632
     30     0.07295     0.13706     0.97875     0.83974     9.41176     5.29412     0.88120     0.60495     0.02542     0.03995
     37     0.06363     0.13985     0.98965     0.82316    10.00000     5.29412     0.93876     0.57249     0.02300     0.03995
     40     0.06229     0.14110     0.99010     0.81497    10.00000     5.29412     0.93939     0.50245     0.02240     0.04237
     50     0.05354     0.14578     0.99391     0.81241    10.00000     5.29412     0.94760     0.50810     0.01877     0.04237
     60     0.04889     0.14753     0.99557     0.80593    10.00000     5.00000     0.94697     0.48678     0.01574     0.04116
     70     0.04501     0.14980     0.99683     0.80374    10.00000     5.00000     0.96654     0.50156     0.01453     0.04358
     80     0.04221     0.15335     0.99745     0.79800    10.00000     4.70588     0.97664     0.49057     0.01332     0.04358
     90     0.03874     0.15552     0.99836     0.79540    10.00000     4.70588     0.97664     0.43887     0.01211     0.04358
    100     0.03559     0.15817     0.99898     0.78803    10.00000     4.70588     0.98864     0.44771     0.00969     0.04237
    110     0.03284     0.16015     0.99929     0.79254    10.00000     4.70588     0.99116     0.46524     0.00969     0.04237
    120     0.03116     0.16235     0.99951     0.78838    10.00000     5.00000     0.99369     0.48165     0.00847     0.04237
    130     0.02961     0.16344     0.99967     0.78779    10.00000     5.00000     0.99432     0.46739     0.00847     0.04358
    140     0.02719     0.16592     0.99979     0.79208    10.00000     5.00000     0.99621     0.47118     0.00726     0.04358
    150     0.02609     0.16808     0.99983     0.78873    10.00000     5.29412     0.99621     0.47445     0.00666     0.04358
    160     0.02450     0.17045     0.99989     0.79568    10.00000     5.17647     0.99811     0.48329     0.00666     0.04358
    170     0.02270     0.17295     0.99993     0.79234    10.00000     5.00000     0.99874     0.48240     0.00484     0.04358
    171     0.02245     0.17393     0.99995     0.79040    10.00000     5.00000     0.99937     0.48203     0.00484     0.04358
    180     0.02131     0.17581     0.99997     0.78654    10.00000     4.70588     0.99937     0.48492     0.00363     0.04237
    190     0.02011     0.17827     0.99996     0.78335    10.00000     5.00000     0.99937     0.48745     0.00303     0.04237
    200     0.01903     0.18179     0.99996     0.77696    10.00000     4.88235     0.99937     0.47950     0.00303     0.04358
    210     0.01808     0.18376     0.99997     0.77444    10.00000     4.70588     0.99937     0.46687     0.00303     0.04479
    220     0.01670     0.18595     0.99999     0.77575    10.00000     4.58824     0.99937     0.48203     0.00303     0.04479
    223     0.01597     0.18799     1.00000     0.77561    10.00000     4.41176     0.99937     0.48960     0.00061     0.04600
    230     0.01501     0.19085     1.00000     0.77390    10.00000     4.11765     0.99937     0.48656     0.00061     0.04479
    240     0.01397     0.19404     1.00000     0.76836    10.00000     4.11765     0.99937     0.49034     0.00061     0.04479
    250     0.01277     0.19711     1.00000     0.77301    10.00000     4.41176     0.99937     0.51181     0.00061     0.04600
    260     0.01195     0.19894     1.00000     0.77639    10.00000     4.11765     0.99937     0.48656     0.00061     0.04358
    270     0.01130     0.20269     1.00000     0.77457    10.00000     4.41176     0.99937     0.48366     0.00061     0.04479
    280     0.01034     0.20706     1.00000     0.77717    10.00000     4.11765     0.99937     0.50045     0.00061     0.04600
    290     0.00962     0.21118     1.00000     0.77171    10.00000     4.11765     0.99937     0.48351     0.00061     0.04600
    300     0.00893     0.21482     1.00000     0.77408    10.00000     4.11765     0.99937     0.49198     0.00061     0.04600
    310     0.00843     0.21724     1.00000     0.77416    10.00000     4.11765     0.99937     0.49577     0.00061     0.04722
    320     0.00786     0.21995     1.00000     0.77505    10.00000     4.41176     0.99937     0.49540     0.00061     0.04722
    330     0.00738     0.22342     1.00000     0.77304    10.00000     4.29412     0.99937     0.50171     0.00061     0.04722
    340     0.00702     0.22638     1.00000     0.77159    10.00000     3.82353     0.99937     0.49034     0.00061     0.04843
    350     0.00664     0.22879     1.00000     0.77185    10.00000     3.82353     0.99937     0.49072     0.00061     0.04843
    360     0.00628     0.23156     1.00000     0.76855    10.00000     4.11765     0.99937     0.48945     0.00061     0.04843
    370     0.00598     0.23471     1.00000     0.76651    10.00000     4.11765     0.99937     0.48099     0.00061     0.04964
    380     0.00569     0.23771     1.00000     0.76335    10.00000     3.82353     0.99937     0.48604     0.00061     0.04843
    390     0.00539     0.23952     1.00000     0.76517    10.00000     4.00000     0.99937     0.49866     0.00061     0.04964
    400     0.00499     0.24302     1.00000     0.76498    10.00000     4.11765     0.99937     0.48225     0.00061     0.04964


 =========================================
 Variable Importance for the 17-tree Model
 =========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     48.56412   48.56 |******     |
 PD         47.25590   47.26 |******     |
 FH         16.86864   16.87 |***        |


 Learn Sample Misclassification by Target Class
 For The 17-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1583.00         1.00       0.0006
 1                   68.00        20.00        48.00       0.7059


 Test Sample Misclassification by Target Class
 For The 17-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       789.00         3.00       0.0038
 1                   34.00         5.00        29.00       0.8529

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 668 kb , 77% compression

 Grove file created containing:
      1 TreeNet

