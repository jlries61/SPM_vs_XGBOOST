
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:01

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14954      0.15775      0.04116      0.04116      1.00000 |                                               *
      2       0.13982      0.15260      0.04116      0.04116      1.00000 |                                             *
      3       0.13257      0.14984      0.04116      0.04116      1.00000 |                                             *
      4       0.12662      0.14783      0.04116      0.04116      1.00000 |                                            *
      5       0.12007      0.14597      0.04116      0.04116      1.00000 |                                           *
      6       0.11595      0.14493      0.04116      0.04116      1.00000 |                                           *
      7       0.11139      0.14366      0.04116      0.03995      1.00000 |                                           *
      8       0.10811      0.14206      0.03995      0.03995      1.00000 |                                          *
      9       0.10502      0.14123      0.03874      0.03995      1.00000 |                                          *
     10       0.10213      0.14072      0.03874      0.04116      1.00000 |                                          *
     11       0.09985      0.13969      0.03814      0.04116      1.00000 |                                          *
     12       0.09721      0.13934      0.03753      0.04116      1.00000 |                                         *
     13       0.09595      0.13899      0.03632      0.04116      1.00000 |                                         *
     14       0.09369      0.13953      0.03511      0.03995      1.00000 |                                         *
     15       0.09257      0.13899      0.03511      0.04116      1.00000 |                                         *
     16       0.09137      0.13953      0.03511      0.04116      1.00000 |                                         *
     17       0.08999      0.13942      0.03571      0.04116      1.00000 |                                         *
     18       0.08911      0.13960      0.03450      0.04116      1.00000 |                                         *
     19       0.08788      0.13927      0.03511      0.04116      1.00000 |                                         *
     20       0.08700      0.13910      0.03390      0.03995      1.00000 |                                         *
     30       0.08124      0.13741      0.02845      0.03874      1.00000 |                                         *
     40       0.07181      0.13823      0.02240      0.03995      1.00000 |                                         *
     50       0.06618      0.14040      0.02179      0.03995      1.00000 |                                          *
     60       0.06256      0.14121      0.02179      0.03995      1.00000 |                                          *
     70       0.05729      0.14421      0.02119      0.04116      1.00000 |                                           *
     80       0.05195      0.14754      0.01695      0.04116      1.00000 |                                            *
     90       0.04811      0.14985      0.01392      0.03995      1.00000 |                                             *
    100       0.04448      0.15221      0.01150      0.03995      1.00000 |                                             *
    110       0.04155      0.15387      0.00969      0.03995      1.00000 |                                              *
    120       0.03905      0.15670      0.00726      0.03995      1.00000 |                                               *
    130       0.03663      0.16079      0.00726      0.03995      1.00000 |                                               *
    140       0.03421      0.16378      0.00605      0.04358      1.00000 |                                               *
    150       0.03169      0.16423      0.00605      0.04358      1.00000 |                                               *
    160       0.02983      0.16599      0.00545      0.04358      1.00000 |                                               *
    170       0.02715      0.16860      0.00484      0.04237      1.00000 |                                               *
    180       0.02477      0.17051      0.00424      0.04237      1.00000 |                                               *
    190       0.02366      0.17213      0.00424      0.04237      1.00000 |                                               *
    200       0.02193      0.17431      0.00363      0.04479      1.00000 |                                               *
    210       0.02087      0.17641      0.00363      0.04358      1.00000 |                                               *
    220       0.01967      0.17904      0.00303      0.04358      1.00000 |                                               *
    230       0.01823      0.17999      0.00242      0.04600      1.00000 |                                               *
    240       0.01750      0.18221      0.00182      0.04722      1.00000 |                                               *
    250       0.01659      0.18375      0.00121      0.04843      1.00000 |                                               *
    260       0.01599      0.18606      0.00121      0.04722      1.00000 |                                               *
    270       0.01515      0.18856      0.00121      0.04722      1.00000 |                                               *
    280       0.01446      0.18938      0.00121      0.04722      1.00000 |                                               *
    290       0.01314      0.19149      0.00061      0.04600      1.00000 |                                               *
    300       0.01269      0.19404      0.00061      0.04964      1.00000 |                                               *
    310       0.01151      0.19585      0.00061      0.04964      1.00000 |                                               *
    320       0.01089      0.19769      0.00061      0.04722      1.00000 |                                               *
    330       0.01050      0.19960      0.00061      0.04843      1.00000 |                                               *
    340       0.00949      0.20194      0.00061      0.04600      1.00000 |                                               *
    350       0.00909      0.20337      0.00061      0.04600      1.00000 |                                               *
    360       0.00857      0.20635      0.00061      0.04843      1.00000 |                                               *
    370       0.00793      0.20892      0.00061      0.04964      1.00000 |                                               *
    380       0.00754      0.21156      0.00061      0.04964      1.00000 |                                               *
    390       0.00719      0.21325      0.00061      0.04964      1.00000 |                                               *
    400       0.00697      0.21488      0.00061      0.04843      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.31      6.69  FOLLOW
    384      1    400      1      7      2.75      5.04  ENTAGE
    240      1    400      1      7      4.47      2.12  PD
     78      1    398      2      7      4.96      0.59  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    44 terminal nodes
    Average :     19.53750 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 33 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 33 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 33

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 15230 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           33      0.13651
                  ROC           33      0.81209
                 Lift            2      5.58824
              KS-stat          110      0.50498
          Class.Error           25      0.03874

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14954     0.15775     0.92755     0.75446     7.13725     5.23785     0.69478     0.50275     0.04116     0.04116
      2     0.13982     0.15260     0.93105     0.76268     7.35294     5.58824     0.71955     0.49480     0.04116     0.04116
     10     0.10213     0.14072     0.96743     0.75115     8.38235     5.00000     0.83530     0.45566     0.03874     0.04116
     20     0.08700     0.13910     0.97185     0.78448     8.52941     5.00000     0.83430     0.49577     0.03390     0.03995
     25     0.08393     0.13758     0.97238     0.79709     8.67647     5.00000     0.83114     0.49955     0.03148     0.03874
     30     0.08124     0.13741     0.97330     0.80192     8.67647     5.29412     0.83177     0.49324     0.02845     0.03874
     33     0.07669     0.13651     0.97867     0.81209     9.11765     5.47059     0.85116     0.47802     0.02482     0.03874
     40     0.07181     0.13823     0.98150     0.80440     9.11765     5.29412     0.87010     0.47452     0.02240     0.03995
     50     0.06618     0.14040     0.98450     0.80327     9.11765     5.29412     0.87831     0.46962     0.02179     0.03995
     60     0.06256     0.14121     0.98690     0.80154     9.11765     5.29412     0.88336     0.47720     0.02179     0.03995
     70     0.05729     0.14421     0.99032     0.79618     9.55882     5.00000     0.89888     0.46635     0.02119     0.04116
     80     0.05195     0.14754     0.99331     0.79373     9.70588     4.70588     0.91630     0.46925     0.01695     0.04116
     90     0.04811     0.14985     0.99481     0.79174     9.85294     4.88235     0.93921     0.47720     0.01392     0.03995
    100     0.04448     0.15221     0.99575     0.78851     9.85294     4.88235     0.93731     0.47215     0.01150     0.03995
    110     0.04155     0.15387     0.99636     0.79360     9.85294     4.88235     0.93795     0.50498     0.00969     0.03995
    119     0.03951     0.15646     0.99741     0.78639    10.00000     4.70588     0.94615     0.48945     0.00726     0.03995
    120     0.03905     0.15670     0.99742     0.78699    10.00000     4.70588     0.94615     0.48477     0.00726     0.03995
    130     0.03663     0.16079     0.99782     0.77711    10.00000     4.11765     0.95247     0.45648     0.00726     0.03995
    140     0.03421     0.16378     0.99812     0.77418    10.00000     4.11765     0.95499     0.45900     0.00605     0.04358
    150     0.03169     0.16423     0.99881     0.77986    10.00000     4.11765     0.97222     0.46658     0.00605     0.04358
    160     0.02983     0.16599     0.99915     0.78136    10.00000     4.11765     0.97222     0.46064     0.00545     0.04358
    170     0.02715     0.16860     0.99975     0.78051    10.00000     3.82353     0.99432     0.46569     0.00484     0.04237
    180     0.02477     0.17051     0.99991     0.78214    10.00000     3.70588     0.99747     0.48247     0.00424     0.04237
    190     0.02366     0.17213     0.99992     0.78173    10.00000     3.52941     0.99811     0.49131     0.00424     0.04237
    197     0.02278     0.17319     0.99995     0.78092    10.00000     3.82353     0.99937     0.47995     0.00363     0.04358
    200     0.02193     0.17431     0.99995     0.78329    10.00000     3.82353     0.99937     0.47742     0.00363     0.04479
    210     0.02087     0.17641     0.99995     0.78177    10.00000     3.82353     0.99937     0.46294     0.00363     0.04358
    220     0.01967     0.17904     0.99995     0.77791    10.00000     3.82353     0.99937     0.47935     0.00303     0.04358
    230     0.01823     0.17999     0.99997     0.78470    10.00000     3.82353     0.99937     0.48188     0.00242     0.04600
    240     0.01750     0.18221     0.99998     0.78281    10.00000     3.82353     0.99937     0.46925     0.00182     0.04722
    250     0.01659     0.18375     0.99999     0.78348    10.00000     3.82353     0.99937     0.47898     0.00121     0.04843
    260     0.01599     0.18606     0.99999     0.77806    10.00000     3.82353     0.99937     0.46762     0.00121     0.04722
    270     0.01515     0.18856     0.99999     0.77457    10.00000     3.52941     0.99937     0.47393     0.00121     0.04722
    280     0.01446     0.18938     0.99999     0.77876    10.00000     3.52941     0.99937     0.46383     0.00121     0.04722
    287     0.01341     0.19127     1.00000     0.78045    10.00000     3.82353     0.99937     0.48908     0.00061     0.04843
    290     0.01314     0.19149     1.00000     0.77937    10.00000     3.82353     0.99937     0.49161     0.00061     0.04600
    300     0.01269     0.19404     1.00000     0.77484    10.00000     3.82353     0.99937     0.49034     0.00061     0.04964
    310     0.01151     0.19585     1.00000     0.77759    10.00000     3.70588     0.99937     0.48819     0.00061     0.04964
    320     0.01089     0.19769     1.00000     0.78027    10.00000     3.82353     0.99937     0.48819     0.00061     0.04722
    330     0.01050     0.19960     1.00000     0.77848    10.00000     3.82353     0.99937     0.48188     0.00061     0.04843
    340     0.00949     0.20194     1.00000     0.77967    10.00000     3.82353     0.99937     0.47089     0.00061     0.04600
    350     0.00909     0.20337     1.00000     0.78101    10.00000     3.82353     0.99937     0.47341     0.00061     0.04600
    360     0.00857     0.20635     1.00000     0.77833    10.00000     3.82353     0.99937     0.47646     0.00061     0.04843
    370     0.00793     0.20892     1.00000     0.77900    10.00000     3.82353     0.99937     0.46078     0.00061     0.04964
    380     0.00754     0.21156     1.00000     0.77637    10.00000     3.82353     0.99937     0.46583     0.00061     0.04964
    390     0.00719     0.21325     1.00000     0.77689    10.00000     3.70588     0.99937     0.46962     0.00061     0.04964
    400     0.00697     0.21488     1.00000     0.77347    10.00000     3.82353     0.99937     0.47215     0.00061     0.04843


 =========================================
 Variable Importance for the 33-tree Model
 =========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     70.07994   70.08 |********   |
 PD         42.60057   42.60 |*****      |
 FH         19.50409   19.50 |***        |


 Learn Sample Misclassification by Target Class
 For The 33-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1583.00         1.00       0.0006
 1                   68.00        28.00        40.00       0.5882


 Test Sample Misclassification by Target Class
 For The 33-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       790.00         2.00       0.0025
 1                   34.00         4.00        30.00       0.8824

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 661 kb , 77% compression

 Grove file created containing:
      1 TreeNet

