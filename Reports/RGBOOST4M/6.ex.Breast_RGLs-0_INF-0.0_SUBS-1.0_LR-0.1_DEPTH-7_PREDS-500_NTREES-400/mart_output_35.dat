
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14406      0.16041      0.04116      0.04116      1.00000 |                                               *
      2       0.13411      0.15752      0.04116      0.04116      1.00000 |                                              *
      3       0.12663      0.15575      0.04116      0.04116      1.00000 |                                              *
      4       0.11941      0.15424      0.04116      0.04116      1.00000 |                                             *
      5       0.11269      0.15304      0.04116      0.04116      1.00000 |                                             *
      6       0.10823      0.15203      0.04116      0.04116      1.00000 |                                            *
      7       0.10499      0.15164      0.04116      0.03995      1.00000 |                                            *
      8       0.10140      0.15103      0.03874      0.03874      1.00000 |                                            *
      9       0.09757      0.15186      0.03692      0.03995      1.00000 |                                            *
     10       0.09436      0.15248      0.03390      0.04116      1.00000 |                                             *
     11       0.09181      0.15296      0.03208      0.04358      1.00000 |                                             *
     12       0.08934      0.15278      0.03148      0.04237      1.00000 |                                             *
     13       0.08744      0.15308      0.03148      0.04237      1.00000 |                                             *
     14       0.08518      0.15345      0.03269      0.04843      1.00000 |                                             *
     15       0.08344      0.15449      0.03208      0.04843      1.00000 |                                             *
     16       0.08223      0.15533      0.03148      0.04843      1.00000 |                                             *
     17       0.08071      0.15495      0.03087      0.04964      1.00000 |                                             *
     18       0.07965      0.15509      0.03027      0.04964      1.00000 |                                             *
     19       0.07904      0.15563      0.03027      0.04964      1.00000 |                                              *
     20       0.07619      0.15572      0.02966      0.04964      1.00000 |                                              *
     30       0.06810      0.15647      0.02482      0.05085      1.00000 |                                              *
     40       0.06405      0.15896      0.02361      0.04843      1.00000 |                                               *
     50       0.05859      0.15914      0.02300      0.04964      1.00000 |                                               *
     60       0.05597      0.15943      0.02179      0.04964      1.00000 |                                               *
     70       0.05078      0.15995      0.01937      0.04964      1.00000 |                                               *
     80       0.04681      0.16269      0.01755      0.04964      1.00000 |                                               *
     90       0.04416      0.16394      0.01695      0.04722      1.00000 |                                               *
    100       0.04253      0.16457      0.01574      0.04600      1.00000 |                                               *
    110       0.04044      0.16727      0.01332      0.04843      1.00000 |                                               *
    120       0.03661      0.17059      0.01211      0.04600      1.00000 |                                               *
    130       0.03332      0.17385      0.01090      0.04843      1.00000 |                                               *
    140       0.03098      0.17635      0.01029      0.04722      1.00000 |                                               *
    150       0.02921      0.17895      0.00969      0.04722      1.00000 |                                               *
    160       0.02782      0.18233      0.00787      0.04843      1.00000 |                                               *
    170       0.02622      0.18440      0.00545      0.04843      1.00000 |                                               *
    180       0.02458      0.18562      0.00484      0.04843      1.00000 |                                               *
    190       0.02336      0.18894      0.00424      0.04964      1.00000 |                                               *
    200       0.02133      0.19251      0.00363      0.05206      1.00000 |                                               *
    210       0.02027      0.19456      0.00182      0.05085      1.00000 |                                               *
    220       0.01927      0.19726      0.00061      0.05206      1.00000 |                                               *
    230       0.01802      0.20012      0.00061      0.05206      1.00000 |                                               *
    240       0.01721      0.20294      0.00061      0.04964      1.00000 |                                               *
    250       0.01631      0.20618      0.00061      0.04964      1.00000 |                                               *
    260       0.01508      0.20942      0.00061      0.04964      1.00000 |                                               *
    270       0.01398      0.21316      0.00061      0.04964      1.00000 |                                               *
    280       0.01325      0.21609      0.00061      0.05206      1.00000 |                                               *
    290       0.01252      0.21808      0.00061      0.05206      1.00000 |                                               *
    300       0.01201      0.22073      0.00061      0.05206      1.00000 |                                               *
    310       0.01113      0.22457      0.00061      0.05327      1.00000 |                                               *
    320       0.01047      0.22745      0.00000      0.05327      1.00000 |                                               *
    330       0.00994      0.23044      0.00000      0.05327      1.00000 |                                               *
    340       0.00942      0.23261      0.00000      0.05327      1.00000 |                                               *
    350       0.00899      0.23567      0.00000      0.05327      1.00000 |                                               *
    360       0.00858      0.23782      0.00000      0.05206      1.00000 |                                               *
    370       0.00821      0.23983      0.00000      0.05206      1.00000 |                                               *
    380       0.00766      0.24245      0.00000      0.05206      1.00000 |                                               *
    390       0.00731      0.24465      0.00000      0.05206      1.00000 |                                               *
    400       0.00695      0.24771      0.00000      0.05206      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.12      6.89  FOLLOW
    384      1    400      1      7      3.65      4.18  ENTAGE
    217      1    400      1      7      4.55      1.87  PD
    101      1    400      1      7      4.29      0.94  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    47 terminal nodes
    Average :     16.94250 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 78 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 78 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 13154 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.15103
                  ROC           30      0.81161
                 Lift           78      4.88235
              KS-stat           30      0.53060
          Class.Error            8      0.03874

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14406     0.16041     0.95342     0.73802     7.54118     4.11765     0.79219     0.43642     0.04116     0.04116
      8     0.10140     0.15103     0.97179     0.71155     8.67647     4.11765     0.86642     0.43115     0.03874     0.03874
     10     0.09436     0.15248     0.97692     0.70906     9.26471     4.11765     0.87103     0.40300     0.03390     0.04116
     20     0.07619     0.15572     0.98541     0.78491     9.26471     4.11765     0.89944     0.49131     0.02966     0.04964
     30     0.06810     0.15647     0.98884     0.81161     9.70588     4.11765     0.90809     0.53060     0.02482     0.05085
     40     0.06405     0.15896     0.98982     0.79696     9.70588     4.11765     0.90809     0.51671     0.02361     0.04843
     50     0.05859     0.15914     0.99268     0.79367     9.85294     4.41176     0.93100     0.52302     0.02300     0.04964
     60     0.05597     0.15943     0.99356     0.78925     9.85294     4.70588     0.94236     0.47972     0.02179     0.04964
     70     0.05078     0.15995     0.99579     0.79668     9.85294     4.41176     0.95436     0.49614     0.01937     0.04964
     78     0.04853     0.16124     0.99643     0.80080     9.85294     4.88235     0.95815     0.52013     0.01937     0.04843
     80     0.04681     0.16269     0.99681     0.79995     9.85294     4.70588     0.96067     0.50624     0.01755     0.04964
     90     0.04416     0.16394     0.99754     0.79802     9.85294     4.41176     0.97393     0.49272     0.01695     0.04722
    100     0.04253     0.16457     0.99780     0.79304     9.85294     4.41176     0.97456     0.47935     0.01574     0.04600
    110     0.04044     0.16727     0.99813     0.78461     9.85294     4.58824     0.97519     0.46383     0.01332     0.04843
    112     0.03855     0.16784     0.99898     0.78448    10.00000     4.41176     0.97709     0.46710     0.01271     0.04964
    120     0.03661     0.17059     0.99915     0.78158    10.00000     4.11765     0.98151     0.48010     0.01211     0.04600
    130     0.03332     0.17385     0.99944     0.77271    10.00000     4.11765     0.98864     0.48262     0.01090     0.04843
    140     0.03098     0.17635     0.99967     0.76246    10.00000     4.11765     0.98864     0.46182     0.01029     0.04722
    150     0.02921     0.17895     0.99973     0.75210    10.00000     4.11765     0.98927     0.44704     0.00969     0.04722
    160     0.02782     0.18233     0.99977     0.74790    10.00000     3.82353     0.99053     0.45967     0.00787     0.04843
    170     0.02622     0.18440     0.99982     0.74827    10.00000     3.82353     0.99179     0.45714     0.00545     0.04843
    180     0.02458     0.18562     0.99990     0.74415    10.00000     3.82353     0.99621     0.45462     0.00484     0.04843
    190     0.02336     0.18894     0.99994     0.74293    10.00000     3.52941     0.99621     0.44920     0.00424     0.04964
    200     0.02133     0.19251     0.99998     0.74649    10.00000     3.52941     0.99874     0.44541     0.00363     0.05206
    210     0.02027     0.19456     0.99999     0.74374    10.00000     3.52941     0.99937     0.43278     0.00182     0.05085
    220     0.01927     0.19726     0.99999     0.74553    10.00000     3.52941     0.99937     0.43278     0.00061     0.05206
    230     0.01802     0.20012     0.99999     0.74155    10.00000     3.52941     0.99937     0.44378     0.00061     0.05206
    240     0.01721     0.20294     0.99999     0.73899    10.00000     3.52941     0.99937     0.44756     0.00061     0.04964
    245     0.01662     0.20447     1.00000     0.73739    10.00000     3.52941     1.00000     0.45009     0.00061     0.05085
    250     0.01631     0.20618     1.00000     0.73386    10.00000     3.52941     1.00000     0.44378     0.00061     0.04964
    260     0.01508     0.20942     1.00000     0.73531    10.00000     3.52941     1.00000     0.43999     0.00061     0.04964
    270     0.01398     0.21316     1.00000     0.73464    10.00000     3.52941     1.00000     0.43769     0.00061     0.04964
    280     0.01325     0.21609     1.00000     0.73583    10.00000     3.52941     1.00000     0.42989     0.00061     0.05206
    290     0.01252     0.21808     1.00000     0.73676    10.00000     3.52941     1.00000     0.42610     0.00061     0.05206
    300     0.01201     0.22073     1.00000     0.73294    10.00000     3.52941     1.00000     0.41347     0.00061     0.05206
    310     0.01113     0.22457     1.00000     0.73141    10.00000     3.52941     1.00000     0.40300     0.00061     0.05327
    314     0.01085     0.22570     1.00000     0.73060    10.00000     3.52941     1.00000     0.41043     0.00000     0.05327
    320     0.01047     0.22745     1.00000     0.73368    10.00000     3.52941     1.00000     0.41674     0.00000     0.05327
    330     0.00994     0.23044     1.00000     0.73379    10.00000     3.52941     1.00000     0.43189     0.00000     0.05327
    340     0.00942     0.23261     1.00000     0.73364    10.00000     3.52941     1.00000     0.42558     0.00000     0.05327
    350     0.00899     0.23567     1.00000     0.73056    10.00000     3.23529     1.00000     0.41548     0.00000     0.05327
    360     0.00858     0.23782     1.00000     0.73052    10.00000     3.23529     1.00000     0.41674     0.00000     0.05206
    370     0.00821     0.23983     1.00000     0.72848    10.00000     3.23529     1.00000     0.41927     0.00000     0.05206
    380     0.00766     0.24245     1.00000     0.72963    10.00000     3.23529     1.00000     0.41258     0.00000     0.05206
    390     0.00731     0.24465     1.00000     0.72967    10.00000     3.23529     1.00000     0.42142     0.00000     0.05206
    400     0.00695     0.24771     1.00000     0.72618    10.00000     3.23529     1.00000     0.40122     0.00000     0.05206


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 PD         60.29843   60.30 |*******    |
 ENTAGE     59.87987   59.88 |*******    |
 FH         18.24515   18.25 |***        |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         4.00        64.00       0.9412


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         2.00        32.00       0.9412

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               0.000 sec ( 0.00 hrs,   0.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs, 100.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000278 hrs100.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 576 kb , 78% compression

 Grove file created containing:
      1 TreeNet

