
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14785      0.16003      0.04116      0.04116      1.00000 |                                               *
      2       0.13656      0.15692      0.04116      0.04116      1.00000 |                                              *
      3       0.12888      0.15469      0.04116      0.04116      1.00000 |                                             *
      4       0.12333      0.15412      0.04116      0.04116      1.00000 |                                             *
      5       0.11839      0.15378      0.04116      0.04116      1.00000 |                                             *
      6       0.11404      0.15308      0.04116      0.04116      1.00000 |                                             *
      7       0.11019      0.15362      0.03935      0.03995      1.00000 |                                             *
      8       0.10698      0.15340      0.03692      0.03995      1.00000 |                                             *
      9       0.10375      0.15414      0.03571      0.03874      1.00000 |                                             *
     10       0.10180      0.15415      0.03571      0.03874      1.00000 |                                             *
     11       0.09905      0.15483      0.03571      0.03874      1.00000 |                                             *
     12       0.09746      0.15524      0.03511      0.03874      1.00000 |                                              *
     13       0.09553      0.15498      0.03450      0.03874      1.00000 |                                             *
     14       0.09382      0.15550      0.03390      0.03995      1.00000 |                                              *
     15       0.09255      0.15592      0.03329      0.04116      1.00000 |                                              *
     16       0.09161      0.15678      0.03329      0.03995      1.00000 |                                              *
     17       0.09053      0.15667      0.03148      0.03995      1.00000 |                                              *
     18       0.08874      0.15787      0.03087      0.03995      1.00000 |                                              *
     19       0.08785      0.15815      0.02966      0.04116      1.00000 |                                              *
     20       0.08693      0.15822      0.03087      0.04358      1.00000 |                                              *
     30       0.08149      0.16012      0.02845      0.04116      1.00000 |                                               *
     40       0.07452      0.16170      0.02482      0.03995      1.00000 |                                               *
     50       0.06991      0.16419      0.02300      0.03995      1.00000 |                                               *
     60       0.06517      0.16924      0.02179      0.03874      1.00000 |                                               *
     70       0.06213      0.17167      0.02058      0.03995      1.00000 |                                               *
     80       0.05687      0.17482      0.01937      0.03995      1.00000 |                                               *
     90       0.05491      0.17601      0.01877      0.03995      1.00000 |                                               *
    100       0.05358      0.17795      0.01816      0.04116      1.00000 |                                               *
    110       0.05019      0.18093      0.01513      0.04116      1.00000 |                                               *
    120       0.04931      0.18261      0.01513      0.04237      1.00000 |                                               *
    130       0.04641      0.18703      0.01453      0.04358      1.00000 |                                               *
    140       0.04568      0.18767      0.01453      0.04358      1.00000 |                                               *
    150       0.04408      0.19084      0.01392      0.04600      1.00000 |                                               *
    160       0.04307      0.19112      0.01392      0.04600      1.00000 |                                               *
    170       0.04248      0.19307      0.01392      0.04600      1.00000 |                                               *
    180       0.04149      0.19447      0.01332      0.04600      1.00000 |                                               *
    190       0.04004      0.19592      0.01332      0.04600      1.00000 |                                               *
    200       0.03770      0.19760      0.01332      0.04479      1.00000 |                                               *
    210       0.03525      0.19963      0.01271      0.04600      1.00000 |                                               *
    220       0.03202      0.20322      0.01029      0.04600      1.00000 |                                               *
    230       0.03130      0.20443      0.00908      0.04600      1.00000 |                                               *
    240       0.03076      0.20581      0.00908      0.04722      1.00000 |                                               *
    250       0.03028      0.20713      0.00908      0.04722      1.00000 |                                               *
    260       0.02952      0.20859      0.00908      0.04722      1.00000 |                                               *
    270       0.02829      0.21097      0.00908      0.04722      1.00000 |                                               *
    280       0.02703      0.21250      0.00787      0.04722      1.00000 |                                               *
    290       0.02605      0.21478      0.00787      0.04722      1.00000 |                                               *
    300       0.02419      0.21787      0.00726      0.04722      1.00000 |                                               *
    310       0.02311      0.21955      0.00605      0.04722      1.00000 |                                               *
    320       0.02130      0.22317      0.00484      0.04843      1.00000 |                                               *
    330       0.02069      0.22467      0.00424      0.04843      1.00000 |                                               *
    340       0.01991      0.22677      0.00303      0.04843      1.00000 |                                               *
    350       0.01875      0.22886      0.00121      0.04843      1.00000 |                                               *
    360       0.01809      0.22949      0.00121      0.04843      1.00000 |                                               *
    370       0.01689      0.23287      0.00121      0.04722      1.00000 |                                               *
    380       0.01622      0.23445      0.00121      0.04722      1.00000 |                                               *
    390       0.01551      0.23573      0.00121      0.04722      1.00000 |                                               *
    400       0.01457      0.23853      0.00121      0.04843      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.12      6.88  FOLLOW
    330      1    400      1      7      4.24      3.10  ENTAGE
    118      1    400      2      7      4.91      0.91  PD
     63      1    397      1      7      4.67      0.53  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    47 terminal nodes
    Average :     14.63000 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 9 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 9 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 6

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 11304 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            6      0.15308
                  ROC            3      0.72131
                 Lift            8      4.41176
              KS-stat           48      0.44236
          Class.Error            9      0.03874

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14785     0.16003     0.93797     0.69496     7.04412     3.71008     0.74781     0.35643     0.04116     0.04116
      3     0.12888     0.15469     0.94841     0.72131     7.82353     3.32353     0.76953     0.43078     0.04116     0.04116
      6     0.11404     0.15308     0.95883     0.69541     8.38235     3.82353     0.81959     0.38495     0.04116     0.04116
      8     0.10698     0.15340     0.96224     0.69047     8.83333     4.41176     0.83159     0.36349     0.03692     0.03995
      9     0.10375     0.15414     0.96461     0.67809     8.97059     3.52941     0.84774     0.35354     0.03571     0.03874
     10     0.10180     0.15415     0.96477     0.66667     8.90196     3.82353     0.84964     0.34395     0.03571     0.03874
     20     0.08693     0.15822     0.96829     0.68570     9.11765     3.52941     0.84800     0.34581     0.03087     0.04358
     30     0.08149     0.16012     0.96955     0.68607     8.97059     3.82353     0.84187     0.39542     0.02845     0.04116
     40     0.07452     0.16170     0.97732     0.70338     9.26471     3.52941     0.88102     0.40842     0.02482     0.03995
     48     0.07018     0.16379     0.98318     0.70195     9.41176     3.82353     0.89257     0.44236     0.02361     0.03995
     50     0.06991     0.16419     0.98326     0.69805     9.41176     3.82353     0.89320     0.43731     0.02300     0.03995
     60     0.06517     0.16924     0.98693     0.69177     9.55882     3.52941     0.89906     0.35524     0.02179     0.03874
     70     0.06213     0.17167     0.98898     0.68444     9.55882     3.02941     0.91422     0.34715     0.02058     0.03995
     80     0.05687     0.17482     0.99213     0.68627     9.70588     2.94118     0.93839     0.33541     0.01937     0.03995
     90     0.05491     0.17601     0.99304     0.68577     9.85294     2.94118     0.93776     0.33326     0.01877     0.03995
    100     0.05358     0.17795     0.99337     0.67682     9.85294     2.94118     0.94092     0.29664     0.01816     0.04116
    110     0.05019     0.18093     0.99542     0.67560     9.85294     2.64706     0.95625     0.29805     0.01513     0.04116
    120     0.04931     0.18261     0.99556     0.66836     9.85294     2.64706     0.95689     0.29471     0.01513     0.04237
    130     0.04641     0.18703     0.99661     0.65970     9.85294     2.64706     0.96446     0.28840     0.01453     0.04358
    140     0.04568     0.18767     0.99679     0.65389     9.85294     2.52941     0.96509     0.29345     0.01453     0.04358
    150     0.04408     0.19084     0.99710     0.64838     9.85294     2.64706     0.96635     0.28714     0.01392     0.04600
    160     0.04307     0.19112     0.99752     0.64801     9.85294     2.64706     0.96699     0.27830     0.01392     0.04600
    170     0.04248     0.19307     0.99756     0.63876     9.85294     2.64706     0.96762     0.26567     0.01392     0.04600
    180     0.04149     0.19447     0.99782     0.63880     9.85294     2.64706     0.96762     0.27689     0.01332     0.04600
    187     0.04013     0.19528     0.99850     0.63891    10.00000     2.35294     0.96907     0.27941     0.01332     0.04600
    190     0.04004     0.19592     0.99848     0.63594    10.00000     2.35294     0.96907     0.28194     0.01332     0.04600
    200     0.03770     0.19760     0.99891     0.63876    10.00000     2.64706     0.97664     0.27399     0.01332     0.04479
    210     0.03525     0.19963     0.99938     0.63694    10.00000     2.64706     0.98737     0.30882     0.01271     0.04600
    220     0.03202     0.20322     0.99980     0.64136    10.00000     2.64706     0.99684     0.31135     0.01029     0.04600
    230     0.03130     0.20443     0.99981     0.63601    10.00000     2.64706     0.99684     0.31387     0.00908     0.04600
    240     0.03076     0.20581     0.99985     0.63453    10.00000     2.35294     0.99747     0.30882     0.00908     0.04722
    250     0.03028     0.20713     0.99987     0.63304    10.00000     2.35294     0.99874     0.28862     0.00908     0.04722
    254     0.03011     0.20780     0.99987     0.63178    10.00000     2.35294     0.99937     0.28320     0.00908     0.04722
    260     0.02952     0.20859     0.99988     0.63382    10.00000     2.35294     0.99937     0.28699     0.00908     0.04722
    270     0.02829     0.21097     0.99988     0.63350    10.00000     2.35294     0.99937     0.29456     0.00908     0.04722
    280     0.02703     0.21250     0.99988     0.63016    10.00000     2.35294     0.99937     0.30340     0.00787     0.04722
    290     0.02605     0.21478     0.99991     0.63122    10.00000     2.35294     0.99937     0.31098     0.00787     0.04722
    300     0.02419     0.21787     0.99994     0.63354    10.00000     2.35294     0.99937     0.29204     0.00726     0.04722
    310     0.02311     0.21955     0.99996     0.63451    10.00000     2.35294     0.99937     0.29999     0.00605     0.04722
    320     0.02130     0.22317     0.99998     0.63759    10.00000     2.35294     0.99937     0.30251     0.00484     0.04843
    330     0.02069     0.22467     0.99998     0.63651    10.00000     2.64706     0.99937     0.29999     0.00424     0.04843
    340     0.01991     0.22677     0.99999     0.63469    10.00000     2.64706     0.99937     0.29241     0.00303     0.04843
    347     0.01922     0.22811     0.99999     0.63681    10.00000     2.64706     0.99937     0.29241     0.00121     0.04843
    350     0.01875     0.22886     0.99999     0.63640    10.00000     2.64706     0.99937     0.29746     0.00121     0.04843
    360     0.01809     0.22949     0.99999     0.63718    10.00000     2.64706     0.99937     0.30630     0.00121     0.04843
    370     0.01689     0.23287     0.99999     0.64312    10.00000     2.64706     0.99937     0.30756     0.00121     0.04722
    380     0.01622     0.23445     0.99999     0.64416    10.00000     2.64706     0.99937     0.30125     0.00121     0.04722
    387     0.01567     0.23549     1.00000     0.64594    10.00000     2.64706     0.99937     0.30882     0.00121     0.04722
    390     0.01551     0.23573     1.00000     0.64531    10.00000     2.64706     0.99937     0.31261     0.00121     0.04722
    400     0.01457     0.23853     1.00000     0.64858    10.00000     2.64706     0.99937     0.30719     0.00121     0.04843


 ========================================
 Variable Importance for the 6-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     52.89619   52.90 |******     |
 PD         23.09190   23.09 |***        |
 FH         11.82695   11.83 |**         |


 Learn Sample Misclassification by Target Class
 For The 6-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         0.00        68.00       1.0000


 Test Sample Misclassification by Target Class
 For The 6-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 488 kb , 79% compression

 Grove file created containing:
      1 TreeNet

