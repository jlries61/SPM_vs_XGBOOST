
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14785      0.16003      0.04116      0.04116      1.00000 |                                               *
      2       0.13732      0.15701      0.04116      0.04116      1.00000 |                                              *
      3       0.12942      0.15517      0.04116      0.04116      1.00000 |                                              *
      4       0.12284      0.15345      0.04116      0.04116      1.00000 |                                             *
      5       0.11615      0.15350      0.04116      0.04116      1.00000 |                                             *
      6       0.11120      0.15260      0.04116      0.04116      1.00000 |                                             *
      7       0.10657      0.15234      0.04116      0.04116      1.00000 |                                             *
      8       0.10242      0.15273      0.04056      0.03995      1.00000 |                                             *
      9       0.09897      0.15398      0.03874      0.03995      1.00000 |                                             *
     10       0.09614      0.15309      0.03753      0.03995      1.00000 |                                             *
     11       0.09379      0.15355      0.03632      0.03874      1.00000 |                                             *
     12       0.09115      0.15384      0.03511      0.03874      1.00000 |                                             *
     13       0.08938      0.15368      0.03511      0.03874      1.00000 |                                             *
     14       0.08746      0.15418      0.03511      0.03995      1.00000 |                                             *
     15       0.08611      0.15473      0.03511      0.04358      1.00000 |                                             *
     16       0.08440      0.15551      0.03511      0.04358      1.00000 |                                              *
     17       0.08245      0.15589      0.03390      0.04479      1.00000 |                                              *
     18       0.08056      0.15683      0.03390      0.04358      1.00000 |                                              *
     19       0.07955      0.15689      0.03390      0.04479      1.00000 |                                              *
     20       0.07793      0.15799      0.03269      0.04479      1.00000 |                                              *
     30       0.06839      0.16202      0.02966      0.04358      1.00000 |                                               *
     40       0.06225      0.16382      0.02663      0.04358      1.00000 |                                               *
     50       0.05650      0.16732      0.02482      0.04479      1.00000 |                                               *
     60       0.05216      0.17065      0.01998      0.04600      1.00000 |                                               *
     70       0.04916      0.17561      0.01937      0.04600      1.00000 |                                               *
     80       0.04678      0.17995      0.01695      0.04600      1.00000 |                                               *
     90       0.04282      0.18476      0.01574      0.04600      1.00000 |                                               *
    100       0.03879      0.18868      0.01211      0.04600      1.00000 |                                               *
    110       0.03616      0.18989      0.01090      0.04600      1.00000 |                                               *
    120       0.03364      0.19278      0.00787      0.04722      1.00000 |                                               *
    130       0.03168      0.19640      0.00545      0.04843      1.00000 |                                               *
    140       0.02946      0.20028      0.00424      0.04843      1.00000 |                                               *
    150       0.02711      0.20328      0.00303      0.04843      1.00000 |                                               *
    160       0.02462      0.20829      0.00242      0.04843      1.00000 |                                               *
    170       0.02207      0.21355      0.00121      0.04964      1.00000 |                                               *
    180       0.02062      0.21677      0.00061      0.04964      1.00000 |                                               *
    190       0.01929      0.21917      0.00061      0.04964      1.00000 |                                               *
    200       0.01785      0.22283      0.00061      0.05085      1.00000 |                                               *
    210       0.01681      0.22722      0.00061      0.05085      1.00000 |                                               *
    220       0.01563      0.23147      0.00061      0.05085      1.00000 |                                               *
    230       0.01437      0.23442      0.00061      0.04964      1.00000 |                                               *
    240       0.01300      0.23999      0.00061      0.04843      1.00000 |                                               *
    250       0.01219      0.24227      0.00061      0.04843      1.00000 |                                               *
    260       0.01139      0.24507      0.00061      0.04722      1.00000 |                                               *
    270       0.01057      0.24836      0.00061      0.04722      1.00000 |                                               *
    280       0.00975      0.25179      0.00061      0.04964      1.00000 |                                               *
    290       0.00893      0.25517      0.00061      0.04843      1.00000 |                                               *
    300       0.00804      0.25931      0.00061      0.04843      1.00000 |                                               *
    310       0.00731      0.26349      0.00061      0.04843      1.00000 |                                               *
    320       0.00676      0.26632      0.00061      0.04843      1.00000 |                                               *
    330       0.00621      0.26932      0.00061      0.04964      1.00000 |                                               *
    340       0.00568      0.27269      0.00061      0.04843      1.00000 |                                               *
    350       0.00527      0.27717      0.00061      0.04843      1.00000 |                                               *
    360       0.00491      0.27986      0.00061      0.04843      1.00000 |                                               *
    370       0.00453      0.28332      0.00061      0.04964      1.00000 |                                               *
    380       0.00425      0.28683      0.00061      0.04964      1.00000 |                                               *
    390       0.00394      0.29114      0.00061      0.04964      1.00000 |                                               *
    400       0.00372      0.29462      0.00061      0.04964      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.61      6.39  FOLLOW
    391      1    400      1      7      2.17      5.70  ENTAGE
    307      1    399      2      7      4.12      2.98  PD
    113      1    399      1      7      4.39      1.02  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    54 terminal nodes
    Average :     23.66750 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 35 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 35 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 7

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 18534 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            7      0.15234
                  ROC           35      0.74198
                 Lift           31      4.70588
              KS-stat          275      0.44556
          Class.Error           11      0.03874

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14785     0.16003     0.93797     0.67250     7.04412     3.82353     0.74781     0.35643     0.04116     0.04116
      7     0.10657     0.15234     0.97198     0.73710     9.26471     3.82353     0.86208     0.43115     0.04116     0.04116
     10     0.09614     0.15309     0.97648     0.72265     9.41176     4.00000     0.89004     0.39795     0.03753     0.03995
     11     0.09379     0.15355     0.97692     0.73264     9.41176     4.17647     0.89149     0.38532     0.03632     0.03874
     20     0.07793     0.15799     0.98493     0.73563     9.52941     4.11765     0.90619     0.38518     0.03269     0.04479
     30     0.06839     0.16202     0.98977     0.72328     9.70588     4.41176     0.91919     0.39141     0.02966     0.04358
     31     0.06776     0.16282     0.98987     0.72005     9.70588     4.70588     0.92045     0.39141     0.02845     0.04237
     34     0.06561     0.16268     0.99155     0.73604    10.00000     4.58824     0.94318     0.39520     0.02906     0.04358
     35     0.06465     0.16243     0.99227     0.74198    10.00000     4.58824     0.94255     0.39394     0.02785     0.04358
     40     0.06225     0.16382     0.99305     0.73652    10.00000     4.11765     0.94634     0.39453     0.02663     0.04358
     50     0.05650     0.16732     0.99554     0.73513    10.00000     3.52941     0.97475     0.39765     0.02482     0.04479
     60     0.05216     0.17065     0.99640     0.74014    10.00000     4.11765     0.97790     0.40991     0.01998     0.04600
     70     0.04916     0.17561     0.99727     0.73173    10.00000     4.11765     0.97917     0.39401     0.01937     0.04600
     80     0.04678     0.17995     0.99758     0.72625    10.00000     3.82353     0.97980     0.40159     0.01695     0.04600
     90     0.04282     0.18476     0.99857     0.72319    10.00000     3.52941     0.98422     0.39364     0.01574     0.04600
    100     0.03879     0.18868     0.99916     0.72204    10.00000     3.52941     0.98737     0.39654     0.01211     0.04600
    110     0.03616     0.18989     0.99943     0.72499    10.00000     4.11765     0.99116     0.39706     0.01090     0.04600
    120     0.03364     0.19278     0.99970     0.72521    10.00000     3.82353     0.99495     0.40211     0.00787     0.04722
    130     0.03168     0.19640     0.99984     0.72419    10.00000     3.52941     0.99558     0.41637     0.00545     0.04843
    140     0.02946     0.20028     0.99990     0.71992    10.00000     3.23529     0.99747     0.42521     0.00424     0.04843
    150     0.02711     0.20328     0.99995     0.71379    10.00000     3.23529     0.99811     0.41763     0.00303     0.04843
    160     0.02462     0.20829     0.99996     0.70974    10.00000     3.23529     0.99874     0.42395     0.00242     0.04843
    169     0.02214     0.21301     1.00000     0.70830    10.00000     3.23529     0.99937     0.40894     0.00121     0.04964
    170     0.02207     0.21355     0.99999     0.70752    10.00000     3.23529     0.99874     0.40894     0.00121     0.04964
    171     0.02167     0.21389     1.00000     0.70740    10.00000     3.23529     0.99937     0.41652     0.00061     0.04964
    180     0.02062     0.21677     1.00000     0.70800    10.00000     3.23529     0.99937     0.42536     0.00061     0.04964
    190     0.01929     0.21917     1.00000     0.70856    10.00000     3.23529     0.99937     0.41689     0.00061     0.04964
    200     0.01785     0.22283     1.00000     0.70993    10.00000     3.23529     0.99937     0.42699     0.00061     0.05085
    210     0.01681     0.22722     1.00000     0.71171    10.00000     3.23529     0.99937     0.42699     0.00061     0.05085
    220     0.01563     0.23147     1.00000     0.70785    10.00000     3.23529     0.99937     0.42825     0.00061     0.05085
    230     0.01437     0.23442     1.00000     0.71104    10.00000     3.23529     0.99937     0.42952     0.00061     0.04964
    240     0.01300     0.23999     1.00000     0.70937    10.00000     3.23529     0.99937     0.43204     0.00061     0.04843
    250     0.01219     0.24227     1.00000     0.70856    10.00000     3.23529     0.99937     0.43078     0.00061     0.04843
    260     0.01139     0.24507     1.00000     0.71208    10.00000     3.23529     0.99937     0.43925     0.00061     0.04722
    270     0.01057     0.24836     1.00000     0.70859    10.00000     3.23529     0.99937     0.44051     0.00061     0.04722
    275     0.01015     0.25036     1.00000     0.70941    10.00000     3.23529     0.99937     0.44556     0.00061     0.04843
    280     0.00975     0.25179     1.00000     0.71090    10.00000     3.23529     0.99937     0.43419     0.00061     0.04964
    290     0.00893     0.25517     1.00000     0.70926    10.00000     3.23529     0.99937     0.43041     0.00061     0.04843
    300     0.00804     0.25931     1.00000     0.70763    10.00000     3.23529     0.99937     0.41904     0.00061     0.04843
    310     0.00731     0.26349     1.00000     0.70659    10.00000     3.41176     0.99937     0.40642     0.00061     0.04843
    320     0.00676     0.26632     1.00000     0.70559    10.00000     3.52941     0.99937     0.41020     0.00061     0.04843
    330     0.00621     0.26932     1.00000     0.71028    10.00000     3.52941     0.99937     0.41488     0.00061     0.04964
    340     0.00568     0.27269     1.00000     0.70880    10.00000     3.52941     0.99937     0.41904     0.00061     0.04843
    350     0.00527     0.27717     1.00000     0.70835    10.00000     3.52941     0.99937     0.41399     0.00061     0.04843
    360     0.00491     0.27986     1.00000     0.71051    10.00000     3.52941     0.99937     0.41526     0.00061     0.04843
    370     0.00453     0.28332     1.00000     0.71207    10.00000     3.52941     0.99937     0.40389     0.00061     0.04964
    380     0.00425     0.28683     1.00000     0.71069    10.00000     3.52941     0.99937     0.39721     0.00061     0.04964
    390     0.00394     0.29114     1.00000     0.70750    10.00000     3.52941     0.99937     0.39342     0.00061     0.04964
    400     0.00372     0.29462     1.00000     0.70668    10.00000     3.52941     0.99937     0.39216     0.00061     0.04964


 ========================================
 Variable Importance for the 7-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     55.02211   55.02 |******     |
 PD         27.53321   27.53 |****       |
 FH         13.52748   13.53 |**         |


 Learn Sample Misclassification by Target Class
 For The 7-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         0.00        68.00       1.0000


 Test Sample Misclassification by Target Class
 For The 7-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 815 kb , 77% compression

 Grove file created containing:
      1 TreeNet

