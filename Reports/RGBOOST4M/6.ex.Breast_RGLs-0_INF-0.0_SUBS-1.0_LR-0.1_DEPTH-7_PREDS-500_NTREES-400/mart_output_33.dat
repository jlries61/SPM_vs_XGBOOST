
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.15514      0.15723      0.04116      0.04116      1.00000 |                                               *
      2       0.14510      0.15327      0.04116      0.04116      1.00000 |                                              *
      3       0.13836      0.14965      0.04116      0.04116      1.00000 |                                             *
      4       0.13186      0.14780      0.04116      0.04116      1.00000 |                                            *
      5       0.12759      0.14604      0.04116      0.04116      1.00000 |                                            *
      6       0.12453      0.14394      0.04116      0.04116      1.00000 |                                           *
      7       0.12086      0.14317      0.04116      0.04116      1.00000 |                                           *
      8       0.11758      0.14223      0.04116      0.04116      1.00000 |                                          *
      9       0.11463      0.14180      0.03995      0.04116      1.00000 |                                          *
     10       0.11216      0.14138      0.03995      0.03874      1.00000 |                                          *
     11       0.10938      0.14177      0.03935      0.03995      1.00000 |                                          *
     12       0.10766      0.14106      0.03814      0.03995      1.00000 |                                          *
     13       0.10623      0.14084      0.03874      0.03995      1.00000 |                                          *
     14       0.10484      0.14092      0.03814      0.03995      1.00000 |                                          *
     15       0.10357      0.14106      0.03571      0.03874      1.00000 |                                          *
     16       0.10226      0.14097      0.03632      0.03874      1.00000 |                                          *
     17       0.10094      0.14091      0.03632      0.03874      1.00000 |                                          *
     18       0.09982      0.14101      0.03632      0.03874      1.00000 |                                          *
     19       0.09874      0.14087      0.03571      0.03874      1.00000 |                                          *
     20       0.09772      0.14076      0.03450      0.03874      1.00000 |                                          *
     30       0.08814      0.14191      0.03027      0.03874      1.00000 |                                          *
     40       0.08218      0.14303      0.02845      0.03632      1.00000 |                                           *
     50       0.07630      0.14503      0.02663      0.03632      1.00000 |                                           *
     60       0.06827      0.14659      0.02482      0.03511      1.00000 |                                            *
     70       0.06249      0.14786      0.02240      0.03632      1.00000 |                                            *
     80       0.05776      0.14927      0.02058      0.03632      1.00000 |                                             *
     90       0.05551      0.15072      0.01877      0.03632      1.00000 |                                             *
    100       0.05232      0.15296      0.01877      0.03632      1.00000 |                                              *
    110       0.04880      0.15452      0.01816      0.03632      1.00000 |                                              *
    120       0.04415      0.15703      0.01634      0.03632      1.00000 |                                               *
    130       0.04005      0.15857      0.01392      0.03632      1.00000 |                                               *
    140       0.03484      0.16206      0.00969      0.03753      1.00000 |                                               *
    150       0.03281      0.16508      0.00787      0.03753      1.00000 |                                               *
    160       0.03127      0.16709      0.00666      0.03874      1.00000 |                                               *
    170       0.02886      0.17036      0.00424      0.03874      1.00000 |                                               *
    180       0.02556      0.17444      0.00303      0.03874      1.00000 |                                               *
    190       0.02466      0.17548      0.00303      0.03753      1.00000 |                                               *
    200       0.02310      0.17695      0.00182      0.03874      1.00000 |                                               *
    210       0.02172      0.17946      0.00121      0.03874      1.00000 |                                               *
    220       0.01964      0.18249      0.00061      0.03874      1.00000 |                                               *
    230       0.01877      0.18352      0.00061      0.03874      1.00000 |                                               *
    240       0.01742      0.18586      0.00061      0.03995      1.00000 |                                               *
    250       0.01597      0.18779      0.00061      0.03995      1.00000 |                                               *
    260       0.01540      0.18960      0.00061      0.03874      1.00000 |                                               *
    270       0.01487      0.19122      0.00061      0.03874      1.00000 |                                               *
    280       0.01440      0.19333      0.00061      0.03874      1.00000 |                                               *
    290       0.01328      0.19665      0.00061      0.03995      1.00000 |                                               *
    300       0.01291      0.19870      0.00061      0.03995      1.00000 |                                               *
    310       0.01168      0.20151      0.00061      0.04116      1.00000 |                                               *
    320       0.01094      0.20384      0.00061      0.03995      1.00000 |                                               *
    330       0.01025      0.20686      0.00061      0.03995      1.00000 |                                               *
    340       0.00981      0.20858      0.00061      0.03995      1.00000 |                                               *
    350       0.00914      0.21135      0.00061      0.03995      1.00000 |                                               *
    360       0.00863      0.21391      0.00061      0.03995      1.00000 |                                               *
    370       0.00818      0.21683      0.00061      0.03995      1.00000 |                                               *
    380       0.00766      0.21925      0.00061      0.03995      1.00000 |                                               *
    390       0.00730      0.22097      0.00061      0.03995      1.00000 |                                               *
    400       0.00698      0.22259      0.00061      0.04116      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.56      6.44  FOLLOW
    394      1    400      1      7      2.25      5.67  ENTAGE
    227      1    398      1      7      4.28      2.11  PD
     57      1    399      2      7      4.33      0.52  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    52 terminal nodes
    Average :     20.48750 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 45 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 45 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 21

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 15990 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           21      0.14069
                  ROC           14      0.77646
                 Lift            6      5.58824
              KS-stat           12      0.48812
          Class.Error           45      0.03511

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.15514     0.15723     0.90244     0.76400     5.85370     5.08824     0.63659     0.47660     0.04116     0.04116
      6     0.12453     0.14394     0.94147     0.75557     7.35294     5.58824     0.75765     0.47928     0.04116     0.04116
     10     0.11216     0.14138     0.94829     0.77293     7.52941     5.17647     0.77395     0.47296     0.03995     0.03874
     12     0.10766     0.14106     0.95280     0.77529     7.64706     5.58824     0.78027     0.48812     0.03814     0.03995
     14     0.10484     0.14092     0.95585     0.77646     7.67647     5.29412     0.77711     0.46539     0.03814     0.03995
     20     0.09772     0.14076     0.96040     0.77509     7.79412     5.08824     0.78929     0.46346     0.03450     0.03874
     21     0.09680     0.14069     0.96025     0.77083     7.79412     5.29412     0.78740     0.46309     0.03450     0.04116
     30     0.08814     0.14191     0.96869     0.76688     8.38235     5.17647     0.80596     0.44734     0.03027     0.03874
     40     0.08218     0.14303     0.97354     0.75823     8.67647     5.00000     0.82635     0.44682     0.02845     0.03632
     45     0.07983     0.14451     0.97556     0.75085     9.00000     5.00000     0.84611     0.46294     0.02724     0.03511
     50     0.07630     0.14503     0.98180     0.74950     9.14706     4.88235     0.87652     0.44236     0.02663     0.03632
     58     0.06933     0.14637     0.99006     0.74608    10.00000     4.70588     0.94571     0.43442     0.02482     0.03511
     60     0.06827     0.14659     0.99029     0.74378    10.00000     4.70588     0.94760     0.44363     0.02482     0.03511
     70     0.06249     0.14786     0.99312     0.74371    10.00000     4.70588     0.95455     0.45588     0.02240     0.03632
     80     0.05776     0.14927     0.99534     0.73899    10.00000     4.70588     0.95455     0.42848     0.02058     0.03632
     90     0.05551     0.15072     0.99566     0.73548    10.00000     4.70588     0.95455     0.41927     0.01877     0.03632
    100     0.05232     0.15296     0.99716     0.73418    10.00000     4.41176     0.96717     0.40627     0.01877     0.03632
    110     0.04880     0.15452     0.99802     0.72675    10.00000     4.11765     0.97348     0.38948     0.01816     0.03632
    120     0.04415     0.15703     0.99903     0.72152    10.00000     4.11765     0.98169     0.39060     0.01634     0.03632
    130     0.04005     0.15857     0.99962     0.72478    10.00000     4.11765     0.99179     0.40865     0.01392     0.03632
    140     0.03484     0.16206     0.99994     0.72219    10.00000     4.11765     0.99621     0.39944     0.00969     0.03753
    150     0.03281     0.16508     0.99996     0.71338    10.00000     4.11765     0.99747     0.37389     0.00787     0.03753
    160     0.03127     0.16709     0.99995     0.71049    10.00000     4.11765     0.99811     0.37641     0.00666     0.03874
    170     0.02886     0.17036     0.99998     0.70451    10.00000     4.11765     0.99937     0.37136     0.00424     0.03874
    173     0.02713     0.17281     1.00000     0.69730    10.00000     4.11765     0.99937     0.37010     0.00363     0.03874
    180     0.02556     0.17444     0.99999     0.69701    10.00000     4.11765     0.99937     0.37760     0.00303     0.03874
    190     0.02466     0.17548     0.99999     0.69998    10.00000     4.11765     0.99937     0.36884     0.00303     0.03753
    200     0.02310     0.17695     1.00000     0.69987    10.00000     4.11765     0.99937     0.37136     0.00182     0.03874
    210     0.02172     0.17946     1.00000     0.69920    10.00000     4.11765     0.99937     0.36884     0.00121     0.03874
    219     0.01990     0.18183     1.00000     0.70087    10.00000     4.11765     0.99937     0.36884     0.00061     0.03874
    220     0.01964     0.18249     1.00000     0.69920    10.00000     4.11765     0.99937     0.37010     0.00061     0.03874
    230     0.01877     0.18352     1.00000     0.69730    10.00000     4.11765     0.99937     0.37136     0.00061     0.03874
    240     0.01742     0.18586     1.00000     0.69734    10.00000     4.11765     0.99937     0.37292     0.00061     0.03995
    250     0.01597     0.18779     1.00000     0.70013    10.00000     4.11765     0.99937     0.36965     0.00061     0.03995
    260     0.01540     0.18960     1.00000     0.69894    10.00000     4.11765     0.99937     0.36408     0.00061     0.03874
    270     0.01487     0.19122     1.00000     0.69790    10.00000     4.11765     0.99937     0.36534     0.00061     0.03874
    280     0.01440     0.19333     1.00000     0.69448    10.00000     4.11765     0.99937     0.36787     0.00061     0.03874
    290     0.01328     0.19665     1.00000     0.69107    10.00000     4.11765     0.99937     0.35495     0.00061     0.03995
    300     0.01291     0.19870     1.00000     0.68679    10.00000     4.11765     0.99937     0.35368     0.00061     0.03995
    310     0.01168     0.20151     1.00000     0.68620    10.00000     4.11765     0.99937     0.35747     0.00061     0.04116
    320     0.01094     0.20384     1.00000     0.68568    10.00000     4.11765     0.99937     0.35495     0.00061     0.03995
    330     0.01025     0.20686     1.00000     0.68575    10.00000     4.11765     0.99937     0.34990     0.00061     0.03995
    340     0.00981     0.20858     1.00000     0.68598    10.00000     4.11765     0.99937     0.34990     0.00061     0.03995
    350     0.00914     0.21135     1.00000     0.68386    10.00000     4.11765     0.99937     0.34485     0.00061     0.03995
    360     0.00863     0.21391     1.00000     0.68564    10.00000     4.11765     0.99937     0.34358     0.00061     0.03995
    370     0.00818     0.21683     1.00000     0.68238    10.00000     4.11765     0.99937     0.32717     0.00061     0.03995
    380     0.00766     0.21925     1.00000     0.68089    10.00000     4.11765     0.99937     0.33155     0.00061     0.03995
    390     0.00730     0.22097     1.00000     0.67922    10.00000     4.00000     0.99937     0.32962     0.00061     0.03995
    400     0.00698     0.22259     1.00000     0.68056    10.00000     4.11765     0.99937     0.33044     0.00061     0.04116


 =========================================
 Variable Importance for the 21-tree Model
 =========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     56.02120   56.02 |*******    |
 PD         39.18783   39.19 |*****      |
 FH          7.80412    7.80 |**         |


 Learn Sample Misclassification by Target Class
 For The 21-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1583.00         1.00       0.0006
 1                   68.00        12.00        56.00       0.8235


 Test Sample Misclassification by Target Class
 For The 21-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       788.00         4.00       0.0051
 1                   34.00         4.00        30.00       0.8824

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 711 kb , 77% compression

 Grove file created containing:
      1 TreeNet

