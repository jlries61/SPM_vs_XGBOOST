
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14341      0.16561      0.04116      0.04116      1.00000 |                                               *
      2       0.13352      0.16316      0.04116      0.04116      1.00000 |                                              *
      3       0.12586      0.16204      0.04116      0.04116      1.00000 |                                              *
      4       0.11936      0.16005      0.04116      0.04116      1.00000 |                                             *
      5       0.11409      0.15915      0.04116      0.04116      1.00000 |                                             *
      6       0.10965      0.15942      0.04116      0.04116      1.00000 |                                             *
      7       0.10559      0.15823      0.03632      0.04237      1.00000 |                                             *
      8       0.10156      0.15710      0.03632      0.04237      1.00000 |                                             *
      9       0.09869      0.15802      0.03329      0.04116      1.00000 |                                             *
     10       0.09680      0.15749      0.03208      0.04116      1.00000 |                                             *
     11       0.09378      0.15770      0.03208      0.04116      1.00000 |                                             *
     12       0.09148      0.15757      0.03208      0.04237      1.00000 |                                             *
     13       0.08946      0.15758      0.03208      0.04237      1.00000 |                                             *
     14       0.08794      0.15750      0.03269      0.04237      1.00000 |                                             *
     15       0.08686      0.15752      0.02966      0.04237      1.00000 |                                             *
     16       0.08583      0.15793      0.02906      0.04237      1.00000 |                                             *
     17       0.08476      0.15791      0.02906      0.04237      1.00000 |                                             *
     18       0.08331      0.15848      0.02906      0.04237      1.00000 |                                             *
     19       0.08254      0.15851      0.02785      0.04237      1.00000 |                                             *
     20       0.08039      0.15887      0.02785      0.04237      1.00000 |                                             *
     30       0.07392      0.16368      0.02421      0.04358      1.00000 |                                              *
     40       0.07177      0.16521      0.02119      0.04237      1.00000 |                                               *
     50       0.06966      0.16701      0.02058      0.04237      1.00000 |                                               *
     60       0.06780      0.16993      0.01998      0.04237      1.00000 |                                               *
     70       0.06472      0.17216      0.01816      0.04358      1.00000 |                                               *
     80       0.06281      0.17443      0.01816      0.04479      1.00000 |                                               *
     90       0.06061      0.17563      0.01816      0.04479      1.00000 |                                               *
    100       0.05773      0.17858      0.01816      0.04479      1.00000 |                                               *
    110       0.05586      0.18039      0.01816      0.04479      1.00000 |                                               *
    120       0.05267      0.18232      0.01816      0.04479      1.00000 |                                               *
    130       0.05059      0.18422      0.01755      0.04600      1.00000 |                                               *
    140       0.04917      0.18606      0.01695      0.04722      1.00000 |                                               *
    150       0.04455      0.18703      0.01574      0.04722      1.00000 |                                               *
    160       0.04272      0.18801      0.01513      0.04722      1.00000 |                                               *
    170       0.04101      0.18918      0.01392      0.04843      1.00000 |                                               *
    180       0.03807      0.19031      0.01271      0.04843      1.00000 |                                               *
    190       0.03525      0.19222      0.01211      0.04722      1.00000 |                                               *
    200       0.03336      0.19287      0.01150      0.04843      1.00000 |                                               *
    210       0.03156      0.19498      0.00969      0.04722      1.00000 |                                               *
    220       0.03060      0.19636      0.00969      0.04722      1.00000 |                                               *
    230       0.02865      0.19848      0.00847      0.04722      1.00000 |                                               *
    240       0.02657      0.20297      0.00726      0.04843      1.00000 |                                               *
    250       0.02514      0.20493      0.00666      0.04843      1.00000 |                                               *
    260       0.02412      0.20706      0.00605      0.04843      1.00000 |                                               *
    270       0.02268      0.20813      0.00424      0.04843      1.00000 |                                               *
    280       0.02127      0.20974      0.00303      0.04843      1.00000 |                                               *
    290       0.02072      0.21063      0.00242      0.04843      1.00000 |                                               *
    300       0.02019      0.21158      0.00242      0.04843      1.00000 |                                               *
    310       0.01899      0.21384      0.00242      0.04843      1.00000 |                                               *
    320       0.01862      0.21611      0.00242      0.04843      1.00000 |                                               *
    330       0.01811      0.21776      0.00242      0.04843      1.00000 |                                               *
    340       0.01758      0.21877      0.00182      0.04843      1.00000 |                                               *
    350       0.01681      0.22026      0.00121      0.04964      1.00000 |                                               *
    360       0.01608      0.22151      0.00121      0.04964      1.00000 |                                               *
    370       0.01532      0.22393      0.00121      0.04964      1.00000 |                                               *
    380       0.01498      0.22522      0.00121      0.04964      1.00000 |                                               *
    390       0.01460      0.22754      0.00121      0.04964      1.00000 |                                               *
    400       0.01393      0.22878      0.00121      0.04964      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      2      1.06      6.94  FOLLOW
    331      1    400      1      7      4.20      3.14  ENTAGE
    132      1    400      2      7      5.18      0.93  PD
     57      2    397      3      7      5.33      0.38  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    38 terminal nodes
    Average :     14.26500 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 22 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 22 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 11012 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.15710
                  ROC           22      0.71301
                 Lift           10      4.11765
              KS-stat           53      0.41295
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14341     0.16561     0.92747     0.61505     7.20856     3.52941     0.68951     0.32501     0.04116     0.04116
      8     0.10156     0.15710     0.97307     0.69586     8.52941     3.82353     0.83682     0.36312     0.03632     0.04237
     10     0.09680     0.15749     0.97295     0.69543     8.52941     4.11765     0.84161     0.35502     0.03208     0.04116
     20     0.08039     0.15887     0.97931     0.71084     8.97059     3.52941     0.88915     0.38206     0.02785     0.04237
     22     0.07830     0.16053     0.97967     0.71301     9.11765     3.70588     0.88220     0.35703     0.02603     0.04237
     30     0.07392     0.16368     0.98133     0.70592     9.41176     3.52941     0.89925     0.40411     0.02421     0.04358
     40     0.07177     0.16521     0.98143     0.69886     9.26471     3.52941     0.89609     0.40411     0.02119     0.04237
     50     0.06966     0.16701     0.98232     0.69569     9.41176     3.52941     0.89925     0.38012     0.02058     0.04237
     53     0.06902     0.16805     0.98265     0.69656     9.41176     3.52941     0.89925     0.41295     0.02058     0.04237
     60     0.06780     0.16993     0.98318     0.68837     9.55882     3.52941     0.90367     0.38012     0.01998     0.04237
     70     0.06472     0.17216     0.98464     0.67725     9.55882     3.52941     0.90367     0.32598     0.01816     0.04358
     80     0.06281     0.17443     0.98610     0.65785     9.55882     3.52941     0.90051     0.29152     0.01816     0.04479
     90     0.06061     0.17563     0.98751     0.66399     9.55882     3.52941     0.90917     0.28179     0.01816     0.04479
    100     0.05773     0.17858     0.99012     0.65306     9.70588     3.23529     0.91440     0.27600     0.01816     0.04479
    110     0.05586     0.18039     0.99087     0.64862     9.70588     3.23529     0.91503     0.26374     0.01816     0.04479
    120     0.05267     0.18232     0.99268     0.65506     9.85294     3.23529     0.92469     0.28773     0.01816     0.04479
    127     0.05100     0.18348     0.99434     0.65287    10.00000     3.23529     0.94255     0.27169     0.01755     0.04479
    130     0.05059     0.18422     0.99460     0.65035    10.00000     3.23529     0.94192     0.27042     0.01755     0.04600
    140     0.04917     0.18606     0.99528     0.64299    10.00000     3.23529     0.95057     0.27726     0.01695     0.04722
    150     0.04455     0.18703     0.99754     0.66056    10.00000     3.11765     0.97285     0.28268     0.01574     0.04722
    160     0.04272     0.18801     0.99803     0.66572    10.00000     2.94118     0.97980     0.29909     0.01513     0.04722
    170     0.04101     0.18918     0.99842     0.66769    10.00000     2.64706     0.98548     0.30288     0.01392     0.04843
    180     0.03807     0.19031     0.99903     0.67330    10.00000     2.94118     0.98990     0.32813     0.01271     0.04843
    190     0.03525     0.19222     0.99950     0.67842    10.00000     2.94118     0.99495     0.31425     0.01211     0.04722
    200     0.03336     0.19287     0.99965     0.68808    10.00000     2.94118     0.99558     0.31395     0.01150     0.04843
    210     0.03156     0.19498     0.99967     0.68403    10.00000     2.64706     0.99558     0.29026     0.00969     0.04722
    220     0.03060     0.19636     0.99974     0.68057    10.00000     2.64706     0.99558     0.30511     0.00969     0.04722
    230     0.02865     0.19848     0.99982     0.68447    10.00000     2.64706     0.99684     0.29701     0.00847     0.04722
    240     0.02657     0.20297     0.99991     0.67343    10.00000     2.94118     0.99747     0.26448     0.00726     0.04843
    250     0.02514     0.20493     0.99993     0.67324    10.00000     3.23529     0.99747     0.28469     0.00666     0.04843
    260     0.02412     0.20706     0.99994     0.66878    10.00000     2.82353     0.99747     0.28342     0.00605     0.04843
    270     0.02268     0.20813     0.99996     0.67643    10.00000     3.23529     0.99874     0.27800     0.00424     0.04843
    280     0.02127     0.20974     0.99997     0.68657    10.00000     3.23529     0.99874     0.32947     0.00303     0.04843
    290     0.02072     0.21063     0.99997     0.68865    10.00000     2.94118     0.99874     0.31432     0.00242     0.04843
    300     0.02019     0.21158     0.99997     0.68843    10.00000     2.94118     0.99874     0.30422     0.00242     0.04843
    307     0.01919     0.21343     0.99999     0.69040    10.00000     2.94118     0.99937     0.30741     0.00242     0.04843
    310     0.01899     0.21384     0.99998     0.68939    10.00000     2.94118     0.99874     0.30578     0.00242     0.04843
    320     0.01862     0.21611     0.99998     0.68219    10.00000     2.94118     0.99874     0.30830     0.00242     0.04843
    330     0.01811     0.21776     0.99999     0.67974    10.00000     2.94118     0.99937     0.31083     0.00242     0.04843
    340     0.01758     0.21877     0.99999     0.68115    10.00000     2.94118     0.99937     0.31462     0.00182     0.04843
    343     0.01725     0.21955     0.99999     0.68275    10.00000     2.94118     0.99937     0.31840     0.00121     0.04964
    350     0.01681     0.22026     0.99999     0.68672    10.00000     2.94118     0.99937     0.32472     0.00121     0.04964
    360     0.01608     0.22151     0.99999     0.68787    10.00000     2.94118     0.99937     0.31083     0.00121     0.04964
    370     0.01532     0.22393     0.99999     0.68750    10.00000     2.94118     0.99937     0.31714     0.00121     0.04964
    380     0.01498     0.22522     0.99999     0.68538    10.00000     2.94118     0.99937     0.30957     0.00121     0.04964
    390     0.01460     0.22754     0.99999     0.68204    10.00000     2.64706     0.99937     0.31967     0.00121     0.04964
    400     0.01393     0.22878     0.99999     0.68549    10.00000     2.82353     0.99937     0.32346     0.00121     0.04964


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     64.58217   64.58 |*******    |
 PD         54.59615   54.60 |******     |
 FH          6.37120    6.37 |**         |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1583.00         1.00       0.0006
 1                   68.00         9.00        59.00       0.8676


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       791.00         1.00       0.0013
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 468 kb , 79% compression

 Grove file created containing:
      1 TreeNet

