
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.13482      0.16338      0.04116      0.04116      1.00000 |                                               *
      2       0.12292      0.15945      0.04116      0.04116      1.00000 |                                              *
      3       0.11480      0.15925      0.04116      0.04116      1.00000 |                                              *
      4       0.10764      0.15913      0.03935      0.04237      1.00000 |                                              *
      5       0.10170      0.15963      0.03753      0.04358      1.00000 |                                              *
      6       0.09631      0.15990      0.03753      0.04358      1.00000 |                                              *
      7       0.09178      0.16044      0.03753      0.04237      1.00000 |                                              *
      8       0.08870      0.16077      0.03632      0.04116      1.00000 |                                              *
      9       0.08592      0.16162      0.03390      0.04358      1.00000 |                                              *
     10       0.08311      0.16160      0.03027      0.04237      1.00000 |                                              *
     11       0.08097      0.16263      0.02845      0.04479      1.00000 |                                               *
     12       0.07910      0.16302      0.02724      0.04479      1.00000 |                                               *
     13       0.07754      0.16299      0.02785      0.04600      1.00000 |                                               *
     14       0.07541      0.16449      0.02724      0.04600      1.00000 |                                               *
     15       0.07315      0.16485      0.02724      0.04600      1.00000 |                                               *
     16       0.07175      0.16466      0.02724      0.04600      1.00000 |                                               *
     17       0.06998      0.16516      0.02603      0.04600      1.00000 |                                               *
     18       0.06808      0.16606      0.02482      0.04600      1.00000 |                                               *
     19       0.06697      0.16590      0.02361      0.04600      1.00000 |                                               *
     20       0.06604      0.16681      0.02361      0.04964      1.00000 |                                               *
     30       0.05421      0.17048      0.01998      0.05327      1.00000 |                                               *
     40       0.04448      0.17253      0.01513      0.05085      1.00000 |                                               *
     50       0.03681      0.17497      0.01211      0.05206      1.00000 |                                               *
     60       0.03228      0.17771      0.00847      0.05085      1.00000 |                                               *
     70       0.02843      0.18299      0.00605      0.04964      1.00000 |                                               *
     80       0.02336      0.19008      0.00242      0.05206      1.00000 |                                               *
     90       0.02116      0.19450      0.00182      0.05327      1.00000 |                                               *
    100       0.01931      0.19720      0.00182      0.05206      1.00000 |                                               *
    110       0.01686      0.20197      0.00061      0.05085      1.00000 |                                               *
    120       0.01474      0.20674      0.00061      0.05085      1.00000 |                                               *
    130       0.01285      0.21355      0.00061      0.04843      1.00000 |                                               *
    140       0.01104      0.22135      0.00061      0.04964      1.00000 |                                               *
    150       0.00931      0.22892      0.00061      0.04964      1.00000 |                                               *
    160       0.00825      0.23516      0.00061      0.05085      1.00000 |                                               *
    170       0.00713      0.24530      0.00061      0.05206      1.00000 |                                               *
    180       0.00630      0.25307      0.00061      0.05206      1.00000 |                                               *
    190       0.00567      0.25989      0.00061      0.05206      1.00000 |                                               *
    200       0.00488      0.26495      0.00061      0.05206      1.00000 |                                               *
    210       0.00424      0.27380      0.00061      0.05327      1.00000 |                                               *
    220       0.00386      0.28093      0.00061      0.05327      1.00000 |                                               *
    230       0.00341      0.28762      0.00061      0.05327      1.00000 |                                               *
    240       0.00312      0.29303      0.00061      0.05448      1.00000 |                                               *
    250       0.00282      0.29979      0.00061      0.05206      1.00000 |                                               *
    260       0.00263      0.30385      0.00061      0.05206      1.00000 |                                               *
    270       0.00239      0.30801      0.00061      0.05327      1.00000 |                                               *
    280       0.00212      0.31662      0.00061      0.05085      1.00000 |                                               *
    290       0.00194      0.32412      0.00061      0.05085      1.00000 |                                               *
    300       0.00176      0.33356      0.00061      0.04964      1.00000 |                                               *
    310       0.00166      0.33883      0.00061      0.04964      1.00000 |                                               *
    320       0.00155      0.34625      0.00061      0.05085      1.00000 |                                               *
    330       0.00146      0.35104      0.00061      0.05085      1.00000 |                                               *
    340       0.00137      0.36159      0.00061      0.05085      1.00000 |                                               *
    350       0.00127      0.37210      0.00061      0.05085      1.00000 |                                               *
    360       0.00121      0.38103      0.00061      0.05085      1.00000 |                                               *
    370       0.00116      0.38974      0.00061      0.05327      1.00000 |                                               *
    380       0.00111      0.39785      0.00061      0.05448      1.00000 |                                               *
    390       0.00108      0.40528      0.00061      0.05206      1.00000 |                                               *
    400       0.00105      0.41254      0.00061      0.05327      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.77      6.24  FOLLOW
    400      1    400      1      5      2.15      5.85  ENTAGE
    381      1    400      1      7      3.64      4.16  PD
    288      1    400      1      7      4.08      2.83  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    12 terminal nodes
    Largest :    69 terminal nodes
    Average :     42.65000 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 105 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 105 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 4

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 33720 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            4      0.15913
                  ROC          105      0.77341
                 Lift           58      4.11765
              KS-stat          129      0.56395
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.13482     0.16338     0.94931     0.60346     8.06224     3.27412     0.74391     0.33155     0.04116     0.04116
      4     0.10764     0.15913     0.95976     0.74580     8.69118     3.23529     0.82004     0.45083     0.03935     0.04237
     10     0.08311     0.16160     0.98394     0.72330     9.41176     3.23529     0.88499     0.36356     0.03027     0.04237
     20     0.06604     0.16681     0.98698     0.73516     9.41176     3.23529     0.88815     0.41652     0.02361     0.04964
     30     0.05421     0.17048     0.99557     0.74870     9.85294     3.52941     0.94931     0.43241     0.01998     0.05327
     35     0.04977     0.17137     0.99708     0.75165    10.00000     3.52941     0.96275     0.44756     0.01695     0.04964
     40     0.04448     0.17253     0.99850     0.75949    10.00000     3.52941     0.98422     0.47193     0.01513     0.05085
     50     0.03681     0.17497     0.99953     0.76625    10.00000     3.82353     0.99179     0.50349     0.01211     0.05206
     58     0.03334     0.17683     0.99973     0.76940    10.00000     4.11765     0.99621     0.52317     0.00908     0.05206
     60     0.03228     0.17771     0.99977     0.76818    10.00000     4.11765     0.99811     0.52481     0.00847     0.05085
     70     0.02843     0.18299     0.99987     0.76903    10.00000     3.52941     0.99874     0.52986     0.00605     0.04964
     74     0.02640     0.18671     0.99990     0.76498    10.00000     3.52941     0.99937     0.51939     0.00545     0.05085
     80     0.02336     0.19008     0.99996     0.76680    10.00000     3.52941     0.99937     0.54122     0.00242     0.05206
     90     0.02116     0.19450     0.99995     0.76740    10.00000     3.23529     0.99937     0.54627     0.00182     0.05327
    100     0.01931     0.19720     0.99996     0.77308    10.00000     3.23529     0.99937     0.54627     0.00182     0.05206
    105     0.01838     0.19877     0.99996     0.77341    10.00000     3.23529     0.99937     0.55006     0.00182     0.05085
    107     0.01747     0.20070     0.99997     0.77197    10.00000     3.23529     0.99937     0.55890     0.00061     0.05206
    110     0.01686     0.20197     0.99999     0.76955    10.00000     3.23529     0.99937     0.56142     0.00061     0.05085
    111     0.01669     0.20206     1.00000     0.76992    10.00000     3.23529     0.99937     0.56016     0.00061     0.05085
    120     0.01474     0.20674     1.00000     0.77107    10.00000     3.23529     0.99937     0.55511     0.00061     0.05085
    129     0.01299     0.21313     1.00000     0.76866    10.00000     3.23529     0.99937     0.56395     0.00061     0.05085
    130     0.01285     0.21355     1.00000     0.76907    10.00000     3.23529     0.99937     0.56395     0.00061     0.04843
    140     0.01104     0.22135     1.00000     0.76647    10.00000     3.23529     0.99937     0.54753     0.00061     0.04964
    150     0.00931     0.22892     1.00000     0.76250    10.00000     3.11765     0.99937     0.53365     0.00061     0.04964
    160     0.00825     0.23516     1.00000     0.76101    10.00000     3.52941     0.99937     0.51181     0.00061     0.05085
    170     0.00713     0.24530     1.00000     0.75319    10.00000     2.94118     0.99937     0.48277     0.00061     0.05206
    180     0.00630     0.25307     1.00000     0.75379    10.00000     3.23529     0.99937     0.49324     0.00061     0.05206
    190     0.00567     0.25989     1.00000     0.75227    10.00000     3.23529     0.99937     0.48656     0.00061     0.05206
    200     0.00488     0.26495     1.00000     0.75594    10.00000     3.23529     0.99937     0.50045     0.00061     0.05206
    210     0.00424     0.27380     1.00000     0.75267    10.00000     2.94118     0.99937     0.48908     0.00061     0.05327
    220     0.00386     0.28093     1.00000     0.75143    10.00000     2.94118     0.99937     0.47772     0.00061     0.05327
    230     0.00341     0.28762     1.00000     0.75299    10.00000     2.94118     0.99937     0.47519     0.00061     0.05327
    240     0.00312     0.29303     1.00000     0.75392    10.00000     2.94118     0.99937     0.47987     0.00061     0.05448
    250     0.00282     0.29979     1.00000     0.75566    10.00000     2.94118     0.99937     0.47772     0.00061     0.05206
    260     0.00263     0.30385     1.00000     0.75644    10.00000     3.11765     0.99937     0.49413     0.00061     0.05206
    270     0.00239     0.30801     1.00000     0.75860    10.00000     3.52941     0.99937     0.51686     0.00061     0.05327
    280     0.00212     0.31662     1.00000     0.75732    10.00000     3.23529     0.99937     0.51181     0.00061     0.05085
    290     0.00194     0.32412     1.00000     0.75609    10.00000     2.94118     0.99937     0.49666     0.00061     0.05085
    300     0.00176     0.33356     1.00000     0.75665    10.00000     2.94118     0.99937     0.49918     0.00061     0.04964
    310     0.00166     0.33883     1.00000     0.75832    10.00000     3.23529     0.99937     0.48908     0.00061     0.04964
    320     0.00155     0.34625     1.00000     0.75824    10.00000     2.94118     0.99937     0.46026     0.00061     0.05085
    330     0.00146     0.35104     1.00000     0.76151    10.00000     3.41176     0.99937     0.48715     0.00061     0.05085
    340     0.00137     0.36159     1.00000     0.75854    10.00000     3.11765     0.99937     0.46205     0.00061     0.05085
    350     0.00127     0.37210     1.00000     0.75431    10.00000     2.94118     0.99937     0.47467     0.00061     0.05085
    360     0.00121     0.38103     1.00000     0.75397    10.00000     2.94118     0.99937     0.48604     0.00061     0.05085
    370     0.00116     0.38974     1.00000     0.75349    10.00000     2.94118     0.99937     0.45700     0.00061     0.05327
    380     0.00111     0.39785     1.00000     0.75327    10.00000     3.23529     0.99937     0.46799     0.00061     0.05448
    390     0.00108     0.40528     1.00000     0.75160    10.00000     3.23529     0.99937     0.46294     0.00061     0.05206
    400     0.00105     0.41254     1.00000     0.75149    10.00000     3.23529     0.99937     0.46041     0.00061     0.05327


 ========================================
 Variable Importance for the 4-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     56.89156   56.89 |*******    |
 PD         30.90782   30.91 |****       |
 FH         15.00573   15.01 |**         |


 Learn Sample Misclassification by Target Class
 For The 4-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         3.00        65.00       0.9559


 Test Sample Misclassification by Target Class
 For The 4-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       791.00         1.00       0.0013
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.4 MB, 76% compression

 Grove file created containing:
      1 TreeNet

