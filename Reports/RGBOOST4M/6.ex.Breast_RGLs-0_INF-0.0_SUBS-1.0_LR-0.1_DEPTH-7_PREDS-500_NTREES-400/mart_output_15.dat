
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14669      0.16533      0.04116      0.04116      1.00000 |                                               *
      2       0.13614      0.16300      0.04116      0.04116      1.00000 |                                              *
      3       0.12834      0.16083      0.04116      0.04116      1.00000 |                                              *
      4       0.12345      0.16010      0.04116      0.04116      1.00000 |                                             *
      5       0.11879      0.15927      0.04116      0.04116      1.00000 |                                             *
      6       0.11421      0.15948      0.04116      0.04116      1.00000 |                                             *
      7       0.10992      0.15962      0.03935      0.04116      1.00000 |                                             *
      8       0.10671      0.15912      0.03632      0.04116      1.00000 |                                             *
      9       0.10346      0.15941      0.03632      0.04116      1.00000 |                                             *
     10       0.10071      0.15978      0.03692      0.04116      1.00000 |                                             *
     11       0.09809      0.16039      0.03511      0.04116      1.00000 |                                              *
     12       0.09586      0.16037      0.03511      0.04237      1.00000 |                                              *
     13       0.09298      0.16030      0.03208      0.04116      1.00000 |                                              *
     14       0.09130      0.16118      0.03148      0.04237      1.00000 |                                              *
     15       0.09016      0.16115      0.03087      0.04116      1.00000 |                                              *
     16       0.08844      0.16068      0.02966      0.04116      1.00000 |                                              *
     17       0.08666      0.16118      0.02906      0.04116      1.00000 |                                              *
     18       0.08531      0.16088      0.02906      0.04237      1.00000 |                                              *
     19       0.08389      0.16116      0.02845      0.04237      1.00000 |                                              *
     20       0.08248      0.16164      0.02724      0.04237      1.00000 |                                              *
     30       0.07380      0.16506      0.02421      0.04237      1.00000 |                                               *
     40       0.06844      0.16730      0.02179      0.04358      1.00000 |                                               *
     50       0.06108      0.17070      0.02058      0.04358      1.00000 |                                               *
     60       0.05685      0.17203      0.01695      0.04600      1.00000 |                                               *
     70       0.05262      0.17536      0.01513      0.04600      1.00000 |                                               *
     80       0.04850      0.17829      0.01453      0.04600      1.00000 |                                               *
     90       0.04329      0.18210      0.01332      0.04722      1.00000 |                                               *
    100       0.03763      0.18845      0.01029      0.04843      1.00000 |                                               *
    110       0.03344      0.19092      0.00787      0.04964      1.00000 |                                               *
    120       0.03090      0.19180      0.00666      0.04843      1.00000 |                                               *
    130       0.02847      0.19450      0.00605      0.04843      1.00000 |                                               *
    140       0.02574      0.19750      0.00484      0.04722      1.00000 |                                               *
    150       0.02393      0.20056      0.00424      0.04722      1.00000 |                                               *
    160       0.02143      0.20348      0.00424      0.04600      1.00000 |                                               *
    170       0.01969      0.20786      0.00242      0.04722      1.00000 |                                               *
    180       0.01817      0.21060      0.00061      0.04600      1.00000 |                                               *
    190       0.01692      0.21321      0.00061      0.04479      1.00000 |                                               *
    200       0.01590      0.21640      0.00000      0.04479      1.00000 |                                               *
    210       0.01481      0.21870      0.00000      0.04479      1.00000 |                                               *
    220       0.01412      0.22093      0.00000      0.04479      1.00000 |                                               *
    230       0.01294      0.22434      0.00000      0.04600      1.00000 |                                               *
    240       0.01188      0.22747      0.00000      0.04479      1.00000 |                                               *
    250       0.01110      0.23110      0.00000      0.04479      1.00000 |                                               *
    260       0.01024      0.23270      0.00000      0.04479      1.00000 |                                               *
    270       0.00960      0.23455      0.00000      0.04600      1.00000 |                                               *
    280       0.00880      0.23755      0.00000      0.04600      1.00000 |                                               *
    290       0.00838      0.24005      0.00000      0.04600      1.00000 |                                               *
    300       0.00776      0.24391      0.00000      0.04722      1.00000 |                                               *
    310       0.00709      0.24742      0.00000      0.04600      1.00000 |                                               *
    320       0.00670      0.24871      0.00000      0.04600      1.00000 |                                               *
    330       0.00620      0.25134      0.00000      0.04600      1.00000 |                                               *
    340       0.00583      0.25450      0.00000      0.04600      1.00000 |                                               *
    350       0.00539      0.25741      0.00000      0.04722      1.00000 |                                               *
    360       0.00499      0.26058      0.00000      0.04600      1.00000 |                                               *
    370       0.00467      0.26163      0.00000      0.04600      1.00000 |                                               *
    380       0.00439      0.26545      0.00000      0.04600      1.00000 |                                               *
    390       0.00414      0.26851      0.00000      0.04600      1.00000 |                                               *
    400       0.00388      0.27156      0.00000      0.04600      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.44      6.56  FOLLOW
    385      1    400      1      7      2.75      5.06  ENTAGE
    212      1    400      1      7      3.88      2.19  PD
    141      2    399      1      7      4.01      1.41  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    50 terminal nodes
    Average :     20.74250 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 8 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 8 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 16194 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.15912
                  ROC            5      0.72124
                 Lift            3      4.11765
              KS-stat           36      0.41028
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14669     0.16533     0.90547     0.56803     6.79412     3.95098     0.63592     0.34395     0.04116     0.04116
      3     0.12834     0.16083     0.94619     0.66613     7.64706     4.11765     0.74625     0.34485     0.04116     0.04116
      5     0.11879     0.15927     0.94887     0.72124     7.94118     4.07059     0.75590     0.40827     0.04116     0.04116
      8     0.10671     0.15912     0.95984     0.70488     8.35294     3.32353     0.78543     0.37151     0.03632     0.04116
     10     0.10071     0.15978     0.96076     0.68666     8.38235     3.52941     0.79839     0.33014     0.03692     0.04116
     20     0.08248     0.16164     0.97098     0.68763     8.68824     3.76471     0.84314     0.34180     0.02724     0.04237
     30     0.07380     0.16506     0.98071     0.69309     8.98235     3.52941     0.86360     0.36572     0.02421     0.04237
     36     0.07067     0.16608     0.98256     0.69431     9.26471     3.52941     0.86360     0.41028     0.02300     0.04358
     40     0.06844     0.16730     0.98324     0.69318     9.26471     3.52941     0.87092     0.38339     0.02179     0.04358
     50     0.06108     0.17070     0.99011     0.68856     9.26471     3.52941     0.90467     0.38213     0.02058     0.04358
     60     0.05685     0.17203     0.99213     0.68967     9.55882     3.52941     0.90783     0.36950     0.01695     0.04600
     70     0.05262     0.17536     0.99344     0.68663     9.61765     3.52941     0.91232     0.33415     0.01513     0.04600
     80     0.04850     0.17829     0.99510     0.68295     9.85294     3.52941     0.92406     0.32784     0.01453     0.04600
     83     0.04606     0.17880     0.99665     0.68527    10.00000     3.52941     0.95391     0.31647     0.01453     0.04722
     90     0.04329     0.18210     0.99750     0.68044    10.00000     3.52941     0.96212     0.33163     0.01332     0.04722
    100     0.03763     0.18845     0.99903     0.67927    10.00000     3.52941     0.98169     0.32383     0.01029     0.04843
    110     0.03344     0.19092     0.99946     0.68251    10.00000     3.52941     0.99116     0.30348     0.00787     0.04964
    120     0.03090     0.19180     0.99971     0.68124    10.00000     3.23529     0.99495     0.31952     0.00666     0.04843
    130     0.02847     0.19450     0.99984     0.68095    10.00000     3.23529     0.99684     0.33214     0.00605     0.04843
    140     0.02574     0.19750     0.99994     0.68015    10.00000     3.23529     0.99937     0.29033     0.00484     0.04722
    150     0.02393     0.20056     0.99994     0.67413    10.00000     3.23529     0.99937     0.30296     0.00424     0.04722
    160     0.02143     0.20348     0.99999     0.67810    10.00000     3.23529     0.99937     0.29664     0.00424     0.04600
    163     0.02080     0.20491     1.00000     0.67612    10.00000     3.23529     1.00000     0.28402     0.00363     0.04722
    170     0.01969     0.20786     1.00000     0.67409    10.00000     3.23529     1.00000     0.28275     0.00242     0.04722
    180     0.01817     0.21060     1.00000     0.67276    10.00000     3.23529     1.00000     0.30258     0.00061     0.04600
    190     0.01692     0.21321     1.00000     0.67292    10.00000     3.23529     1.00000     0.28818     0.00061     0.04479
    198     0.01603     0.21622     1.00000     0.67103    10.00000     3.23529     1.00000     0.28186     0.00000     0.04479
    200     0.01590     0.21640     1.00000     0.66984    10.00000     3.23529     1.00000     0.28313     0.00000     0.04479
    210     0.01481     0.21870     1.00000     0.66966    10.00000     3.23529     1.00000     0.29553     0.00000     0.04479
    220     0.01412     0.22093     1.00000     0.66925    10.00000     3.23529     1.00000     0.28795     0.00000     0.04479
    230     0.01294     0.22434     1.00000     0.66988    10.00000     3.23529     1.00000     0.29932     0.00000     0.04600
    240     0.01188     0.22747     1.00000     0.67021    10.00000     3.23529     1.00000     0.27681     0.00000     0.04479
    250     0.01110     0.23110     1.00000     0.66706    10.00000     3.23529     1.00000     0.27176     0.00000     0.04479
    260     0.01024     0.23270     1.00000     0.66895    10.00000     3.23529     1.00000     0.28327     0.00000     0.04479
    270     0.00960     0.23455     1.00000     0.67055    10.00000     3.23529     1.00000     0.28959     0.00000     0.04600
    280     0.00880     0.23755     1.00000     0.67697    10.00000     3.23529     1.00000     0.33252     0.00000     0.04600
    290     0.00838     0.24005     1.00000     0.67229    10.00000     3.23529     1.00000     0.29011     0.00000     0.04600
    300     0.00776     0.24391     1.00000     0.67148    10.00000     3.23529     1.00000     0.29538     0.00000     0.04722
    310     0.00709     0.24742     1.00000     0.66980    10.00000     3.23529     1.00000     0.28253     0.00000     0.04600
    320     0.00670     0.24871     1.00000     0.67142    10.00000     3.23529     1.00000     0.28417     0.00000     0.04600
    330     0.00620     0.25134     1.00000     0.67740    10.00000     3.23529     1.00000     0.29427     0.00000     0.04600
    340     0.00583     0.25450     1.00000     0.67101    10.00000     3.23529     1.00000     0.27585     0.00000     0.04600
    350     0.00539     0.25741     1.00000     0.67227    10.00000     3.23529     1.00000     0.26827     0.00000     0.04722
    360     0.00499     0.26058     1.00000     0.67250    10.00000     3.23529     1.00000     0.28090     0.00000     0.04600
    370     0.00467     0.26163     1.00000     0.67762    10.00000     3.23529     1.00000     0.28595     0.00000     0.04600
    380     0.00439     0.26545     1.00000     0.67131    10.00000     3.23529     1.00000     0.26820     0.00000     0.04600
    390     0.00414     0.26851     1.00000     0.66919    10.00000     2.94118     1.00000     0.27325     0.00000     0.04600
    400     0.00388     0.27156     1.00000     0.66856    10.00000     2.94118     1.00000     0.26879     0.00000     0.04600


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     57.36391   57.36 |*******    |
 PD         55.94834   55.95 |*******    |
 FH         15.80444   15.80 |***        |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         8.00        60.00       0.8824


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 700 kb , 77% compression

 Grove file created containing:
      1 TreeNet

