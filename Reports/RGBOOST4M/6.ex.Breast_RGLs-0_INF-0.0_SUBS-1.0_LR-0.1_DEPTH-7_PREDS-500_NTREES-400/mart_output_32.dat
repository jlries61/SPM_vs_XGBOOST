
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14739      0.15864      0.04116      0.04116      1.00000 |                                               *
      2       0.13566      0.15506      0.04116      0.04116      1.00000 |                                              *
      3       0.12843      0.15367      0.04116      0.04116      1.00000 |                                             *
      4       0.12161      0.15203      0.04116      0.04116      1.00000 |                                             *
      5       0.11670      0.15177      0.04116      0.04116      1.00000 |                                             *
      6       0.11265      0.15196      0.04116      0.04116      1.00000 |                                             *
      7       0.10918      0.15194      0.04056      0.04116      1.00000 |                                             *
      8       0.10582      0.15230      0.03814      0.04116      1.00000 |                                             *
      9       0.10316      0.15309      0.03814      0.04116      1.00000 |                                             *
     10       0.10062      0.15393      0.03753      0.04479      1.00000 |                                              *
     11       0.09843      0.15448      0.03632      0.04479      1.00000 |                                              *
     12       0.09595      0.15617      0.03511      0.04722      1.00000 |                                              *
     13       0.09419      0.15701      0.03390      0.04600      1.00000 |                                               *
     14       0.09251      0.15764      0.03329      0.04479      1.00000 |                                               *
     15       0.08904      0.15848      0.03390      0.04358      1.00000 |                                               *
     16       0.08746      0.15944      0.03329      0.04358      1.00000 |                                               *
     17       0.08620      0.16049      0.03208      0.04479      1.00000 |                                               *
     18       0.08382      0.16130      0.03208      0.04600      1.00000 |                                               *
     19       0.08305      0.16205      0.03208      0.04600      1.00000 |                                               *
     20       0.08261      0.16247      0.03269      0.04479      1.00000 |                                               *
     30       0.07547      0.16886      0.02906      0.05327      1.00000 |                                               *
     40       0.06726      0.17549      0.02542      0.05569      1.00000 |                                               *
     50       0.06510      0.17843      0.02300      0.05448      1.00000 |                                               *
     60       0.06204      0.18079      0.02119      0.05448      1.00000 |                                               *
     70       0.05985      0.18204      0.02119      0.05448      1.00000 |                                               *
     80       0.05787      0.18375      0.01937      0.05327      1.00000 |                                               *
     90       0.05556      0.18482      0.01755      0.05448      1.00000 |                                               *
    100       0.05421      0.18581      0.01695      0.05448      1.00000 |                                               *
    110       0.05241      0.18716      0.01634      0.05327      1.00000 |                                               *
    120       0.04988      0.18904      0.01513      0.05206      1.00000 |                                               *
    130       0.04647      0.19298      0.01332      0.05327      1.00000 |                                               *
    140       0.04521      0.19452      0.01332      0.05327      1.00000 |                                               *
    150       0.04421      0.19637      0.01332      0.05327      1.00000 |                                               *
    160       0.04309      0.19739      0.01211      0.05327      1.00000 |                                               *
    170       0.04037      0.20053      0.01150      0.05569      1.00000 |                                               *
    180       0.03640      0.20419      0.00847      0.05327      1.00000 |                                               *
    190       0.03443      0.20663      0.00787      0.05327      1.00000 |                                               *
    200       0.03322      0.20779      0.00787      0.05206      1.00000 |                                               *
    210       0.03114      0.20990      0.00787      0.05206      1.00000 |                                               *
    220       0.02931      0.21295      0.00787      0.05448      1.00000 |                                               *
    230       0.02720      0.21738      0.00666      0.05448      1.00000 |                                               *
    240       0.02465      0.22034      0.00484      0.05569      1.00000 |                                               *
    250       0.02237      0.22520      0.00424      0.05448      1.00000 |                                               *
    260       0.02076      0.23026      0.00363      0.05448      1.00000 |                                               *
    270       0.02030      0.23157      0.00363      0.05448      1.00000 |                                               *
    280       0.01824      0.23882      0.00182      0.05448      1.00000 |                                               *
    290       0.01719      0.24326      0.00182      0.05448      1.00000 |                                               *
    300       0.01618      0.24792      0.00182      0.05569      1.00000 |                                               *
    310       0.01552      0.25148      0.00182      0.05569      1.00000 |                                               *
    320       0.01491      0.25378      0.00182      0.05569      1.00000 |                                               *
    330       0.01367      0.25894      0.00121      0.05569      1.00000 |                                               *
    340       0.01297      0.26239      0.00121      0.05569      1.00000 |                                               *
    350       0.01242      0.26539      0.00121      0.05569      1.00000 |                                               *
    360       0.01182      0.27010      0.00121      0.05569      1.00000 |                                               *
    370       0.01127      0.27298      0.00121      0.05690      1.00000 |                                               *
    380       0.01073      0.27614      0.00121      0.05811      1.00000 |                                               *
    390       0.01005      0.27970      0.00121      0.05811      1.00000 |                                               *
    400       0.00948      0.28367      0.00121      0.05811      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.35      6.65  FOLLOW
    341      1    400      1      7      2.85      4.39  ENTAGE
    189      1    400      1      7      3.70      2.03  PD
     81      1    400      1      7      4.31      0.75  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    43 terminal nodes
    Average :     17.43750 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 7 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 7 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 5

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 13550 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            5      0.15177
                  ROC            7      0.71903
                 Lift            1      4.27353
              KS-stat           11      0.43367
          Class.Error            1      0.04116

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14739     0.15864     0.94297     0.70464     7.12539     4.27353     0.74395     0.38800     0.04116     0.04116
      5     0.11670     0.15177     0.95887     0.68035     8.24020     3.82353     0.78624     0.41511     0.04116     0.04116
      7     0.10918     0.15194     0.96016     0.71903     8.08824     4.11765     0.79066     0.42395     0.04056     0.04116
     10     0.10062     0.15393     0.96502     0.69690     8.38235     4.11765     0.79319     0.42194     0.03753     0.04479
     11     0.09843     0.15448     0.96573     0.70607     8.52941     4.11765     0.79308     0.43367     0.03632     0.04479
     20     0.08261     0.16247     0.97652     0.70768     9.11765     4.11765     0.86858     0.39528     0.03269     0.04479
     30     0.07547     0.16886     0.98055     0.70948     9.13235     3.82353     0.86958     0.36208     0.02906     0.05327
     40     0.06726     0.17549     0.98542     0.69331     9.26471     3.52941     0.89817     0.37344     0.02542     0.05569
     50     0.06510     0.17843     0.98595     0.68971     9.26471     3.52941     0.89880     0.36334     0.02300     0.05448
     60     0.06204     0.18079     0.98773     0.68095     9.41176     3.52941     0.90304     0.32546     0.02119     0.05448
     70     0.05985     0.18204     0.98879     0.67992     9.55882     3.52941     0.91017     0.31298     0.02119     0.05448
     80     0.05787     0.18375     0.98960     0.68213     9.55882     3.52941     0.91585     0.31751     0.01937     0.05327
     90     0.05556     0.18482     0.99070     0.68195     9.85294     3.52941     0.92469     0.30934     0.01755     0.05448
    100     0.05421     0.18581     0.99115     0.67799     9.85294     3.52941     0.92469     0.32219     0.01695     0.05448
    110     0.05241     0.18716     0.99158     0.67610     9.85294     3.52941     0.92532     0.31588     0.01634     0.05327
    120     0.04988     0.18904     0.99272     0.67168     9.73529     3.52941     0.92279     0.31840     0.01513     0.05206
    130     0.04647     0.19298     0.99467     0.68037     9.85294     3.52941     0.94173     0.32598     0.01332     0.05327
    140     0.04521     0.19452     0.99512     0.67770     9.85294     3.52941     0.95247     0.31714     0.01332     0.05327
    150     0.04421     0.19637     0.99535     0.67454     9.85294     3.52941     0.95183     0.31001     0.01332     0.05327
    160     0.04309     0.19739     0.99553     0.67409     9.85294     3.52941     0.95373     0.30875     0.01211     0.05327
    165     0.04094     0.19918     0.99704     0.67718    10.00000     3.52941     0.95310     0.32115     0.01090     0.05327
    170     0.04037     0.20053     0.99715     0.67491    10.00000     3.52941     0.95499     0.32115     0.01150     0.05569
    180     0.03640     0.20419     0.99841     0.67406    10.00000     3.52941     0.97475     0.30563     0.00847     0.05327
    190     0.03443     0.20663     0.99879     0.67822    10.00000     3.52941     0.97854     0.33504     0.00787     0.05327
    200     0.03322     0.20779     0.99902     0.67740    10.00000     3.52941     0.97917     0.31826     0.00787     0.05206
    210     0.03114     0.20990     0.99944     0.67771    10.00000     3.52941     0.98548     0.32657     0.00787     0.05206
    220     0.02931     0.21295     0.99964     0.67911    10.00000     3.52941     0.99116     0.35725     0.00787     0.05448
    230     0.02720     0.21738     0.99976     0.67614    10.00000     3.52941     0.99432     0.35599     0.00666     0.05448
    240     0.02465     0.22034     0.99990     0.68100    10.00000     3.52941     0.99747     0.32836     0.00484     0.05569
    250     0.02237     0.22520     0.99994     0.68052    10.00000     3.52941     0.99811     0.31736     0.00424     0.05448
    260     0.02076     0.23026     0.99995     0.67402    10.00000     3.52941     0.99874     0.31068     0.00363     0.05448
    270     0.02030     0.23157     0.99996     0.67320    10.00000     3.52941     0.99874     0.31068     0.00363     0.05448
    280     0.01824     0.23882     0.99997     0.66570    10.00000     3.52941     0.99874     0.30652     0.00182     0.05448
    290     0.01719     0.24326     0.99997     0.65761    10.00000     3.52941     0.99874     0.29234     0.00182     0.05448
    296     0.01640     0.24643     0.99998     0.65746    10.00000     3.52941     0.99874     0.29501     0.00182     0.05569
    300     0.01618     0.24792     0.99998     0.65538    10.00000     3.52941     0.99874     0.29880     0.00182     0.05569
    310     0.01552     0.25148     0.99998     0.65181    10.00000     3.52941     0.99874     0.29234     0.00182     0.05569
    320     0.01491     0.25378     0.99998     0.65152    10.00000     3.52941     0.99874     0.29234     0.00182     0.05569
    323     0.01445     0.25576     0.99998     0.64984    10.00000     3.52941     0.99874     0.29234     0.00121     0.05569
    330     0.01367     0.25894     0.99998     0.64854    10.00000     3.52941     0.99874     0.29360     0.00121     0.05569
    340     0.01297     0.26239     0.99998     0.64483    10.00000     3.52941     0.99874     0.29234     0.00121     0.05569
    350     0.01242     0.26539     0.99998     0.64368    10.00000     3.52941     0.99874     0.29234     0.00121     0.05569
    360     0.01182     0.27010     0.99998     0.63989    10.00000     3.52941     0.99874     0.29107     0.00121     0.05569
    370     0.01127     0.27298     0.99998     0.64138    10.00000     3.52941     0.99874     0.29360     0.00121     0.05690
    380     0.01073     0.27614     0.99998     0.64736    10.00000     3.52941     0.99874     0.29234     0.00121     0.05811
    390     0.01005     0.27970     0.99998     0.64698    10.00000     3.52941     0.99874     0.28855     0.00121     0.05811
    400     0.00948     0.28367     0.99998     0.64464    10.00000     3.52941     0.99874     0.28981     0.00121     0.05811


 ========================================
 Variable Importance for the 5-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     70.65874   70.66 |********   |
 PD         52.43528   52.44 |******     |
 FH         15.76079   15.76 |***        |


 Learn Sample Misclassification by Target Class
 For The 5-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         0.00        68.00       1.0000


 Test Sample Misclassification by Target Class
 For The 5-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 566 kb , 78% compression

 Grove file created containing:
      1 TreeNet

