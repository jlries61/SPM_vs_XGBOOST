
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.14503      0.16123      0.04116      0.04116      1.00000 |                                               *
      2       0.13611      0.15804      0.04116      0.04116      1.00000 |                                              *
      3       0.12848      0.15610      0.04116      0.04116      1.00000 |                                             *
      4       0.12284      0.15448      0.04116      0.04116      1.00000 |                                             *
      5       0.11693      0.15281      0.04116      0.04116      1.00000 |                                            *
      6       0.11263      0.15206      0.04116      0.04116      1.00000 |                                            *
      7       0.10822      0.15155      0.03995      0.04116      1.00000 |                                            *
      8       0.10493      0.15232      0.03935      0.04237      1.00000 |                                            *
      9       0.10106      0.15211      0.03571      0.03995      1.00000 |                                            *
     10       0.09802      0.15277      0.03511      0.03995      1.00000 |                                            *
     11       0.09561      0.15316      0.03390      0.03995      1.00000 |                                             *
     12       0.09386      0.15302      0.03329      0.04116      1.00000 |                                             *
     13       0.09217      0.15358      0.03390      0.04116      1.00000 |                                             *
     14       0.09037      0.15382      0.03208      0.04237      1.00000 |                                             *
     15       0.08887      0.15468      0.03269      0.03995      1.00000 |                                             *
     16       0.08753      0.15524      0.03269      0.04358      1.00000 |                                             *
     17       0.08536      0.15606      0.03208      0.04479      1.00000 |                                             *
     18       0.08407      0.15647      0.03148      0.04479      1.00000 |                                              *
     19       0.08314      0.15694      0.03148      0.04358      1.00000 |                                              *
     20       0.08215      0.15734      0.03148      0.04358      1.00000 |                                              *
     30       0.07652      0.16245      0.02966      0.04600      1.00000 |                                               *
     40       0.07292      0.16581      0.02785      0.04600      1.00000 |                                               *
     50       0.06717      0.16776      0.02542      0.04843      1.00000 |                                               *
     60       0.06251      0.17006      0.02119      0.04600      1.00000 |                                               *
     70       0.05764      0.17261      0.02058      0.04600      1.00000 |                                               *
     80       0.05504      0.17354      0.01937      0.04600      1.00000 |                                               *
     90       0.05253      0.17574      0.01816      0.04600      1.00000 |                                               *
    100       0.05036      0.17753      0.01695      0.04600      1.00000 |                                               *
    110       0.04762      0.17963      0.01453      0.04722      1.00000 |                                               *
    120       0.04539      0.18128      0.01453      0.04722      1.00000 |                                               *
    130       0.04482      0.18200      0.01453      0.04722      1.00000 |                                               *
    140       0.04283      0.18440      0.01453      0.04722      1.00000 |                                               *
    150       0.04074      0.18607      0.01453      0.04843      1.00000 |                                               *
    160       0.03986      0.18746      0.01392      0.04843      1.00000 |                                               *
    170       0.03800      0.18853      0.01332      0.04843      1.00000 |                                               *
    180       0.03675      0.19068      0.01211      0.04843      1.00000 |                                               *
    190       0.03486      0.19187      0.01211      0.04843      1.00000 |                                               *
    200       0.03234      0.19547      0.01211      0.04843      1.00000 |                                               *
    210       0.03121      0.19692      0.01211      0.04722      1.00000 |                                               *
    220       0.02922      0.19939      0.01090      0.04843      1.00000 |                                               *
    230       0.02576      0.20475      0.00787      0.04600      1.00000 |                                               *
    240       0.02438      0.20695      0.00605      0.04600      1.00000 |                                               *
    250       0.02280      0.21108      0.00666      0.04843      1.00000 |                                               *
    260       0.02167      0.21393      0.00424      0.04600      1.00000 |                                               *
    270       0.02095      0.21505      0.00424      0.04600      1.00000 |                                               *
    280       0.01995      0.21848      0.00303      0.04722      1.00000 |                                               *
    290       0.01952      0.22047      0.00303      0.04479      1.00000 |                                               *
    300       0.01836      0.22352      0.00303      0.04722      1.00000 |                                               *
    310       0.01760      0.22701      0.00242      0.04600      1.00000 |                                               *
    320       0.01724      0.22972      0.00242      0.04722      1.00000 |                                               *
    330       0.01694      0.23126      0.00242      0.04722      1.00000 |                                               *
    340       0.01608      0.23464      0.00242      0.04600      1.00000 |                                               *
    350       0.01566      0.23590      0.00242      0.04722      1.00000 |                                               *
    360       0.01505      0.23773      0.00121      0.04843      1.00000 |                                               *
    370       0.01448      0.23992      0.00061      0.04843      1.00000 |                                               *
    380       0.01399      0.24164      0.00061      0.04722      1.00000 |                                               *
    390       0.01310      0.24416      0.00061      0.04722      1.00000 |                                               *
    400       0.01255      0.24510      0.00061      0.04843      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.33      6.67  FOLLOW
    291      1    400      1      7      2.97      3.66  ENTAGE
    193      1    400      1      7      3.32      2.26  PD
     91      1    394      2      7      4.76      0.74  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    45 terminal nodes
    Average :     15.70250 terminal nodes

 Reconciling 1652 Learn sample scores across 4 selected models,
 the largest having 9 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 4 selected models,
 the largest having 9 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 7

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 12162 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            7      0.15155
                  ROC            1      0.75212
                 Lift            2      5.00000
              KS-stat            2      0.41919
          Class.Error            9      0.03995

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.14503     0.16123     0.93856     0.75212     7.31513     4.41176     0.73697     0.40315     0.04116     0.04116
      2     0.13611     0.15804     0.94664     0.71069     8.08824     5.00000     0.75438     0.41919     0.04116     0.04116
      7     0.10822     0.15155     0.96387     0.71145     8.52941     4.11765     0.82539     0.38042     0.03995     0.04116
      9     0.10106     0.15211     0.97016     0.70518     8.70588     4.11765     0.83612     0.38421     0.03571     0.03995
     10     0.09802     0.15277     0.97098     0.70096     8.52941     4.11765     0.83991     0.36757     0.03511     0.03995
     20     0.08215     0.15734     0.97814     0.68501     8.82353     4.11765     0.87400     0.37010     0.03148     0.04358
     30     0.07652     0.16245     0.97981     0.66631     8.97059     4.11765     0.87210     0.37032     0.02966     0.04600
     40     0.07292     0.16581     0.98139     0.66401     8.82353     3.82353     0.87526     0.34470     0.02785     0.04600
     50     0.06717     0.16776     0.98626     0.67205     9.41176     3.82353     0.89546     0.35227     0.02542     0.04843
     60     0.06251     0.17006     0.98858     0.66618     9.70588     3.82353     0.91061     0.35985     0.02119     0.04600
     70     0.05764     0.17261     0.99241     0.66292     9.85294     3.82353     0.93245     0.33207     0.02058     0.04600
     80     0.05504     0.17354     0.99344     0.66682     9.85294     3.82353     0.93624     0.32791     0.01937     0.04600
     88     0.05280     0.17567     0.99455     0.66587    10.00000     3.82353     0.94697     0.33586     0.01877     0.04600
     90     0.05253     0.17574     0.99457     0.66565    10.00000     3.82353     0.94571     0.33712     0.01816     0.04600
    100     0.05036     0.17753     0.99526     0.65642    10.00000     4.11765     0.94634     0.32843     0.01695     0.04600
    110     0.04762     0.17963     0.99603     0.65393    10.00000     4.11765     0.94949     0.34358     0.01453     0.04722
    120     0.04539     0.18128     0.99675     0.65545    10.00000     4.11765     0.95202     0.34358     0.01453     0.04722
    130     0.04482     0.18200     0.99686     0.65567    10.00000     4.11765     0.95202     0.33980     0.01453     0.04722
    140     0.04283     0.18440     0.99741     0.65567    10.00000     4.11765     0.95833     0.33474     0.01453     0.04722
    150     0.04074     0.18607     0.99816     0.65846    10.00000     4.11765     0.96320     0.33333     0.01453     0.04843
    160     0.03986     0.18746     0.99826     0.65367    10.00000     4.11765     0.96446     0.33207     0.01392     0.04843
    170     0.03800     0.18853     0.99874     0.65493    10.00000     3.82353     0.97014     0.32828     0.01332     0.04843
    180     0.03675     0.19068     0.99900     0.65118    10.00000     3.82353     0.97475     0.33207     0.01211     0.04843
    190     0.03486     0.19187     0.99926     0.65120    10.00000     3.82353     0.98106     0.32576     0.01211     0.04843
    200     0.03234     0.19547     0.99948     0.64708    10.00000     3.82353     0.98611     0.32323     0.01211     0.04843
    210     0.03121     0.19692     0.99953     0.64897    10.00000     3.61765     0.98864     0.32323     0.01211     0.04722
    220     0.02922     0.19939     0.99974     0.64938    10.00000     3.82353     0.99306     0.32412     0.01090     0.04843
    226     0.02672     0.20233     0.99996     0.64880    10.00000     3.82353     0.99937     0.32665     0.00847     0.04843
    230     0.02576     0.20475     0.99996     0.64769    10.00000     3.52941     0.99937     0.33675     0.00787     0.04600
    240     0.02438     0.20695     0.99996     0.64663    10.00000     2.94118     0.99937     0.34306     0.00605     0.04600
    250     0.02280     0.21108     0.99996     0.64613    10.00000     2.94118     0.99937     0.33170     0.00666     0.04843
    260     0.02167     0.21393     0.99997     0.64030    10.00000     2.64706     0.99937     0.33801     0.00424     0.04600
    270     0.02095     0.21505     0.99997     0.64320    10.00000     2.64706     0.99937     0.33170     0.00424     0.04600
    280     0.01995     0.21848     0.99997     0.64216    10.00000     2.64706     0.99937     0.32539     0.00303     0.04722
    290     0.01952     0.22047     0.99997     0.63896    10.00000     2.64706     0.99937     0.32034     0.00303     0.04479
    300     0.01836     0.22352     0.99997     0.63596    10.00000     2.64706     0.99937     0.33422     0.00303     0.04722
    310     0.01760     0.22701     0.99997     0.63280    10.00000     2.64706     0.99937     0.33170     0.00242     0.04600
    320     0.01724     0.22972     0.99997     0.62827    10.00000     2.64706     0.99937     0.30140     0.00242     0.04722
    330     0.01694     0.23126     0.99997     0.62756    10.00000     2.64706     0.99937     0.29887     0.00242     0.04722
    340     0.01608     0.23464     0.99999     0.62808    10.00000     2.64706     0.99937     0.29003     0.00242     0.04600
    350     0.01566     0.23590     0.99998     0.62908    10.00000     2.64706     0.99937     0.29382     0.00242     0.04722
    354     0.01532     0.23720     1.00000     0.63053    10.00000     2.64706     0.99937     0.29130     0.00182     0.04843
    360     0.01505     0.23773     1.00000     0.63220    10.00000     2.64706     0.99937     0.29003     0.00121     0.04843
    368     0.01451     0.23947     1.00000     0.62875    10.00000     2.64706     0.99937     0.26842     0.00061     0.04843
    370     0.01448     0.23992     1.00000     0.62797    10.00000     2.64706     0.99937     0.26968     0.00061     0.04843
    380     0.01399     0.24164     1.00000     0.62764    10.00000     2.64706     0.99937     0.27005     0.00061     0.04722
    390     0.01310     0.24416     1.00000     0.63087    10.00000     2.64706     0.99937     0.26619     0.00061     0.04722
    400     0.01255     0.24510     1.00000     0.63295    10.00000     2.64706     0.99937     0.27978     0.00061     0.04843


 ========================================
 Variable Importance for the 7-tree Model
 ========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 PD         54.05425   54.05 |******     |
 ENTAGE     42.74002   42.74 |*****      |
 FH         13.23914   13.24 |**         |


 Learn Sample Misclassification by Target Class
 For The 7-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         2.00        66.00       0.9706


 Test Sample Misclassification by Target Class
 For The 7-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 517 kb , 78% compression

 Grove file created containing:
      1 TreeNet

