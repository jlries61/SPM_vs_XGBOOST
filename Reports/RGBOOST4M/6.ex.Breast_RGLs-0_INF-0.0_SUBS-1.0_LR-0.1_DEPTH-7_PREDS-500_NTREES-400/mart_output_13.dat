
 The "USE "../Data/Classification/6.ex.Breast/SAMPLES4/d" command: 00:00:00

 Model (target and predictors) reset: FATE

 The KEEP list has 4 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 1652
 Records Kept in Learning sample: 1652

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 826
 Records Kept in Test sample: 826

 Discrete         N Levels
 Variable         in Model
 -------------------------
 FATE                    2

 ======================
 Target Frequency Table
 ======================

 Variable: FATE
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         1584  95.88              1584.00  95.88
                 T         (792  95.88)             (792.00  95.88)
 1               L           68   4.12                68.00   4.12
                 T          (34   4.12)              (34.00   4.12)
 -----------------------------------------------------------------
 Totals
 0                         2376  95.88              2376.00  95.88
 1                          102   4.12               102.00   4.12
 -----------------------------------------------------------------
 Total                     2478                     2478.00
 Total Learn               1652                     1652.00
 Total Test                 826                      826.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.15189      0.16167      0.04116      0.04116      1.00000 |                                               *
      2       0.14203      0.15480      0.04116      0.04116      1.00000 |                                             *
      3       0.13421      0.15103      0.04116      0.04116      1.00000 |                                            *
      4       0.12729      0.14904      0.04116      0.04116      1.00000 |                                           *
      5       0.12112      0.14778      0.04116      0.04116      1.00000 |                                           *
      6       0.11665      0.14707      0.04116      0.04116      1.00000 |                                           *
      7       0.11233      0.14535      0.04116      0.04116      1.00000 |                                          *
      8       0.10930      0.14371      0.04116      0.04116      1.00000 |                                          *
      9       0.10504      0.14189      0.03935      0.04116      1.00000 |                                         *
     10       0.10230      0.14120      0.03874      0.04116      1.00000 |                                         *
     11       0.09996      0.14075      0.03874      0.04116      1.00000 |                                         *
     12       0.09752      0.14025      0.03874      0.04116      1.00000 |                                         *
     13       0.09543      0.13944      0.03874      0.04116      1.00000 |                                        *
     14       0.09402      0.13931      0.03874      0.04116      1.00000 |                                        *
     15       0.09293      0.13911      0.03753      0.04116      1.00000 |                                        *
     16       0.09098      0.13900      0.03692      0.04116      1.00000 |                                        *
     17       0.08896      0.13938      0.03511      0.04116      1.00000 |                                        *
     18       0.08774      0.13954      0.03450      0.03995      1.00000 |                                        *
     19       0.08615      0.13958      0.03450      0.04116      1.00000 |                                        *
     20       0.08507      0.13988      0.03329      0.03995      1.00000 |                                         *
     30       0.07645      0.14247      0.02906      0.04479      1.00000 |                                         *
     40       0.07047      0.14352      0.02421      0.04116      1.00000 |                                          *
     50       0.06520      0.14559      0.02300      0.04116      1.00000 |                                          *
     60       0.06141      0.14669      0.01998      0.04116      1.00000 |                                           *
     70       0.05859      0.14781      0.01816      0.04116      1.00000 |                                           *
     80       0.05602      0.14975      0.01695      0.04116      1.00000 |                                           *
     90       0.05272      0.15111      0.01695      0.03995      1.00000 |                                            *
    100       0.05064      0.15317      0.01453      0.03995      1.00000 |                                            *
    110       0.04769      0.15601      0.01453      0.03995      1.00000 |                                             *
    120       0.04522      0.15725      0.01332      0.03995      1.00000 |                                              *
    130       0.04151      0.15978      0.01150      0.03995      1.00000 |                                              *
    140       0.03775      0.16131      0.01029      0.03995      1.00000 |                                               *
    150       0.03520      0.16322      0.00908      0.03995      1.00000 |                                               *
    160       0.03235      0.16473      0.00847      0.03995      1.00000 |                                               *
    170       0.03001      0.16682      0.00726      0.04116      1.00000 |                                               *
    180       0.02796      0.16789      0.00666      0.04116      1.00000 |                                               *
    190       0.02696      0.16960      0.00605      0.04116      1.00000 |                                               *
    200       0.02563      0.17066      0.00424      0.04116      1.00000 |                                               *
    210       0.02494      0.17145      0.00424      0.04116      1.00000 |                                               *
    220       0.02354      0.17327      0.00424      0.04237      1.00000 |                                               *
    230       0.02199      0.17539      0.00303      0.04237      1.00000 |                                               *
    240       0.02066      0.17704      0.00182      0.04237      1.00000 |                                               *
    250       0.01963      0.17887      0.00242      0.04116      1.00000 |                                               *
    260       0.01905      0.17992      0.00061      0.04237      1.00000 |                                               *
    270       0.01779      0.18168      0.00000      0.04358      1.00000 |                                               *
    280       0.01688      0.18334      0.00000      0.04358      1.00000 |                                               *
    290       0.01567      0.18584      0.00000      0.04237      1.00000 |                                               *
    300       0.01464      0.18830      0.00000      0.04479      1.00000 |                                               *
    310       0.01437      0.18920      0.00000      0.04479      1.00000 |                                               *
    320       0.01386      0.19035      0.00000      0.04358      1.00000 |                                               *
    330       0.01318      0.19196      0.00000      0.04358      1.00000 |                                               *
    340       0.01248      0.19370      0.00000      0.04600      1.00000 |                                               *
    350       0.01185      0.19492      0.00000      0.04479      1.00000 |                                               *
    360       0.01119      0.19722      0.00000      0.04479      1.00000 |                                               *
    370       0.01047      0.19955      0.00000      0.04358      1.00000 |                                               *
    380       0.00996      0.20240      0.00000      0.04479      1.00000 |                                               *
    390       0.00959      0.20278      0.00000      0.04600      1.00000 |                                               *
    400       0.00892      0.20478      0.00000      0.04600      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      5      1.38      6.62  FOLLOW
    323      1    400      1      7      3.03      4.01  ENTAGE
    151      1    397      1      7      4.63      1.27  PD
     58      1    400      2      7      4.76      0.47  FH

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    47 terminal nodes
    Average :     17.23000 terminal nodes

 Reconciling 1652 Learn sample scores across 5 selected models,
 the largest having 53 trees, to compute gains and PS tables.

 Reconciling 826 Test sample scores across 5 selected models,
 the largest having 53 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: FATE
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     1652      1652.00
 N Test  Obs:      826       826.00
 Learn Rate :    0.1000000

 Storage requirements: 13384 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.13900
                  ROC           11      0.79022
                 Lift           14      5.76471
              KS-stat           34      0.57836
          Class.Error           53      0.03874

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.15189     0.16167     0.92708     0.65168     6.63503     4.41176     0.72623     0.39431     0.04116     0.04116
     10     0.10230     0.14120     0.96259     0.78626     8.52941     4.70588     0.81788     0.53365     0.03874     0.04116
     11     0.09996     0.14075     0.96303     0.79022     8.67647     4.70588     0.81599     0.54427     0.03874     0.04116
     14     0.09402     0.13931     0.96591     0.78821     8.67647     5.76471     0.82409     0.54300     0.03874     0.04116
     16     0.09098     0.13900     0.96713     0.78697     8.67647     5.47059     0.82483     0.53417     0.03692     0.04116
     20     0.08507     0.13988     0.97170     0.78478     8.75735     5.29412     0.83356     0.56068     0.03329     0.03995
     30     0.07645     0.14247     0.97993     0.77924     8.82353     5.58824     0.84113     0.56194     0.02906     0.04479
     34     0.07363     0.14292     0.98238     0.77700     8.90441     5.58824     0.85038     0.57836     0.02724     0.04237
     40     0.07047     0.14352     0.98382     0.77971     9.11765     5.29412     0.85647     0.57583     0.02421     0.04116
     50     0.06520     0.14559     0.98737     0.77353     9.11765     5.00000     0.86579     0.56410     0.02300     0.04116
     53     0.06419     0.14545     0.98786     0.77609     9.11765     5.00000     0.87147     0.56157     0.02240     0.03874
     60     0.06141     0.14669     0.98937     0.77568     9.26471     4.88235     0.88618     0.54300     0.01998     0.04116
     70     0.05859     0.14781     0.99053     0.77345     9.41176     4.88235     0.89375     0.53595     0.01816     0.04116
     80     0.05602     0.14975     0.99252     0.76948     9.55882     4.70588     0.91225     0.52711     0.01695     0.04116
     90     0.05272     0.15111     0.99480     0.76868     9.85294     4.70588     0.93479     0.51070     0.01695     0.03995
    100     0.05064     0.15317     0.99527     0.76905     9.85294     4.41176     0.93226     0.50438     0.01453     0.03995
    110     0.04769     0.15601     0.99631     0.76420     9.85294     4.41176     0.94912     0.48633     0.01453     0.03995
    119     0.04527     0.15709     0.99750     0.76131    10.00000     4.41176     0.95039     0.49770     0.01332     0.03995
    120     0.04522     0.15725     0.99750     0.76142    10.00000     4.29412     0.95039     0.49391     0.01332     0.03995
    130     0.04151     0.15978     0.99856     0.75930    10.00000     4.11765     0.97096     0.48671     0.01150     0.03995
    140     0.03775     0.16131     0.99931     0.75997    10.00000     4.41176     0.98295     0.49592     0.01029     0.03995
    150     0.03520     0.16322     0.99958     0.76047    10.00000     4.11765     0.99053     0.48002     0.00908     0.03995
    160     0.03235     0.16473     0.99978     0.75735    10.00000     4.11765     0.99306     0.47623     0.00847     0.03995
    170     0.03001     0.16682     0.99991     0.75635    10.00000     4.41176     0.99495     0.47534     0.00726     0.04116
    180     0.02796     0.16789     0.99994     0.75850    10.00000     4.41176     0.99684     0.47534     0.00666     0.04116
    190     0.02696     0.16960     0.99998     0.75576    10.00000     4.41176     0.99937     0.46903     0.00605     0.04116
    200     0.02563     0.17066     0.99999     0.75828    10.00000     4.41176     0.99937     0.46650     0.00424     0.04116
    205     0.02511     0.17150     1.00000     0.75743    10.00000     4.29412     1.00000     0.46650     0.00424     0.04116
    210     0.02494     0.17145     1.00000     0.75832    10.00000     4.11765     1.00000     0.46108     0.00424     0.04116
    220     0.02354     0.17327     1.00000     0.75973    10.00000     4.11765     1.00000     0.46487     0.00424     0.04237
    230     0.02199     0.17539     1.00000     0.75914    10.00000     4.11765     1.00000     0.46866     0.00303     0.04237
    240     0.02066     0.17704     1.00000     0.76296    10.00000     4.11765     1.00000     0.46866     0.00182     0.04237
    250     0.01963     0.17887     1.00000     0.76222    10.00000     4.11765     1.00000     0.46866     0.00242     0.04116
    260     0.01905     0.17992     1.00000     0.76222    10.00000     4.11765     1.00000     0.46613     0.00061     0.04237
    265     0.01842     0.18127     1.00000     0.76097    10.00000     4.11765     1.00000     0.46361     0.00000     0.04479
    270     0.01779     0.18168     1.00000     0.76131    10.00000     4.11765     1.00000     0.47245     0.00000     0.04358
    280     0.01688     0.18334     1.00000     0.75953    10.00000     4.11765     1.00000     0.47066     0.00000     0.04358
    290     0.01567     0.18584     1.00000     0.75626    10.00000     4.11765     1.00000     0.48203     0.00000     0.04237
    300     0.01464     0.18830     1.00000     0.75522    10.00000     4.11765     1.00000     0.47950     0.00000     0.04479
    310     0.01437     0.18920     1.00000     0.75362    10.00000     4.11765     1.00000     0.46687     0.00000     0.04479
    320     0.01386     0.19035     1.00000     0.75262    10.00000     3.82353     1.00000     0.48455     0.00000     0.04358
    330     0.01318     0.19196     1.00000     0.75020    10.00000     4.41176     1.00000     0.47950     0.00000     0.04358
    340     0.01248     0.19370     1.00000     0.75169    10.00000     4.00000     1.00000     0.48455     0.00000     0.04600
    350     0.01185     0.19492     1.00000     0.75076    10.00000     4.41176     1.00000     0.48455     0.00000     0.04479
    360     0.01119     0.19722     1.00000     0.74887    10.00000     4.41176     1.00000     0.47319     0.00000     0.04479
    370     0.01047     0.19955     1.00000     0.74955    10.00000     4.41176     1.00000     0.47698     0.00000     0.04358
    380     0.00996     0.20240     1.00000     0.74681    10.00000     4.11765     1.00000     0.46940     0.00000     0.04479
    390     0.00959     0.20278     1.00000     0.74855    10.00000     4.11765     1.00000     0.47066     0.00000     0.04600
    400     0.00892     0.20478     1.00000     0.75223    10.00000     4.29412     1.00000     0.48076     0.00000     0.04600


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                 Abs     Rel

 FOLLOW    100.00000  100.00 |***********|
 ENTAGE     69.88221   69.88 |********   |
 PD         29.62334   29.62 |****       |
 FH         23.38577   23.39 |***        |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1584.00      1584.00         0.00       0.0000
 1                   68.00         7.00        61.00       0.8971


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  792.00       792.00         0.00       0.0000
 1                   34.00         0.00        34.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 595 kb , 78% compression

 Grove file created containing:
      1 TreeNet

