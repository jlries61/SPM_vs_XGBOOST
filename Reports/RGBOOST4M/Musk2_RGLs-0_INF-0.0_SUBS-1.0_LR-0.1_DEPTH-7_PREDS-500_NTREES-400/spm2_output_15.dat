
 The "USE "../Data/Classification/Musk2/SAMPLES4/data_tr" command: 00:00:01

 Model (target and predictors) reset: CLASS

 The KEEP list has 166 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 3300
 Records Kept in Learning sample: 3300

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1649
 Records Kept in Test sample: 1649

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         2791  84.58              2791.00  84.58
                 T        (1395  84.60)            (1395.00  84.60)
 1               L          509  15.42               509.00  15.42
                 T         (254  15.40)             (254.00  15.40)
 -----------------------------------------------------------------
 Totals
 0                         4186  84.58              4186.00  84.58
 1                          763  15.42               763.00  15.42
 -----------------------------------------------------------------
 Total                     4949                     4949.00
 Total Learn               3300                     3300.00
 Total Test                1649                     1649.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.35182      0.36314      0.15424      0.15403      1.00000 |                                               *
      2       0.30236      0.31838      0.15424      0.15403      1.00000 |                                         *
      3       0.26543      0.28617      0.15424      0.15403      1.00000 |                                     *
      4       0.23566      0.25919      0.15394      0.15403      1.00000 |                                 *
      5       0.21043      0.23769      0.03818      0.05822      1.00000 |                              *
      6       0.18973      0.22019      0.02848      0.04912      1.00000 |                            *
      7       0.17194      0.20486      0.02485      0.04427      1.00000 |                          *
      8       0.15614      0.19000      0.01879      0.04184      1.00000 |                        *
      9       0.14268      0.17847      0.01576      0.03699      1.00000 |                       *
     10       0.13066      0.16786      0.01303      0.03457      1.00000 |                     *
     11       0.12033      0.15919      0.01273      0.03457      1.00000 |                    *
     12       0.11084      0.15173      0.01152      0.03457      1.00000 |                   *
     13       0.10266      0.14545      0.01030      0.03214      1.00000 |                  *
     14       0.09524      0.13954      0.01030      0.03153      1.00000 |                 *
     15       0.08858      0.13418      0.00909      0.03153      1.00000 |                 *
     16       0.08253      0.12963      0.00788      0.03275      1.00000 |                *
     17       0.07632      0.12494      0.00788      0.03275      1.00000 |                *
     18       0.07020      0.12120      0.00636      0.03275      1.00000 |               *
     19       0.06496      0.11838      0.00636      0.03214      1.00000 |               *
     20       0.06048      0.11595      0.00606      0.03214      1.00000 |              *
     30       0.03441      0.09869      0.00273      0.03093      1.00000 |            *
     40       0.01942      0.08724      0.00061      0.02971      1.00000 |           *
     50       0.01209      0.08091      0.00000      0.02668      1.00000 |          *
     60       0.00753      0.07751      0.00000      0.02668      1.00000 |         *
     70       0.00499      0.07476      0.00000      0.02547      1.00000 |         *
     80       0.00336      0.07398      0.00000      0.02486      1.00000 |         *
     90       0.00226      0.07468      0.00000      0.02547      1.00000 |         *
    100       0.00162      0.07493      0.00000      0.02547      1.00000 |         *
    110       0.00113      0.07507      0.00000      0.02486      1.00000 |         *
    120       0.00080      0.07629      0.00000      0.02426      1.00000 |         *
    130       0.00056      0.07767      0.00000      0.02304      1.00000 |         *
    140       0.00039      0.07749      0.00000      0.02304      1.00000 |         *
    150       0.00029      0.07941      0.00000      0.02365      1.00000 |         *
    160       0.00020      0.08031      0.00000      0.02304      1.00000 |          *
    170       0.00015      0.08214      0.00000      0.02304      1.00000 |          *
    180       0.00011      0.08394      0.00000      0.02244      1.00000 |          *
    190       0.00008      0.08539      0.00000      0.02244      1.00000 |          *
    200       0.00006      0.08686      0.00000      0.02183      1.00000 |          *
    210       0.00004      0.08712      0.00000      0.02122      1.00000 |           *
    220       0.00003      0.08922      0.00000      0.02122      1.00000 |           *
    230       0.00002      0.09234      0.00000      0.02062      1.00000 |           *
    240       0.00001      0.09219      0.00000      0.02062      1.00000 |           *
    250       0.00001      0.09293      0.00000      0.02122      1.00000 |           *
    260       0.00001      0.09522      0.00000      0.02122      1.00000 |            *
    270       0.00001      0.09956      0.00000      0.02122      1.00000 |            *
    280       0.00000      0.10340      0.00000      0.02062      1.00000 |             *
    290       0.00000      0.10500      0.00000      0.02062      1.00000 |             *
    300       0.00000      0.10586      0.00000      0.02001      1.00000 |             *
    310       0.00000      0.10599      0.00000      0.02001      1.00000 |             *
    320       0.00000      0.10661      0.00000      0.02001      1.00000 |             *
    330       0.00000      0.10864      0.00000      0.02001      1.00000 |             *
    340       0.00000      0.11110      0.00000      0.02001      1.00000 |              *
    350       0.00000      0.11372      0.00000      0.02062      1.00000 |              *
    360       0.00000      0.11610      0.00000      0.02062      1.00000 |              *
    370       0.00000      0.11861      0.00000      0.02062      1.00000 |               *
    380       0.00000      0.12022      0.00000      0.02062      1.00000 |               *
    390       0.00000      0.12460      0.00000      0.02062      1.00000 |               *
    400       0.00000      0.12449      0.00000      0.01880      1.00000 |               *

 Core TN model building:          5.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    233      1    396      1      7      4.98      1.76  F1
    224      1    400      1      7      4.65      1.88  F132
    216      1    400      1      7      4.67      1.80  F36
    207      1    396      1      7      4.85      1.63  F116
    200      5    400      1      7      4.18      1.91  F68
    200      4    392      2      7      5.16      1.42  F20
    199      2    400      1      7      4.62      1.68  F4
    195      2    397      1      7      4.92      1.50  F160
    194      3    397      2      7      5.57      1.18  F8
    193      4    400      2      7      4.83      1.53  F92
    191      2    399      2      7      5.32      1.28  F25
    189      1    400      1      7      5.77      1.05  F10
    188      5    400      2      7      5.14      1.34  F24
    188      2    399      3      7      5.34      1.25  F95
    183      1    399      1      7      4.92      1.41  F126
    182      6    395      1      7      5.26      1.25  F7
    178      6    400      1      7      5.49      1.12  F111
    177      1    400      1      7      4.36      1.61  F151
    172      1    400      2      7      5.72      0.98  F22
    172      1    400      2      7      4.86      1.35  F140
    171      1    399      2      7      5.18      1.21  F55
    171      1    399      2      7      5.59      1.03  F3
    170      1    400      2      7      5.24      1.18  F42
    170      1    398      2      7      5.76      0.95  F6
    168      8    391      2      7      5.02      1.25  F162
    164      3    400      1      7      5.29      1.11  F54
    164      1    400      2      7      5.52      1.02  F32
    164      7    399      1      7      4.64      1.38  F106
    163      2    397      3      7      5.48      1.03  F43
    162      1    390      2      7      5.28      1.10  F80
    162      4    398      1      7      4.88      1.27  F88
    161      2    400      2      7      5.04      1.19  F13
    160      3    399      2      7      5.76      0.90  F144
    157      1    378      3      7      5.25      1.08  F109
    154      1    396      1      7      5.04      1.14  F122
    153      3    399      1      7      5.00      1.15  F59
    152     21    400      2      7      5.32      1.02  F161
    151      6    400      2      7      5.38      0.99  F46
    151      1    392      2      7      5.75      0.85  F50
    149      2    400      2      7      5.60      0.90  F61
    149      3    399      3      7      5.82      0.81  F14
    148      3    392      1      7      4.46      1.31  F34
    147      8    399      2      7      5.29      1.00  F12
    147      1    390      2      7      4.97      1.11  F110
    144     11    400      1      7      4.75      1.17  F163
    142     20    398      1      7      5.49      0.89  F66
    139      1    399      3      7      5.68      0.81  F38
    138      7    400      1      7      4.96      1.05  F84
    137      8    392      2      7      5.54      0.84  F56
    137      1    400      3      7      5.74      0.78  F18
    135     11    399      2      7      5.42      0.87  F105
    133      1    400      3      7      5.91      0.70  F2
    132     13    397      2      7      4.95      1.01  F47
    131      2    394      2      7      5.80      0.72  F11
    131     18    400      1      7      5.11      0.95  F123
    130      3    400      1      7      4.86      1.02  F96
    130      4    397      1      7      5.24      0.90  F21
    128      5    400      2      7      5.26      0.88  F165
    127      2    389      1      7      5.09      0.93  F136
    127      1    396      2      7      5.78      0.71  F17
    127      1    399      2      7      5.41      0.82  F9
    124      8    398      1      7      5.16      0.88  F117
    124      1    400      1      7      5.02      0.93  F124
    124      2    399      2      7      5.21      0.87  F15
    121      3    397      2      7      5.64      0.71  F166
    120      3    392      2      7      5.74      0.68  F29
    119      1    400      1      7      4.03      1.18  F146
    119      4    399      1      7      4.99      0.90  F89
    118      2    396      3      7      5.05      0.87  F121
    117      1    397      1      7      5.03      0.87  F35
    117      1    400      1      7      5.18      0.83  F158
    116      2    400      3      7      5.68      0.67  F30
    115      1    399      2      7      5.75      0.65  F115
    115      8    400      1      7      4.85      0.91  F143
    115      4    399      3      7      5.72      0.66  F107
    115      8    369      3      7      5.92      0.60  F75
    112      3    382      2      7      5.61      0.67  F154
    112      6    388      1      7      5.02      0.84  F72
    112      4    399      3      7      5.87      0.60  F58
    111      1    399      3      7      5.47      0.70  F93
    111      2    400      1      7      4.98      0.84  F86
    111      1    399      1      7      5.51      0.69  F23
    109      5    395      4      7      5.91      0.57  F28
    109      3    400      3      7      4.99      0.82  F19
    106      6    353      1      7      5.29      0.72  F141
    106      1    395      1      7      5.51      0.66  F27
    105      3    400      2      7      5.12      0.76  F102
    105      1    389      2      7      5.60      0.63  F52
    104      2    400      3      7      5.74      0.59  F78
    103      8    399      2      7      5.48      0.65  F73
    101      3    400      2      7      5.61      0.60  F63
    100      6    395      1      7      4.93      0.77  F5
     99     11    396      1      7      5.19      0.70  F138
     99      3    400      1      7      5.78      0.55  F39
     99      5    399      2      7      5.47      0.63  F49
     98      4    394      2      7      5.80      0.54  F16
     98      4    398      1      7      4.68      0.81  F70
     95      9    391      2      7      5.60      0.57  F44
     95      1    393      3      7      5.84      0.51  F81
     94      6    400      3      7      5.81      0.52  F94
     93      2    395      2      7      5.41      0.60  F64
     93      1    399      3      7      5.90      0.49  F83
     92      6    400      3      7      5.63      0.55  F120
     91      1    396      2      7      5.88      0.48  F85
     91      4    399      1      7      5.29      0.62  F77
     90     19    395      1      7      5.86      0.48  F108
     89     17    396      3      7      5.96      0.46  F155
     89     10    395      3      7      5.40      0.58  F137
     89      8    391      2      7      5.61      0.53  F45
     89     10    397      1      7      4.52      0.78  F31
     89     25    399      1      7      4.58      0.76  F145
     88      6    399      3      7      5.43      0.57  F97
     87      2    397      2      7      5.31      0.59  F65
     87      6    394      3      7      5.95      0.45  F74
     87      2    400      2      7      6.21      0.39  F33
     87      5    390      2      7      5.64      0.51  F133
     86     12    394      3      7      5.66      0.50  F134
     86      8    399      2      7      5.87      0.46  F48
     85      1    391      1      7      4.74      0.69  F129
     85      1    399      2      7      5.65      0.50  F127
     84      5    398      2      7      5.01      0.63  F99
     84      5    393      1      7      4.93      0.65  F76
     83      3    400      2      7      5.14      0.59  F91
     83      1    390      4      7      6.16      0.38  F62
     83      3    400      3      7      6.10      0.40  F60
     82      5    393      1      7      5.26      0.56  F118
     81      2    394      2      7      5.83      0.44  F156
     81      7    397      2      7      5.46      0.52  F53
     81     18    399      1      7      5.35      0.54  F67
     80      3    395      2      7      5.38      0.53  F139
     79     19    400      3      7      6.10      0.38  F26
     79     12    400      1      7      5.23      0.55  F37
     78     16    386      2      7      5.51      0.49  F51
     77     20    398      3      7      5.75      0.43  F98
     76      2    392      2      7      5.70      0.44  F112
     76      1    395      2      7      5.49      0.48  F69
     76     10    396      2      7      5.70      0.44  F147
     74     27    391      3      7      5.35      0.49  F148
     73      4    382      1      7      5.05      0.54  F131
     72     15    398      3      7      5.99      0.36  F87
     71      9    388      3      7      5.75      0.40  F41
     70      8    384      3      7      5.23      0.49  F142
     69     12    389      3      7      5.77      0.39  F157
     67     17    390      2      7      5.10      0.49  F119
     67     14    400      4      7      6.12      0.32  F90
     67      7    393      3      7      5.75      0.38  F113
     66      7    394      2      7      5.58      0.40  F104
     65     40    392      2      7      5.72      0.37  F79
     65     12    390      3      7      5.74      0.37  F128
     64      3    378      3      7      5.63      0.38  F159
     61     10    379      3      7      5.92      0.32  F40
     61      3    393      2      7      5.38      0.40  F125
     58      5    385      1      7      5.14      0.42  F135
     55      7    395      3      7      5.84      0.30  F103
     50     20    394      4      7      6.26      0.22  F114
     50      4    400      2      7      5.86      0.27  F164
     49     10    399      2      7      6.10      0.23  F130
     48      9    394      1      7      5.17      0.34  F150
     48      2    400      3      7      5.46      0.31  F149
     46     11    399      3      7      6.04      0.23  F82
     44      1    394      1      7      5.70      0.25  F153
     43     10    385      2      7      5.40      0.28  F100
     43     17    381      3      7      6.23      0.19  F57
     41      6    399      4      7      5.73      0.23  F71
     34      5    378      3      7      6.03      0.17  F101
     28     24    377      3      7      6.25      0.12  F152

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    38 terminal nodes
    Largest :    84 terminal nodes
    Average :     58.55750 terminal nodes

 Reconciling 3300 Learn sample scores across 5 selected models,
 the largest having 400 trees, to compute gains and PS tables.

 Reconciling 1649 Test sample scores across 5 selected models,
 the largest having 400 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 78

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     3300      3300.00
 N Test  Obs:     1649      1649.00
 Learn Rate :    0.1000000

 Storage requirements: 46446 tree / 1 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           78      0.07338
                  ROC          317      0.99619
                 Lift            2      6.49213
              KS-stat          337      0.96132
          Class.Error          400      0.01880

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.35182     0.36314     0.97494     0.92304     6.48330     6.30494     0.87863     0.79016     0.15424     0.15403
      2     0.30236     0.31838     0.97993     0.95393     6.48330     6.49213     0.91565     0.82808     0.15424     0.15403
     10     0.13066     0.16786     0.99225     0.98250     6.48330     6.49213     0.96695     0.87002     0.01303     0.03457
     20     0.06048     0.11595     0.99976     0.98485     6.48330     6.49213     0.99052     0.88398     0.00606     0.03214
     30     0.03441     0.09869     0.99997     0.98559     6.48330     6.49213     0.99624     0.89366     0.00273     0.03093
     36     0.02418     0.09091     1.00000     0.98831     6.48330     6.49213     1.00000     0.89433     0.00121     0.03032
     40     0.01942     0.08724     1.00000     0.98907     6.48330     6.49213     1.00000     0.89898     0.00061     0.02971
     47     0.01391     0.08241     1.00000     0.99089     6.48330     6.49213     1.00000     0.90688     0.00000     0.02729
     50     0.01209     0.08091     1.00000     0.99107     6.48330     6.49213     1.00000     0.90831     0.00000     0.02668
     60     0.00753     0.07751     1.00000     0.99228     6.48330     6.49213     1.00000     0.91475     0.00000     0.02668
     70     0.00499     0.07476     1.00000     0.99290     6.48330     6.49213     1.00000     0.92050     0.00000     0.02547
     78     0.00359     0.07338     1.00000     0.99323     6.48330     6.49213     1.00000     0.92013     0.00000     0.02486
     80     0.00336     0.07398     1.00000     0.99327     6.48330     6.49213     1.00000     0.91978     0.00000     0.02486
     90     0.00226     0.07468     1.00000     0.99348     6.48330     6.49213     1.00000     0.92371     0.00000     0.02547
    100     0.00162     0.07493     1.00000     0.99316     6.48330     6.49213     1.00000     0.93014     0.00000     0.02547
    110     0.00113     0.07507     1.00000     0.99364     6.48330     6.49213     1.00000     0.92835     0.00000     0.02486
    120     0.00080     0.07629     1.00000     0.99401     6.48330     6.49213     1.00000     0.93192     0.00000     0.02426
    130     0.00056     0.07767     1.00000     0.99436     6.48330     6.49213     1.00000     0.93339     0.00000     0.02304
    140     0.00039     0.07749     1.00000     0.99473     6.48330     6.49213     1.00000     0.93519     0.00000     0.02304
    150     0.00029     0.07941     1.00000     0.99489     6.48330     6.49213     1.00000     0.94092     0.00000     0.02365
    160     0.00020     0.08031     1.00000     0.99524     6.48330     6.49213     1.00000     0.94092     0.00000     0.02304
    170     0.00015     0.08214     1.00000     0.99513     6.48330     6.49213     1.00000     0.94307     0.00000     0.02304
    180     0.00011     0.08394     1.00000     0.99500     6.48330     6.49213     1.00000     0.94629     0.00000     0.02244
    190     0.00008     0.08539     1.00000     0.99503     6.48330     6.49213     1.00000     0.94558     0.00000     0.02244
    200     0.00006     0.08686     1.00000     0.99506     6.48330     6.49213     1.00000     0.94701     0.00000     0.02183
    210     0.00004     0.08712     1.00000     0.99526     6.48330     6.49213     1.00000     0.94736     0.00000     0.02122
    220     0.00003     0.08922     1.00000     0.99536     6.48330     6.49213     1.00000     0.94880     0.00000     0.02122
    230     0.00002     0.09234     1.00000     0.99509     6.48330     6.49213     1.00000     0.94665     0.00000     0.02062
    240     0.00001     0.09219     1.00000     0.99533     6.48330     6.49213     1.00000     0.95237     0.00000     0.02062
    250     0.00001     0.09293     1.00000     0.99548     6.48330     6.49213     1.00000     0.95452     0.00000     0.02122
    260     0.00001     0.09522     1.00000     0.99553     6.48330     6.49213     1.00000     0.95739     0.00000     0.02122
    270     0.00001     0.09956     1.00000     0.99525     6.48330     6.49213     1.00000     0.95595     0.00000     0.02122
    280     0.00000     0.10340     1.00000     0.99519     6.48330     6.49213     1.00000     0.95202     0.00000     0.02062
    290     0.00000     0.10500     1.00000     0.99547     6.48330     6.49213     1.00000     0.95524     0.00000     0.02062
    300     0.00000     0.10586     1.00000     0.99578     6.48330     6.49213     1.00000     0.95595     0.00000     0.02001
    310     0.00000     0.10599     1.00000     0.99597     6.48330     6.49213     1.00000     0.95667     0.00000     0.02001
    317     0.00000     0.10658     1.00000     0.99619     6.48330     6.49213     1.00000     0.95954     0.00000     0.02001
    320     0.00000     0.10661     1.00000     0.99613     6.48330     6.49213     1.00000     0.95954     0.00000     0.02001
    330     0.00000     0.10864     1.00000     0.99596     6.48330     6.49213     1.00000     0.95989     0.00000     0.02001
    337     0.00000     0.11061     1.00000     0.99607     6.48330     6.49213     1.00000     0.96132     0.00000     0.02062
    340     0.00000     0.11110     1.00000     0.99608     6.48330     6.49213     1.00000     0.96132     0.00000     0.02001
    350     0.00000     0.11372     1.00000     0.99602     6.48330     6.49213     1.00000     0.95989     0.00000     0.02062
    360     0.00000     0.11610     1.00000     0.99602     6.48330     6.49213     1.00000     0.95846     0.00000     0.02062
    370     0.00000     0.11861     1.00000     0.99593     6.48330     6.49213     1.00000     0.95667     0.00000     0.02062
    380     0.00000     0.12022     1.00000     0.99602     6.48330     6.49213     1.00000     0.95739     0.00000     0.02062
    390     0.00000     0.12460     1.00000     0.99585     6.48330     6.49213     1.00000     0.95739     0.00000     0.02062
    400     0.00000     0.12449     1.00000     0.99605     6.48330     6.49213     1.00000     0.95810     0.00000     0.01880


 =========================================
 Variable Importance for the 78-tree Model
 =========================================

               Abs     Rel

 F36     100.00000  100.00 |***********|
 F132     61.96057   61.96 |*******    |
 F35      53.81744   53.82 |******     |
 F151     50.53536   50.54 |******     |
 F1       49.88297   49.88 |******     |
 F126     35.85193   35.85 |*****      |
 F124     35.84665   35.85 |*****      |
 F102     32.47685   32.48 |****       |
 F122     31.95037   31.95 |****       |
 F55      30.75709   30.76 |****       |
 F42      30.63606   30.64 |****       |
 F83      30.45675   30.46 |****       |
 F9       29.86917   29.87 |****       |
 F163     28.63724   28.64 |****       |
 F140     28.12942   28.13 |****       |
 F62      27.50964   27.51 |****       |
 F43      27.05648   27.06 |****       |
 F156     26.96961   26.97 |****       |
 F22      25.77124   25.77 |****       |
 F4       25.63136   25.63 |****       |
 F32      24.52390   24.52 |***        |
 F80      24.41593   24.42 |***        |
 F91      23.96929   23.97 |***        |
 F25      23.55602   23.56 |***        |
 F146     23.13921   23.14 |***        |
 F50      22.94325   22.94 |***        |
 F154     22.68504   22.69 |***        |
 F38      22.63779   22.64 |***        |
 F109     22.36740   22.37 |***        |
 F86      21.55480   21.55 |***        |
 F15      20.75838   20.76 |***        |
 F153     19.27507   19.28 |***        |
 F115     19.23759   19.24 |***        |
 F111     17.17260   17.17 |***        |
 F10      16.96904   16.97 |***        |
 F52      16.75402   16.75 |***        |
 F29      16.63277   16.63 |***        |
 F95      15.98921   15.99 |***        |
 F136     15.97212   15.97 |***        |
 F110     15.87760   15.88 |***        |
 F127     15.56655   15.57 |***        |
 F17      15.22603   15.23 |**         |
 F144     14.74347   14.74 |**         |
 F23      14.73239   14.73 |**         |
 F3       14.71582   14.72 |**         |
 F18      14.50084   14.50 |**         |
 F125     14.44823   14.45 |**         |
 F44      14.37538   14.38 |**         |
 F160     14.35633   14.36 |**         |
 F89      14.19554   14.20 |**         |
 F5       13.98281   13.98 |**         |
 F54      13.90172   13.90 |**         |
 F88      13.51636   13.52 |**         |
 F76      13.49436   13.49 |**         |
 F6       13.41787   13.42 |**         |
 F92      13.40691   13.41 |**         |
 F81      13.20027   13.20 |**         |
 F8       13.16090   13.16 |**         |
 F158     12.96298   12.96 |**         |
 F116     12.81575   12.82 |**         |
 F31      12.74193   12.74 |**         |
 F105     12.59104   12.59 |**         |
 F39      12.58833   12.59 |**         |
 F85      12.39742   12.40 |**         |
 F59      12.34915   12.35 |**         |
 F61      12.23029   12.23 |**         |
 F162     12.04735   12.05 |**         |
 F134     11.97156   11.97 |**         |
 F68      11.74817   11.75 |**         |
 F58      11.52287   11.52 |**         |
 F139     11.43176   11.43 |**         |
 F93      11.36094   11.36 |**         |
 F135     10.98533   10.99 |**         |
 F165     10.89361   10.89 |**         |
 F112     10.84659   10.85 |**         |
 F67      10.77196   10.77 |**         |
 F27      10.18738   10.19 |**         |
 F69      10.14466   10.14 |**         |
 F14      10.13931   10.14 |**         |
 F56       9.88969    9.89 |**         |
 F66       9.67829    9.68 |**         |
 F84       9.67627    9.68 |**         |
 F143      9.59231    9.59 |**         |
 F129      9.55971    9.56 |**         |
 F78       9.48072    9.48 |**         |
 F121      9.40207    9.40 |**         |
 F138      9.35512    9.36 |**         |
 F24       9.29285    9.29 |**         |
 F63       9.24193    9.24 |**         |
 F21       9.05371    9.05 |**         |
 F13       8.98516    8.99 |**         |
 F11       8.97198    8.97 |**         |
 F133      8.84277    8.84 |**         |
 F45       8.77269    8.77 |**         |
 F30       8.52319    8.52 |**         |
 F28       8.39387    8.39 |**         |
 F20       8.35059    8.35 |**         |
 F145      8.24124    8.24 |**         |
 F106      8.14354    8.14 |**         |
 F117      8.13304    8.13 |**         |
 F70       8.10295    8.10 |**         |
 F64       7.90371    7.90 |**         |
 F53       7.88930    7.89 |**         |
 F147      7.80586    7.81 |**         |
 F7        7.40574    7.41 |**         |
 F2        7.37313    7.37 |**         |
 F119      7.26967    7.27 |**         |
 F46       7.09534    7.10 |**         |
 F96       7.02685    7.03 |**         |
 F12       6.88139    6.88 |**         |
 F164      6.77929    6.78 |**         |
 F99       6.76142    6.76 |**         |
 F159      6.66773    6.67 |**         |
 F65       6.61504    6.62 |**         |
 F49       6.56670    6.57 |**         |
 F141      6.54165    6.54 |**         |
 F149      6.50147    6.50 |**         |
 F128      6.46672    6.47 |**         |
 F37       6.45951    6.46 |**         |
 F73       6.11202    6.11 |**         |
 F48       6.08231    6.08 |**         |
 F107      6.05071    6.05 |**         |
 F51       5.95705    5.96 |**         |
 F101      5.90258    5.90 |**         |
 F123      5.88646    5.89 |**         |
 F142      5.80287    5.80 |**         |
 F19       5.68747    5.69 |**         |
 F33       5.53850    5.54 |**         |
 F82       5.42989    5.43 |*          |
 F157      5.39603    5.40 |*          |
 F16       5.32465    5.32 |*          |
 F94       5.30075    5.30 |*          |
 F60       5.23363    5.23 |*          |
 F104      5.23177    5.23 |*          |
 F75       5.20685    5.21 |*          |
 F34       5.11872    5.12 |*          |
 F74       4.90372    4.90 |*          |
 F97       4.89652    4.90 |*          |
 F120      4.81795    4.82 |*          |
 F150      4.65210    4.65 |*          |
 F118      4.40521    4.41 |*          |
 F130      4.12096    4.12 |*          |
 F113      4.10656    4.11 |*          |
 F161      3.90204    3.90 |*          |
 F79       3.80477    3.80 |*          |
 F72       3.68684    3.69 |*          |
 F114      3.50727    3.51 |*          |
 F148      3.49868    3.50 |*          |
 F90       3.44076    3.44 |*          |
 F100      3.30043    3.30 |*          |
 F155      3.22894    3.23 |*          |
 F77       3.22780    3.23 |*          |
 F166      3.19734    3.20 |*          |
 F131      3.10003    3.10 |*          |
 F108      3.01463    3.01 |*          |
 F57       2.94172    2.94 |*          |
 F47       2.69284    2.69 |*          |
 F40       2.63556    2.64 |*          |
 F41       2.47634    2.48 |*          |
 F71       2.34254    2.34 |*          |
 F87       2.28406    2.28 |*          |
 F103      2.26054    2.26 |*          |
 F152      2.19673    2.20 |*          |
 F98       2.07285    2.07 |*          |
 F26       2.00012    2.00 |*          |
 F137      1.44890    1.45 |*          |


 Learn Sample Misclassification by Target Class
 For The 78-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 2791.00      2791.00         0.00       0.0000
 1                  509.00       509.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 78-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1395.00      1394.00         1.00       0.0007
 1                  254.00       214.00        40.00       0.1575

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                6.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               5.000 sec ( 0.00 hrs,  83.33%)
    Core model:         5.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  16.67%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

