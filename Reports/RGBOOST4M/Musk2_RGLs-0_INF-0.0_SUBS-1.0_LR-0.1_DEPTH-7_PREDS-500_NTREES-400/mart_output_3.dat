
 The "USE "../Data/Classification/Musk2/SAMPLES4/data_tr" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 166 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 3300
 Records Kept in Learning sample: 3300

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1649
 Records Kept in Test sample: 1649

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         2791  84.58              2791.00  84.58
                 T        (1395  84.60)            (1395.00  84.60)
 1               L          509  15.42               509.00  15.42
                 T         (254  15.40)             (254.00  15.40)
 -----------------------------------------------------------------
 Totals
 0                         4186  84.58              4186.00  84.58
 1                          763  15.42               763.00  15.42
 -----------------------------------------------------------------
 Total                     4949                     4949.00
 Total Learn               3300                     3300.00
 Total Test                1649                     1649.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.35620      0.36291      0.15424      0.15403      1.00000 |                                               *
      2       0.30928      0.32012      0.15424      0.15403      1.00000 |                                         *
      3       0.27502      0.28939      0.15424      0.15403      1.00000 |                                     *
      4       0.24796      0.26471      0.15303      0.15221      1.00000 |                                  *
      5       0.22570      0.24519      0.06242      0.06853      1.00000 |                               *
      6       0.20667      0.22862      0.04848      0.05518      1.00000 |                             *
      7       0.19070      0.21398      0.04273      0.05276      1.00000 |                           *
      8       0.17623      0.20158      0.03788      0.05155      1.00000 |                          *
      9       0.16435      0.19169      0.03606      0.05155      1.00000 |                        *
     10       0.15419      0.18294      0.03364      0.04912      1.00000 |                       *
     11       0.14416      0.17411      0.03182      0.04791      1.00000 |                      *
     12       0.13422      0.16518      0.02788      0.04366      1.00000 |                     *
     13       0.12570      0.15851      0.02576      0.04306      1.00000 |                    *
     14       0.11754      0.15148      0.02364      0.04366      1.00000 |                   *
     15       0.10971      0.14518      0.01970      0.04124      1.00000 |                  *
     16       0.10331      0.14059      0.01727      0.04002      1.00000 |                  *
     17       0.09706      0.13579      0.01576      0.04002      1.00000 |                 *
     18       0.09204      0.13208      0.01424      0.03942      1.00000 |                *
     19       0.08707      0.12907      0.01333      0.03820      1.00000 |                *
     20       0.08140      0.12451      0.01242      0.03517      1.00000 |               *
     30       0.04883      0.10052      0.00485      0.03032      1.00000 |            *
     40       0.03068      0.08125      0.00273      0.02365      1.00000 |          *
     50       0.02192      0.06956      0.00182      0.02062      1.00000 |        *
     60       0.01541      0.06235      0.00030      0.01941      1.00000 |       *
     70       0.01143      0.05709      0.00000      0.01637      1.00000 |       *
     80       0.00876      0.05325      0.00000      0.01637      1.00000 |      *
     90       0.00656      0.05037      0.00000      0.01637      1.00000 |      *
    100       0.00506      0.04678      0.00000      0.01637      1.00000 |     *
    110       0.00387      0.04443      0.00000      0.01637      1.00000 |     *
    120       0.00292      0.04198      0.00000      0.01455      1.00000 |     *
    130       0.00212      0.04055      0.00000      0.01334      1.00000 |    *
    140       0.00165      0.03894      0.00000      0.01455      1.00000 |    *
    150       0.00126      0.03780      0.00000      0.01334      1.00000 |    *
    160       0.00095      0.03720      0.00000      0.01334      1.00000 |    *
    170       0.00072      0.03592      0.00000      0.01395      1.00000 |    *
    180       0.00056      0.03540      0.00000      0.01395      1.00000 |    *
    190       0.00041      0.03523      0.00000      0.01395      1.00000 |    *
    200       0.00032      0.03503      0.00000      0.01273      1.00000 |    *
    210       0.00026      0.03462      0.00000      0.01152      1.00000 |    *
    220       0.00019      0.03427      0.00000      0.01213      1.00000 |    *
    230       0.00015      0.03435      0.00000      0.01152      1.00000 |    *
    240       0.00011      0.03390      0.00000      0.01213      1.00000 |   *
    250       0.00008      0.03414      0.00000      0.01273      1.00000 |    *
    260       0.00006      0.03373      0.00000      0.01273      1.00000 |   *
    270       0.00005      0.03305      0.00000      0.01152      1.00000 |   *
    280       0.00004      0.03302      0.00000      0.01152      1.00000 |   *
    290       0.00003      0.03211      0.00000      0.01152      1.00000 |   *
    300       0.00002      0.03241      0.00000      0.01213      1.00000 |   *
    310       0.00002      0.03261      0.00000      0.01213      1.00000 |   *
    320       0.00001      0.03284      0.00000      0.01152      1.00000 |   *
    330       0.00001      0.03319      0.00000      0.01152      1.00000 |   *
    340       0.00001      0.03332      0.00000      0.01152      1.00000 |   *
    350       0.00001      0.03392      0.00000      0.01152      1.00000 |   *
    360       0.00000      0.03331      0.00000      0.01152      1.00000 |   *
    370       0.00000      0.03352      0.00000      0.01152      1.00000 |   *
    380       0.00000      0.03406      0.00000      0.01152      1.00000 |    *
    390       0.00000      0.03451      0.00000      0.01152      1.00000 |    *
    400       0.00000      0.03448      0.00000      0.01092      1.00000 |    *

 Core TN model building:          4.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    201      5    400      1      7      4.07      1.98  F132
    194      1    398      2      7      4.69      1.61  F63
    187      1    399      1      7      4.43      1.67  F122
    180      3    400      1      7      4.93      1.38  F162
    167      4    400      2      7      4.68      1.39  F163
    163      9    400      2      7      4.82      1.30  F102
    161      1    398      2      7      5.40      1.05  F22
    156      1    399      1      7      4.38      1.41  F36
    148      9    398      1      7      4.51      1.29  F55
    148      6    392      1      7      4.49      1.30  F1
    147      1    398      2      7      5.50      0.92  F42
    146      1    400      1      7      4.93      1.12  F89
    132      1    400      1      7      4.51      1.15  F116
    132      5    400      1      7      4.33      1.21  F92
    132      1    397      2      7      4.42      1.18  F161
    129      7    400      2      7      5.16      0.92  F29
    129      1    398      2      7      5.21      0.90  F38
    128      1    399      2      7      5.41      0.83  F25
    125      2    395      1      7      5.13      0.90  F59
    123     14    399      3      7      5.42      0.79  F144
    121      1    389      2      7      4.89      0.94  F126
    120      1    399      3      7      5.18      0.85  F140
    116      1    397      2      7      5.27      0.79  F124
    114      1    399      1      7      4.42      1.02  F96
    111      6    396      1      7      5.16      0.79  F160
    109      8    397      1      7      4.74      0.89  F131
    109      2    400      1      7      5.05      0.81  F136
    108      3    389      2      7      5.45      0.69  F110
    107      4    400      1      7      3.96      1.08  F80
    106      7    396      1      7      3.78      1.12  F158
    105      8    400      1      7      4.45      0.93  F123
    103      4    396      1      7      4.89      0.80  F68
    103      8    397      2      7      5.02      0.77  F109
     99      1    397      2      7      5.44      0.63  F20
     98      1    396      2      7      5.50      0.61  F3
     97      4    399      1      7      4.70      0.80  F88
     95      1    398      1      7      5.09      0.69  F70
     94      1    394      2      7      5.29      0.64  F151
     91      6    390      2      7      4.59      0.78  F6
     88      4    396      1      7      4.57      0.76  F105
     88     26    398      1      7      4.30      0.82  F111
     84      4    386      1      7      4.54      0.73  F34
     84      1    399      3      7      5.43      0.54  F43
     83     12    389      2      7      4.55      0.72  F97
     82      6    399      2      7      5.13      0.59  F100
     82      1    396      1      7      5.01      0.61  F10
     80      3    400      1      7      4.09      0.78  F14
     79      2    399      2      7      5.47      0.50  F54
     79      5    397      2      7      4.94      0.61  F66
     77      1    395      1      7      4.66      0.64  F83
     76     22    393      2      7      5.17      0.54  F143
     75      1    389      2      7      5.24      0.52  F15
     74     17    400      1      7      5.14      0.53  F137
     74     12    400      3      7      5.57      0.45  F61
     74      3    387      2      7      4.65      0.62  F13
     72      2    400      2      7      5.14      0.51  F93
     71      2    399      3      7      5.42      0.46  F40
     71      1    396      2      7      4.99      0.54  F50
     70      2    387      2      7      4.81      0.56  F35
     69      2    397      1      7      5.83      0.38  F8
     68      4    399      1      7      5.56      0.42  F52
     68      5    399      1      7      5.32      0.46  F46
     68      2    400      1      7      4.87      0.53  F148
     66     17    397      2      7      5.32      0.44  F85
     65      1    393      3      7      4.88      0.51  F7
     64      2    391      1      7      3.92      0.65  F138
     64     10    398      2      7      5.05      0.47  F98
     64     14    397      2      7      5.78      0.35  F99
     64     15    398      2      7      5.67      0.37  F121
     63      3    383      2      7      5.05      0.47  F58
     63     10    397      2      7      5.48      0.40  F69
     62      5    400      1      7      5.26      0.43  F84
     62      9    394      3      7      5.29      0.42  F30
     62      2    397      2      7      5.24      0.43  F133
     61      4    391      1      7      4.74      0.50  F141
     61      3    400      2      7      5.43      0.39  F4
     61      5    373      2      7      5.25      0.42  F155
     61      7    397      1      7      4.95      0.47  F95
     60     12    393      1      7      5.45      0.38  F49
     60      3    391      2      7      5.05      0.44  F165
     60      9    394      1      7      4.40      0.54  F108
     60      3    396      1      7      5.10      0.44  F21
     59      2    398      3      7      5.08      0.43  F17
     59      1    400      1      7      5.85      0.32  F32
     58      8    394      1      7      4.31      0.54  F117
     58      1    394      3      7      5.52      0.36  F33
     58      8    391      2      7      4.72      0.48  F154
     58      1    390      2      7      5.66      0.34  F19
     58     19    399      3      7      5.59      0.35  F86
     56      2    383      1      7      5.50      0.35  F47
     56      2    400      3      7      4.41      0.50  F153
     54     25    400      2      7      4.91      0.42  F150
     54     16    393      1      7      2.94      0.68  F67
     53     17    398      2      7      5.53      0.33  F135
     52      2    383      3      7      5.48      0.33  F79
     52      1    400      1      7      4.90      0.40  F125
     52      8    393      3      7      5.27      0.36  F107
     51      3    377      2      7      5.65      0.30  F106
     50      4    393      3      7      5.76      0.28  F60
     50      6    385      3      7      5.76      0.28  F56
     49     19    368      1      7      4.63      0.41  F147
     49      1    392      1      7      5.67      0.29  F115
     48      1    399      2      7      5.29      0.33  F130
     48      2    391      3      7      5.94      0.25  F152
     48      3    400      3      7      5.31      0.32  F39
     48     34    399      3      7      5.44      0.31  F159
     48      1    400      3      7      5.48      0.30  F9
     47      2    375      2      7      4.96      0.36  F156
     47      2    400      3      7      5.53      0.29  F65
     46     16    387      3      7      5.26      0.32  F27
     46      8    391      3      7      5.22      0.32  F120
     46      6    398      2      7      4.76      0.37  F146
     45      5    398      3      7      5.82      0.25  F24
     45     23    382      2      7      5.27      0.31  F78
     45     21    388      2      7      4.82      0.36  F166
     45      7    397      2      7      5.36      0.30  F73
     44      6    394      3      7      5.61      0.26  F26
     44      8    400      2      7      5.30      0.30  F31
     44     11    396      3      7      5.82      0.24  F53
     43      1    385      2      7      5.07      0.32  F2
     42      2    388      1      7      5.81      0.23  F94
     41      3    395      3      7      5.22      0.29  F81
     41     25    398      2      7      5.68      0.24  F113
     41      4    390      2      7      5.66      0.24  F62
     41      7    400      2      7      5.34      0.27  F51
     40     24    393      3      7      5.08      0.29  F114
     40      8    394      2      7      4.60      0.34  F75
     40      6    398      3      7      5.63      0.24  F104
     40      5    390      1      7      5.10      0.29  F18
     39      1    390      3      7      5.77      0.22  F119
     39     36    393      2      7      5.64      0.23  F11
     39      8    396      3      7      5.28      0.27  F48
     38      4    391      1      7      5.05      0.28  F90
     38      5    395      1      7      5.68      0.22  F45
     38      7    385      2      7      5.63      0.23  F103
     38     20    399      1      7      4.47      0.34  F37
     38      9    391      3      7      5.84      0.21  F112
     37     18    397      2      7      5.24      0.26  F157
     37      8    362      3      7      5.70      0.21  F44
     36      4    386      2      7      5.78      0.20  F64
     36      8    390      3      7      5.47      0.23  F77
     36     31    395      1      7      3.83      0.38  F91
     35     16    399      1      7      3.66      0.38  F145
     35     10    396      1      7      5.34      0.23  F72
     34      2    398      4      7      6.06      0.17  F129
     34      5    396      3      7      5.97      0.17  F16
     33     21    400      3      7      6.15      0.15  F28
     33      3    385      4      7      5.94      0.17  F127
     33     21    384      2      7      4.79      0.27  F164
     32     29    354      3      7      5.69      0.19  F87
     32      5    393      3      7      5.88      0.17  F134
     32     23    393      3      7      5.28      0.22  F139
     32      1    388      2      7      5.81      0.18  F12
     31     34    397      2      7      5.61      0.19  F57
     31     39    390      2      7      5.65      0.18  F74
     30     15    397      3      7      5.80      0.17  F23
     30      6    399      4      7      6.10      0.14  F82
     30     25    393      1      7      4.90      0.23  F71
     28      4    377      2      7      5.43      0.18  F118
     28     16    392      4      7      5.86      0.15  F76
     26      8    389      3      7      5.88      0.14  F41
     25     15    371      4      7      6.16      0.12  F142
     25     22    388      3      7      5.88      0.13  F101
     24     34    378      2      7      5.58      0.15  F128
     23      1    370      1      7      5.43      0.15  F5
     20     21    365      3      7      5.50      0.13  F149

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    17 terminal nodes
    Largest :    60 terminal nodes
    Average :     33.75000 terminal nodes

 Reconciling 3300 Learn sample scores across 5 selected models,
 the largest having 400 trees, to compute gains and PS tables.

 Reconciling 1649 Test sample scores across 5 selected models,
 the largest having 400 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 289

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     3300      3300.00
 N Test  Obs:     1649      1649.00
 Learn Rate :    0.1000000

 Storage requirements: 26600 tree / 1 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL          289      0.03210
                  ROC          400      0.99940
                 Lift          112      6.49213
              KS-stat          193      0.98316
          Class.Error          397      0.01031

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.35620     0.36291     0.97814     0.92492     6.42633     6.00098     0.89426     0.81950     0.15424     0.15403
      2     0.30928     0.32012     0.97868     0.95652     6.48330     6.21752     0.91163     0.83958     0.15424     0.15403
     10     0.15419     0.18294     0.98720     0.96691     6.48330     6.29528     0.94101     0.87288     0.03364     0.04912
     20     0.08140     0.12451     0.99746     0.98438     6.48330     6.45276     0.96731     0.89435     0.01242     0.03517
     30     0.04883     0.10052     0.99960     0.98751     6.48330     6.41339     0.98142     0.90690     0.00485     0.03032
     40     0.03068     0.08125     0.99998     0.99245     6.48330     6.41339     0.99642     0.92301     0.00273     0.02365
     49     0.02226     0.07030     1.00000     0.99456     6.48330     6.45276     1.00000     0.92875     0.00182     0.02122
     50     0.02192     0.06956     1.00000     0.99467     6.48330     6.45276     1.00000     0.93090     0.00182     0.02062
     60     0.01541     0.06235     1.00000     0.99596     6.48330     6.45276     1.00000     0.93734     0.00030     0.01941
     62     0.01453     0.06137     1.00000     0.99606     6.48330     6.45276     1.00000     0.93734     0.00000     0.02001
     70     0.01143     0.05709     1.00000     0.99668     6.48330     6.45276     1.00000     0.94592     0.00000     0.01637
     80     0.00876     0.05325     1.00000     0.99715     6.48330     6.45276     1.00000     0.95201     0.00000     0.01637
     90     0.00656     0.05037     1.00000     0.99757     6.48330     6.45276     1.00000     0.95559     0.00000     0.01637
    100     0.00506     0.04678     1.00000     0.99801     6.48330     6.45276     1.00000     0.96058     0.00000     0.01637
    110     0.00387     0.04443     1.00000     0.99821     6.48330     6.45276     1.00000     0.96168     0.00000     0.01637
    112     0.00359     0.04347     1.00000     0.99831     6.48330     6.49213     1.00000     0.96202     0.00000     0.01637
    120     0.00292     0.04198     1.00000     0.99845     6.48330     6.49213     1.00000     0.96453     0.00000     0.01455
    130     0.00212     0.04055     1.00000     0.99857     6.48330     6.49213     1.00000     0.96667     0.00000     0.01334
    140     0.00165     0.03894     1.00000     0.99865     6.48330     6.49213     1.00000     0.96882     0.00000     0.01455
    150     0.00126     0.03780     1.00000     0.99880     6.48330     6.49213     1.00000     0.97241     0.00000     0.01334
    160     0.00095     0.03720     1.00000     0.99888     6.48330     6.49213     1.00000     0.97420     0.00000     0.01334
    170     0.00072     0.03592     1.00000     0.99898     6.48330     6.49213     1.00000     0.97742     0.00000     0.01395
    180     0.00056     0.03540     1.00000     0.99902     6.48330     6.49213     1.00000     0.97886     0.00000     0.01395
    190     0.00041     0.03523     1.00000     0.99905     6.48330     6.49213     1.00000     0.98244     0.00000     0.01395
    193     0.00038     0.03522     1.00000     0.99905     6.48330     6.49213     1.00000     0.98316     0.00000     0.01395
    200     0.00032     0.03503     1.00000     0.99906     6.48330     6.49213     1.00000     0.98316     0.00000     0.01273
    210     0.00026     0.03462     1.00000     0.99905     6.48330     6.49213     1.00000     0.97958     0.00000     0.01152
    220     0.00019     0.03427     1.00000     0.99909     6.48330     6.49213     1.00000     0.98244     0.00000     0.01213
    230     0.00015     0.03435     1.00000     0.99912     6.48330     6.49213     1.00000     0.98244     0.00000     0.01152
    240     0.00011     0.03390     1.00000     0.99915     6.48330     6.49213     1.00000     0.98244     0.00000     0.01213
    250     0.00008     0.03414     1.00000     0.99917     6.48330     6.49213     1.00000     0.98173     0.00000     0.01273
    260     0.00006     0.03373     1.00000     0.99922     6.48330     6.49213     1.00000     0.98173     0.00000     0.01273
    270     0.00005     0.03305     1.00000     0.99927     6.48330     6.49213     1.00000     0.98316     0.00000     0.01152
    280     0.00004     0.03302     1.00000     0.99927     6.48330     6.49213     1.00000     0.98316     0.00000     0.01152
    289     0.00003     0.03210     1.00000     0.99931     6.48330     6.49213     1.00000     0.98316     0.00000     0.01152
    290     0.00003     0.03211     1.00000     0.99932     6.48330     6.49213     1.00000     0.98316     0.00000     0.01152
    300     0.00002     0.03241     1.00000     0.99931     6.48330     6.49213     1.00000     0.98173     0.00000     0.01213
    310     0.00002     0.03261     1.00000     0.99932     6.48330     6.49213     1.00000     0.98173     0.00000     0.01213
    320     0.00001     0.03284     1.00000     0.99931     6.48330     6.49213     1.00000     0.98136     0.00000     0.01152
    330     0.00001     0.03319     1.00000     0.99929     6.48330     6.49213     1.00000     0.98136     0.00000     0.01152
    340     0.00001     0.03332     1.00000     0.99931     6.48330     6.49213     1.00000     0.98136     0.00000     0.01152
    350     0.00001     0.03392     1.00000     0.99933     6.48330     6.49213     1.00000     0.98137     0.00000     0.01152
    360     0.00000     0.03331     1.00000     0.99936     6.48330     6.49213     1.00000     0.98137     0.00000     0.01152
    370     0.00000     0.03352     1.00000     0.99935     6.48330     6.49213     1.00000     0.98066     0.00000     0.01152
    380     0.00000     0.03406     1.00000     0.99937     6.48330     6.49213     1.00000     0.98209     0.00000     0.01152
    390     0.00000     0.03451     1.00000     0.99938     6.48330     6.49213     1.00000     0.98209     0.00000     0.01152
    397     0.00000     0.03458     1.00000     0.99938     6.48330     6.49213     1.00000     0.98209     0.00000     0.01031
    400     0.00000     0.03448     1.00000     0.99940     6.48330     6.49213     1.00000     0.98209     0.00000     0.01092


 ==========================================
 Variable Importance for the 289-tree Model
 ==========================================

               Abs     Rel

 F36     100.00000  100.00 |***********|
 F35      58.77891   58.78 |*******    |
 F63      52.07098   52.07 |******     |
 F151     48.28307   48.28 |******     |
 F126     47.39402   47.39 |******     |
 F33      45.97972   45.98 |******     |
 F124     41.38914   41.39 |*****      |
 F7       38.24694   38.25 |*****      |
 F140     32.51066   32.51 |****       |
 F9       32.44597   32.45 |****       |
 F132     31.42719   31.43 |****       |
 F50      29.57682   29.58 |****       |
 F38      29.50936   29.51 |****       |
 F163     28.86700   28.87 |****       |
 F22      28.80330   28.80 |****       |
 F83      25.28758   25.29 |***        |
 F96      24.06982   24.07 |***        |
 F122     23.56485   23.56 |***        |
 F43      23.08642   23.09 |***        |
 F25      21.28018   21.28 |***        |
 F10      20.81196   20.81 |***        |
 F156     20.47953   20.48 |***        |
 F133     19.52435   19.52 |***        |
 F92      19.51271   19.51 |***        |
 F32      18.94345   18.94 |***        |
 F15      18.69176   18.69 |***        |
 F58      18.68165   18.68 |***        |
 F1       18.23210   18.23 |***        |
 F89      17.63248   17.63 |***        |
 F17      16.97361   16.97 |***        |
 F152     16.70272   16.70 |***        |
 F153     16.67197   16.67 |***        |
 F129     16.33423   16.33 |***        |
 F93      15.99718   16.00 |***        |
 F116     15.78373   15.78 |***        |
 F120     15.34753   15.35 |**         |
 F42      15.20923   15.21 |**         |
 F136     14.78908   14.79 |**         |
 F20      14.65155   14.65 |**         |
 F155     14.57332   14.57 |**         |
 F21      14.55650   14.56 |**         |
 F165     14.35708   14.36 |**         |
 F110     13.99592   14.00 |**         |
 F70      13.73727   13.74 |**         |
 F19      13.46891   13.47 |**         |
 F109     13.36353   13.36 |**         |
 F119     13.29196   13.29 |**         |
 F54      13.21340   13.21 |**         |
 F47      13.12404   13.12 |**         |
 F31      12.69335   12.69 |**         |
 F141     12.64955   12.65 |**         |
 F77      12.01957   12.02 |**         |
 F162     11.92476   11.92 |**         |
 F161     11.64685   11.65 |**         |
 F88      11.60301   11.60 |**         |
 F115     11.46374   11.46 |**         |
 F69      11.45860   11.46 |**         |
 F148     11.43326   11.43 |**         |
 F59      11.22843   11.23 |**         |
 F130     11.07294   11.07 |**         |
 F158     11.00142   11.00 |**         |
 F55      10.98319   10.98 |**         |
 F29      10.52416   10.52 |**         |
 F79      10.46215   10.46 |**         |
 F6       10.30727   10.31 |**         |
 F66      10.23000   10.23 |**         |
 F40      10.03863   10.04 |**         |
 F102      9.96221    9.96 |**         |
 F30       9.84174    9.84 |**         |
 F125      9.68755    9.69 |**         |
 F144      9.66518    9.67 |**         |
 F81       9.47653    9.48 |**         |
 F13       9.29349    9.29 |**         |
 F80       9.10539    9.11 |**         |
 F46       9.06347    9.06 |**         |
 F99       8.80575    8.81 |**         |
 F2        8.78984    8.79 |**         |
 F3        8.71932    8.72 |**         |
 F39       8.69130    8.69 |**         |
 F84       8.41377    8.41 |**         |
 F160      8.33151    8.33 |**         |
 F14       8.27672    8.28 |**         |
 F106      8.18636    8.19 |**         |
 F60       8.16165    8.16 |**         |
 F95       8.08619    8.09 |**         |
 F131      8.06920    8.07 |**         |
 F146      7.96168    7.96 |**         |
 F97       7.95488    7.95 |**         |
 F61       7.94998    7.95 |**         |
 F75       7.84177    7.84 |**         |
 F82       7.79664    7.80 |**         |
 F68       7.41211    7.41 |**         |
 F105      7.38840    7.39 |**         |
 F98       7.29452    7.29 |**         |
 F157      7.21556    7.22 |**         |
 F78       7.11914    7.12 |**         |
 F107      6.89489    6.89 |**         |
 F5        6.80118    6.80 |**         |
 F154      6.78786    6.79 |**         |
 F62       6.67729    6.68 |**         |
 F145      6.66939    6.67 |**         |
 F45       6.65929    6.66 |**         |
 F56       6.65625    6.66 |**         |
 F123      6.45103    6.45 |**         |
 F127      6.43897    6.44 |**         |
 F72       6.41749    6.42 |**         |
 F52       6.39594    6.40 |**         |
 F49       6.35355    6.35 |**         |
 F111      6.30705    6.31 |**         |
 F104      6.30543    6.31 |**         |
 F53       6.26420    6.26 |**         |
 F112      6.21836    6.22 |**         |
 F166      6.20067    6.20 |**         |
 F117      6.09250    6.09 |**         |
 F4        6.06240    6.06 |**         |
 F28       6.02519    6.03 |**         |
 F65       5.92938    5.93 |**         |
 F135      5.64726    5.65 |**         |
 F34       5.48633    5.49 |*          |
 F139      5.46533    5.47 |*          |
 F147      5.46416    5.46 |*          |
 F121      5.37720    5.38 |*          |
 F137      5.27874    5.28 |*          |
 F8        5.23947    5.24 |*          |
 F85       5.21513    5.22 |*          |
 F18       5.11880    5.12 |*          |
 F164      4.80187    4.80 |*          |
 F26       4.77342    4.77 |*          |
 F23       4.71672    4.72 |*          |
 F24       4.50703    4.51 |*          |
 F12       4.41810    4.42 |*          |
 F142      4.36454    4.36 |*          |
 F143      4.15855    4.16 |*          |
 F94       4.15666    4.16 |*          |
 F76       4.12787    4.13 |*          |
 F86       4.09239    4.09 |*          |
 F37       4.01722    4.02 |*          |
 F108      3.90134    3.90 |*          |
 F16       3.84259    3.84 |*          |
 F51       3.77969    3.78 |*          |
 F11       3.71209    3.71 |*          |
 F138      3.68694    3.69 |*          |
 F67       3.31280    3.31 |*          |
 F73       3.28979    3.29 |*          |
 F71       3.19400    3.19 |*          |
 F101      3.16823    3.17 |*          |
 F44       2.96478    2.96 |*          |
 F103      2.89917    2.90 |*          |
 F57       2.86914    2.87 |*          |
 F27       2.82184    2.82 |*          |
 F118      2.81097    2.81 |*          |
 F64       2.68675    2.69 |*          |
 F100      2.66130    2.66 |*          |
 F48       2.64366    2.64 |*          |
 F150      2.53370    2.53 |*          |
 F113      2.41755    2.42 |*          |
 F90       2.07513    2.08 |*          |
 F87       1.98806    1.99 |*          |
 F128      1.91858    1.92 |*          |
 F114      1.86483    1.86 |*          |
 F91       1.81832    1.82 |*          |
 F149      1.53608    1.54 |*          |
 F134      1.48474    1.48 |*          |
 F159      1.44890    1.45 |*          |
 F41       1.40395    1.40 |*          |
 F74       0.95174    0.95 |*          |


 Learn Sample Misclassification by Target Class
 For The 289-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 2791.00      2791.00         0.00       0.0000
 1                  509.00       509.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 289-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1395.00      1391.00         4.00       0.0029
 1                  254.00       239.00        15.00       0.0591

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                4.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               4.000 sec ( 0.00 hrs, 100.00%)
    Core model:         4.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

