
 The "USE "../Data/Classification/Musk2/SAMPLES4/data_tr" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 166 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 3300
 Records Kept in Learning sample: 3300

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1649
 Records Kept in Test sample: 1649

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         2791  84.58              2791.00  84.58
                 T        (1395  84.60)            (1395.00  84.60)
 1               L          509  15.42               509.00  15.42
                 T         (254  15.40)             (254.00  15.40)
 -----------------------------------------------------------------
 Totals
 0                         4186  84.58              4186.00  84.58
 1                          763  15.42               763.00  15.42
 -----------------------------------------------------------------
 Total                     4949                     4949.00
 Total Learn               3300                     3300.00
 Total Test                1649                     1649.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.35907      0.36301      0.15424      0.15403      1.00000 |                                               *
      2       0.31315      0.32051      0.15424      0.15403      1.00000 |                                         *
      3       0.27789      0.28671      0.15424      0.15403      1.00000 |                                     *
      4       0.24990      0.26201      0.15212      0.15221      1.00000 |                                  *
      5       0.22671      0.24130      0.07394      0.07580      1.00000 |                               *
      6       0.20675      0.22417      0.05364      0.06307      1.00000 |                             *
      7       0.18888      0.20965      0.04485      0.06004      1.00000 |                           *
      8       0.17280      0.19664      0.03697      0.05337      1.00000 |                         *
      9       0.15904      0.18453      0.03364      0.05094      1.00000 |                       *
     10       0.14721      0.17475      0.02879      0.04366      1.00000 |                      *
     11       0.13743      0.16624      0.02636      0.04427      1.00000 |                     *
     12       0.12862      0.15877      0.02485      0.04124      1.00000 |                    *
     13       0.12050      0.15222      0.02273      0.03881      1.00000 |                   *
     14       0.11333      0.14657      0.02061      0.03760      1.00000 |                  *
     15       0.10628      0.14037      0.01848      0.03639      1.00000 |                  *
     16       0.10020      0.13483      0.01788      0.03457      1.00000 |                 *
     17       0.09483      0.13006      0.01515      0.03335      1.00000 |                *
     18       0.09017      0.12631      0.01455      0.03275      1.00000 |                *
     19       0.08471      0.12235      0.01303      0.03396      1.00000 |               *
     20       0.07927      0.11798      0.01182      0.03335      1.00000 |               *
     30       0.04690      0.09214      0.00424      0.02547      1.00000 |           *
     40       0.03086      0.08104      0.00121      0.02547      1.00000 |          *
     50       0.02108      0.07192      0.00000      0.02365      1.00000 |         *
     60       0.01419      0.06501      0.00000      0.02001      1.00000 |        *
     70       0.01014      0.05997      0.00000      0.01941      1.00000 |       *
     80       0.00705      0.05567      0.00000      0.01941      1.00000 |      *
     90       0.00527      0.05459      0.00000      0.01759      1.00000 |      *
    100       0.00373      0.05246      0.00000      0.01880      1.00000 |      *
    110       0.00272      0.05196      0.00000      0.02001      1.00000 |      *
    120       0.00198      0.05106      0.00000      0.02001      1.00000 |      *
    130       0.00149      0.05141      0.00000      0.02001      1.00000 |      *
    140       0.00106      0.05033      0.00000      0.01941      1.00000 |      *
    150       0.00077      0.04999      0.00000      0.01880      1.00000 |      *
    160       0.00056      0.04967      0.00000      0.01880      1.00000 |      *
    170       0.00042      0.04891      0.00000      0.01941      1.00000 |     *
    180       0.00031      0.04842      0.00000      0.01880      1.00000 |     *
    190       0.00023      0.04812      0.00000      0.01819      1.00000 |     *
    200       0.00016      0.04737      0.00000      0.01819      1.00000 |     *
    210       0.00012      0.04750      0.00000      0.01880      1.00000 |     *
    220       0.00008      0.04766      0.00000      0.01759      1.00000 |     *
    230       0.00006      0.04719      0.00000      0.01759      1.00000 |     *
    240       0.00004      0.04717      0.00000      0.01759      1.00000 |     *
    250       0.00003      0.04764      0.00000      0.01759      1.00000 |     *
    260       0.00002      0.04797      0.00000      0.01637      1.00000 |     *
    270       0.00001      0.04825      0.00000      0.01577      1.00000 |     *
    280       0.00001      0.04922      0.00000      0.01637      1.00000 |      *
    290       0.00001      0.04856      0.00000      0.01516      1.00000 |     *
    300       0.00001      0.04960      0.00000      0.01577      1.00000 |      *
    310       0.00000      0.04994      0.00000      0.01577      1.00000 |      *
    320       0.00000      0.05029      0.00000      0.01455      1.00000 |      *
    330       0.00000      0.05167      0.00000      0.01455      1.00000 |      *
    340       0.00000      0.05171      0.00000      0.01455      1.00000 |      *
    350       0.00000      0.05268      0.00000      0.01455      1.00000 |      *
    360       0.00000      0.05506      0.00000      0.01516      1.00000 |      *
    370       0.00000      0.05615      0.00000      0.01577      1.00000 |      *
    380       0.00000      0.05726      0.00000      0.01455      1.00000 |       *
    390       0.00000      0.05648      0.00000      0.01455      1.00000 |      *
    400       0.00000      0.05693      0.00000      0.01516      1.00000 |       *

 Core TN model building:          5.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    220      4    399      1      7      5.03      1.64  F160
    209      1    397      1      7      4.64      1.76  F1
    194      1    400      1      7      4.69      1.61  F126
    184      1    400      1      7      5.00      1.38  F117
    181      2    400      1      7      4.45      1.61  F116
    177      1    399      2      7      4.93      1.36  F110
    170      6    400      1      7      4.80      1.36  F96
    161      6    399      1      7      4.88      1.26  F111
    161      3    398      1      7      4.06      1.59  F130
    160      2    398      2      7      5.00      1.20  F144
    159      5    398      2      7      4.67      1.32  F97
    158      1    398      2      7      5.64      0.93  F22
    154      1    398      2      7      5.27      1.05  F132
    152      7    398      2      7      5.47      0.96  F163
    151      1    396      2      7      4.84      1.19  F140
    149      4    399      1      7      4.79      1.20  F88
    148      5    399      2      7      4.70      1.22  F25
    146      7    399      1      7      4.81      1.17  F84
    146      2    396      2      7      4.79      1.17  F6
    146      1    396      1      7      4.52      1.27  F36
    143      1    398      1      7      4.62      1.21  F124
    140      3    393      1      7      4.84      1.11  F61
    134     12    400      1      7      5.46      0.85  F54
    134      5    400      1      7      5.28      0.91  F68
    134      5    398      2      7      5.12      0.97  F162
    132      1    397      1      7      4.68      1.10  F151
    131      6    400      1      7      4.66      1.09  F106
    129      1    400      2      7      4.65      1.08  F4
    127      1    400      2      7      5.24      0.88  F10
    126      5    400      1      7      5.19      0.89  F80
    126      3    399      2      7      5.52      0.78  F161
    124      3    399      2      7      4.84      0.98  F63
    123      2    400      1      7      5.11      0.89  F66
    123      1    394      1      7      5.37      0.81  F50
    122      1    399      1      7      4.64      1.03  F146
    122      4    399      1      7      4.07      1.20  F34
    119      1    393      2      7      4.98      0.90  F92
    118     24    397      2      7      4.81      0.94  F47
    116      1    398      1      7      5.06      0.85  F115
    115      6    399      1      7      4.90      0.89  F158
    115      1    390      1      7      5.67      0.67  F30
    114      2    392      1      7      5.44      0.73  F93
    113      8    399      1      7      5.05      0.83  F29
    112      6    395      1      7      5.04      0.83  F86
    111      6    398      4      7      5.77      0.62  F89
    109      4    400      1      7      5.52      0.68  F56
    109      3    389      2      7      5.75      0.61  F107
    108      1    398      2      7      5.58      0.65  F42
    108      1    393      1      7      4.55      0.93  F18
    107      3    397      2      7      5.34      0.71  F165
    106      5    399      3      7      5.89      0.56  F8
    106      6    400      1      7      4.78      0.85  F49
    105      8    400      1      7      4.73      0.86  F59
    104      5    397      1      7      4.88      0.81  F148
    104      3    400      2      7      5.58      0.63  F15
    103      1    400      2      7      5.23      0.71  F122
    103      7    399      2      7      5.32      0.69  F109
    101     12    399      1      7      4.81      0.81  F138
    100      3    399      2      7      5.42      0.65  F44
    100      2    392      1      7      4.78      0.81  F135
     99      3    399      1      7      4.15      0.95  F31
     99      2    400      2      7      5.19      0.70  F21
     99     10    399      2      7      5.46      0.63  F105
     98      3    393      2      7      5.60      0.59  F20
     97      5    395      2      7      4.96      0.74  F16
     97      1    400      2      7      5.61      0.58  F118
     95      2    397      1      7      5.33      0.64  F43
     95      1    390      2      7      5.40      0.62  F55
     95      2    396      1      7      5.87      0.51  F83
     95     10    400      1      7      5.15      0.68  F123
     93      5    394      2      7      5.13      0.67  F3
     92      1    396      1      7      5.05      0.68  F37
     91      1    395      2      7      5.64      0.54  F32
     91      3    384      2      7      5.71      0.52  F121
     91      1    399      2      7      5.70      0.52  F155
     90      2    398      1      7      4.73      0.74  F136
     90      2    400      2      7      5.90      0.47  F133
     90      2    397      2      7      5.12      0.65  F143
     89      6    394      2      7      5.60      0.54  F131
     88      9    397      1      7      4.69      0.73  F108
     88      5    399      2      7      5.40      0.57  F95
     86      4    399      3      7      5.40      0.56  F45
     85      1    396      2      7      5.60      0.51  F141
     85     10    400      2      7      5.72      0.49  F154
     84      3    397      2      7      5.45      0.54  F159
     83      2    400      2      7      4.65      0.70  F13
     83      1    400      3      7      5.75      0.47  F2
     83     13    394      1      7      5.04      0.62  F91
     83      7    399      2      7      5.53      0.51  F102
     83      1    397      2      7      5.80      0.46  F17
     82     15    390      3      7      5.60      0.49  F38
     82     14    399      1      7      4.13      0.79  F76
     81      2    398      2      7      5.60      0.49  F53
     81      3    399      3      7      5.57      0.49  F24
     81     12    391      3      7      5.58      0.49  F87
     80      1    400      2      7      4.75      0.65  F85
     80      2    396      2      7      5.74      0.45  F69
     80      2    398      2      7      5.38      0.53  F74
     80      1    400      2      7      5.61      0.48  F75
     79     13    396      3      7      5.47      0.50  F77
     79      2    393      1      7      4.95      0.60  F119
     78      8    398      1      7      5.17      0.55  F72
     78      3    399      1      7      4.24      0.73  F150
     77      5    390      2      7      6.12      0.36  F39
     76      4    398      2      7      5.29      0.52  F7
     76      5    400      1      7      4.42      0.68  F152
     75      5    400      2      7      5.51      0.47  F64
     75      2    400      2      7      5.55      0.46  F58
     75      9    396      2      7      5.09      0.55  F94
     74      2    400      1      7      5.31      0.50  F27
     74     22    400      2      7      5.45      0.47  F51
     74     10    380      2      7      5.65      0.44  F14
     73     11    391      1      7      5.14      0.52  F78
     73      2    400      2      7      5.21      0.51  F35
     73      3    394      1      7      4.90      0.57  F90
     72      2    394      3      7      5.82      0.39  F156
     71     14    399      3      7      5.37      0.47  F26
     71      5    396      2      7      5.55      0.44  F134
     70      2    395      1      7      3.66      0.76  F67
     70      2    399      3      7      5.73      0.40  F48
     69      2    400      1      7      5.04      0.51  F157
     69      5    392      3      7      5.84      0.37  F99
     69     10    397      2      7      5.59      0.42  F46
     69      5    392      2      7      5.01      0.52  F5
     68      3    400      3      7      5.94      0.35  F166
     67      5    391      3      7      5.57      0.41  F104
     66     18    399      3      7      5.73      0.38  F28
     65     17    397      2      7      5.43      0.42  F127
     65      4    399      2      7      5.69      0.38  F129
     65      2    397      1      7      5.12      0.47  F70
     65      6    384      3      7      6.20      0.29  F11
     64     13    394      3      7      5.58      0.39  F98
     64     11    389      2      7      5.45      0.41  F12
     64     20    400      2      7      5.34      0.43  F52
     64      1    389      3      7      5.66      0.38  F9
     64      3    386      3      7      5.28      0.44  F62
     63     18    392      3      7      6.03      0.31  F103
     62      5    400      2      7      5.29      0.42  F71
     62      8    393      3      7      5.63      0.37  F19
     62      8    399      2      7      5.61      0.37  F120
     61      9    399      3      7      5.82      0.33  F79
     60      4    398      2      7      5.30      0.41  F164
     60      6    348      3      7      5.63      0.36  F101
     59      4    400      3      7      5.58      0.36  F60
     59      3    381      3      7      5.85      0.32  F112
     59      1    400      3      7      5.61      0.35  F153
     58      8    399      3      7      5.64      0.34  F125
     55      2    375      2      7      5.20      0.39  F40
     55     18    400      3      7      5.69      0.32  F23
     54      6    384      3      7      5.67      0.32  F33
     52      5    399      1      7      4.25      0.49  F145
     52      7    398      2      7      5.23      0.36  F147
     51      8    396      3      7      5.80      0.28  F73
     51      2    390      1      7      5.29      0.35  F57
     50      9    400      2      7      5.84      0.27  F128
     49     18    383      3      7      5.78      0.27  F149
     48      5    385      4      7      6.17      0.22  F100
     47      6    381      2      7      5.38      0.31  F142
     47     41    372      2      7      5.74      0.27  F139
     47      8    392      2      7      6.00      0.24  F82
     46      6    396      3      7      6.28      0.20  F65
     44      4    383      3      7      5.68      0.26  F113
     43     28    385      2      7      5.44      0.28  F41
     43      3    398      3      7      5.77      0.24  F81
     42      2    392      3      7      5.36      0.28  F137
     41      3    352      4      7      6.05      0.20  F114

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    27 terminal nodes
    Largest :    73 terminal nodes
    Average :     46.40750 terminal nodes

 Reconciling 3300 Learn sample scores across 5 selected models,
 the largest having 399 trees, to compute gains and PS tables.

 Reconciling 1649 Test sample scores across 5 selected models,
 the largest having 399 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 228

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     3300      3300.00
 N Test  Obs:     1649      1649.00
 Learn Rate :    0.1000000

 Storage requirements: 36726 tree / 1 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL          228      0.04688
                  ROC          399      0.99891
                 Lift           48      6.49213
              KS-stat          399      0.97886
          Class.Error          384      0.01395

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.35907     0.36301     0.97331     0.94884     6.40265     6.20103     0.86237     0.82805     0.15424     0.15403
      5     0.22671     0.24130     0.98781     0.97777     6.48330     6.45276     0.93455     0.87787     0.07394     0.07580
     10     0.14721     0.17475     0.99710     0.98367     6.48330     6.45276     0.95175     0.88579     0.02879     0.04366
     20     0.07927     0.11798     0.99963     0.98696     6.48330     6.45276     0.97925     0.90726     0.01182     0.03335
     30     0.04690     0.09214     0.99999     0.98830     6.48330     6.45276     0.99857     0.91403     0.00424     0.02547
     40     0.03086     0.08104     1.00000     0.98955     6.48330     6.45276     1.00000     0.92299     0.00121     0.02547
     46     0.02405     0.07476     1.00000     0.99121     6.48330     6.45276     1.00000     0.92657     0.00000     0.02426
     48     0.02253     0.07333     1.00000     0.99132     6.48330     6.49213     1.00000     0.92729     0.00000     0.02304
     50     0.02108     0.07192     1.00000     0.99187     6.48330     6.49213     1.00000     0.93052     0.00000     0.02365
     60     0.01419     0.06501     1.00000     0.99300     6.48330     6.49213     1.00000     0.93626     0.00000     0.02001
     70     0.01014     0.05997     1.00000     0.99453     6.48330     6.49213     1.00000     0.94234     0.00000     0.01941
     80     0.00705     0.05567     1.00000     0.99534     6.48330     6.49213     1.00000     0.94879     0.00000     0.01941
     90     0.00527     0.05459     1.00000     0.99558     6.48330     6.49213     1.00000     0.95344     0.00000     0.01759
    100     0.00373     0.05246     1.00000     0.99618     6.48330     6.49213     1.00000     0.95201     0.00000     0.01880
    110     0.00272     0.05196     1.00000     0.99622     6.48330     6.49213     1.00000     0.95271     0.00000     0.02001
    120     0.00198     0.05106     1.00000     0.99664     6.48330     6.49213     1.00000     0.95451     0.00000     0.02001
    130     0.00149     0.05141     1.00000     0.99649     6.48330     6.49213     1.00000     0.96023     0.00000     0.02001
    140     0.00106     0.05033     1.00000     0.99698     6.48330     6.49213     1.00000     0.96238     0.00000     0.01941
    150     0.00077     0.04999     1.00000     0.99703     6.48330     6.49213     1.00000     0.95988     0.00000     0.01880
    160     0.00056     0.04967     1.00000     0.99717     6.48330     6.49213     1.00000     0.96060     0.00000     0.01880
    170     0.00042     0.04891     1.00000     0.99740     6.48330     6.49213     1.00000     0.96238     0.00000     0.01941
    180     0.00031     0.04842     1.00000     0.99760     6.48330     6.49213     1.00000     0.96310     0.00000     0.01880
    190     0.00023     0.04812     1.00000     0.99778     6.48330     6.49213     1.00000     0.96490     0.00000     0.01819
    200     0.00016     0.04737     1.00000     0.99792     6.48330     6.49213     1.00000     0.96597     0.00000     0.01819
    210     0.00012     0.04750     1.00000     0.99800     6.48330     6.49213     1.00000     0.96812     0.00000     0.01880
    220     0.00008     0.04766     1.00000     0.99812     6.48330     6.49213     1.00000     0.96955     0.00000     0.01759
    228     0.00006     0.04688     1.00000     0.99823     6.48330     6.49213     1.00000     0.96705     0.00000     0.01759
    230     0.00006     0.04719     1.00000     0.99825     6.48330     6.49213     1.00000     0.96633     0.00000     0.01759
    240     0.00004     0.04717     1.00000     0.99837     6.48330     6.49213     1.00000     0.97062     0.00000     0.01759
    250     0.00003     0.04764     1.00000     0.99844     6.48330     6.49213     1.00000     0.96955     0.00000     0.01759
    260     0.00002     0.04797     1.00000     0.99846     6.48330     6.49213     1.00000     0.96955     0.00000     0.01637
    270     0.00001     0.04825     1.00000     0.99853     6.48330     6.49213     1.00000     0.97242     0.00000     0.01577
    280     0.00001     0.04922     1.00000     0.99852     6.48330     6.49213     1.00000     0.97242     0.00000     0.01637
    290     0.00001     0.04856     1.00000     0.99865     6.48330     6.49213     1.00000     0.97314     0.00000     0.01516
    300     0.00001     0.04960     1.00000     0.99867     6.48330     6.49213     1.00000     0.97385     0.00000     0.01577
    310     0.00000     0.04994     1.00000     0.99872     6.48330     6.49213     1.00000     0.97529     0.00000     0.01577
    320     0.00000     0.05029     1.00000     0.99874     6.48330     6.49213     1.00000     0.97564     0.00000     0.01455
    330     0.00000     0.05167     1.00000     0.99875     6.48330     6.49213     1.00000     0.97420     0.00000     0.01455
    340     0.00000     0.05171     1.00000     0.99878     6.48330     6.49213     1.00000     0.97277     0.00000     0.01455
    350     0.00000     0.05268     1.00000     0.99878     6.48330     6.49213     1.00000     0.97207     0.00000     0.01455
    360     0.00000     0.05506     1.00000     0.99876     6.48330     6.49213     1.00000     0.97027     0.00000     0.01516
    370     0.00000     0.05615     1.00000     0.99876     6.48330     6.49213     1.00000     0.97098     0.00000     0.01577
    380     0.00000     0.05726     1.00000     0.99880     6.48330     6.49213     1.00000     0.97098     0.00000     0.01455
    384     0.00000     0.05818     1.00000     0.99880     6.48330     6.49213     1.00000     0.97027     0.00000     0.01395
    390     0.00000     0.05648     1.00000     0.99890     6.48330     6.49213     1.00000     0.97742     0.00000     0.01455
    399     0.00000     0.05655     1.00000     0.99891     6.48330     6.49213     1.00000     0.97886     0.00000     0.01516
    400     0.00000     0.05693     1.00000     0.99890     6.48330     6.49213     1.00000     0.97742     0.00000     0.01516


 ==========================================
 Variable Importance for the 228-tree Model
 ==========================================

               Abs     Rel

 F36     100.00000  100.00 |***********|
 F124     55.43940   55.44 |******     |
 F132     47.46659   47.47 |******     |
 F126     45.34095   45.34 |*****      |
 F35      36.77330   36.77 |*****      |
 F1       36.51330   36.51 |*****      |
 F31      33.53416   33.53 |****       |
 F151     30.95893   30.96 |****       |
 F162     29.89099   29.89 |****       |
 F146     29.51485   29.51 |****       |
 F122     28.43294   28.43 |****       |
 F9       27.44168   27.44 |****       |
 F140     26.17544   26.18 |****       |
 F22      25.19742   25.20 |***        |
 F95      24.61431   24.61 |***        |
 F55      24.52984   24.53 |***        |
 F85      23.86353   23.86 |***        |
 F15      23.47424   23.47 |***        |
 F153     22.46631   22.47 |***        |
 F63      22.43810   22.44 |***        |
 F144     22.41124   22.41 |***        |
 F17      22.02808   22.03 |***        |
 F62      21.66344   21.66 |***        |
 F163     21.61471   21.61 |***        |
 F96      20.69354   20.69 |***        |
 F50      20.64282   20.64 |***        |
 F117     20.49400   20.49 |***        |
 F110     20.07190   20.07 |***        |
 F141     19.97279   19.97 |***        |
 F155     19.89768   19.90 |***        |
 F4       19.76777   19.77 |***        |
 F37      19.72475   19.72 |***        |
 F44      19.60599   19.61 |***        |
 F102     19.53276   19.53 |***        |
 F92      19.29243   19.29 |***        |
 F42      19.13286   19.13 |***        |
 F10      18.85862   18.86 |***        |
 F116     18.39293   18.39 |***        |
 F56      18.09468   18.09 |***        |
 F111     17.99547   18.00 |***        |
 F109     17.74451   17.74 |***        |
 F43      17.60037   17.60 |***        |
 F40      17.21992   17.22 |***        |
 F58      17.15000   17.15 |***        |
 F68      17.00792   17.01 |***        |
 F164     16.74332   16.74 |***        |
 F136     16.62779   16.63 |***        |
 F86      16.41897   16.42 |***        |
 F165     16.24945   16.25 |***        |
 F21      16.18967   16.19 |***        |
 F156     15.82823   15.83 |***        |
 F158     15.81976   15.82 |***        |
 F93      15.55139   15.55 |***        |
 F105     15.47878   15.48 |**         |
 F25      15.45676   15.46 |**         |
 F61      15.30842   15.31 |**         |
 F30      14.89021   14.89 |**         |
 F34      14.59446   14.59 |**         |
 F119     14.39982   14.40 |**         |
 F80      14.24331   14.24 |**         |
 F160     13.89984   13.90 |**         |
 F107     13.87638   13.88 |**         |
 F66      13.76698   13.77 |**         |
 F76      13.60103   13.60 |**         |
 F88      12.95719   12.96 |**         |
 F143     12.88613   12.89 |**         |
 F45      12.61105   12.61 |**         |
 F83      12.54662   12.55 |**         |
 F166     12.29921   12.30 |**         |
 F49      12.22107   12.22 |**         |
 F115     12.00867   12.01 |**         |
 F39      12.00253   12.00 |**         |
 F150     11.93131   11.93 |**         |
 F106     11.88667   11.89 |**         |
 F11      11.87225   11.87 |**         |
 F130     11.86053   11.86 |**         |
 F97      11.84369   11.84 |**         |
 F67      11.74458   11.74 |**         |
 F154     11.63470   11.63 |**         |
 F135     11.53791   11.54 |**         |
 F121     11.50401   11.50 |**         |
 F57      11.50250   11.50 |**         |
 F70      11.42481   11.42 |**         |
 F71      11.33586   11.34 |**         |
 F129     11.27445   11.27 |**         |
 F152     10.81507   10.82 |**         |
 F18      10.77013   10.77 |**         |
 F81      10.50117   10.50 |**         |
 F7       10.20898   10.21 |**         |
 F148     10.16703   10.17 |**         |
 F101     10.07474   10.07 |**         |
 F157     10.06496   10.06 |**         |
 F32      10.03124   10.03 |**         |
 F79       9.93730    9.94 |**         |
 F74       9.80861    9.81 |**         |
 F77       9.74437    9.74 |**         |
 F54       9.58232    9.58 |**         |
 F59       9.55949    9.56 |**         |
 F131      9.54710    9.55 |**         |
 F46       9.32246    9.32 |**         |
 F133      9.25465    9.25 |**         |
 F27       9.13283    9.13 |**         |
 F29       8.89446    8.89 |**         |
 F69       8.85579    8.86 |**         |
 F114      8.69555    8.70 |**         |
 F5        8.61689    8.62 |**         |
 F145      8.55213    8.55 |**         |
 F78       8.52051    8.52 |**         |
 F51       8.40628    8.41 |**         |
 F64       8.20391    8.20 |**         |
 F123      8.20132    8.20 |**         |
 F3        8.18834    8.19 |**         |
 F6        8.16590    8.17 |**         |
 F118      8.15519    8.16 |**         |
 F99       8.13866    8.14 |**         |
 F94       8.05603    8.06 |**         |
 F52       8.05272    8.05 |**         |
 F2        8.02693    8.03 |**         |
 F75       7.98920    7.99 |**         |
 F13       7.93672    7.94 |**         |
 F147      7.88964    7.89 |**         |
 F89       7.86631    7.87 |**         |
 F84       7.84190    7.84 |**         |
 F134      7.75720    7.76 |**         |
 F48       7.68777    7.69 |**         |
 F159      7.63341    7.63 |**         |
 F12       7.62997    7.63 |**         |
 F100      7.20659    7.21 |**         |
 F16       7.17124    7.17 |**         |
 F142      7.16679    7.17 |**         |
 F161      7.12573    7.13 |**         |
 F47       7.01536    7.02 |**         |
 F112      6.95679    6.96 |**         |
 F20       6.86871    6.87 |**         |
 F137      6.78095    6.78 |**         |
 F24       6.67810    6.68 |**         |
 F72       6.67617    6.68 |**         |
 F138      6.66766    6.67 |**         |
 F108      6.64533    6.65 |**         |
 F38       6.63161    6.63 |**         |
 F149      6.61049    6.61 |**         |
 F90       6.55185    6.55 |**         |
 F14       6.41470    6.41 |**         |
 F19       6.29571    6.30 |**         |
 F87       6.25927    6.26 |**         |
 F127      6.12769    6.13 |**         |
 F33       6.11753    6.12 |**         |
 F60       6.07706    6.08 |**         |
 F82       6.02037    6.02 |**         |
 F120      5.86397    5.86 |**         |
 F113      5.80008    5.80 |**         |
 F53       5.70458    5.70 |**         |
 F28       5.53288    5.53 |**         |
 F103      5.14726    5.15 |*          |
 F65       4.91390    4.91 |*          |
 F8        4.83533    4.84 |*          |
 F98       4.36854    4.37 |*          |
 F125      4.33690    4.34 |*          |
 F104      3.93850    3.94 |*          |
 F73       3.90634    3.91 |*          |
 F91       3.61341    3.61 |*          |
 F41       3.42283    3.42 |*          |
 F23       2.81794    2.82 |*          |
 F139      1.95747    1.96 |*          |
 F128      1.78890    1.79 |*          |
 F26       1.38297    1.38 |*          |


 Learn Sample Misclassification by Target Class
 For The 228-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 2791.00      2791.00         0.00       0.0000
 1                  509.00       509.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 228-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1395.00      1386.00         9.00       0.0065
 1                  254.00       234.00        20.00       0.0787

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                5.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               5.000 sec ( 0.00 hrs, 100.00%)
    Core model:         5.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.7 MB, 75% compression

 Grove file created containing:
      1 TreeNet

