
 The "USE "../Data/Classification/Musk2/SAMPLES4/data_tr" command: 00:00:01

 Model (target and predictors) reset: CLASS

 The KEEP list has 166 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 3300
 Records Kept in Learning sample: 3300

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1649
 Records Kept in Test sample: 1649

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         2791  84.58              2791.00  84.58
                 T        (1395  84.60)            (1395.00  84.60)
 1               L          509  15.42               509.00  15.42
                 T         (254  15.40)             (254.00  15.40)
 -----------------------------------------------------------------
 Totals
 0                         4186  84.58              4186.00  84.58
 1                          763  15.42               763.00  15.42
 -----------------------------------------------------------------
 Total                     4949                     4949.00
 Total Learn               3300                     3300.00
 Total Test                1649                     1649.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.35808      0.36136      0.15424      0.15403      1.00000 |                                               *
      2       0.31580      0.32318      0.15424      0.15403      1.00000 |                                          *
      3       0.28329      0.29228      0.15424      0.15403      1.00000 |                                      *
      4       0.25634      0.26863      0.15424      0.15403      1.00000 |                                   *
      5       0.23381      0.24832      0.07303      0.07944      1.00000 |                                *
      6       0.21572      0.23160      0.05879      0.06792      1.00000 |                              *
      7       0.20004      0.21816      0.04879      0.05943      1.00000 |                            *
      8       0.18596      0.20500      0.04424      0.05518      1.00000 |                          *
      9       0.17330      0.19402      0.04091      0.04912      1.00000 |                         *
     10       0.16126      0.18213      0.03879      0.04851      1.00000 |                       *
     11       0.15036      0.17192      0.03606      0.04791      1.00000 |                      *
     12       0.14013      0.16227      0.03091      0.04669      1.00000 |                     *
     13       0.13209      0.15422      0.02818      0.04427      1.00000 |                   *
     14       0.12367      0.14582      0.02576      0.04306      1.00000 |                  *
     15       0.11719      0.14013      0.02333      0.03881      1.00000 |                  *
     16       0.10993      0.13458      0.02273      0.03881      1.00000 |                 *
     17       0.10380      0.12845      0.02212      0.03699      1.00000 |                *
     18       0.09803      0.12424      0.02030      0.03578      1.00000 |                *
     19       0.09263      0.11905      0.02000      0.03396      1.00000 |               *
     20       0.08822      0.11494      0.01818      0.03275      1.00000 |              *
     30       0.05312      0.08727      0.00879      0.03093      1.00000 |           *
     40       0.03390      0.06946      0.00242      0.02304      1.00000 |        *
     50       0.02435      0.06106      0.00030      0.01941      1.00000 |       *
     60       0.01757      0.05448      0.00000      0.01698      1.00000 |      *
     70       0.01293      0.04868      0.00000      0.01637      1.00000 |     *
     80       0.00962      0.04459      0.00000      0.01516      1.00000 |     *
     90       0.00735      0.04156      0.00000      0.01455      1.00000 |     *
    100       0.00526      0.03917      0.00000      0.01395      1.00000 |    *
    110       0.00399      0.03688      0.00000      0.01395      1.00000 |    *
    120       0.00305      0.03484      0.00000      0.01213      1.00000 |    *
    130       0.00235      0.03345      0.00000      0.01092      1.00000 |   *
    140       0.00180      0.03255      0.00000      0.01092      1.00000 |   *
    150       0.00136      0.03228      0.00000      0.01152      1.00000 |   *
    160       0.00102      0.03194      0.00000      0.01152      1.00000 |   *
    170       0.00078      0.03134      0.00000      0.01092      1.00000 |   *
    180       0.00058      0.03106      0.00000      0.01152      1.00000 |   *
    190       0.00044      0.03063      0.00000      0.01152      1.00000 |   *
    200       0.00034      0.03028      0.00000      0.01152      1.00000 |   *
    210       0.00026      0.02959      0.00000      0.01152      1.00000 |   *
    220       0.00020      0.02915      0.00000      0.01152      1.00000 |   *
    230       0.00015      0.02869      0.00000      0.00910      1.00000 |   *
    240       0.00012      0.02797      0.00000      0.01031      1.00000 |   *
    250       0.00009      0.02773      0.00000      0.00910      1.00000 |   *
    260       0.00007      0.02784      0.00000      0.00910      1.00000 |   *
    270       0.00005      0.02716      0.00000      0.00910      1.00000 |   *
    280       0.00004      0.02723      0.00000      0.00849      1.00000 |   *
    290       0.00003      0.02686      0.00000      0.00910      1.00000 |   *
    300       0.00003      0.02685      0.00000      0.00970      1.00000 |   *
    310       0.00002      0.02758      0.00000      0.00970      1.00000 |   *
    320       0.00002      0.02781      0.00000      0.00970      1.00000 |   *
    330       0.00001      0.02796      0.00000      0.01092      1.00000 |   *
    340       0.00001      0.02808      0.00000      0.01031      1.00000 |   *
    350       0.00001      0.02782      0.00000      0.00970      1.00000 |   *
    360       0.00001      0.02763      0.00000      0.00910      1.00000 |   *
    370       0.00000      0.02709      0.00000      0.00849      1.00000 |   *
    380       0.00000      0.02762      0.00000      0.00910      1.00000 |   *
    390       0.00000      0.02795      0.00000      0.00910      1.00000 |   *
    400       0.00000      0.02801      0.00000      0.00849      1.00000 |   *

 Core TN model building:          5.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    225      1    399      1      7      4.16      2.16  F122
    208      1    399      2      7      4.48      1.83  F163
    184      2    400      1      7      4.38      1.67  F132
    171      7    400      1      7      4.70      1.41  F162
    159      1    399      2      7      5.18      1.12  F25
    155      1    399      2      7      5.47      0.98  F22
    153      3    400      3      7      5.48      0.97  F89
    152      3    394      2      7      5.40      0.99  F102
    150      3    400      2      7      4.75      1.22  F92
    148      1    397      1      7      4.86      1.16  F63
    147      2    400      1      7      4.64      1.24  F1
    146      1    397      1      7      4.43      1.30  F36
    140      3    400      1      7      4.97      1.06  F136
    140      3    400      1      7      4.19      1.33  F96
    139      3    398      1      7      4.60      1.18  F143
    129      1    394      2      7      5.41      0.84  F50
    128      8    400      2      7      5.23      0.89  F160
    128      1    398      2      7      4.51      1.12  F126
    128      4    397      1      7      4.75      1.04  F59
    125      1    400      1      7      5.46      0.79  F29
    124      1    397      2      7      5.09      0.90  F38
    122      1    398      1      7      4.24      1.15  F55
    121      1    399      1      7      5.04      0.90  F131
    120      1    399      2      7      4.75      0.98  F66
    120     21    397      2      7      4.68      1.00  F144
    120      7    395      1      7      4.66      1.00  F111
    120      4    399      3      7      5.88      0.64  F110
    118      7    400      2      7      5.31      0.80  F140
    115      1    397      2      7      5.37      0.76  F99
    112      5    400      1      7      5.20      0.79  F68
    112      1    396      2      7      5.51      0.70  F42
    111      1    390      2      7      4.93      0.85  F124
    107      1    399      2      7      4.57      0.92  F151
    106      7    396      1      7      4.00      1.06  F35
    102      2    396      2      7      5.62      0.61  F54
    100      4    399      1      7      4.29      0.93  F141
     98     11    400      2      7      5.40      0.64  F109
     96      1    395      1      7      4.48      0.85  F21
     96      3    398      1      7      4.77      0.78  F116
     94      1    400      2      7      5.51      0.59  F6
     94      3    393      1      7      4.44      0.84  F88
     91      1    400      1      7      4.89      0.71  F105
     91      3    399      2      7      5.52      0.57  F3
     90      7    398      2      7      5.11      0.65  F100
     89      1    399      1      7      4.42      0.80  F10
     87      2    399      1      7      4.87      0.68  F83
     87     16    383      2      7      5.10      0.63  F161
     86      4    398      1      7      4.99      0.65  F106
     86      9    400      1      7      4.65      0.72  F80
     84      5    391      2      7      4.17      0.81  F93
     79      4    400      2      7      5.14      0.57  F43
     75      3    385      1      7      4.68      0.62  F34
     74      1    396      2      7      5.62      0.44  F8
     73      1    394      1      7      5.63      0.43  F115
     73      2    396      3      7      5.37      0.48  F85
     71      1    397      1      7      3.20      0.85  F67
     71      1    388      2      7      5.00      0.53  F70
     71     12    392      3      7      5.52      0.44  F95
     70      3    395      2      7      4.91      0.54  F123
     69     12    395      2      7      4.49      0.61  F125
     68      1    400      2      7      5.32      0.46  F15
     68      1    396      2      7      5.53      0.42  F56
     67     17    396      1      7      4.88      0.52  F14
     67      8    393      2      7      5.61      0.40  F20
     66      1    395      3      7      5.32      0.44  F40
     66      1    392      2      7      5.23      0.46  F130
     65      2    399      1      7      4.80      0.52  F37
     64      3    394      1      7      4.08      0.63  F71
     64      5    393      1      7      4.48      0.56  F117
     63      6    399      3      7      5.75      0.36  F18
     63      4    388      2      7      6.08      0.30  F121
     63      1    399      2      7      5.25      0.43  F133
     63      7    386      2      7      5.11      0.46  F165
     63      7    400      2      7      5.16      0.45  F52
     62      1    397      3      7      5.79      0.34  F86
     62      2    394      1      7      4.82      0.49  F84
     62     12    393      1      7      4.73      0.51  F108
     61     25    399      1      7      5.49      0.38  F142
     61     11    387      2      7      4.89      0.48  F13
     60      3    397      1      7      5.43      0.39  F4
     59      3    400      1      7      3.75      0.63  F158
     58      6    399      3      7      5.66      0.34  F24
     56     12    395      2      7      5.09      0.41  F61
     56      2    400      2      7      5.45      0.36  F19
     56     16    400      3      7      5.46      0.36  F79
     55      4    398      2      7      5.16      0.39  F62
     54     19    399      1      7      4.91      0.42  F31
     54      1    388      3      7      5.43      0.35  F17
     53      2    398      2      7      5.43      0.34  F33
     53      2    383      1      7      4.83      0.42  F77
     53     13    396      2      7      5.23      0.37  F27
     52     31    387      3      7      5.71      0.30  F139
     52      4    400      1      7      4.69      0.43  F107
     52      8    400      1      7      5.60      0.31  F94
     52     24    392      1      7      4.44      0.46  F146
     51     14    391      2      7      5.25      0.35  F156
     51      3    396      2      7      5.06      0.38  F75
     51     10    397      3      7      5.16      0.36  F120
     50     18    397      3      7      5.30      0.34  F23
     50      1    399      3      7      4.68      0.42  F32
     49      4    395      3      7      5.10      0.36  F39
     49     13    394      1      7      5.02      0.37  F44
     48      3    391      1      7      4.23      0.45  F82
     48      7    396      2      7      5.48      0.30  F103
     48     15    394      2      7      5.04      0.36  F58
     48     15    383      3      7      5.13      0.35  F30
     47      2    393      1      7      5.53      0.29  F11
     47      4    399      1      7      4.53      0.41  F129
     47      3    389      3      7      5.72      0.27  F72
     47      3    396      2      7      5.53      0.29  F155
     47     14    399      4      7      5.96      0.24  F135
     47     17    400      4      7      5.72      0.27  F137
     46      4    400      3      7      5.57      0.28  F16
     46     23    400      2      7      5.89      0.24  F138
     46      7    394      2      7      5.80      0.25  F49
     45     10    395      1      7      4.91      0.35  F152
     45      1    389      2      7      5.60      0.27  F9
     45     13    390      3      7      5.56      0.28  F157
     45     33    399      3      7      5.31      0.30  F46
     45      2    394      3      7      5.58      0.27  F73
     45     11    400      4      7      5.96      0.23  F60
     45     28    396      1      7      4.62      0.38  F147
     45      3    389      2      7      5.53      0.28  F148
     44      4    399      3      7      5.43      0.28  F97
     43      8    396      1      7      5.42      0.28  F47
     43      2    385      2      7      5.42      0.28  F154
     42      4    397      3      7      5.74      0.24  F74
     41      6    391      3      7      5.02      0.31  F64
     41      7    399      2      7      4.98      0.31  F153
     41      1    389      2      7      5.61      0.25  F134
     41     15    399      3      7      5.49      0.26  F12
     41      8    395      2      7      5.32      0.28  F51
     41     21    389      1      7      5.27      0.28  F5
     39     30    395      3      7      5.69      0.23  F149
     39      5    397      1      7      5.08      0.29  F104
     38      8    339      2      7      4.58      0.33  F164
     38      7    396      3      7      5.84      0.21  F98
     38     10    378      3      7      5.82      0.21  F87
     37      4    397      4      7      6.00      0.19  F159
     37     10    400      3      7      5.51      0.23  F48
     36     14    389      1      7      4.72      0.30  F166
     36      2    389      4      7      5.64      0.21  F69
     36     16    399      3      7      5.69      0.21  F150
     36     16    378      2      7      5.19      0.25  F57
     35     28    395      2      7      5.63      0.21  F118
     35      4    387      3      7      5.77      0.20  F81
     34      7    396      2      7      5.18      0.24  F28
     32      9    398      4      7      6.03      0.16  F26
     31      7    396      2      7      5.16      0.22  F90
     30      2    375      4      7      5.73      0.17  F41
     29     13    399      3      7      5.90      0.15  F45
     29     12    386      3      7      5.55      0.18  F65
     28      6    383      3      7      5.61      0.17  F91
     27      5    399      3      7      5.48      0.17  F127
     27     10    392      3      7      4.89      0.21  F119
     27      8    385      1      7      5.44      0.17  F128
     27      4    367      1      7      5.30      0.18  F114
     26      5    313      3      7      5.77      0.15  F2
     26     13    399      2      7      5.85      0.14  F78
     26     34    394      1      7      5.15      0.19  F112
     25     14    383      5      7      6.24      0.11  F53
     24     22    377      2      7      5.00      0.18  F7
     24     35    397      1      7      3.96      0.24  F145
     20      2    384      2      7      5.80      0.11  F113
     20     14    397      2      7      5.65      0.12  F76
     19      3    380      4      7      6.21      0.09  F101

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    17 terminal nodes
    Largest :    63 terminal nodes
    Average :     34.49500 terminal nodes

 Reconciling 3300 Learn sample scores across 5 selected models,
 the largest having 370 trees, to compute gains and PS tables.

 Reconciling 1649 Test sample scores across 5 selected models,
 the largest having 370 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 299

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     3300      3300.00
 N Test  Obs:     1649      1649.00
 Learn Rate :    0.1000000

 Storage requirements: 27196 tree / 1 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL          299      0.02670
                  ROC          370      0.99951
                 Lift          134      6.49213
              KS-stat          388      0.98639
          Class.Error          276      0.00849

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.35808     0.36136     0.97612     0.95622     6.42997     6.21654     0.87123     0.85062     0.15424     0.15403
     10     0.16126     0.18213     0.99036     0.98373     6.46365     6.41339     0.93548     0.88611     0.03879     0.04851
     12     0.14013     0.16227     0.99318     0.98703     6.48330     6.41339     0.94477     0.90650     0.03091     0.04669
     20     0.08822     0.11494     0.99855     0.99298     6.48330     6.45276     0.96281     0.91191     0.01818     0.03275
     30     0.05312     0.08727     0.99993     0.99519     6.48330     6.45276     0.99498     0.93123     0.00879     0.03093
     40     0.03390     0.06946     1.00000     0.99703     6.48330     6.45276     0.99964     0.94734     0.00242     0.02304
     44     0.02947     0.06610     1.00000     0.99711     6.48330     6.45276     1.00000     0.95272     0.00152     0.02365
     50     0.02435     0.06106     1.00000     0.99756     6.48330     6.45276     1.00000     0.95594     0.00030     0.01941
     51     0.02366     0.06072     1.00000     0.99751     6.48330     6.45276     1.00000     0.95416     0.00000     0.02062
     60     0.01757     0.05448     1.00000     0.99795     6.48330     6.45276     1.00000     0.96275     0.00000     0.01698
     70     0.01293     0.04868     1.00000     0.99838     6.48330     6.45276     1.00000     0.96383     0.00000     0.01637
     80     0.00962     0.04459     1.00000     0.99843     6.48330     6.45276     1.00000     0.96776     0.00000     0.01516
     90     0.00735     0.04156     1.00000     0.99865     6.48330     6.45276     1.00000     0.97063     0.00000     0.01455
    100     0.00526     0.03917     1.00000     0.99871     6.48330     6.45276     1.00000     0.97350     0.00000     0.01395
    110     0.00399     0.03688     1.00000     0.99886     6.48330     6.45276     1.00000     0.97493     0.00000     0.01395
    120     0.00305     0.03484     1.00000     0.99896     6.48330     6.45276     1.00000     0.97493     0.00000     0.01213
    130     0.00235     0.03345     1.00000     0.99902     6.48330     6.45276     1.00000     0.97493     0.00000     0.01092
    134     0.00214     0.03257     1.00000     0.99913     6.48330     6.49213     1.00000     0.97637     0.00000     0.01092
    140     0.00180     0.03255     1.00000     0.99913     6.48330     6.49213     1.00000     0.97565     0.00000     0.01092
    150     0.00136     0.03228     1.00000     0.99911     6.48330     6.49213     1.00000     0.97565     0.00000     0.01152
    160     0.00102     0.03194     1.00000     0.99915     6.48330     6.49213     1.00000     0.97565     0.00000     0.01152
    170     0.00078     0.03134     1.00000     0.99918     6.48330     6.49213     1.00000     0.97637     0.00000     0.01092
    180     0.00058     0.03106     1.00000     0.99917     6.48330     6.49213     1.00000     0.97780     0.00000     0.01152
    190     0.00044     0.03063     1.00000     0.99922     6.48330     6.49213     1.00000     0.97565     0.00000     0.01152
    200     0.00034     0.03028     1.00000     0.99926     6.48330     6.49213     1.00000     0.97637     0.00000     0.01152
    210     0.00026     0.02959     1.00000     0.99930     6.48330     6.49213     1.00000     0.97922     0.00000     0.01152
    220     0.00020     0.02915     1.00000     0.99935     6.48330     6.49213     1.00000     0.98066     0.00000     0.01152
    230     0.00015     0.02869     1.00000     0.99933     6.48330     6.49213     1.00000     0.98066     0.00000     0.00910
    240     0.00012     0.02797     1.00000     0.99936     6.48330     6.49213     1.00000     0.98066     0.00000     0.01031
    250     0.00009     0.02773     1.00000     0.99936     6.48330     6.49213     1.00000     0.98137     0.00000     0.00910
    260     0.00007     0.02784     1.00000     0.99938     6.48330     6.49213     1.00000     0.98066     0.00000     0.00910
    270     0.00005     0.02716     1.00000     0.99941     6.48330     6.49213     1.00000     0.97995     0.00000     0.00910
    276     0.00005     0.02725     1.00000     0.99942     6.48330     6.49213     1.00000     0.98209     0.00000     0.00849
    280     0.00004     0.02723     1.00000     0.99943     6.48330     6.49213     1.00000     0.98209     0.00000     0.00849
    290     0.00003     0.02686     1.00000     0.99943     6.48330     6.49213     1.00000     0.98137     0.00000     0.00910
    299     0.00003     0.02670     1.00000     0.99943     6.48330     6.49213     1.00000     0.98209     0.00000     0.00910
    300     0.00003     0.02685     1.00000     0.99942     6.48330     6.49213     1.00000     0.98137     0.00000     0.00970
    310     0.00002     0.02758     1.00000     0.99942     6.48330     6.49213     1.00000     0.98174     0.00000     0.00970
    320     0.00002     0.02781     1.00000     0.99942     6.48330     6.49213     1.00000     0.98245     0.00000     0.00970
    330     0.00001     0.02796     1.00000     0.99942     6.48330     6.49213     1.00000     0.98102     0.00000     0.01092
    340     0.00001     0.02808     1.00000     0.99945     6.48330     6.49213     1.00000     0.98352     0.00000     0.01031
    350     0.00001     0.02782     1.00000     0.99945     6.48330     6.49213     1.00000     0.98281     0.00000     0.00970
    360     0.00001     0.02763     1.00000     0.99948     6.48330     6.49213     1.00000     0.98281     0.00000     0.00910
    370     0.00000     0.02709     1.00000     0.99951     6.48330     6.49213     1.00000     0.98424     0.00000     0.00849
    380     0.00000     0.02762     1.00000     0.99950     6.48330     6.49213     1.00000     0.98567     0.00000     0.00910
    388     0.00000     0.02777     1.00000     0.99949     6.48330     6.49213     1.00000     0.98639     0.00000     0.00910
    390     0.00000     0.02795     1.00000     0.99947     6.48330     6.49213     1.00000     0.98424     0.00000     0.00910
    400     0.00000     0.02801     1.00000     0.99948     6.48330     6.49213     1.00000     0.98639     0.00000     0.00849


 ==========================================
 Variable Importance for the 299-tree Model
 ==========================================

               Abs     Rel

 F36     100.00000  100.00 |***********|
 F124     71.90188   71.90 |********   |
 F9       51.24392   51.24 |******     |
 F126     40.27574   40.28 |*****      |
 F133     39.32173   39.32 |*****      |
 F151     38.34143   38.34 |*****      |
 F32      37.90415   37.90 |*****      |
 F132     37.48393   37.48 |*****      |
 F66      36.84398   36.84 |*****      |
 F63      34.14671   34.15 |****       |
 F35      32.84155   32.84 |****       |
 F55      32.83801   32.84 |****       |
 F17      32.75066   32.75 |****       |
 F162     30.68047   30.68 |****       |
 F50      29.20368   29.20 |****       |
 F29      28.05920   28.06 |****       |
 F33      27.82306   27.82 |****       |
 F163     26.02034   26.02 |****       |
 F122     25.99494   25.99 |****       |
 F22      25.14027   25.14 |***        |
 F96      22.45128   22.45 |***        |
 F40      22.41326   22.41 |***        |
 F115     22.39482   22.39 |***        |
 F141     22.38013   22.38 |***        |
 F59      22.08127   22.08 |***        |
 F43      21.82345   21.82 |***        |
 F52      21.78557   21.79 |***        |
 F92      21.63903   21.64 |***        |
 F97      20.40063   20.40 |***        |
 F25      20.39126   20.39 |***        |
 F38      20.21556   20.22 |***        |
 F99      20.04665   20.05 |***        |
 F89      19.70657   19.71 |***        |
 F19      19.01348   19.01 |***        |
 F158     18.55257   18.55 |***        |
 F136     18.09117   18.09 |***        |
 F86      17.96132   17.96 |***        |
 F10      17.90403   17.90 |***        |
 F74      17.75964   17.76 |***        |
 F21      17.61884   17.62 |***        |
 F42      16.60844   16.61 |***        |
 F114     16.58308   16.58 |***        |
 F16      16.54064   16.54 |***        |
 F82      16.23633   16.24 |***        |
 F93      16.21180   16.21 |***        |
 F129     16.06588   16.07 |***        |
 F51      15.76685   15.77 |***        |
 F56      15.69927   15.70 |***        |
 F131     15.61521   15.62 |***        |
 F101     15.51831   15.52 |***        |
 F110     14.76882   14.77 |**         |
 F140     14.68328   14.68 |**         |
 F77      14.12041   14.12 |**         |
 F102     14.08538   14.09 |**         |
 F116     13.83760   13.84 |**         |
 F54      13.67575   13.68 |**         |
 F119     13.66657   13.67 |**         |
 F123     13.40708   13.41 |**         |
 F1       12.97182   12.97 |**         |
 F111     12.87734   12.88 |**         |
 F80      12.85885   12.86 |**         |
 F28      12.80778   12.81 |**         |
 F18      12.67510   12.68 |**         |
 F34      12.58731   12.59 |**         |
 F83      12.47441   12.47 |**         |
 F143     12.18435   12.18 |**         |
 F105     12.09627   12.10 |**         |
 F39      12.01182   12.01 |**         |
 F70      11.94378   11.94 |**         |
 F121     11.88678   11.89 |**         |
 F68      11.83311   11.83 |**         |
 F109     11.79198   11.79 |**         |
 F85      11.53891   11.54 |**         |
 F160     11.30433   11.30 |**         |
 F164     11.19585   11.20 |**         |
 F67      10.80364   10.80 |**         |
 F165     10.65998   10.66 |**         |
 F113     10.51073   10.51 |**         |
 F2       10.45345   10.45 |**         |
 F15      10.37310   10.37 |**         |
 F69      10.21599   10.22 |**         |
 F125     10.08287   10.08 |**         |
 F8        9.95602    9.96 |**         |
 F81       9.95200    9.95 |**         |
 F84       9.86178    9.86 |**         |
 F130      9.66214    9.66 |**         |
 F100      9.38026    9.38 |**         |
 F88       9.17465    9.17 |**         |
 F76       8.91418    8.91 |**         |
 F104      8.77973    8.78 |**         |
 F157      8.77695    8.78 |**         |
 F24       8.60275    8.60 |**         |
 F20       8.58524    8.59 |**         |
 F108      8.43764    8.44 |**         |
 F44       8.34364    8.34 |**         |
 F12       8.32804    8.33 |**         |
 F161      8.30725    8.31 |**         |
 F3        8.24106    8.24 |**         |
 F58       8.04635    8.05 |**         |
 F4        7.99708    8.00 |**         |
 F152      7.90722    7.91 |**         |
 F117      7.82069    7.82 |**         |
 F107      7.81021    7.81 |**         |
 F106      7.77859    7.78 |**         |
 F61       7.66830    7.67 |**         |
 F134      7.65110    7.65 |**         |
 F30       7.64527    7.65 |**         |
 F41       7.50795    7.51 |**         |
 F48       7.43585    7.44 |**         |
 F31       7.32429    7.32 |**         |
 F27       7.27765    7.28 |**         |
 F49       7.17990    7.18 |**         |
 F156      6.85178    6.85 |**         |
 F6        6.73502    6.74 |**         |
 F72       6.70238    6.70 |**         |
 F146      6.66868    6.67 |**         |
 F153      6.59241    6.59 |**         |
 F14       6.57405    6.57 |**         |
 F144      6.42083    6.42 |**         |
 F138      6.30230    6.30 |**         |
 F13       6.28869    6.29 |**         |
 F154      6.23500    6.23 |**         |
 F118      6.21264    6.21 |**         |
 F155      6.16880    6.17 |**         |
 F37       5.96683    5.97 |**         |
 F78       5.92322    5.92 |**         |
 F79       5.60772    5.61 |**         |
 F95       5.58939    5.59 |**         |
 F150      5.53397    5.53 |**         |
 F60       5.50741    5.51 |**         |
 F103      5.48135    5.48 |*          |
 F65       5.40716    5.41 |*          |
 F159      5.33776    5.34 |*          |
 F87       5.28054    5.28 |*          |
 F166      5.25085    5.25 |*          |
 F53       5.07778    5.08 |*          |
 F142      4.94290    4.94 |*          |
 F135      4.85261    4.85 |*          |
 F23       4.83566    4.84 |*          |
 F127      4.73516    4.74 |*          |
 F91       4.73481    4.73 |*          |
 F75       4.57395    4.57 |*          |
 F5        4.38695    4.39 |*          |
 F62       4.22235    4.22 |*          |
 F148      4.09234    4.09 |*          |
 F71       4.03979    4.04 |*          |
 F26       3.93049    3.93 |*          |
 F47       3.89670    3.90 |*          |
 F147      3.24462    3.24 |*          |
 F137      3.13422    3.13 |*          |
 F11       3.01763    3.02 |*          |
 F94       2.83073    2.83 |*          |
 F139      2.79353    2.79 |*          |
 F64       2.65001    2.65 |*          |
 F98       2.50721    2.51 |*          |
 F149      2.50345    2.50 |*          |
 F128      2.48769    2.49 |*          |
 F145      2.42811    2.43 |*          |
 F46       2.41066    2.41 |*          |
 F112      2.40159    2.40 |*          |
 F120      2.38832    2.39 |*          |
 F7        2.10395    2.10 |*          |
 F57       1.86105    1.86 |*          |
 F90       1.72283    1.72 |*          |
 F45       1.71460    1.71 |*          |
 F73       1.58174    1.58 |*          |


 Learn Sample Misclassification by Target Class
 For The 299-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 2791.00      2791.00         0.00       0.0000
 1                  509.00       509.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 299-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1395.00      1393.00         2.00       0.0014
 1                  254.00       241.00        13.00       0.0512

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                5.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               5.000 sec ( 0.00 hrs, 100.00%)
    Core model:         5.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

