
 The "USE "../Data/Classification/Musk2/SAMPLES4/data_tr" command: 00:00:01

 Model (target and predictors) reset: CLASS

 The KEEP list has 166 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 3300
 Records Kept in Learning sample: 3300

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 1649
 Records Kept in Test sample: 1649

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         2791  84.58              2791.00  84.58
                 T        (1395  84.60)            (1395.00  84.60)
 1               L          509  15.42               509.00  15.42
                 T         (254  15.40)             (254.00  15.40)
 -----------------------------------------------------------------
 Totals
 0                         4186  84.58              4186.00  84.58
 1                          763  15.42               763.00  15.42
 -----------------------------------------------------------------
 Total                     4949                     4949.00
 Total Learn               3300                     3300.00
 Total Test                1649                     1649.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.35891      0.36369      0.15424      0.15403      1.00000 |                                               *
      2       0.31472      0.32238      0.15424      0.15403      1.00000 |                                          *
      3       0.28251      0.29250      0.15424      0.15403      1.00000 |                                      *
      4       0.25539      0.26784      0.15394      0.15343      1.00000 |                                  *
      5       0.23328      0.24752      0.07515      0.07641      1.00000 |                                *
      6       0.21454      0.23165      0.05364      0.05882      1.00000 |                              *
      7       0.19849      0.21793      0.04273      0.05033      1.00000 |                            *
      8       0.18285      0.20508      0.03697      0.04730      1.00000 |                          *
      9       0.16962      0.19508      0.03364      0.04548      1.00000 |                         *
     10       0.15776      0.18555      0.03242      0.04488      1.00000 |                       *
     11       0.14752      0.17843      0.02970      0.04488      1.00000 |                       *
     12       0.13757      0.17079      0.02515      0.04427      1.00000 |                      *
     13       0.12841      0.16297      0.02333      0.04063      1.00000 |                     *
     14       0.12071      0.15668      0.02121      0.04002      1.00000 |                    *
     15       0.11355      0.15059      0.02000      0.03881      1.00000 |                   *
     16       0.10748      0.14586      0.01939      0.03820      1.00000 |                  *
     17       0.10133      0.14132      0.01879      0.03760      1.00000 |                  *
     18       0.09515      0.13663      0.01788      0.03760      1.00000 |                 *
     19       0.08929      0.13271      0.01697      0.03639      1.00000 |                 *
     20       0.08469      0.12956      0.01606      0.03639      1.00000 |                *
     30       0.05052      0.10392      0.00727      0.03639      1.00000 |             *
     40       0.03275      0.08677      0.00303      0.03275      1.00000 |          *
     50       0.02325      0.07640      0.00121      0.02911      1.00000 |         *
     60       0.01738      0.06847      0.00030      0.02668      1.00000 |        *
     70       0.01269      0.06154      0.00000      0.02486      1.00000 |       *
     80       0.00950      0.05800      0.00000      0.02365      1.00000 |       *
     90       0.00718      0.05365      0.00000      0.02122      1.00000 |      *
    100       0.00558      0.05099      0.00000      0.02062      1.00000 |      *
    110       0.00430      0.04932      0.00000      0.01880      1.00000 |      *
    120       0.00329      0.04807      0.00000      0.01941      1.00000 |     *
    130       0.00243      0.04723      0.00000      0.01941      1.00000 |     *
    140       0.00184      0.04616      0.00000      0.02001      1.00000 |     *
    150       0.00143      0.04524      0.00000      0.01880      1.00000 |     *
    160       0.00107      0.04363      0.00000      0.01819      1.00000 |     *
    170       0.00085      0.04261      0.00000      0.01819      1.00000 |     *
    180       0.00067      0.04256      0.00000      0.01819      1.00000 |     *
    190       0.00053      0.04159      0.00000      0.01759      1.00000 |    *
    200       0.00040      0.04163      0.00000      0.01759      1.00000 |    *
    210       0.00031      0.04114      0.00000      0.01698      1.00000 |    *
    220       0.00024      0.04104      0.00000      0.01698      1.00000 |    *
    230       0.00018      0.04139      0.00000      0.01698      1.00000 |    *
    240       0.00014      0.04066      0.00000      0.01577      1.00000 |    *
    250       0.00011      0.03975      0.00000      0.01637      1.00000 |    *
    260       0.00008      0.03970      0.00000      0.01637      1.00000 |    *
    270       0.00006      0.04005      0.00000      0.01516      1.00000 |    *
    280       0.00005      0.03971      0.00000      0.01455      1.00000 |    *
    290       0.00004      0.03916      0.00000      0.01334      1.00000 |    *
    300       0.00003      0.03964      0.00000      0.01273      1.00000 |    *
    310       0.00002      0.03974      0.00000      0.01213      1.00000 |    *
    320       0.00002      0.03873      0.00000      0.01273      1.00000 |    *
    330       0.00001      0.03885      0.00000      0.01213      1.00000 |    *
    340       0.00001      0.03930      0.00000      0.01273      1.00000 |    *
    350       0.00001      0.03908      0.00000      0.01273      1.00000 |    *
    360       0.00001      0.03926      0.00000      0.01334      1.00000 |    *
    370       0.00000      0.03921      0.00000      0.01334      1.00000 |    *
    380       0.00000      0.03897      0.00000      0.01334      1.00000 |    *
    390       0.00000      0.03909      0.00000      0.01273      1.00000 |    *
    400       0.00000      0.03932      0.00000      0.01273      1.00000 |    *

 Core TN model building:          4.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    187      1    400      1      7      4.73      1.53  F163
    178      1    398      2      7      4.90      1.38  F38
    178      1    398      2      7      5.51      1.11  F22
    177      7    395      2      7      5.42      1.14  F25
    172      6    399      1      7      4.47      1.52  F55
    160      1    400      1      7      4.23      1.51  F122
    159      1    400      1      7      4.62      1.34  F63
    158     19    398      1      7      4.87      1.24  F1
    158      7    400      2      7      5.25      1.09  F162
    158      1    397      2      7      4.51      1.38  F42
    156      1    399      1      7      4.62      1.32  F36
    156      1    398      1      7      4.40      1.40  F132
    154      4    400      1      7      4.14      1.49  F96
    139      1    391      1      7      4.90      1.08  F126
    139      1    399      2      7      5.39      0.91  F140
    138      1    399      1      7      4.91      1.07  F136
    136      4    400      2      7      5.13      0.98  F102
    128      4    395      1      7      4.66      1.07  F68
    126      1    400      1      7      4.29      1.17  F92
    125      5    398      1      7      4.76      1.01  F59
    122      1    397      2      7      4.65      1.02  F66
    119      1    394      1      7      4.87      0.93  F124
    118      6    395      2      7      5.34      0.79  F144
    116      2    399      2      7      5.02      0.87  F151
    115      5    392      1      7      3.66      1.25  F158
    112      4    398      1      7      5.04      0.83  F160
    111      9    395      1      7      4.28      1.03  F111
    110     16    399      2      7      5.01      0.82  F109
    110      5    400      2      7      5.16      0.78  F29
    108      3    397      1      7      4.63      0.91  F88
    107      1    394      1      7      4.88      0.84  F10
    107     11    399      1      7      4.64      0.90  F123
    103      2    400      1      7      4.84      0.81  F131
    103      2    398      2      7      5.63      0.61  F110
    101     14    400      1      7      4.56      0.87  F3
     99      7    398      2      7      5.49      0.62  F89
     98      9    390      1      7      4.74      0.80  F105
     94      1    400      2      7      5.47      0.60  F43
     93      1    392      1      7      4.34      0.85  F116
     93      2    391      2      7      5.22      0.65  F50
     92     24    394      1      7      4.80      0.74  F117
     91      2    396      1      7      5.47      0.58  F95
     88      1    399      2      7      5.09      0.64  F161
     87      8    394      2      7      4.41      0.78  F93
     87      1    399      1      7      4.21      0.83  F35
     85      1    400      1      7      4.58      0.73  F83
     85     24    397      2      7      5.29      0.58  F143
     85      2    397      2      7      5.31      0.57  F133
     82      1    397      1      7      4.40      0.74  F14
     80      8    395      1      7      4.43      0.72  F84
     80      2    395      1      7      4.21      0.76  F6
     79      1    394      2      7      4.95      0.60  F61
     78      3    400      1      7      4.33      0.72  F80
     76      5    395      3      7      5.63      0.45  F54
     76      4    397      2      7      5.49      0.48  F20
     72      9    398      3      7      5.63      0.43  F70
     72      1    400      3      7      5.58      0.44  F32
     69      5    397      1      7      4.78      0.56  F108
     69     21    397      1      7      5.33      0.46  F44
     68      1    394      2      7      4.99      0.51  F13
     65      1    398      2      7      5.20      0.46  F148
     65      1    394      3      7      5.74      0.37  F8
     65     10    399      1      7      5.03      0.48  F18
     64      1    391      2      7      5.36      0.42  F9
     64     10    392      3      7      5.70      0.37  F40
     63      1    397      1      7      4.81      0.50  F15
     62      5    399      2      7      5.13      0.45  F125
     61      9    398      2      7      5.25      0.42  F155
     61      9    388      3      7      4.74      0.50  F166
     60      9    397      1      7      5.05      0.44  F17
     59      9    397      2      7      4.66      0.49  F30
     59     13    388      3      7      5.29      0.40  F86
     59      4    398      3      7      5.63      0.35  F77
     59      1    399      3      7      5.66      0.35  F33
     57      1    398      2      7      5.16      0.41  F28
     57     11    396      2      7      4.89      0.44  F130
     56     15    391      1      7      4.84      0.44  F97
     56      1    373      2      7      5.38      0.37  F4
     56     13    400      3      7      5.38      0.37  F165
     55      4    396      4      7      6.18      0.25  F99
     54      8    387      1      7      3.46      0.61  F67
     54      7    398      1      7      4.28      0.50  F34
     53      6    393      2      7      5.36      0.35  F157
     53     10    400      3      7      4.74      0.43  F115
     53     17    385      2      7      4.96      0.40  F85
     52      1    392      3      7      5.65      0.31  F137
     52      3    369      2      7      5.58      0.32  F106
     51      4    397      2      7      5.61      0.31  F121
     51      3    387      1      7      4.59      0.44  F138
     51      4    397      3      7      5.31      0.34  F62
     51      7    400      2      7      5.16      0.36  F114
     50      1    381      1      7      3.70      0.54  F146
     49      2    397      4      7      5.92      0.26  F48
     48     28    381      2      7      4.46      0.43  F53
     48      1    382      3      7      4.85      0.38  F7
     48      2    390      2      7      5.77      0.27  F47
     47     68    389      3      7      5.72      0.27  F37
     47     17    382      2      7      5.28      0.32  F120
     47     13    399      2      7      5.49      0.30  F79
     47      7    393      2      7      5.53      0.29  F141
     47     28    396      3      7      5.66      0.28  F118
     46      4    398      3      7      5.76      0.26  F56
     46      1    397      3      7      5.78      0.26  F72
     46      8    400      3      7      6.07      0.22  F52
     46      8    391      3      7      5.28      0.31  F81
     45     10    397      3      7      5.42      0.29  F94
     45     24    393      3      7      5.71      0.26  F100
     45     11    396      1      7      5.09      0.33  F147
     44     11    400      2      7      3.68      0.48  F164
     44     20    400      2      7      5.95      0.22  F21
     43     12    384      3      7      5.28      0.29  F98
     42      7    390      3      7      5.83      0.23  F11
     42      2    382      1      7      4.52      0.37  F5
     42      9    385      3      7      5.74      0.24  F45
     42      1    391      2      7      5.83      0.23  F149
     42      1    385      2      7      5.36      0.28  F39
     41     15    397      2      7      5.59      0.25  F103
     41      7    400      3      7      5.80      0.23  F154
     40     13    399      3      7      5.88      0.21  F87
     40      6    398      3      7      5.63      0.24  F78
     40      8    400      2      7      5.58      0.24  F152
     39      4    372      4      7      6.13      0.18  F82
     39     27    397      3      7      5.79      0.22  F64
     39      3    400      1      7      5.10      0.28  F71
     38     10    390      2      7      5.71      0.22  F128
     38     15    391      2      7      5.84      0.21  F104
     38     42    396      2      7      5.42      0.25  F49
     37      6    382      3      7      6.05      0.18  F90
     37      6    397      4      7      5.76      0.21  F73
     36      5    399      3      7      5.67      0.21  F24
     36      1    400      3      7      5.67      0.21  F23
     35     12    393      4      7      5.91      0.18  F135
     35     13    382      2      7      4.91      0.27  F58
     35      2    399      3      7      5.94      0.18  F2
     35      1    390      3      7      5.80      0.19  F51
     34     10    393      1      7      5.26      0.23  F31
     34     11    385      3      7      5.03      0.25  F65
     34      4    398      3      7      5.79      0.19  F156
     34      3    399      4      7      5.71      0.20  F75
     34      2    385      2      7      5.79      0.19  F26
     34      8    372      4      7      6.41      0.14  F107
     33      2    400      3      7      5.85      0.18  F159
     33     14    398      3      7      5.76      0.19  F69
     32      1    380      2      7      4.97      0.24  F119
     32      5    396      3      7      5.75      0.18  F19
     32     33    398      1      7      5.47      0.20  F76
     31      2    398      4      7      5.84      0.17  F129
     29      4    390      2      7      6.03      0.14  F134
     29     13    351      3      7      5.72      0.17  F46
     28     11    379      3      7      6.07      0.14  F12
     27      8    364      2      7      4.96      0.21  F153
     26     18    400      1      7      3.50      0.29  F145
     26     64    388      3      7      6.04      0.13  F27
     26      2    371      3      7      5.58      0.16  F113
     26      2    360      3      7      5.85      0.14  F150
     26      7    389      2      7      5.46      0.17  F91
     26     17    394      3      7      6.08      0.13  F41
     25     16    379      3      7      5.72      0.14  F16
     24      2    391      4      7      6.13      0.11  F112
     23     96    395      4      7      6.13      0.11  F127
     23      5    372      1      7      5.17      0.16  F57
     20     71    398      2      7      5.50      0.13  F74
     20      2    378      4      7      6.20      0.09  F60
     18     25    390      4      7      6.06      0.09  F142
     18     10    389      4      7      6.11      0.09  F101
     11    105    324      4      7      5.45      0.07  F139

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    18 terminal nodes
    Largest :    57 terminal nodes
    Average :     33.06250 terminal nodes

 Reconciling 3300 Learn sample scores across 5 selected models,
 the largest having 382 trees, to compute gains and PS tables.

 Reconciling 1649 Test sample scores across 5 selected models,
 the largest having 382 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 326

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     3300      3300.00
 N Test  Obs:     1649      1649.00
 Learn Rate :    0.1000000

 Storage requirements: 26050 tree / 1 categorical splits

 Mean time per tree: 00:00:00.01
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL          326      0.03839
                  ROC          382      0.99924
                 Lift           40      6.49213
              KS-stat          349      0.97600
          Class.Error          329      0.01152

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.35891     0.36369     0.97536     0.94749     6.39936     6.09843     0.86514     0.80233     0.15424     0.15403
      7     0.19849     0.21793     0.98343     0.97496     6.48330     6.33465     0.90590     0.82303     0.04273     0.05033
     10     0.15776     0.18555     0.99029     0.97699     6.48330     6.29528     0.93207     0.83710     0.03242     0.04488
     20     0.08469     0.12956     0.99706     0.98389     6.48330     6.41339     0.96212     0.86466     0.01606     0.03639
     30     0.05052     0.10392     0.99956     0.98903     6.48330     6.41339     0.98391     0.88396     0.00727     0.03639
     40     0.03275     0.08677     0.99998     0.99244     6.48330     6.49213     0.99498     0.90975     0.00303     0.03275
     50     0.02325     0.07640     1.00000     0.99419     6.48330     6.49213     0.99964     0.91728     0.00121     0.02911
     52     0.02201     0.07447     1.00000     0.99444     6.48330     6.49213     1.00000     0.91871     0.00091     0.02729
     60     0.01738     0.06847     1.00000     0.99547     6.48330     6.49213     1.00000     0.92977     0.00030     0.02668
     64     0.01513     0.06552     1.00000     0.99585     6.48330     6.49213     1.00000     0.93514     0.00000     0.02608
     70     0.01269     0.06154     1.00000     0.99636     6.48330     6.49213     1.00000     0.94087     0.00000     0.02486
     80     0.00950     0.05800     1.00000     0.99682     6.48330     6.49213     1.00000     0.94517     0.00000     0.02365
     90     0.00718     0.05365     1.00000     0.99737     6.48330     6.49213     1.00000     0.95055     0.00000     0.02122
    100     0.00558     0.05099     1.00000     0.99763     6.48330     6.49213     1.00000     0.95234     0.00000     0.02062
    110     0.00430     0.04932     1.00000     0.99777     6.48330     6.49213     1.00000     0.95808     0.00000     0.01880
    120     0.00329     0.04807     1.00000     0.99791     6.48330     6.49213     1.00000     0.96058     0.00000     0.01941
    130     0.00243     0.04723     1.00000     0.99804     6.48330     6.49213     1.00000     0.95880     0.00000     0.01941
    140     0.00184     0.04616     1.00000     0.99821     6.48330     6.49213     1.00000     0.96238     0.00000     0.02001
    150     0.00143     0.04524     1.00000     0.99833     6.48330     6.49213     1.00000     0.96309     0.00000     0.01880
    160     0.00107     0.04363     1.00000     0.99845     6.48330     6.49213     1.00000     0.96453     0.00000     0.01819
    170     0.00085     0.04261     1.00000     0.99853     6.48330     6.49213     1.00000     0.96525     0.00000     0.01819
    180     0.00067     0.04256     1.00000     0.99860     6.48330     6.49213     1.00000     0.96667     0.00000     0.01819
    190     0.00053     0.04159     1.00000     0.99867     6.48330     6.49213     1.00000     0.96525     0.00000     0.01759
    200     0.00040     0.04163     1.00000     0.99870     6.48330     6.49213     1.00000     0.96667     0.00000     0.01759
    210     0.00031     0.04114     1.00000     0.99874     6.48330     6.49213     1.00000     0.96667     0.00000     0.01698
    220     0.00024     0.04104     1.00000     0.99878     6.48330     6.49213     1.00000     0.96631     0.00000     0.01698
    230     0.00018     0.04139     1.00000     0.99876     6.48330     6.49213     1.00000     0.96739     0.00000     0.01698
    240     0.00014     0.04066     1.00000     0.99884     6.48330     6.49213     1.00000     0.96526     0.00000     0.01577
    250     0.00011     0.03975     1.00000     0.99890     6.48330     6.49213     1.00000     0.96774     0.00000     0.01637
    260     0.00008     0.03970     1.00000     0.99894     6.48330     6.49213     1.00000     0.96918     0.00000     0.01637
    270     0.00006     0.04005     1.00000     0.99895     6.48330     6.49213     1.00000     0.96882     0.00000     0.01516
    280     0.00005     0.03971     1.00000     0.99902     6.48330     6.49213     1.00000     0.97061     0.00000     0.01455
    290     0.00004     0.03916     1.00000     0.99904     6.48330     6.49213     1.00000     0.97061     0.00000     0.01334
    300     0.00003     0.03964     1.00000     0.99905     6.48330     6.49213     1.00000     0.97204     0.00000     0.01273
    310     0.00002     0.03974     1.00000     0.99910     6.48330     6.49213     1.00000     0.97133     0.00000     0.01213
    320     0.00002     0.03873     1.00000     0.99915     6.48330     6.49213     1.00000     0.97276     0.00000     0.01273
    326     0.00001     0.03839     1.00000     0.99919     6.48330     6.49213     1.00000     0.97348     0.00000     0.01273
    329     0.00001     0.03886     1.00000     0.99918     6.48330     6.49213     1.00000     0.97314     0.00000     0.01152
    330     0.00001     0.03885     1.00000     0.99919     6.48330     6.49213     1.00000     0.97348     0.00000     0.01213
    340     0.00001     0.03930     1.00000     0.99917     6.48330     6.49213     1.00000     0.97457     0.00000     0.01273
    349     0.00001     0.03891     1.00000     0.99921     6.48330     6.49213     1.00000     0.97600     0.00000     0.01273
    350     0.00001     0.03908     1.00000     0.99919     6.48330     6.49213     1.00000     0.97491     0.00000     0.01273
    360     0.00001     0.03926     1.00000     0.99920     6.48330     6.49213     1.00000     0.97491     0.00000     0.01334
    370     0.00000     0.03921     1.00000     0.99922     6.48330     6.49213     1.00000     0.97529     0.00000     0.01334
    380     0.00000     0.03897     1.00000     0.99922     6.48330     6.49213     1.00000     0.97600     0.00000     0.01334
    382     0.00000     0.03876     1.00000     0.99924     6.48330     6.49213     1.00000     0.97529     0.00000     0.01273
    390     0.00000     0.03909     1.00000     0.99923     6.48330     6.49213     1.00000     0.97600     0.00000     0.01273
    400     0.00000     0.03932     1.00000     0.99923     6.48330     6.49213     1.00000     0.97600     0.00000     0.01273


 ==========================================
 Variable Importance for the 326-tree Model
 ==========================================

               Abs     Rel

 F36     100.00000  100.00 |***********|
 F35      57.37479   57.37 |*******    |
 F126     52.20723   52.21 |******     |
 F9       51.81975   51.82 |******     |
 F77      47.67199   47.67 |******     |
 F124     47.42885   47.43 |******     |
 F140     45.44760   45.45 |*****      |
 F132     44.34935   44.35 |*****      |
 F146     40.86966   40.87 |*****      |
 F122     35.84024   35.84 |*****      |
 F43      33.69680   33.70 |****       |
 F33      32.51600   32.52 |****       |
 F151     31.08945   31.09 |****       |
 F10      30.36750   30.37 |****       |
 F133     29.95602   29.96 |****       |
 F50      29.38065   29.38 |****       |
 F63      26.35416   26.35 |****       |
 F22      25.49286   25.49 |***        |
 F137     25.02320   25.02 |***        |
 F131     24.33069   24.33 |***        |
 F42      23.84797   23.85 |***        |
 F83      23.22148   23.22 |***        |
 F32      22.57642   22.58 |***        |
 F72      22.54971   22.55 |***        |
 F136     22.53959   22.54 |***        |
 F110     22.30859   22.31 |***        |
 F61      22.06690   22.07 |***        |
 F163     21.87880   21.88 |***        |
 F15      20.55000   20.55 |***        |
 F96      20.52087   20.52 |***        |
 F25      20.47090   20.47 |***        |
 F148     19.88685   19.89 |***        |
 F116     19.36945   19.37 |***        |
 F55      17.40658   17.41 |***        |
 F156     17.10650   17.11 |***        |
 F92      16.94850   16.95 |***        |
 F29      16.66748   16.67 |***        |
 F153     16.28060   16.28 |***        |
 F54      16.25265   16.25 |***        |
 F150     16.22725   16.23 |***        |
 F158     16.17313   16.17 |***        |
 F95      15.98570   15.99 |***        |
 F129     15.80293   15.80 |***        |
 F59      15.47267   15.47 |**         |
 F162     15.28536   15.29 |**         |
 F48      15.25791   15.26 |**         |
 F13      15.24742   15.25 |**         |
 F38      14.55139   14.55 |**         |
 F14      14.35263   14.35 |**         |
 F4       14.21194   14.21 |**         |
 F161     14.00816   14.01 |**         |
 F149     13.88102   13.88 |**         |
 F51      13.80872   13.81 |**         |
 F113     13.63460   13.63 |**         |
 F75      13.41713   13.42 |**         |
 F66      13.29059   13.29 |**         |
 F73      13.13647   13.14 |**         |
 F89      12.74789   12.75 |**         |
 F62      12.72078   12.72 |**         |
 F111     12.62330   12.62 |**         |
 F144     12.42027   12.42 |**         |
 F8       12.30994   12.31 |**         |
 F99      12.25211   12.25 |**         |
 F6       12.15368   12.15 |**         |
 F39      12.03009   12.03 |**         |
 F3       11.90647   11.91 |**         |
 F112     11.87526   11.88 |**         |
 F28      11.76715   11.77 |**         |
 F125     11.70835   11.71 |**         |
 F155     11.13164   11.13 |**         |
 F80      11.10591   11.11 |**         |
 F86      11.00732   11.01 |**         |
 F93      11.00338   11.00 |**         |
 F105     10.92998   10.93 |**         |
 F157     10.81220   10.81 |**         |
 F121     10.75592   10.76 |**         |
 F56      10.60745   10.61 |**         |
 F114     10.51552   10.52 |**         |
 F82       9.97048    9.97 |**         |
 F106      9.87633    9.88 |**         |
 F109      9.86796    9.87 |**         |
 F1        9.58482    9.58 |**         |
 F134      9.57364    9.57 |**         |
 F19       9.42399    9.42 |**         |
 F141      9.13156    9.13 |**         |
 F138      9.09645    9.10 |**         |
 F123      9.02112    9.02 |**         |
 F7        9.00247    9.00 |**         |
 F71       8.88332    8.88 |**         |
 F12       8.83085    8.83 |**         |
 F52       8.73770    8.74 |**         |
 F159      8.57028    8.57 |**         |
 F165      8.48753    8.49 |**         |
 F94       8.36448    8.36 |**         |
 F115      8.16856    8.17 |**         |
 F128      8.14878    8.15 |**         |
 F91       8.12880    8.13 |**         |
 F84       8.11058    8.11 |**         |
 F5        7.78507    7.79 |**         |
 F20       7.76088    7.76 |**         |
 F160      7.72680    7.73 |**         |
 F164      7.71337    7.71 |**         |
 F70       7.66409    7.66 |**         |
 F88       7.55969    7.56 |**         |
 F65       7.29362    7.29 |**         |
 F47       7.29017    7.29 |**         |
 F117      7.17551    7.18 |**         |
 F46       7.15876    7.16 |**         |
 F58       7.08948    7.09 |**         |
 F67       6.90581    6.91 |**         |
 F24       6.80453    6.80 |**         |
 F154      6.78430    6.78 |**         |
 F135      6.72055    6.72 |**         |
 F97       6.56818    6.57 |**         |
 F31       6.53758    6.54 |**         |
 F101      6.47316    6.47 |**         |
 F44       6.37431    6.37 |**         |
 F119      6.22285    6.22 |**         |
 F81       6.17914    6.18 |**         |
 F108      6.04421    6.04 |**         |
 F18       6.03862    6.04 |**         |
 F85       5.88292    5.88 |**         |
 F21       5.73976    5.74 |**         |
 F147      5.69665    5.70 |**         |
 F166      5.68745    5.69 |**         |
 F11       5.56415    5.56 |**         |
 F68       5.51279    5.51 |**         |
 F17       5.45077    5.45 |*          |
 F90       5.43458    5.43 |*          |
 F130      5.32599    5.33 |*          |
 F64       5.15040    5.15 |*          |
 F34       5.06428    5.06 |*          |
 F107      5.05254    5.05 |*          |
 F103      4.94103    4.94 |*          |
 F76       4.85580    4.86 |*          |
 F69       4.80468    4.80 |*          |
 F41       4.78481    4.78 |*          |
 F87       4.76214    4.76 |*          |
 F104      4.75965    4.76 |*          |
 F79       4.71532    4.72 |*          |
 F78       4.69946    4.70 |*          |
 F102      4.68938    4.69 |*          |
 F30       4.58719    4.59 |*          |
 F40       4.32462    4.32 |*          |
 F143      4.14734    4.15 |*          |
 F98       4.04324    4.04 |*          |
 F16       3.97711    3.98 |*          |
 F23       3.96975    3.97 |*          |
 F45       3.85718    3.86 |*          |
 F2        3.83130    3.83 |*          |
 F60       3.76394    3.76 |*          |
 F57       3.74320    3.74 |*          |
 F100      3.48274    3.48 |*          |
 F53       3.30789    3.31 |*          |
 F120      2.83749    2.84 |*          |
 F26       2.65351    2.65 |*          |
 F152      2.28128    2.28 |*          |
 F118      2.19518    2.20 |*          |
 F49       2.03919    2.04 |*          |
 F145      1.58284    1.58 |*          |
 F27       1.39729    1.40 |*          |
 F142      1.08235    1.08 |*          |
 F37       0.99494    0.99 |*          |
 F74       0.75467    0.75 |*          |
 F127      0.18818    0.19 |*          |
 F139      0.11757    0.12 |*          |


 Learn Sample Misclassification by Target Class
 For The 326-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 2791.00      2791.00         0.00       0.0000
 1                  509.00       509.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 326-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 1395.00      1392.00         3.00       0.0022
 1                  254.00       236.00        18.00       0.0709

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                5.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               4.000 sec ( 0.00 hrs,  80.00%)
    Core model:         4.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  20.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

