
 The "USE "../Data/Classification/Haberman/SAMPLES4/data" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 3 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 154
 Records Kept in Learning sample: 154

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 76
 Records Kept in Test sample: 76

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          113  73.38               113.00  73.38
                 T          (56  73.68)              (56.00  73.68)
 1               L           41  26.62                41.00  26.62
                 T          (20  26.32)              (20.00  26.32)
 -----------------------------------------------------------------
 Totals
 0                          169  73.48               169.00  73.48
 1                           61  26.52                61.00  26.52
 -----------------------------------------------------------------
 Total                      230                      230.00
 Total Learn                154                      154.00
 Total Test                  76                       76.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.55265      0.56604      0.26623      0.26316      1.00000 |                                               *
      2       0.53057      0.56739      0.26623      0.26316      1.00000 |                                               *
      3       0.51317      0.56396      0.26623      0.26316      1.00000 |                                               *
      4       0.49660      0.56031      0.26623      0.26316      1.00000 |                                               *
      5       0.48236      0.56265      0.25325      0.27632      1.00000 |                                               *
      6       0.46881      0.56163      0.24026      0.26316      1.00000 |                                               *
      7       0.45832      0.56586      0.22078      0.31579      1.00000 |                                               *
      8       0.44942      0.57193      0.20779      0.32895      1.00000 |                                               *
      9       0.43867      0.57556      0.22078      0.34211      1.00000 |                                               *
     10       0.43131      0.57967      0.22078      0.34211      1.00000 |                                               *
     11       0.42463      0.57935      0.20779      0.32895      1.00000 |                                               *
     12       0.41754      0.58246      0.19481      0.32895      1.00000 |                                               *
     13       0.41257      0.58485      0.19481      0.32895      1.00000 |                                               *
     14       0.40675      0.58776      0.18182      0.34211      1.00000 |                                               *
     15       0.40049      0.59304      0.18831      0.34211      1.00000 |                                               *
     16       0.39435      0.59141      0.18831      0.32895      1.00000 |                                               *
     17       0.38909      0.59007      0.16234      0.32895      1.00000 |                                               *
     18       0.38462      0.59196      0.16883      0.31579      1.00000 |                                               *
     19       0.38077      0.59097      0.15584      0.32895      1.00000 |                                               *
     20       0.37776      0.59484      0.14935      0.32895      1.00000 |                                               *
     30       0.33578      0.62156      0.12987      0.32895      1.00000 |                                               *
     40       0.29744      0.63757      0.11039      0.31579      1.00000 |                                               *
     50       0.26709      0.66036      0.11039      0.31579      1.00000 |                                               *
     60       0.24614      0.67619      0.09091      0.32895      1.00000 |                                               *
     70       0.22869      0.70312      0.09091      0.32895      1.00000 |                                               *
     80       0.21378      0.71629      0.07792      0.32895      1.00000 |                                               *
     90       0.19880      0.74080      0.06494      0.32895      1.00000 |                                               *
    100       0.18567      0.76378      0.02597      0.34211      1.00000 |                                               *
    110       0.17379      0.77766      0.03247      0.32895      1.00000 |                                               *
    120       0.16170      0.79702      0.03247      0.32895      1.00000 |                                               *
    130       0.15157      0.81828      0.03247      0.32895      1.00000 |                                               *
    140       0.14292      0.82762      0.02597      0.34211      1.00000 |                                               *
    150       0.13363      0.85234      0.01299      0.36842      1.00000 |                                               *
    160       0.12580      0.86950      0.00649      0.34211      1.00000 |                                               *
    170       0.11828      0.88415      0.00649      0.34211      1.00000 |                                               *
    180       0.11245      0.89648      0.00649      0.35526      1.00000 |                                               *
    190       0.10416      0.91011      0.00649      0.35526      1.00000 |                                               *
    200       0.09827      0.92732      0.00649      0.34211      1.00000 |                                               *
    210       0.09385      0.92806      0.00649      0.34211      1.00000 |                                               *
    220       0.08958      0.95724      0.00649      0.32895      1.00000 |                                               *
    230       0.08372      0.96777      0.00649      0.32895      1.00000 |                                               *
    240       0.08005      0.98416      0.00649      0.34211      1.00000 |                                               *
    250       0.07595      1.00289      0.00649      0.34211      1.00000 |                                               *
    260       0.07184      1.02366      0.00649      0.34211      1.00000 |                                               *
    270       0.06816      1.04083      0.00649      0.34211      1.00000 |                                               *
    280       0.06512      1.05220      0.00649      0.34211      1.00000 |                                               *
    290       0.06148      1.06928      0.00649      0.34211      1.00000 |                                               *
    300       0.05879      1.08373      0.00649      0.34211      1.00000 |                                               *
    310       0.05579      1.10412      0.00649      0.34211      1.00000 |                                               *
    320       0.05326      1.12703      0.00649      0.34211      1.00000 |                                               *
    330       0.05028      1.13948      0.00649      0.34211      1.00000 |                                               *
    340       0.04818      1.15280      0.00649      0.34211      1.00000 |                                               *
    350       0.04644      1.16818      0.00649      0.34211      1.00000 |                                               *
    360       0.04480      1.18784      0.00649      0.34211      1.00000 |                                               *
    370       0.04318      1.19986      0.00649      0.34211      1.00000 |                                               *
    380       0.04131      1.21726      0.00649      0.34211      1.00000 |                                               *
    390       0.03908      1.24493      0.00649      0.34211      1.00000 |                                               *
    400       0.03723      1.25924      0.00649      0.35526      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      6      1.63      6.37  AXIL_NODES
    400      1    400      1      6      2.55      5.45  AGE
    393      1    400      1      7      3.14      4.78  OP_YEAR

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    13 terminal nodes
    Average :     10.12750 terminal nodes

 Reconciling 154 Learn sample scores across 4 selected models,
 the largest having 52 trees, to compute gains and PS tables.

 Reconciling 76 Test sample scores across 4 selected models,
 the largest having 52 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 4

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      154       154.00
 N Test  Obs:       76        76.00
 Learn Rate :    0.1000000

 Storage requirements: 7702 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            4      0.56031
                  ROC           47      0.66116
                 Lift           52      1.50000
              KS-stat          252      0.36786
          Class.Error            1      0.26316

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.55265     0.56604     0.82495     0.64375     2.88130     1.14000     0.49514     0.31429     0.26623     0.26316
      4     0.49660     0.56031     0.86218     0.61071     3.17073     1.30000     0.59270     0.30000     0.26623     0.26316
     10     0.43131     0.57967     0.88010     0.60625     2.78049     0.93333     0.60803     0.30000     0.22078     0.34211
     20     0.37776     0.59484     0.90093     0.63259     3.02439     1.00000     0.63695     0.31786     0.14935     0.32895
     30     0.33578     0.62156     0.92597     0.63795     3.51220     1.00000     0.72113     0.33571     0.12987     0.32895
     40     0.29744     0.63757     0.95197     0.64509     3.51220     1.00000     0.79193     0.31429     0.11039     0.31579
     43     0.28824     0.64226     0.95716     0.65670     3.75610     1.00000     0.79193     0.32143     0.12338     0.31579
     47     0.27763     0.64861     0.96212     0.66116     3.75610     1.00000     0.80078     0.32143     0.11039     0.31579
     50     0.26709     0.66036     0.96752     0.65402     3.75610     1.30000     0.81632     0.32143     0.11039     0.31579
     52     0.26235     0.66548     0.96730     0.65491     3.75610     1.50000     0.82517     0.33214     0.11039     0.31579
     60     0.24614     0.67619     0.97593     0.65402     3.75610     1.00000     0.84934     0.33214     0.09091     0.32895
     70     0.22869     0.70312     0.98176     0.64777     3.75610     1.00000     0.87373     0.33214     0.09091     0.32895
     80     0.21378     0.71629     0.98716     0.64598     3.75610     0.80000     0.91582     0.33214     0.07792     0.32895
     90     0.19880     0.74080     0.98910     0.63527     3.75610     0.50000     0.92467     0.33214     0.06494     0.32895
    100     0.18567     0.76378     0.99536     0.62991     3.75610     0.80000     0.94690     0.31071     0.02597     0.34211
    110     0.17379     0.77766     0.99665     0.63438     3.75610     0.80000     0.94906     0.31429     0.03247     0.32895
    120     0.16170     0.79702     0.99795     0.63839     3.75610     1.30000     0.97345     0.32857     0.03247     0.32895
    130     0.15157     0.81828     0.99860     0.62589     3.75610     1.30000     0.98230     0.26071     0.03247     0.32895
    140     0.14292     0.82762     0.99881     0.63482     3.75610     1.30000     0.98230     0.29643     0.02597     0.34211
    150     0.13363     0.85234     0.99924     0.62411     3.75610     1.30000     0.98230     0.27857     0.01299     0.36842
    151     0.13256     0.85393     0.99946     0.62232     3.75610     1.00000     0.99115     0.27857     0.01299     0.35526
    157     0.12828     0.86424     0.99968     0.62500     3.75610     1.00000     0.99115     0.29643     0.00649     0.35526
    159     0.12700     0.86838     0.99989     0.62768     3.75610     0.80000     0.99115     0.29643     0.00649     0.34211
    160     0.12580     0.86950     0.99989     0.63036     3.75610     1.30000     0.99115     0.33214     0.00649     0.34211
    170     0.11828     0.88415     0.99989     0.62946     3.75610     1.30000     0.99115     0.31429     0.00649     0.34211
    180     0.11245     0.89648     0.99989     0.62232     3.75610     1.00000     0.99115     0.26071     0.00649     0.35526
    190     0.10416     0.91011     0.99989     0.63214     3.75610     1.30000     0.99115     0.31429     0.00649     0.35526
    200     0.09827     0.92732     0.99989     0.63304     3.75610     1.30000     0.99115     0.31429     0.00649     0.34211
    210     0.09385     0.92806     0.99989     0.63571     3.75610     1.00000     0.99115     0.31429     0.00649     0.34211
    220     0.08958     0.95724     0.99989     0.63304     3.75610     1.00000     0.99115     0.31429     0.00649     0.32895
    230     0.08372     0.96777     0.99989     0.62768     3.75610     1.00000     0.99115     0.31429     0.00649     0.32895
    240     0.08005     0.98416     0.99989     0.62946     3.75610     1.00000     0.99115     0.29643     0.00649     0.34211
    250     0.07595     1.00289     0.99989     0.62946     3.75610     1.00000     0.99115     0.31786     0.00649     0.34211
    252     0.07479     1.00736     0.99989     0.63571     3.75610     1.00000     0.99115     0.36786     0.00649     0.34211
    260     0.07184     1.02366     0.99989     0.63036     3.75610     1.00000     0.99115     0.31429     0.00649     0.34211
    270     0.06816     1.04083     0.99989     0.63393     3.75610     1.00000     0.99115     0.31786     0.00649     0.34211
    280     0.06512     1.05220     0.99989     0.63482     3.75610     0.80000     0.99115     0.31786     0.00649     0.34211
    290     0.06148     1.06928     0.99989     0.63482     3.75610     0.80000     0.99115     0.36786     0.00649     0.34211
    300     0.05879     1.08373     0.99989     0.63125     3.75610     0.50000     0.99115     0.36786     0.00649     0.34211
    310     0.05579     1.10412     0.99989     0.63125     3.75610     0.50000     0.99115     0.33214     0.00649     0.34211
    320     0.05326     1.12703     0.99989     0.62679     3.75610     0.50000     0.99115     0.31786     0.00649     0.34211
    330     0.05028     1.13948     0.99989     0.62857     3.75610     0.50000     0.99115     0.36786     0.00649     0.34211
    340     0.04818     1.15280     0.99989     0.63482     3.75610     0.50000     0.99115     0.36786     0.00649     0.34211
    350     0.04644     1.16818     0.99989     0.63482     3.75610     0.50000     0.99115     0.36786     0.00649     0.34211
    360     0.04480     1.18784     0.99989     0.63393     3.75610     0.50000     0.99115     0.33214     0.00649     0.34211
    370     0.04318     1.19986     0.99989     0.62857     3.75610     0.50000     0.99115     0.33214     0.00649     0.34211
    380     0.04131     1.21726     0.99989     0.63125     3.75610     0.50000     0.99115     0.33214     0.00649     0.34211
    390     0.03908     1.24493     0.99989     0.62946     3.75610     0.50000     0.99115     0.33214     0.00649     0.34211
    400     0.03723     1.25924     0.99989     0.63214     3.75610     0.50000     0.99115     0.33214     0.00649     0.35526


 ========================================
 Variable Importance for the 4-tree Model
 ========================================

                     Abs     Rel

 AXIL_NODES    100.00000  100.00 |***********|
 AGE            52.48364   52.48 |******     |
 OP_YEAR        41.94058   41.94 |*****      |


 Learn Sample Misclassification by Target Class
 For The 4-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  113.00       113.00         0.00       0.0000
 1                   41.00         0.00        41.00       1.0000


 Test Sample Misclassification by Target Class
 For The 4-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   56.00        56.00         0.00       0.0000
 1                   20.00         0.00        20.00       1.0000

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 289 kb , 82% compression

 Grove file created containing:
      1 TreeNet

