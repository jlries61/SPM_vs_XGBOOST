
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11295      0.11990      0.02910      0.02898      1.00000 |                                               *
      2       0.10412      0.11607      0.02910      0.02898      1.00000 |                                             *
      3       0.09995      0.11349      0.02910      0.02898      1.00000 |                                            *
      4       0.09647      0.11142      0.02910      0.02898      1.00000 |                                            *
      5       0.09239      0.10979      0.02910      0.02898      1.00000 |                                           *
      6       0.08964      0.10836      0.02897      0.02871      1.00000 |                                          *
      7       0.08682      0.10752      0.02818      0.02871      1.00000 |                                          *
      8       0.08440      0.10657      0.02765      0.02845      1.00000 |                                          *
      9       0.08166      0.10640      0.02699      0.02871      1.00000 |                                          *
     10       0.07973      0.10597      0.02673      0.02898      1.00000 |                                         *
     11       0.07821      0.10557      0.02686      0.02898      1.00000 |                                         *
     12       0.07624      0.10558      0.02647      0.02924      1.00000 |                                         *
     13       0.07472      0.10506      0.02647      0.02924      1.00000 |                                         *
     14       0.07328      0.10493      0.02607      0.02924      1.00000 |                                         *
     15       0.07208      0.10450      0.02620      0.02950      1.00000 |                                         *
     16       0.07147      0.10445      0.02581      0.02950      1.00000 |                                         *
     17       0.07102      0.10442      0.02541      0.02924      1.00000 |                                         *
     18       0.06992      0.10436      0.02515      0.02924      1.00000 |                                         *
     19       0.06885      0.10425      0.02449      0.02898      1.00000 |                                         *
     20       0.06844      0.10435      0.02423      0.02898      1.00000 |                                         *
     30       0.06110      0.10382      0.02318      0.02898      1.00000 |                                         *
     40       0.05734      0.10442      0.02173      0.02898      1.00000 |                                         *
     50       0.05411      0.10518      0.02067      0.02898      1.00000 |                                         *
     60       0.05158      0.10626      0.01962      0.02898      1.00000 |                                          *
     70       0.04988      0.10678      0.01804      0.02871      1.00000 |                                          *
     80       0.04775      0.10731      0.01791      0.02898      1.00000 |                                          *
     90       0.04604      0.10738      0.01699      0.02898      1.00000 |                                          *
    100       0.04473      0.10841      0.01593      0.02871      1.00000 |                                          *
    110       0.04245      0.10938      0.01541      0.02898      1.00000 |                                           *
    120       0.04171      0.10978      0.01541      0.02950      1.00000 |                                           *
    130       0.04060      0.11095      0.01462      0.02977      1.00000 |                                           *
    140       0.03956      0.11161      0.01435      0.02977      1.00000 |                                            *
    150       0.03685      0.11275      0.01343      0.03003      1.00000 |                                            *
    160       0.03599      0.11363      0.01290      0.03003      1.00000 |                                            *
    170       0.03452      0.11483      0.01225      0.03003      1.00000 |                                             *
    180       0.03290      0.11550      0.01053      0.03003      1.00000 |                                             *
    190       0.03185      0.11618      0.00961      0.03003      1.00000 |                                              *
    200       0.02964      0.11789      0.00856      0.03003      1.00000 |                                              *
    210       0.02718      0.11966      0.00764      0.03003      1.00000 |                                               *
    220       0.02536      0.12167      0.00658      0.03082      1.00000 |                                               *
    230       0.02407      0.12298      0.00619      0.03109      1.00000 |                                               *
    240       0.02293      0.12412      0.00566      0.03109      1.00000 |                                               *
    250       0.02192      0.12521      0.00540      0.03135      1.00000 |                                               *
    260       0.02113      0.12604      0.00500      0.03161      1.00000 |                                               *
    270       0.02035      0.12676      0.00474      0.03109      1.00000 |                                               *
    280       0.01914      0.12872      0.00421      0.03161      1.00000 |                                               *
    290       0.01807      0.13029      0.00382      0.03109      1.00000 |                                               *
    300       0.01762      0.13118      0.00369      0.03135      1.00000 |                                               *
    310       0.01688      0.13172      0.00329      0.03135      1.00000 |                                               *
    320       0.01634      0.13276      0.00303      0.03135      1.00000 |                                               *
    330       0.01559      0.13428      0.00263      0.03161      1.00000 |                                               *
    340       0.01485      0.13565      0.00263      0.03161      1.00000 |                                               *
    350       0.01436      0.13680      0.00211      0.03188      1.00000 |                                               *
    360       0.01343      0.13802      0.00171      0.03214      1.00000 |                                               *
    370       0.01289      0.13936      0.00145      0.03240      1.00000 |                                               *
    380       0.01228      0.14057      0.00145      0.03214      1.00000 |                                               *
    390       0.01173      0.14175      0.00119      0.03240      1.00000 |                                               *
    400       0.01143      0.14240      0.00105      0.03240      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.25      6.75  CHILDYRS
    298      1    400      1      7      3.64      3.25  AGE
    268      1    399      1      7      4.51      2.34  INCOME
    257      1    399      1      7      4.51      2.24  OTH_CHLD
    254      1    400      2      7      4.69      2.11  EDUC_MOM
    244      1    399      1      7      4.61      2.07  AGE_MOM
    169      1    395      1      7      5.20      1.18  ILLEGIT
    110      1    399      2      7      5.34      0.73  RACE_MOM
     91      1    395      1      7      5.64      0.54  LBW
     79      1    399      2      7      5.59      0.48  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    81 terminal nodes
    Average :     27.08500 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 27

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 21268 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           27      0.10379
                  ROC           28      0.87040
                 Lift            6      5.63636
              KS-stat           12      0.58923
          Class.Error            8      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11295     0.11990     0.92063     0.80280     7.01584     4.81818     0.68271     0.53383     0.02910     0.02898
      6     0.08964     0.10836     0.94595     0.84680     7.87330     5.63636     0.74778     0.58160     0.02897     0.02871
      8     0.08440     0.10657     0.95187     0.85070     8.23756     5.36364     0.75775     0.58909     0.02765     0.02845
     10     0.07973     0.10597     0.96123     0.85604     8.55204     5.18182     0.79460     0.57566     0.02673     0.02898
     12     0.07624     0.10558     0.96554     0.85692     8.73303     5.54545     0.81265     0.58923     0.02647     0.02924
     20     0.06844     0.10435     0.97165     0.86771     9.00452     5.36364     0.82653     0.58446     0.02423     0.02898
     27     0.06254     0.10379     0.98056     0.87040     9.32127     5.36364     0.85929     0.58352     0.02278     0.02924
     28     0.06247     0.10381     0.98055     0.87040     9.32127     5.36364     0.85943     0.58352     0.02265     0.02924
     30     0.06110     0.10382     0.98194     0.87000     9.36652     5.50909     0.86663     0.57958     0.02318     0.02898
     40     0.05734     0.10442     0.98478     0.86598     9.54751     5.36364     0.88417     0.57469     0.02173     0.02898
     50     0.05411     0.10518     0.98687     0.86195     9.54751     5.27273     0.89060     0.56410     0.02067     0.02898
     60     0.05158     0.10626     0.98893     0.85641     9.68326     5.27273     0.89856     0.55583     0.01962     0.02898
     70     0.04988     0.10678     0.98981     0.85423     9.68326     5.27273     0.90407     0.55746     0.01804     0.02871
     80     0.04775     0.10731     0.99144     0.85506     9.68326     5.09091     0.91529     0.55543     0.01791     0.02898
     90     0.04604     0.10738     0.99244     0.85551     9.68326     5.18182     0.91330     0.56249     0.01699     0.02898
    100     0.04473     0.10841     0.99314     0.85099     9.72851     5.09091     0.91547     0.55421     0.01593     0.02871
    110     0.04245     0.10938     0.99464     0.84912     9.86425     4.90909     0.93185     0.55245     0.01541     0.02898
    120     0.04171     0.10978     0.99490     0.84799     9.86425     4.81818     0.93325     0.55258     0.01541     0.02950
    130     0.04060     0.11095     0.99535     0.84438     9.86425     4.81818     0.93406     0.53766     0.01462     0.02977
    140     0.03956     0.11161     0.99566     0.84228     9.86425     4.81818     0.93542     0.53494     0.01435     0.02977
    146     0.03788     0.11241     0.99670     0.84024    10.00000     4.81818     0.94596     0.53521     0.01383     0.03003
    150     0.03685     0.11275     0.99697     0.83887    10.00000     4.72727     0.94569     0.53292     0.01343     0.03003
    160     0.03599     0.11363     0.99714     0.83405    10.00000     4.81818     0.94577     0.52122     0.01290     0.03003
    170     0.03452     0.11483     0.99772     0.82996    10.00000     4.72727     0.95373     0.52707     0.01225     0.03003
    180     0.03290     0.11550     0.99817     0.82827    10.00000     4.72727     0.96128     0.53073     0.01053     0.03003
    190     0.03185     0.11618     0.99839     0.82758    10.00000     4.72727     0.96500     0.53141     0.00961     0.03003
    200     0.02964     0.11789     0.99894     0.82335    10.00000     4.72727     0.97300     0.52245     0.00856     0.03003
    210     0.02718     0.11966     0.99945     0.82082    10.00000     4.54545     0.98300     0.52367     0.00764     0.03003
    220     0.02536     0.12167     0.99968     0.81515    10.00000     4.72727     0.98734     0.50511     0.00658     0.03082
    230     0.02407     0.12298     0.99978     0.81230    10.00000     4.36364     0.99023     0.51161     0.00619     0.03109
    240     0.02293     0.12412     0.99986     0.81034    10.00000     4.27273     0.99173     0.51772     0.00566     0.03109
    250     0.02192     0.12521     0.99992     0.81096    10.00000     4.09091     0.99281     0.51202     0.00540     0.03135
    260     0.02113     0.12604     0.99994     0.80934    10.00000     4.18182     0.99566     0.50793     0.00500     0.03161
    270     0.02035     0.12676     0.99997     0.80758    10.00000     4.18182     0.99797     0.50359     0.00474     0.03109
    280     0.01914     0.12872     0.99999     0.80366    10.00000     4.18182     0.99919     0.50223     0.00421     0.03161
    290     0.01807     0.13029     1.00000     0.80036    10.00000     4.27273     0.99973     0.49004     0.00382     0.03109
    300     0.01762     0.13118     1.00000     0.79796    10.00000     4.27273     0.99973     0.49356     0.00369     0.03135
    310     0.01688     0.13172     1.00000     0.79905    10.00000     4.27273     0.99986     0.49220     0.00329     0.03135
    320     0.01634     0.13276     1.00000     0.79530    10.00000     4.27273     0.99986     0.49029     0.00303     0.03135
    326     0.01578     0.13354     1.00000     0.79359    10.00000     4.27273     1.00000     0.49790     0.00263     0.03135
    330     0.01559     0.13428     1.00000     0.79150    10.00000     4.27273     1.00000     0.49980     0.00263     0.03161
    340     0.01485     0.13565     1.00000     0.78975    10.00000     4.27273     1.00000     0.49749     0.00263     0.03161
    350     0.01436     0.13680     1.00000     0.78773    10.00000     4.27273     1.00000     0.49259     0.00211     0.03188
    360     0.01343     0.13802     1.00000     0.78900    10.00000     4.27273     1.00000     0.48461     0.00171     0.03214
    370     0.01289     0.13936     1.00000     0.78703    10.00000     4.09091     1.00000     0.47780     0.00145     0.03240
    380     0.01228     0.14057     1.00000     0.78519    10.00000     4.18182     1.00000     0.48310     0.00145     0.03214
    390     0.01173     0.14175     1.00000     0.78331    10.00000     4.27273     1.00000     0.47686     0.00119     0.03240
    394     0.01160     0.14199     1.00000     0.78328    10.00000     4.27273     1.00000     0.47780     0.00105     0.03240
    400     0.01143     0.14240     1.00000     0.78336    10.00000     4.27273     1.00000     0.47713     0.00105     0.03240


 =========================================
 Variable Importance for the 27-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     42.81898   42.82 |*****      |
 AGE          39.98094   39.98 |*****      |
 AGE_MOM      34.52671   34.53 |****       |
 INCOME       33.14763   33.15 |****       |
 OTH_CHLD     30.19212   30.19 |****       |
 RACE_MOM     19.37579   19.38 |***        |
 ILLEGIT      18.55281   18.55 |***        |
 PNCLATE      15.47488   15.47 |**         |
 LBW          10.41405   10.41 |**         |


 Learn Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7367.00         6.00       0.0008
 1                  221.00        54.00       167.00       0.7557


 Test Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3678.00         8.00       0.0022
 1                  110.00         7.00       103.00       0.9364

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 994 kb , 75% compression

 Grove file created containing:
      1 TreeNet

