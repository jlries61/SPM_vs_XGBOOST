
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11097      0.11865      0.02910      0.02898      1.00000 |                                               *
      2       0.10330      0.11488      0.02910      0.02898      1.00000 |                                             *
      3       0.09784      0.11253      0.02910      0.02898      1.00000 |                                             *
      4       0.09326      0.11044      0.02910      0.02898      1.00000 |                                            *
      5       0.08982      0.10920      0.02910      0.02898      1.00000 |                                           *
      6       0.08683      0.10807      0.02871      0.02924      1.00000 |                                           *
      7       0.08377      0.10754      0.02699      0.02845      1.00000 |                                           *
      8       0.08115      0.10708      0.02594      0.02924      1.00000 |                                          *
      9       0.07895      0.10641      0.02581      0.02924      1.00000 |                                          *
     10       0.07684      0.10582      0.02594      0.02898      1.00000 |                                          *
     11       0.07492      0.10581      0.02581      0.02898      1.00000 |                                          *
     12       0.07325      0.10584      0.02568      0.02898      1.00000 |                                          *
     13       0.07204      0.10569      0.02541      0.02898      1.00000 |                                          *
     14       0.07062      0.10524      0.02515      0.02898      1.00000 |                                          *
     15       0.06925      0.10542      0.02410      0.02898      1.00000 |                                          *
     16       0.06823      0.10559      0.02357      0.02845      1.00000 |                                          *
     17       0.06745      0.10554      0.02331      0.02871      1.00000 |                                          *
     18       0.06633      0.10533      0.02304      0.02845      1.00000 |                                          *
     19       0.06569      0.10513      0.02291      0.02845      1.00000 |                                          *
     20       0.06493      0.10505      0.02278      0.02871      1.00000 |                                          *
     30       0.05968      0.10559      0.02160      0.02950      1.00000 |                                          *
     40       0.05723      0.10542      0.02002      0.03030      1.00000 |                                          *
     50       0.05487      0.10561      0.01949      0.03030      1.00000 |                                          *
     60       0.05280      0.10641      0.01844      0.02924      1.00000 |                                          *
     70       0.05211      0.10685      0.01778      0.02977      1.00000 |                                          *
     80       0.05099      0.10731      0.01725      0.02977      1.00000 |                                          *
     90       0.04963      0.10755      0.01620      0.02977      1.00000 |                                           *
    100       0.04831      0.10800      0.01541      0.03003      1.00000 |                                           *
    110       0.04630      0.10875      0.01488      0.03030      1.00000 |                                           *
    120       0.04523      0.10922      0.01462      0.03030      1.00000 |                                           *
    130       0.04398      0.10974      0.01343      0.03003      1.00000 |                                           *
    140       0.04325      0.11048      0.01343      0.03082      1.00000 |                                            *
    150       0.04148      0.11094      0.01251      0.03056      1.00000 |                                            *
    160       0.04000      0.11207      0.01211      0.03056      1.00000 |                                            *
    170       0.03892      0.11251      0.01185      0.03082      1.00000 |                                             *
    180       0.03796      0.11304      0.01159      0.03109      1.00000 |                                             *
    190       0.03752      0.11336      0.01119      0.03135      1.00000 |                                             *
    200       0.03671      0.11369      0.01119      0.03135      1.00000 |                                             *
    210       0.03574      0.11410      0.01053      0.03056      1.00000 |                                             *
    220       0.03444      0.11490      0.01014      0.03082      1.00000 |                                             *
    230       0.03361      0.11573      0.00935      0.03003      1.00000 |                                              *
    240       0.03280      0.11602      0.00922      0.03003      1.00000 |                                              *
    250       0.03137      0.11750      0.00856      0.03030      1.00000 |                                               *
    260       0.03000      0.11810      0.00869      0.03030      1.00000 |                                               *
    270       0.02880      0.11899      0.00856      0.03030      1.00000 |                                               *
    280       0.02766      0.11973      0.00790      0.03003      1.00000 |                                               *
    290       0.02677      0.12074      0.00724      0.03030      1.00000 |                                               *
    300       0.02591      0.12151      0.00685      0.03030      1.00000 |                                               *
    310       0.02444      0.12218      0.00619      0.03030      1.00000 |                                               *
    320       0.02332      0.12297      0.00606      0.03030      1.00000 |                                               *
    330       0.02195      0.12419      0.00540      0.03056      1.00000 |                                               *
    340       0.02110      0.12514      0.00553      0.03030      1.00000 |                                               *
    350       0.01985      0.12636      0.00487      0.03109      1.00000 |                                               *
    360       0.01928      0.12725      0.00487      0.03056      1.00000 |                                               *
    370       0.01779      0.12801      0.00395      0.03056      1.00000 |                                               *
    380       0.01728      0.12905      0.00395      0.03082      1.00000 |                                               *
    390       0.01655      0.12993      0.00395      0.03082      1.00000 |                                               *
    400       0.01586      0.13075      0.00356      0.03056      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.23      6.77  CHILDYRS
    294      1    399      1      7      3.92      3.00  AGE
    231      1    398      1      7      4.45      2.05  AGE_MOM
    230      1    398      1      7      4.99      1.73  INCOME
    207      1    398      2      7      5.08      1.51  OTH_CHLD
    185      1    400      2      7      5.24      1.28  EDUC_MOM
    112      1    398      2      7      5.82      0.61  RACE_MOM
    109      1    398      3      7      5.61      0.65  ILLEGIT
     88      1    397      1      7      5.42      0.57  PNCLATE
     52      1    398      2      7      5.62      0.31  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    72 terminal nodes
    Average :     22.73500 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 40 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 40 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 20

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 17788 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           20      0.10505
                  ROC           40      0.84790
                 Lift           13      5.54545
              KS-stat            2      0.56151
          Class.Error            7      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11097     0.11865     0.92993     0.77450     7.51796     4.79636     0.70084     0.47249     0.02910     0.02898
      2     0.10330     0.11488     0.93651     0.81107     7.64721     5.00439     0.72111     0.56151     0.02910     0.02898
      7     0.08377     0.10754     0.95130     0.83770     8.32579     5.09091     0.77004     0.52894     0.02699     0.02845
     10     0.07684     0.10582     0.95817     0.84121     8.68778     5.36364     0.81238     0.52515     0.02594     0.02898
     13     0.07204     0.10569     0.96037     0.83900     8.85520     5.54545     0.81165     0.52135     0.02541     0.02898
     20     0.06493     0.10505     0.96662     0.84281     9.00452     5.54545     0.82975     0.54091     0.02278     0.02871
     30     0.05968     0.10559     0.97299     0.84281     9.09502     5.36364     0.84344     0.52612     0.02160     0.02950
     40     0.05723     0.10542     0.97604     0.84790     9.14027     5.27273     0.84823     0.53752     0.02002     0.03030
     50     0.05487     0.10561     0.97838     0.84707     9.14027     5.09091     0.85724     0.53658     0.01949     0.03030
     60     0.05280     0.10641     0.98035     0.84523     9.23077     5.27273     0.86434     0.54051     0.01844     0.02924
     70     0.05211     0.10685     0.98082     0.84403     9.23077     5.27273     0.86859     0.53711     0.01778     0.02977
     80     0.05099     0.10731     0.98146     0.84345     9.27602     5.18182     0.87176     0.53481     0.01725     0.02977
     90     0.04963     0.10755     0.98319     0.84219     9.36652     5.18182     0.87615     0.52653     0.01620     0.02977
    100     0.04831     0.10800     0.98417     0.84106     9.45701     5.00000     0.87688     0.53373     0.01541     0.03003
    110     0.04630     0.10875     0.98888     0.83846     9.59276     5.09091     0.89398     0.52056     0.01488     0.03030
    120     0.04523     0.10922     0.98939     0.83770     9.63801     5.09091     0.89371     0.51624     0.01462     0.03030
    130     0.04398     0.10974     0.99035     0.83572     9.63801     5.09091     0.90126     0.51676     0.01343     0.03003
    140     0.04325     0.11048     0.99076     0.83313     9.68326     5.00000     0.90276     0.51731     0.01343     0.03082
    150     0.04148     0.11094     0.99184     0.83291     9.74661     5.09091     0.90904     0.51228     0.01251     0.03056
    160     0.04000     0.11207     0.99267     0.83073     9.81900     5.00000     0.91628     0.51229     0.01211     0.03056
    170     0.03892     0.11251     0.99341     0.82922     9.81900     5.09091     0.92094     0.50049     0.01185     0.03082
    180     0.03796     0.11304     0.99464     0.82941     9.86425     5.00000     0.92574     0.50116     0.01159     0.03109
    190     0.03752     0.11336     0.99478     0.82821     9.86425     5.00000     0.92574     0.49967     0.01119     0.03135
    200     0.03671     0.11369     0.99546     0.82683     9.90950     5.00000     0.93121     0.49928     0.01119     0.03135
    210     0.03574     0.11410     0.99577     0.82607     9.90950     5.05455     0.93338     0.49913     0.01053     0.03056
    220     0.03444     0.11490     0.99635     0.82369     9.90950     5.18182     0.93660     0.50117     0.01014     0.03082
    230     0.03361     0.11573     0.99683     0.82083     9.90950     5.09091     0.94660     0.49289     0.00935     0.03003
    240     0.03280     0.11602     0.99725     0.81940     9.95475     5.09091     0.95085     0.49208     0.00922     0.03003
    241     0.03257     0.11620     0.99736     0.81831    10.00000     5.00000     0.95112     0.48977     0.00922     0.02977
    250     0.03137     0.11750     0.99784     0.81407    10.00000     5.00000     0.95578     0.47607     0.00856     0.03030
    260     0.03000     0.11810     0.99828     0.81297    10.00000     5.00000     0.95881     0.47253     0.00869     0.03030
    270     0.02880     0.11899     0.99853     0.81073    10.00000     4.90909     0.96193     0.47038     0.00856     0.03030
    280     0.02766     0.11973     0.99882     0.80947    10.00000     4.90909     0.96664     0.46495     0.00790     0.03003
    290     0.02677     0.12074     0.99892     0.80712    10.00000     4.90909     0.96948     0.46397     0.00724     0.03030
    300     0.02591     0.12151     0.99904     0.80437    10.00000     4.81818     0.97125     0.46506     0.00685     0.03030
    310     0.02444     0.12218     0.99935     0.80370    10.00000     4.90909     0.97762     0.45475     0.00619     0.03030
    320     0.02332     0.12297     0.99946     0.80181    10.00000     4.72727     0.97816     0.45380     0.00606     0.03030
    330     0.02195     0.12419     0.99963     0.79861    10.00000     4.72727     0.98395     0.44960     0.00540     0.03056
    340     0.02110     0.12514     0.99974     0.79596    10.00000     4.72727     0.98562     0.44648     0.00553     0.03030
    350     0.01985     0.12636     0.99988     0.79314    10.00000     4.72727     0.99363     0.43968     0.00487     0.03109
    360     0.01928     0.12725     0.99991     0.79040    10.00000     4.72727     0.99539     0.43859     0.00487     0.03056
    370     0.01779     0.12801     0.99998     0.79615    10.00000     4.63636     0.99878     0.45705     0.00395     0.03056
    380     0.01728     0.12905     0.99998     0.79302    10.00000     4.69091     0.99891     0.45013     0.00395     0.03082
    390     0.01655     0.12993     0.99999     0.79304    10.00000     4.63636     0.99932     0.45311     0.00395     0.03082
    397     0.01605     0.13051     0.99999     0.79157    10.00000     4.54545     0.99932     0.44809     0.00356     0.03056
    399     0.01586     0.13077     0.99999     0.79166    10.00000     4.63636     0.99932     0.44849     0.00356     0.03056
    400     0.01586     0.13075     0.99999     0.79172    10.00000     4.63636     0.99932     0.44849     0.00356     0.03056


 =========================================
 Variable Importance for the 20-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          39.28190   39.28 |*****      |
 AGE_MOM      39.15574   39.16 |*****      |
 OTH_CHLD     38.72989   38.73 |*****      |
 EDUC_MOM     33.54834   33.55 |****       |
 INCOME       27.43248   27.43 |****       |
 RACE_MOM     18.47208   18.47 |***        |
 ILLEGIT      17.20784   17.21 |***        |
 PNCLATE      11.90057   11.90 |**         |
 LBW          10.51894   10.52 |**         |


 Learn Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7368.00         5.00       0.0007
 1                  221.00        53.00       168.00       0.7602


 Test Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3672.00        14.00       0.0038
 1                  110.00        15.00        95.00       0.8636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 841 kb , 75% compression

 Grove file created containing:
      1 TreeNet

