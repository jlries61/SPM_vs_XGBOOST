
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11165      0.11837      0.02910      0.02898      1.00000 |                                               *
      2       0.10584      0.11420      0.02910      0.02898      1.00000 |                                             *
      3       0.10136      0.11189      0.02910      0.02898      1.00000 |                                            *
      4       0.09746      0.10963      0.02910      0.02898      1.00000 |                                           *
      5       0.09428      0.10788      0.02910      0.02898      1.00000 |                                           *
      6       0.09166      0.10670      0.02858      0.02871      1.00000 |                                          *
      7       0.08916      0.10618      0.02858      0.02871      1.00000 |                                          *
      8       0.08634      0.10516      0.02818      0.02819      1.00000 |                                          *
      9       0.08386      0.10492      0.02805      0.02819      1.00000 |                                          *
     10       0.08119      0.10428      0.02726      0.02845      1.00000 |                                         *
     11       0.07950      0.10397      0.02660      0.02871      1.00000 |                                         *
     12       0.07699      0.10330      0.02607      0.02898      1.00000 |                                         *
     13       0.07551      0.10304      0.02568      0.02924      1.00000 |                                         *
     14       0.07414      0.10270      0.02502      0.02924      1.00000 |                                         *
     15       0.07321      0.10273      0.02489      0.02898      1.00000 |                                         *
     16       0.07232      0.10288      0.02489      0.02924      1.00000 |                                         *
     17       0.07105      0.10265      0.02436      0.02871      1.00000 |                                         *
     18       0.07008      0.10237      0.02423      0.02898      1.00000 |                                         *
     19       0.06933      0.10207      0.02397      0.02924      1.00000 |                                        *
     20       0.06850      0.10202      0.02357      0.02977      1.00000 |                                        *
     30       0.06315      0.10204      0.02160      0.02977      1.00000 |                                        *
     40       0.06024      0.10199      0.02028      0.03030      1.00000 |                                        *
     50       0.05817      0.10219      0.01975      0.03003      1.00000 |                                        *
     60       0.05662      0.10254      0.01923      0.03056      1.00000 |                                         *
     70       0.05449      0.10299      0.01909      0.03109      1.00000 |                                         *
     80       0.05224      0.10370      0.01830      0.03109      1.00000 |                                         *
     90       0.05102      0.10434      0.01791      0.03082      1.00000 |                                         *
    100       0.04907      0.10562      0.01699      0.03109      1.00000 |                                          *
    110       0.04736      0.10640      0.01620      0.03188      1.00000 |                                          *
    120       0.04629      0.10700      0.01554      0.03240      1.00000 |                                          *
    130       0.04522      0.10732      0.01514      0.03214      1.00000 |                                           *
    140       0.04417      0.10791      0.01475      0.03240      1.00000 |                                           *
    150       0.04360      0.10820      0.01488      0.03214      1.00000 |                                           *
    160       0.04282      0.10868      0.01462      0.03214      1.00000 |                                           *
    170       0.04227      0.10914      0.01449      0.03214      1.00000 |                                           *
    180       0.04065      0.10978      0.01462      0.03240      1.00000 |                                            *
    190       0.04011      0.10990      0.01422      0.03214      1.00000 |                                            *
    200       0.03913      0.11019      0.01330      0.03267      1.00000 |                                            *
    210       0.03796      0.11069      0.01290      0.03293      1.00000 |                                            *
    220       0.03708      0.11114      0.01251      0.03267      1.00000 |                                            *
    230       0.03649      0.11154      0.01225      0.03267      1.00000 |                                            *
    240       0.03551      0.11181      0.01251      0.03240      1.00000 |                                            *
    250       0.03478      0.11244      0.01172      0.03267      1.00000 |                                             *
    260       0.03363      0.11313      0.01159      0.03267      1.00000 |                                             *
    270       0.03291      0.11402      0.01132      0.03293      1.00000 |                                             *
    280       0.03247      0.11454      0.01119      0.03293      1.00000 |                                             *
    290       0.03188      0.11486      0.01093      0.03293      1.00000 |                                              *
    300       0.03128      0.11550      0.01053      0.03267      1.00000 |                                              *
    310       0.03076      0.11607      0.01027      0.03267      1.00000 |                                              *
    320       0.03002      0.11676      0.01001      0.03267      1.00000 |                                              *
    330       0.02972      0.11711      0.01001      0.03267      1.00000 |                                              *
    340       0.02936      0.11752      0.00988      0.03267      1.00000 |                                               *
    350       0.02912      0.11768      0.00974      0.03267      1.00000 |                                               *
    360       0.02863      0.11837      0.00974      0.03267      1.00000 |                                               *
    370       0.02795      0.11852      0.00922      0.03293      1.00000 |                                               *
    380       0.02729      0.11860      0.00909      0.03293      1.00000 |                                               *
    390       0.02676      0.11917      0.00790      0.03293      1.00000 |                                               *
    400       0.02600      0.11953      0.00764      0.03293      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.09      6.91  CHILDYRS
    274      1    400      1      7      4.68      2.28  AGE
    203      1    398      1      7      5.26      1.39  AGE_MOM
    202      1    400      2      7      5.49      1.27  INCOME
    175      1    399      1      7      5.49      1.10  EDUC_MOM
    175      1    400      2      7      5.59      1.05  OTH_CHLD
     92      1    398      1      7      5.47      0.58  ILLEGIT
     85      1    397      2      7      5.54      0.52  PNCLATE
     60      1    393      4      7      5.93      0.31  RACE_MOM
     51      1    369      3      7      5.31      0.34  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    68 terminal nodes
    Average :     19.29750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 35 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 35 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 24

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 15038 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           24      0.10161
                  ROC            2      0.86482
                 Lift           35      6.18182
              KS-stat          254      0.59640
          Class.Error            8      0.02819

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11165     0.11837     0.92192     0.82240     7.11032     5.54545     0.67912     0.52812     0.02910     0.02898
      2     0.10584     0.11420     0.92902     0.86482     7.20411     5.45455     0.70188     0.59206     0.02910     0.02898
      8     0.08634     0.10516     0.94969     0.85499     8.05430     5.69091     0.77630     0.56355     0.02818     0.02819
     10     0.08119     0.10428     0.96006     0.85583     8.50679     5.78182     0.80839     0.56846     0.02726     0.02845
     20     0.06850     0.10202     0.97054     0.86109     8.82353     6.00000     0.83611     0.58580     0.02357     0.02977
     24     0.06593     0.10161     0.97270     0.86331     8.86878     6.00000     0.83637     0.58498     0.02252     0.03003
     30     0.06315     0.10204     0.97632     0.86132     9.14027     6.09091     0.85574     0.58364     0.02160     0.02977
     35     0.06181     0.10190     0.97753     0.86138     9.27602     6.18182     0.86157     0.58188     0.02146     0.02977
     40     0.06024     0.10199     0.97892     0.86207     9.32127     6.18182     0.86356     0.58160     0.02028     0.03030
     50     0.05817     0.10219     0.98095     0.86247     9.41176     6.18182     0.86919     0.58459     0.01975     0.03003
     60     0.05662     0.10254     0.98203     0.86226     9.36652     6.14545     0.86987     0.58485     0.01923     0.03056
     70     0.05449     0.10299     0.98366     0.86359     9.45701     6.09091     0.87385     0.58647     0.01909     0.03109
     80     0.05224     0.10370     0.98763     0.86187     9.68326     6.00000     0.89549     0.58837     0.01830     0.03109
     90     0.05102     0.10434     0.98807     0.86057     9.72851     5.90909     0.89988     0.58486     0.01791     0.03082
    100     0.04907     0.10562     0.98936     0.85865     9.72851     5.90909     0.90566     0.58393     0.01699     0.03109
    110     0.04736     0.10640     0.99052     0.85725     9.72851     5.72727     0.90707     0.58705     0.01620     0.03188
    120     0.04629     0.10700     0.99106     0.85683     9.72851     5.72727     0.90680     0.59139     0.01554     0.03240
    130     0.04522     0.10732     0.99164     0.85577     9.77376     5.81818     0.91173     0.59125     0.01514     0.03214
    140     0.04417     0.10791     0.99222     0.85574     9.81900     5.63636     0.91788     0.59301     0.01475     0.03240
    150     0.04360     0.10820     0.99256     0.85568     9.81900     5.72727     0.91693     0.59220     0.01488     0.03214
    160     0.04282     0.10868     0.99317     0.85512     9.81900     5.63636     0.92306     0.58704     0.01462     0.03214
    170     0.04227     0.10914     0.99333     0.85426     9.81900     5.54545     0.92537     0.58473     0.01449     0.03214
    180     0.04065     0.10978     0.99419     0.85310     9.81900     5.45455     0.92469     0.58242     0.01462     0.03240
    190     0.04011     0.10990     0.99443     0.85293     9.81900     5.54545     0.92632     0.58392     0.01422     0.03214
    200     0.03913     0.11019     0.99481     0.85272     9.81900     5.54545     0.92713     0.58609     0.01330     0.03267
    210     0.03796     0.11069     0.99538     0.85209     9.86425     5.45455     0.92967     0.57687     0.01290     0.03293
    220     0.03708     0.11114     0.99600     0.85112     9.86425     5.54545     0.94061     0.58894     0.01251     0.03267
    230     0.03649     0.11154     0.99622     0.85085     9.86425     5.36364     0.94093     0.58840     0.01225     0.03267
    240     0.03551     0.11181     0.99659     0.85124     9.86425     5.36364     0.94571     0.59043     0.01251     0.03240
    250     0.03478     0.11244     0.99713     0.84955     9.95475     5.27273     0.94649     0.59328     0.01172     0.03267
    254     0.03456     0.11247     0.99722     0.84969     9.95475     5.27273     0.94757     0.59640     0.01172     0.03293
    260     0.03363     0.11313     0.99751     0.84832     9.95475     5.27273     0.95445     0.58880     0.01159     0.03267
    270     0.03291     0.11402     0.99779     0.84581     9.95475     5.36364     0.95640     0.57605     0.01132     0.03293
    280     0.03247     0.11454     0.99790     0.84453     9.95475     5.36364     0.95694     0.57578     0.01119     0.03293
    290     0.03188     0.11486     0.99802     0.84457     9.95475     5.18182     0.95735     0.57470     0.01093     0.03293
    300     0.03128     0.11550     0.99816     0.84350     9.95475     5.36364     0.95947     0.57063     0.01053     0.03267
    310     0.03076     0.11607     0.99826     0.84350     9.95475     5.36364     0.96001     0.57497     0.01027     0.03267
    320     0.03002     0.11676     0.99839     0.84235     9.95475     5.18182     0.96341     0.56466     0.01001     0.03267
    330     0.02972     0.11711     0.99844     0.84167     9.95475     5.09091     0.96463     0.55679     0.01001     0.03267
    340     0.02936     0.11752     0.99853     0.84177     9.95475     5.14545     0.96300     0.55598     0.00988     0.03267
    350     0.02912     0.11768     0.99856     0.84165     9.95475     5.09091     0.96300     0.55150     0.00974     0.03267
    360     0.02863     0.11837     0.99864     0.83982     9.95475     5.09091     0.96313     0.54878     0.00974     0.03267
    365     0.02823     0.11843     0.99872     0.84047    10.00000     5.00000     0.96463     0.54958     0.00961     0.03293
    370     0.02795     0.11852     0.99875     0.84070    10.00000     5.00000     0.96530     0.55013     0.00922     0.03293
    380     0.02729     0.11860     0.99884     0.84182    10.00000     5.09091     0.96775     0.55637     0.00909     0.03293
    390     0.02676     0.11917     0.99890     0.84075    10.00000     5.09091     0.96775     0.55420     0.00790     0.03293
    398     0.02610     0.11948     0.99902     0.84158    10.00000     5.09091     0.96897     0.54904     0.00764     0.03293
    400     0.02600     0.11953     0.99904     0.84121    10.00000     5.09091     0.97005     0.54945     0.00764     0.03293


 =========================================
 Variable Importance for the 24-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          39.47683   39.48 |*****      |
 EDUC_MOM     37.93691   37.94 |*****      |
 INCOME       36.46307   36.46 |*****      |
 AGE_MOM      29.37918   29.38 |****       |
 OTH_CHLD     29.03314   29.03 |****       |
 RACE_MOM     22.64363   22.64 |***        |
 ILLEGIT      15.71746   15.72 |***        |
 PNCLATE      14.27595   14.28 |**         |
 LBW           9.76554    9.77 |**         |


 Learn Sample Misclassification by Target Class
 For The 24-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7366.00         7.00       0.0009
 1                  221.00        57.00       164.00       0.7421


 Test Sample Misclassification by Target Class
 For The 24-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3673.00        13.00       0.0035
 1                  110.00         9.00       101.00       0.9182

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 698 kb , 76% compression

 Grove file created containing:
      1 TreeNet

