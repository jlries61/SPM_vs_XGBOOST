
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11037      0.11907      0.02910      0.02898      1.00000 |                                               *
      2       0.10262      0.11634      0.02910      0.02898      1.00000 |                                              *
      3       0.09722      0.11465      0.02910      0.02898      1.00000 |                                             *
      4       0.09296      0.11331      0.02910      0.02898      1.00000 |                                             *
      5       0.08875      0.11128      0.02910      0.02898      1.00000 |                                            *
      6       0.08612      0.11006      0.02910      0.02898      1.00000 |                                           *
      7       0.08303      0.10912      0.02805      0.02845      1.00000 |                                           *
      8       0.08056      0.10839      0.02765      0.02792      1.00000 |                                           *
      9       0.07799      0.10792      0.02713      0.02792      1.00000 |                                           *
     10       0.07626      0.10790      0.02699      0.02792      1.00000 |                                           *
     11       0.07455      0.10769      0.02594      0.02845      1.00000 |                                          *
     12       0.07349      0.10776      0.02541      0.02845      1.00000 |                                          *
     13       0.07169      0.10741      0.02502      0.02871      1.00000 |                                          *
     14       0.07082      0.10738      0.02489      0.02871      1.00000 |                                          *
     15       0.07002      0.10740      0.02489      0.02871      1.00000 |                                          *
     16       0.06885      0.10713      0.02410      0.02845      1.00000 |                                          *
     17       0.06827      0.10720      0.02370      0.02792      1.00000 |                                          *
     18       0.06711      0.10740      0.02344      0.02845      1.00000 |                                          *
     19       0.06651      0.10755      0.02344      0.02898      1.00000 |                                          *
     20       0.06536      0.10756      0.02278      0.02845      1.00000 |                                          *
     30       0.06004      0.10789      0.02160      0.02845      1.00000 |                                          *
     40       0.05635      0.10815      0.02002      0.02898      1.00000 |                                           *
     50       0.05312      0.10837      0.01883      0.02898      1.00000 |                                           *
     60       0.05174      0.10856      0.01791      0.02898      1.00000 |                                           *
     70       0.05024      0.10931      0.01738      0.02924      1.00000 |                                           *
     80       0.04891      0.10954      0.01686      0.02924      1.00000 |                                           *
     90       0.04727      0.10971      0.01633      0.02924      1.00000 |                                           *
    100       0.04490      0.11015      0.01580      0.02950      1.00000 |                                           *
    110       0.04309      0.11104      0.01501      0.03003      1.00000 |                                            *
    120       0.04110      0.11186      0.01383      0.03030      1.00000 |                                            *
    130       0.04053      0.11219      0.01356      0.03003      1.00000 |                                            *
    140       0.03858      0.11314      0.01251      0.03056      1.00000 |                                             *
    150       0.03755      0.11396      0.01211      0.03056      1.00000 |                                             *
    160       0.03704      0.11418      0.01185      0.03056      1.00000 |                                             *
    170       0.03665      0.11456      0.01185      0.03056      1.00000 |                                             *
    180       0.03595      0.11483      0.01159      0.03082      1.00000 |                                             *
    190       0.03497      0.11534      0.01119      0.03135      1.00000 |                                             *
    200       0.03458      0.11582      0.01106      0.03161      1.00000 |                                              *
    210       0.03426      0.11611      0.01093      0.03188      1.00000 |                                              *
    220       0.03347      0.11650      0.01067      0.03240      1.00000 |                                              *
    230       0.03255      0.11691      0.01067      0.03188      1.00000 |                                              *
    240       0.03133      0.11753      0.01014      0.03293      1.00000 |                                              *
    250       0.03054      0.11789      0.00988      0.03214      1.00000 |                                               *
    260       0.02992      0.11857      0.00948      0.03240      1.00000 |                                               *
    270       0.02848      0.11942      0.00909      0.03240      1.00000 |                                               *
    280       0.02753      0.11960      0.00895      0.03293      1.00000 |                                               *
    290       0.02680      0.11985      0.00816      0.03267      1.00000 |                                               *
    300       0.02604      0.12051      0.00777      0.03214      1.00000 |                                               *
    310       0.02539      0.12138      0.00711      0.03267      1.00000 |                                               *
    320       0.02454      0.12225      0.00672      0.03240      1.00000 |                                               *
    330       0.02376      0.12341      0.00672      0.03319      1.00000 |                                               *
    340       0.02294      0.12388      0.00619      0.03319      1.00000 |                                               *
    350       0.02200      0.12493      0.00566      0.03293      1.00000 |                                               *
    360       0.02137      0.12525      0.00566      0.03267      1.00000 |                                               *
    370       0.02035      0.12633      0.00448      0.03267      1.00000 |                                               *
    380       0.01971      0.12704      0.00435      0.03293      1.00000 |                                               *
    390       0.01919      0.12780      0.00421      0.03293      1.00000 |                                               *
    400       0.01835      0.12836      0.00408      0.03319      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      2      1.11      6.89  CHILDYRS
    253      1    400      1      7      4.55      2.18  AGE
    252      1    400      1      7      5.30      1.70  INCOME
    208      1    399      2      7      4.61      1.76  AGE_MOM
    204      1    400      1      7      5.48      1.29  OTH_CHLD
    194      1    398      3      7      5.44      1.24  EDUC_MOM
    142      1    400      1      7      5.02      1.06  ILLEGIT
    115      1    397      2      7      5.33      0.77  RACE_MOM
     64      1    396      2      7      5.70      0.37  LBW
     61      1    396      3      7      6.05      0.30  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    72 terminal nodes
    Average :     21.31500 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 16652 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.10713
                  ROC           28      0.84853
                 Lift            9      5.36364
              KS-stat           40      0.58581
          Class.Error            8      0.02792

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11037     0.11907     0.92569     0.78653     7.69903     4.85868     0.72006     0.46345     0.02910     0.02898
      8     0.08056     0.10839     0.96056     0.83244     8.59729     5.00000     0.78654     0.57659     0.02765     0.02792
      9     0.07799     0.10792     0.96223     0.83055     8.68778     5.36364     0.79220     0.57469     0.02713     0.02792
     10     0.07626     0.10790     0.96251     0.83077     8.61538     5.00000     0.79292     0.57172     0.02699     0.02792
     16     0.06885     0.10713     0.96458     0.84272     8.73303     5.09091     0.80529     0.57023     0.02410     0.02845
     20     0.06536     0.10756     0.96655     0.84170     8.82353     4.90909     0.81366     0.57238     0.02278     0.02845
     28     0.06069     0.10749     0.97107     0.84853     8.93213     5.09091     0.83370     0.57552     0.02186     0.02845
     30     0.06004     0.10789     0.97158     0.84581     8.95928     5.00000     0.83383     0.57390     0.02160     0.02845
     40     0.05635     0.10815     0.97644     0.84594     9.00452     5.00000     0.85117     0.58581     0.02002     0.02898
     50     0.05312     0.10837     0.98284     0.84500     9.27602     5.09091     0.87745     0.56683     0.01883     0.02898
     60     0.05174     0.10856     0.98470     0.84448     9.41176     5.09091     0.88022     0.55611     0.01791     0.02898
     70     0.05024     0.10931     0.98580     0.84252     9.45701     4.81818     0.88688     0.56032     0.01738     0.02924
     80     0.04891     0.10954     0.98656     0.84171     9.50226     4.63636     0.88706     0.56237     0.01686     0.02924
     90     0.04727     0.10971     0.98734     0.84123     9.50226     4.72727     0.89637     0.54758     0.01633     0.02924
    100     0.04490     0.11015     0.99118     0.84221     9.72851     4.72727     0.91818     0.55708     0.01580     0.02950
    110     0.04309     0.11104     0.99227     0.84033     9.77376     4.63636     0.92989     0.55301     0.01501     0.03003
    120     0.04110     0.11186     0.99345     0.84059     9.77376     4.90909     0.93229     0.55883     0.01383     0.03030
    130     0.04053     0.11219     0.99358     0.83942     9.77376     4.90909     0.93201     0.55923     0.01356     0.03003
    140     0.03858     0.11314     0.99510     0.83753     9.90950     4.81818     0.93283     0.54716     0.01251     0.03056
    150     0.03755     0.11396     0.99540     0.83473     9.90950     4.72727     0.93545     0.54758     0.01211     0.03056
    160     0.03704     0.11418     0.99554     0.83393     9.90950     4.81818     0.93790     0.54256     0.01185     0.03056
    170     0.03665     0.11456     0.99570     0.83209     9.90950     4.72727     0.94215     0.53984     0.01185     0.03056
    180     0.03595     0.11483     0.99595     0.83168     9.90950     4.81818     0.94242     0.54188     0.01159     0.03082
    190     0.03497     0.11534     0.99630     0.83060     9.90950     4.72727     0.94473     0.53266     0.01119     0.03135
    200     0.03458     0.11582     0.99638     0.82937     9.90950     4.72727     0.94717     0.52913     0.01106     0.03161
    210     0.03426     0.11611     0.99648     0.82914     9.90950     4.69091     0.94730     0.53740     0.01093     0.03188
    220     0.03347     0.11650     0.99680     0.82838     9.90950     4.63636     0.95124     0.53049     0.01067     0.03240
    230     0.03255     0.11691     0.99711     0.82784     9.90950     4.81818     0.95223     0.52980     0.01067     0.03188
    235     0.03175     0.11726     0.99776     0.82768    10.00000     4.81818     0.95278     0.51950     0.01014     0.03188
    240     0.03133     0.11753     0.99784     0.82685    10.00000     4.81818     0.95332     0.52031     0.01014     0.03293
    250     0.03054     0.11789     0.99804     0.82649    10.00000     4.72727     0.95698     0.51502     0.00988     0.03214
    260     0.02992     0.11857     0.99820     0.82482    10.00000     4.63636     0.95685     0.50945     0.00948     0.03240
    270     0.02848     0.11942     0.99868     0.82460    10.00000     4.54545     0.96214     0.52316     0.00909     0.03240
    280     0.02753     0.11960     0.99894     0.82645    10.00000     4.63636     0.96296     0.52208     0.00895     0.03293
    290     0.02680     0.11985     0.99901     0.82624    10.00000     4.72727     0.96553     0.52655     0.00816     0.03267
    300     0.02604     0.12051     0.99918     0.82612    10.00000     4.72727     0.97029     0.52072     0.00777     0.03214
    310     0.02539     0.12138     0.99926     0.82477    10.00000     4.45455     0.97093     0.51814     0.00711     0.03267
    320     0.02454     0.12225     0.99946     0.82156    10.00000     4.45455     0.97694     0.51039     0.00672     0.03240
    330     0.02376     0.12341     0.99958     0.81870    10.00000     4.63636     0.98359     0.50469     0.00672     0.03319
    340     0.02294     0.12388     0.99965     0.81935    10.00000     4.54545     0.98413     0.52328     0.00619     0.03319
    350     0.02200     0.12493     0.99976     0.81871    10.00000     4.63636     0.98476     0.51514     0.00566     0.03293
    360     0.02137     0.12525     0.99981     0.81907    10.00000     4.60000     0.98630     0.52246     0.00566     0.03267
    370     0.02035     0.12633     0.99988     0.81777    10.00000     4.63636     0.99078     0.49982     0.00448     0.03267
    380     0.01971     0.12704     0.99989     0.81819    10.00000     4.63636     0.99091     0.49697     0.00435     0.03293
    390     0.01919     0.12780     0.99990     0.81638    10.00000     4.54545     0.99105     0.49548     0.00421     0.03293
    394     0.01882     0.12826     0.99990     0.81637    10.00000     4.54545     0.99132     0.49657     0.00408     0.03293
    398     0.01849     0.12848     0.99994     0.81667    10.00000     4.45455     0.99425     0.50091     0.00408     0.03319
    399     0.01848     0.12844     0.99994     0.81672    10.00000     4.36364     0.99425     0.50118     0.00408     0.03319
    400     0.01835     0.12836     0.99994     0.81809    10.00000     4.36364     0.99412     0.50335     0.00408     0.03319


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      41.46644   41.47 |*****      |
 OTH_CHLD     33.65866   33.66 |****       |
 AGE          31.51099   31.51 |****       |
 INCOME       26.10628   26.11 |****       |
 EDUC_MOM     23.91172   23.91 |***        |
 ILLEGIT      23.67306   23.67 |***        |
 PNCLATE      13.93781   13.94 |**         |
 LBW          10.68384   10.68 |**         |
 RACE_MOM     10.27861   10.28 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7365.00         8.00       0.0011
 1                  221.00        46.00       175.00       0.7919


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3676.00        10.00       0.0027
 1                  110.00        12.00        98.00       0.8909

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 789 kb , 76% compression

 Grove file created containing:
      1 TreeNet

