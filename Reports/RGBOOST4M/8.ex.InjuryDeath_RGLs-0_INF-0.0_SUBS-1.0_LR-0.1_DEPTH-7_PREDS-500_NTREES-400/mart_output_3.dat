
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11129      0.11967      0.02910      0.02898      1.00000 |                                               *
      2       0.10376      0.11650      0.02910      0.02898      1.00000 |                                              *
      3       0.09818      0.11439      0.02910      0.02898      1.00000 |                                             *
      4       0.09410      0.11252      0.02910      0.02898      1.00000 |                                            *
      5       0.09036      0.11107      0.02910      0.02898      1.00000 |                                            *
      6       0.08745      0.10992      0.02884      0.02924      1.00000 |                                           *
      7       0.08454      0.10962      0.02884      0.02924      1.00000 |                                           *
      8       0.08201      0.10888      0.02831      0.02871      1.00000 |                                           *
      9       0.07974      0.10871      0.02792      0.02871      1.00000 |                                           *
     10       0.07787      0.10850      0.02739      0.02898      1.00000 |                                           *
     11       0.07585      0.10816      0.02739      0.02898      1.00000 |                                          *
     12       0.07434      0.10778      0.02673      0.02924      1.00000 |                                          *
     13       0.07242      0.10745      0.02541      0.02924      1.00000 |                                          *
     14       0.07123      0.10729      0.02528      0.02924      1.00000 |                                          *
     15       0.07024      0.10717      0.02449      0.02924      1.00000 |                                          *
     16       0.06944      0.10692      0.02423      0.02924      1.00000 |                                          *
     17       0.06875      0.10679      0.02357      0.02924      1.00000 |                                          *
     18       0.06824      0.10666      0.02397      0.02950      1.00000 |                                          *
     19       0.06775      0.10675      0.02423      0.02977      1.00000 |                                          *
     20       0.06742      0.10669      0.02397      0.03003      1.00000 |                                          *
     30       0.06214      0.10623      0.02120      0.03082      1.00000 |                                          *
     40       0.05634      0.10683      0.02015      0.02977      1.00000 |                                          *
     50       0.05398      0.10743      0.02015      0.02950      1.00000 |                                          *
     60       0.05161      0.10834      0.01870      0.03056      1.00000 |                                          *
     70       0.04923      0.10894      0.01751      0.03003      1.00000 |                                           *
     80       0.04704      0.10949      0.01620      0.03003      1.00000 |                                           *
     90       0.04444      0.11036      0.01501      0.03056      1.00000 |                                           *
    100       0.04300      0.11116      0.01462      0.03056      1.00000 |                                            *
    110       0.04255      0.11145      0.01435      0.03030      1.00000 |                                            *
    120       0.04120      0.11236      0.01396      0.03030      1.00000 |                                            *
    130       0.04017      0.11294      0.01317      0.03030      1.00000 |                                            *
    140       0.03804      0.11378      0.01211      0.03030      1.00000 |                                             *
    150       0.03536      0.11479      0.01053      0.03056      1.00000 |                                             *
    160       0.03354      0.11579      0.01001      0.03135      1.00000 |                                             *
    170       0.03221      0.11623      0.00988      0.03135      1.00000 |                                              *
    180       0.03001      0.11692      0.00882      0.03161      1.00000 |                                              *
    190       0.02934      0.11775      0.00856      0.03161      1.00000 |                                              *
    200       0.02745      0.11935      0.00790      0.03188      1.00000 |                                               *
    210       0.02661      0.11992      0.00764      0.03188      1.00000 |                                               *
    220       0.02605      0.12053      0.00737      0.03188      1.00000 |                                               *
    230       0.02518      0.12111      0.00672      0.03135      1.00000 |                                               *
    240       0.02454      0.12144      0.00619      0.03109      1.00000 |                                               *
    250       0.02405      0.12169      0.00606      0.03109      1.00000 |                                               *
    260       0.02382      0.12180      0.00579      0.03109      1.00000 |                                               *
    270       0.02330      0.12210      0.00579      0.03109      1.00000 |                                               *
    280       0.02294      0.12253      0.00566      0.03109      1.00000 |                                               *
    290       0.02224      0.12283      0.00514      0.03109      1.00000 |                                               *
    300       0.02194      0.12298      0.00500      0.03109      1.00000 |                                               *
    310       0.02151      0.12316      0.00474      0.03109      1.00000 |                                               *
    320       0.02106      0.12372      0.00487      0.03109      1.00000 |                                               *
    330       0.02083      0.12411      0.00474      0.03109      1.00000 |                                               *
    340       0.01995      0.12506      0.00408      0.03109      1.00000 |                                               *
    350       0.01928      0.12541      0.00369      0.03082      1.00000 |                                               *
    360       0.01882      0.12589      0.00369      0.03056      1.00000 |                                               *
    370       0.01839      0.12681      0.00356      0.03056      1.00000 |                                               *
    380       0.01767      0.12723      0.00329      0.03082      1.00000 |                                               *
    390       0.01690      0.12809      0.00290      0.03056      1.00000 |                                               *
    400       0.01642      0.12909      0.00237      0.03109      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.22      6.78  CHILDYRS
    234      1    399      1      7      4.29      2.17  AGE
    221      1    400      1      7      4.75      1.80  INCOME
    203      1    398      1      7      4.03      2.01  AGE_MOM
    169      1    399      2      7      5.04      1.25  OTH_CHLD
    168      1    398      1      7      4.60      1.43  EDUC_MOM
    153      1    398      1      7      4.75      1.25  ILLEGIT
     83      1    397      1      7      5.20      0.58  RACE_MOM
     76      1    391      2      7      5.45      0.49  PNCLATE
     50      1    397      2      7      5.36      0.33  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    78 terminal nodes
    Average :     23.20250 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 47 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 47 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 30

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 18162 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           30      0.10623
                  ROC           34      0.84318
                 Lift           47      5.45455
              KS-stat           26      0.56885
          Class.Error            8      0.02871

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11129     0.11967     0.92475     0.75328     7.47059     4.86942     0.69372     0.45053     0.02910     0.02898
      8     0.08201     0.10888     0.95018     0.81722     8.32579     5.18182     0.76157     0.50916     0.02831     0.02871
     10     0.07787     0.10850     0.95461     0.81850     8.34389     5.00000     0.77931     0.53181     0.02739     0.02898
     20     0.06742     0.10669     0.96407     0.83183     8.77828     5.32727     0.81191     0.55841     0.02397     0.03003
     26     0.06383     0.10631     0.96986     0.83852     9.00452     5.27273     0.82491     0.56885     0.02173     0.03030
     30     0.06214     0.10623     0.97129     0.84294     9.00452     5.27273     0.83354     0.56804     0.02120     0.03082
     34     0.06004     0.10652     0.97766     0.84318     9.14027     5.27273     0.84879     0.56139     0.02107     0.03030
     40     0.05634     0.10683     0.98456     0.84239     9.36652     5.36364     0.87944     0.55245     0.02015     0.02977
     47     0.05439     0.10726     0.98648     0.84129     9.47511     5.45455     0.88654     0.55381     0.02015     0.03003
     50     0.05398     0.10743     0.98663     0.84058     9.50226     5.18182     0.88722     0.54879     0.02015     0.02950
     60     0.05161     0.10834     0.98786     0.83749     9.45701     5.27273     0.88871     0.53439     0.01870     0.03056
     70     0.04923     0.10894     0.98928     0.83846     9.54751     5.18182     0.89047     0.54877     0.01751     0.03003
     80     0.04704     0.10949     0.99082     0.83804     9.63801     5.18182     0.90049     0.53887     0.01620     0.03003
     90     0.04444     0.11036     0.99238     0.83467     9.72851     5.00000     0.90740     0.53330     0.01501     0.03056
    100     0.04300     0.11116     0.99322     0.83393     9.77376     4.90909     0.91233     0.53465     0.01462     0.03056
    110     0.04255     0.11145     0.99340     0.83282     9.77376     5.00000     0.91342     0.53506     0.01435     0.03030
    120     0.04120     0.11236     0.99403     0.83150     9.90950     5.00000     0.91893     0.52760     0.01396     0.03030
    130     0.04017     0.11294     0.99435     0.83059     9.90950     4.90909     0.92201     0.52624     0.01317     0.03030
    139     0.03805     0.11376     0.99580     0.82832    10.00000     5.00000     0.93461     0.53262     0.01211     0.03030
    140     0.03804     0.11378     0.99580     0.82827    10.00000     5.00000     0.93475     0.53262     0.01211     0.03030
    150     0.03536     0.11479     0.99716     0.82860    10.00000     5.00000     0.94777     0.53112     0.01053     0.03056
    160     0.03354     0.11579     0.99771     0.82690    10.00000     5.09091     0.95397     0.53017     0.01001     0.03135
    170     0.03221     0.11623     0.99821     0.82908    10.00000     5.00000     0.95465     0.53140     0.00988     0.03135
    180     0.03001     0.11692     0.99887     0.82881    10.00000     4.90909     0.97084     0.53575     0.00882     0.03161
    190     0.02934     0.11775     0.99891     0.82741    10.00000     4.90909     0.97138     0.53018     0.00856     0.03161
    200     0.02745     0.11935     0.99921     0.82392    10.00000     4.63636     0.97310     0.52204     0.00790     0.03188
    210     0.02661     0.11992     0.99934     0.82249    10.00000     4.72727     0.97676     0.51837     0.00764     0.03188
    220     0.02605     0.12053     0.99941     0.82083    10.00000     4.72727     0.97744     0.52515     0.00737     0.03188
    230     0.02518     0.12111     0.99952     0.81920    10.00000     4.63636     0.97798     0.51973     0.00672     0.03135
    240     0.02454     0.12144     0.99958     0.81920    10.00000     4.63636     0.97852     0.51810     0.00619     0.03109
    250     0.02405     0.12169     0.99962     0.81913    10.00000     4.63636     0.97920     0.51715     0.00606     0.03109
    260     0.02382     0.12180     0.99964     0.81911    10.00000     4.72727     0.97938     0.51607     0.00579     0.03109
    270     0.02330     0.12210     0.99971     0.81988    10.00000     4.72727     0.98286     0.51851     0.00579     0.03109
    280     0.02294     0.12253     0.99972     0.81945    10.00000     4.63636     0.98300     0.51932     0.00566     0.03109
    290     0.02224     0.12283     0.99980     0.82056    10.00000     4.63636     0.98770     0.52000     0.00514     0.03109
    300     0.02194     0.12298     0.99981     0.82045    10.00000     4.63636     0.98837     0.50821     0.00500     0.03109
    310     0.02151     0.12316     0.99983     0.82058    10.00000     4.54545     0.98837     0.51377     0.00474     0.03109
    320     0.02106     0.12372     0.99984     0.82021    10.00000     4.54545     0.98851     0.51445     0.00487     0.03109
    330     0.02083     0.12411     0.99985     0.82004    10.00000     4.54545     0.98851     0.51527     0.00474     0.03109
    340     0.01995     0.12506     0.99989     0.81951    10.00000     4.54545     0.98919     0.51594     0.00408     0.03109
    350     0.01928     0.12541     0.99993     0.81989    10.00000     4.72727     0.99371     0.51431     0.00369     0.03082
    360     0.01882     0.12589     0.99994     0.81997    10.00000     4.72727     0.99358     0.51499     0.00369     0.03056
    370     0.01839     0.12681     0.99994     0.81751    10.00000     4.54545     0.99358     0.49777     0.00356     0.03056
    380     0.01767     0.12723     0.99995     0.81584    10.00000     4.54545     0.99425     0.49965     0.00329     0.03082
    390     0.01690     0.12809     0.99998     0.81484    10.00000     4.54545     0.99810     0.49559     0.00290     0.03056
    398     0.01645     0.12877     0.99998     0.81469    10.00000     4.54545     0.99810     0.49965     0.00237     0.03109
    400     0.01642     0.12909     0.99998     0.81400    10.00000     4.54545     0.99810     0.49208     0.00237     0.03109


 =========================================
 Variable Importance for the 30-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      39.21637   39.22 |*****      |
 AGE          37.57080   37.57 |*****      |
 OTH_CHLD     33.37495   33.37 |****       |
 INCOME       31.28095   31.28 |****       |
 EDUC_MOM     29.99272   29.99 |****       |
 ILLEGIT      21.80807   21.81 |***        |
 RACE_MOM     14.83391   14.83 |**         |
 PNCLATE      14.15041   14.15 |**         |
 LBW           4.97502    4.98 |*          |


 Learn Sample Misclassification by Target Class
 For The 30-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7369.00         4.00       0.0005
 1                  221.00        64.00       157.00       0.7104


 Test Sample Misclassification by Target Class
 For The 30-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3672.00        14.00       0.0038
 1                  110.00         7.00       103.00       0.9364

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs,  50.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  50.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000278 hrs 50.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 858 kb , 75% compression

 Grove file created containing:
      1 TreeNet

