
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11154      0.12118      0.02910      0.02898      1.00000 |                                               *
      2       0.10420      0.11877      0.02910      0.02898      1.00000 |                                              *
      3       0.09793      0.11648      0.02910      0.02898      1.00000 |                                             *
      4       0.09321      0.11477      0.02910      0.02898      1.00000 |                                            *
      5       0.08935      0.11349      0.02897      0.02898      1.00000 |                                            *
      6       0.08608      0.11280      0.02884      0.02898      1.00000 |                                            *
      7       0.08318      0.11164      0.02739      0.02845      1.00000 |                                           *
      8       0.08069      0.11113      0.02699      0.02871      1.00000 |                                           *
      9       0.07851      0.11095      0.02673      0.02924      1.00000 |                                           *
     10       0.07645      0.11072      0.02594      0.02924      1.00000 |                                           *
     11       0.07513      0.11016      0.02568      0.03003      1.00000 |                                           *
     12       0.07345      0.10993      0.02515      0.03056      1.00000 |                                           *
     13       0.07215      0.10957      0.02476      0.03082      1.00000 |                                          *
     14       0.07064      0.10957      0.02436      0.03056      1.00000 |                                          *
     15       0.06912      0.10960      0.02423      0.03056      1.00000 |                                          *
     16       0.06773      0.10976      0.02383      0.03003      1.00000 |                                          *
     17       0.06672      0.10974      0.02331      0.03003      1.00000 |                                          *
     18       0.06590      0.10973      0.02318      0.03056      1.00000 |                                          *
     19       0.06537      0.10983      0.02304      0.03056      1.00000 |                                           *
     20       0.06475      0.10965      0.02331      0.03056      1.00000 |                                          *
     30       0.06043      0.11011      0.02120      0.03109      1.00000 |                                           *
     40       0.05506      0.11081      0.02028      0.03135      1.00000 |                                           *
     50       0.05178      0.11162      0.01896      0.03214      1.00000 |                                           *
     60       0.04992      0.11254      0.01791      0.03214      1.00000 |                                            *
     70       0.04840      0.11350      0.01686      0.03188      1.00000 |                                            *
     80       0.04693      0.11398      0.01646      0.03267      1.00000 |                                            *
     90       0.04535      0.11499      0.01567      0.03319      1.00000 |                                             *
    100       0.04285      0.11559      0.01501      0.03372      1.00000 |                                             *
    110       0.04136      0.11645      0.01488      0.03372      1.00000 |                                             *
    120       0.03944      0.11709      0.01409      0.03425      1.00000 |                                             *
    130       0.03859      0.11778      0.01396      0.03425      1.00000 |                                              *
    140       0.03685      0.11932      0.01304      0.03477      1.00000 |                                              *
    150       0.03563      0.11999      0.01185      0.03504      1.00000 |                                               *
    160       0.03399      0.12087      0.01106      0.03477      1.00000 |                                               *
    170       0.03275      0.12129      0.01067      0.03477      1.00000 |                                               *
    180       0.03165      0.12221      0.01001      0.03530      1.00000 |                                               *
    190       0.03066      0.12311      0.00948      0.03556      1.00000 |                                               *
    200       0.02954      0.12423      0.00935      0.03530      1.00000 |                                               *
    210       0.02848      0.12462      0.00909      0.03556      1.00000 |                                               *
    220       0.02742      0.12527      0.00856      0.03583      1.00000 |                                               *
    230       0.02633      0.12594      0.00790      0.03530      1.00000 |                                               *
    240       0.02525      0.12705      0.00764      0.03530      1.00000 |                                               *
    250       0.02428      0.12757      0.00724      0.03530      1.00000 |                                               *
    260       0.02331      0.12864      0.00658      0.03583      1.00000 |                                               *
    270       0.02195      0.12869      0.00566      0.03556      1.00000 |                                               *
    280       0.02111      0.12955      0.00514      0.03556      1.00000 |                                               *
    290       0.02035      0.12991      0.00448      0.03556      1.00000 |                                               *
    300       0.01931      0.13070      0.00408      0.03583      1.00000 |                                               *
    310       0.01869      0.13145      0.00342      0.03583      1.00000 |                                               *
    320       0.01750      0.13236      0.00277      0.03609      1.00000 |                                               *
    330       0.01630      0.13329      0.00198      0.03609      1.00000 |                                               *
    340       0.01589      0.13395      0.00198      0.03609      1.00000 |                                               *
    350       0.01525      0.13489      0.00211      0.03583      1.00000 |                                               *
    360       0.01482      0.13584      0.00158      0.03583      1.00000 |                                               *
    370       0.01397      0.13698      0.00145      0.03583      1.00000 |                                               *
    380       0.01348      0.13845      0.00145      0.03583      1.00000 |                                               *
    390       0.01280      0.13916      0.00105      0.03556      1.00000 |                                               *
    400       0.01201      0.14010      0.00079      0.03556      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.24      6.77  CHILDYRS
    293      1    400      1      7      4.22      2.77  AGE
    267      1    400      1      7      4.57      2.29  INCOME
    240      1    400      1      7      4.82      1.91  AGE_MOM
    237      1    400      1      7      4.38      2.14  OTH_CHLD
    210      1    399      1      7      4.63      1.77  EDUC_MOM
    136      1    400      1      7      4.95      1.04  ILLEGIT
    123      1    396      1      7      5.34      0.82  RACE_MOM
    114      1    400      1      7      5.12      0.82  PNCLATE
     69      2    400      2      7      5.70      0.40  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    79 terminal nodes
    Average :     25.65750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 52 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 52 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 13

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 20126 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           13      0.10957
                  ROC           30      0.84423
                 Lift           52      5.36364
              KS-stat           13      0.56507
          Class.Error            7      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11154     0.12118     0.91938     0.74738     7.20957     4.80404     0.68263     0.45879     0.02910     0.02898
      7     0.08318     0.11164     0.95283     0.83043     8.37104     4.76818     0.77407     0.53412     0.02739     0.02845
     10     0.07645     0.11072     0.96013     0.83233     8.46154     5.00000     0.77519     0.52748     0.02594     0.02924
     13     0.07215     0.10957     0.96345     0.83658     8.46154     5.18182     0.78593     0.56507     0.02476     0.03082
     20     0.06475     0.10965     0.96936     0.84018     8.82353     5.18182     0.81273     0.55775     0.02331     0.03056
     30     0.06043     0.11011     0.97305     0.84423     8.86878     5.09091     0.82398     0.56114     0.02120     0.03109
     40     0.05506     0.11081     0.98253     0.84286     9.04977     5.00000     0.85626     0.55271     0.02028     0.03135
     50     0.05178     0.11162     0.98707     0.84131     9.45701     5.18182     0.88301     0.54011     0.01896     0.03214
     52     0.05109     0.11168     0.98787     0.84134     9.63801     5.36364     0.89029     0.54499     0.01883     0.03188
     60     0.04992     0.11254     0.98848     0.83907     9.63801     5.27273     0.89504     0.55192     0.01791     0.03214
     70     0.04840     0.11350     0.99012     0.83570     9.72851     5.27273     0.90300     0.53208     0.01686     0.03188
     80     0.04693     0.11398     0.99142     0.83598     9.81900     5.23636     0.91160     0.52326     0.01646     0.03267
     90     0.04535     0.11499     0.99231     0.83369     9.81900     5.18182     0.91743     0.53264     0.01567     0.03319
    100     0.04285     0.11559     0.99417     0.83384     9.86425     4.81818     0.93050     0.51718     0.01501     0.03372
    110     0.04136     0.11645     0.99488     0.83284     9.90950     4.81818     0.93547     0.51866     0.01488     0.03372
    120     0.03944     0.11709     0.99596     0.83280     9.90950     5.00000     0.94877     0.51280     0.01409     0.03425
    130     0.03859     0.11778     0.99624     0.83074     9.90950     4.90909     0.94863     0.51307     0.01396     0.03425
    140     0.03685     0.11932     0.99701     0.82673     9.95475     4.81818     0.95026     0.50587     0.01304     0.03477
    150     0.03563     0.11999     0.99743     0.82604     9.95475     4.72727     0.95184     0.50642     0.01185     0.03504
    158     0.03409     0.12070     0.99803     0.82288    10.00000     4.72727     0.95948     0.51229     0.01093     0.03477
    160     0.03399     0.12087     0.99805     0.82268    10.00000     4.63636     0.96030     0.51256     0.01106     0.03477
    170     0.03275     0.12129     0.99841     0.82418    10.00000     4.87273     0.96101     0.50547     0.01067     0.03477
    180     0.03165     0.12221     0.99861     0.82295    10.00000     4.87273     0.96237     0.51076     0.01001     0.03530
    190     0.03066     0.12311     0.99882     0.82031    10.00000     4.90909     0.96789     0.50859     0.00948     0.03556
    200     0.02954     0.12423     0.99900     0.81837    10.00000     4.72727     0.96857     0.50181     0.00935     0.03530
    210     0.02848     0.12462     0.99915     0.81772    10.00000     4.81818     0.96911     0.50154     0.00909     0.03556
    220     0.02742     0.12527     0.99929     0.81672    10.00000     4.81818     0.97369     0.49354     0.00856     0.03583
    230     0.02633     0.12594     0.99940     0.81656    10.00000     5.09091     0.97504     0.49734     0.00790     0.03530
    240     0.02525     0.12705     0.99949     0.81379    10.00000     5.00000     0.97847     0.49638     0.00764     0.03530
    250     0.02428     0.12757     0.99957     0.81355    10.00000     4.90909     0.97888     0.50154     0.00724     0.03530
    260     0.02331     0.12864     0.99964     0.81101    10.00000     4.72727     0.97961     0.50045     0.00658     0.03583
    270     0.02195     0.12869     0.99983     0.81385    10.00000     4.81818     0.99227     0.50940     0.00566     0.03556
    280     0.02111     0.12955     0.99990     0.81451    10.00000     4.90909     0.99376     0.50832     0.00514     0.03556
    290     0.02035     0.12991     0.99993     0.81518    10.00000     4.90909     0.99403     0.51266     0.00448     0.03556
    300     0.01931     0.13070     0.99994     0.81386    10.00000     4.90909     0.99498     0.51335     0.00408     0.03583
    310     0.01869     0.13145     0.99996     0.81351    10.00000     4.87273     0.99742     0.50860     0.00342     0.03583
    320     0.01750     0.13236     0.99997     0.81440    10.00000     4.90909     0.99797     0.51647     0.00277     0.03609
    330     0.01630     0.13329     0.99998     0.81398    10.00000     4.90909     0.99837     0.50792     0.00198     0.03609
    340     0.01589     0.13395     0.99998     0.81329    10.00000     4.81818     0.99851     0.50601     0.00198     0.03609
    350     0.01525     0.13489     0.99999     0.81215    10.00000     4.90909     0.99851     0.50982     0.00211     0.03583
    360     0.01482     0.13584     0.99999     0.81163    10.00000     4.90909     0.99878     0.50466     0.00158     0.03583
    370     0.01397     0.13698     1.00000     0.81104    10.00000     4.72727     0.99959     0.50275     0.00145     0.03583
    380     0.01348     0.13845     1.00000     0.81046    10.00000     5.09091     0.99959     0.50413     0.00145     0.03583
    390     0.01280     0.13916     1.00000     0.81045    10.00000     5.00000     0.99973     0.51117     0.00105     0.03556
    395     0.01229     0.13956     1.00000     0.81109    10.00000     5.09091     1.00000     0.51497     0.00105     0.03504
    399     0.01210     0.13991     1.00000     0.81151    10.00000     5.00000     1.00000     0.50940     0.00079     0.03530
    400     0.01201     0.14010     1.00000     0.81138    10.00000     5.00000     1.00000     0.50873     0.00079     0.03556


 =========================================
 Variable Importance for the 13-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      54.02192   54.02 |******     |
 AGE          45.74772   45.75 |******     |
 OTH_CHLD     33.90342   33.90 |****       |
 INCOME       32.50536   32.51 |****       |
 EDUC_MOM     26.58708   26.59 |****       |
 ILLEGIT      23.26608   23.27 |***        |
 RACE_MOM     18.72014   18.72 |***        |
 PNCLATE      17.29543   17.30 |***        |
 LBW           5.64211    5.64 |**         |


 Learn Sample Misclassification by Target Class
 For The 13-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7367.00         6.00       0.0008
 1                  221.00        39.00       182.00       0.8235


 Test Sample Misclassification by Target Class
 For The 13-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3670.00        16.00       0.0043
 1                  110.00         9.00       101.00       0.9182

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 953 kb , 75% compression

 Grove file created containing:
      1 TreeNet

