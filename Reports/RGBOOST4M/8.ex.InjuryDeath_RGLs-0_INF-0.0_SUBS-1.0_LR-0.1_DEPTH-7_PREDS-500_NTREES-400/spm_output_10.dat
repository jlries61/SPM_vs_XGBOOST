
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11169      0.11851      0.02910      0.02898      1.00000 |                                               *
      2       0.10326      0.11525      0.02910      0.02898      1.00000 |                                              *
      3       0.09580      0.11359      0.02910      0.02898      1.00000 |                                             *
      4       0.08975      0.11140      0.02897      0.02898      1.00000 |                                            *
      5       0.08550      0.11078      0.02897      0.02845      1.00000 |                                            *
      6       0.08234      0.10987      0.02844      0.02819      1.00000 |                                           *
      7       0.07921      0.10917      0.02858      0.02819      1.00000 |                                           *
      8       0.07660      0.10882      0.02779      0.02766      1.00000 |                                           *
      9       0.07423      0.10881      0.02739      0.02713      1.00000 |                                           *
     10       0.07213      0.10854      0.02647      0.02713      1.00000 |                                           *
     11       0.06976      0.10870      0.02699      0.02766      1.00000 |                                           *
     12       0.06786      0.10883      0.02620      0.02871      1.00000 |                                           *
     13       0.06602      0.10877      0.02555      0.02871      1.00000 |                                           *
     14       0.06407      0.10900      0.02489      0.02898      1.00000 |                                           *
     15       0.06263      0.10933      0.02476      0.02898      1.00000 |                                           *
     16       0.06128      0.10965      0.02449      0.02898      1.00000 |                                           *
     17       0.05983      0.10972      0.02423      0.02871      1.00000 |                                           *
     18       0.05894      0.10969      0.02410      0.02898      1.00000 |                                           *
     19       0.05816      0.10988      0.02423      0.02871      1.00000 |                                            *
     20       0.05737      0.10990      0.02410      0.02924      1.00000 |                                            *
     30       0.04894      0.11272      0.02067      0.02950      1.00000 |                                             *
     40       0.04465      0.11553      0.01857      0.02924      1.00000 |                                              *
     50       0.04045      0.11792      0.01686      0.02977      1.00000 |                                               *
     60       0.03616      0.12044      0.01422      0.03030      1.00000 |                                               *
     70       0.03264      0.12299      0.01159      0.03082      1.00000 |                                               *
     80       0.02981      0.12656      0.00922      0.03214      1.00000 |                                               *
     90       0.02813      0.12915      0.00816      0.03188      1.00000 |                                               *
    100       0.02696      0.13151      0.00685      0.03240      1.00000 |                                               *
    110       0.02541      0.13357      0.00606      0.03214      1.00000 |                                               *
    120       0.02436      0.13508      0.00514      0.03240      1.00000 |                                               *
    130       0.02278      0.13704      0.00448      0.03267      1.00000 |                                               *
    140       0.02154      0.13949      0.00342      0.03267      1.00000 |                                               *
    150       0.01980      0.14213      0.00263      0.03267      1.00000 |                                               *
    160       0.01868      0.14359      0.00211      0.03267      1.00000 |                                               *
    170       0.01763      0.14597      0.00171      0.03240      1.00000 |                                               *
    180       0.01695      0.14751      0.00158      0.03267      1.00000 |                                               *
    190       0.01624      0.14927      0.00158      0.03293      1.00000 |                                               *
    200       0.01574      0.15069      0.00145      0.03293      1.00000 |                                               *
    210       0.01509      0.15248      0.00105      0.03319      1.00000 |                                               *
    220       0.01420      0.15405      0.00079      0.03293      1.00000 |                                               *
    230       0.01368      0.15550      0.00079      0.03319      1.00000 |                                               *
    240       0.01257      0.15881      0.00040      0.03319      1.00000 |                                               *
    250       0.01187      0.15962      0.00040      0.03319      1.00000 |                                               *
    260       0.01105      0.16137      0.00026      0.03293      1.00000 |                                               *
    270       0.01036      0.16303      0.00013      0.03293      1.00000 |                                               *
    280       0.00986      0.16528      0.00000      0.03319      1.00000 |                                               *
    290       0.00929      0.16688      0.00000      0.03346      1.00000 |                                               *
    300       0.00887      0.16865      0.00000      0.03346      1.00000 |                                               *
    310       0.00850      0.16988      0.00000      0.03346      1.00000 |                                               *
    320       0.00795      0.17240      0.00000      0.03319      1.00000 |                                               *
    330       0.00781      0.17401      0.00000      0.03346      1.00000 |                                               *
    340       0.00738      0.17620      0.00000      0.03398      1.00000 |                                               *
    350       0.00707      0.17770      0.00000      0.03372      1.00000 |                                               *
    360       0.00669      0.17996      0.00000      0.03398      1.00000 |                                               *
    370       0.00639      0.18171      0.00000      0.03398      1.00000 |                                               *
    380       0.00623      0.18291      0.00000      0.03372      1.00000 |                                               *
    390       0.00578      0.18474      0.00000      0.03425      1.00000 |                                               *
    400       0.00547      0.18611      0.00000      0.03398      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.34      6.66  CHILDYRS
    336      1    400      1      7      4.07      3.30  INCOME
    328      1    400      1      7      3.85      3.41  AGE
    307      1    400      1      7      4.42      2.75  EDUC_MOM
    305      1    400      2      7      4.73      2.49  AGE_MOM
    297      1    400      1      7      4.01      2.96  OTH_CHLD
    218      1    400      1      7      4.35      1.99  ILLEGIT
    210      1    400      2      7      5.00      1.58  RACE_MOM
    179      1    400      2      7      5.03      1.33  PNCLATE
    149      1    399      2      7      5.13      1.07  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    95 terminal nodes
    Average :     36.85750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 21 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 21 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 10

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 29086 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           10      0.10854
                  ROC            5      0.82813
                 Lift           21      5.00000
              KS-stat           12      0.54688
          Class.Error            9      0.02713

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11169     0.11851     0.92871     0.77838     7.45249     4.44596     0.71343     0.48431     0.02910     0.02898
      5     0.08550     0.11078     0.96751     0.82813     8.95928     4.90909     0.82355     0.54484     0.02897     0.02845
      9     0.07423     0.10881     0.97547     0.82273     9.23077     4.81818     0.85142     0.53534     0.02739     0.02713
     10     0.07213     0.10854     0.97688     0.82297     9.41176     4.90909     0.87065     0.54010     0.02647     0.02713
     12     0.06786     0.10883     0.98072     0.82216     9.45701     4.72727     0.88159     0.54688     0.02620     0.02871
     20     0.05737     0.10990     0.98830     0.82100     9.77376     4.81818     0.91367     0.53074     0.02410     0.02924
     21     0.05656     0.11022     0.98873     0.81999     9.77376     5.00000     0.91706     0.51852     0.02397     0.02871
     30     0.04894     0.11272     0.99450     0.81550     9.95475     4.90909     0.95238     0.51648     0.02067     0.02950
     40     0.04465     0.11553     0.99603     0.80900     9.95475     4.63636     0.96016     0.50767     0.01857     0.02924
     50     0.04045     0.11792     0.99733     0.80962     9.95475     4.63636     0.96686     0.51757     0.01686     0.02977
     60     0.03616     0.12044     0.99838     0.81044     9.95475     4.54545     0.97717     0.51567     0.01422     0.03030
     70     0.03264     0.12299     0.99895     0.80878    10.00000     4.45455     0.97915     0.51175     0.01159     0.03082
     80     0.02981     0.12656     0.99931     0.80350    10.00000     4.45455     0.98173     0.50727     0.00922     0.03214
     90     0.02813     0.12915     0.99945     0.80088    10.00000     4.45455     0.98340     0.50062     0.00816     0.03188
    100     0.02696     0.13151     0.99951     0.79710    10.00000     4.36364     0.98422     0.50442     0.00685     0.03240
    110     0.02541     0.13357     0.99959     0.79533    10.00000     4.36364     0.98593     0.49506     0.00606     0.03214
    120     0.02436     0.13508     0.99980     0.79618    10.00000     4.23636     0.98715     0.50511     0.00514     0.03240
    130     0.02278     0.13704     0.99986     0.79398    10.00000     4.27273     0.99186     0.49723     0.00448     0.03267
    140     0.02154     0.13949     0.99992     0.79111    10.00000     4.09091     0.99385     0.48799     0.00342     0.03267
    150     0.01980     0.14213     0.99997     0.78929    10.00000     4.00000     0.99891     0.48461     0.00263     0.03267
    160     0.01868     0.14359     0.99998     0.79026    10.00000     4.09091     0.99919     0.48976     0.00211     0.03267
    170     0.01763     0.14597     0.99999     0.79019    10.00000     4.09091     0.99959     0.48718     0.00171     0.03240
    180     0.01695     0.14751     1.00000     0.78823    10.00000     4.18182     0.99973     0.48609     0.00158     0.03267
    190     0.01624     0.14927     1.00000     0.78654    10.00000     4.14545     0.99973     0.48026     0.00158     0.03293
    200     0.01574     0.15069     1.00000     0.78500    10.00000     4.18182     0.99973     0.48162     0.00145     0.03293
    210     0.01509     0.15248     1.00000     0.78423    10.00000     4.18182     0.99986     0.47592     0.00105     0.03319
    220     0.01420     0.15405     1.00000     0.78483    10.00000     4.18182     0.99986     0.47646     0.00079     0.03293
    227     0.01389     0.15491     1.00000     0.78450    10.00000     4.09091     1.00000     0.47525     0.00079     0.03293
    230     0.01368     0.15550     1.00000     0.78366    10.00000     4.09091     1.00000     0.47199     0.00079     0.03319
    240     0.01257     0.15881     1.00000     0.78111    10.00000     4.09091     1.00000     0.48407     0.00040     0.03319
    250     0.01187     0.15962     1.00000     0.78202    10.00000     4.09091     1.00000     0.48501     0.00040     0.03319
    260     0.01105     0.16137     1.00000     0.78138    10.00000     4.00000     1.00000     0.48339     0.00026     0.03293
    270     0.01036     0.16303     1.00000     0.78105    10.00000     4.00000     1.00000     0.46913     0.00013     0.03293
    278     0.00988     0.16507     1.00000     0.77945    10.00000     3.90909     1.00000     0.47117     0.00000     0.03319
    280     0.00986     0.16528     1.00000     0.77989    10.00000     3.90909     1.00000     0.47171     0.00000     0.03319
    290     0.00929     0.16688     1.00000     0.77859    10.00000     4.00000     1.00000     0.46399     0.00000     0.03346
    300     0.00887     0.16865     1.00000     0.77850    10.00000     3.81818     1.00000     0.46508     0.00000     0.03346
    310     0.00850     0.16988     1.00000     0.77931    10.00000     3.90909     1.00000     0.47091     0.00000     0.03346
    320     0.00795     0.17240     1.00000     0.77813    10.00000     4.09091     1.00000     0.46222     0.00000     0.03319
    330     0.00781     0.17401     1.00000     0.77928    10.00000     4.00000     1.00000     0.47009     0.00000     0.03346
    340     0.00738     0.17620     1.00000     0.77729    10.00000     4.00000     1.00000     0.46819     0.00000     0.03398
    350     0.00707     0.17770     1.00000     0.77505    10.00000     4.00000     1.00000     0.46765     0.00000     0.03372
    360     0.00669     0.17996     1.00000     0.77410    10.00000     3.90909     1.00000     0.46385     0.00000     0.03398
    370     0.00639     0.18171     1.00000     0.77380    10.00000     3.90909     1.00000     0.46059     0.00000     0.03398
    380     0.00623     0.18291     1.00000     0.77366    10.00000     3.90909     1.00000     0.45815     0.00000     0.03372
    390     0.00578     0.18474     1.00000     0.77314    10.00000     3.90909     1.00000     0.44893     0.00000     0.03425
    400     0.00547     0.18611     1.00000     0.77326    10.00000     3.90909     1.00000     0.44294     0.00000     0.03398


 =========================================
 Variable Importance for the 10-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          37.65489   37.65 |*****      |
 AGE_MOM      31.19354   31.19 |****       |
 OTH_CHLD     30.81177   30.81 |****       |
 INCOME       29.90124   29.90 |****       |
 EDUC_MOM     29.33149   29.33 |****       |
 ILLEGIT      22.12202   22.12 |***        |
 RACE_MOM     16.93665   16.94 |***        |
 PNCLATE      14.50577   14.51 |**         |
 LBW          10.72413   10.72 |**         |


 Learn Sample Misclassification by Target Class
 For The 10-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7372.00         1.00       0.0001
 1                  221.00        21.00       200.00       0.9050


 Test Sample Misclassification by Target Class
 For The 10-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3683.00         3.00       0.0008
 1                  110.00        10.00       100.00       0.9091

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs,  50.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  50.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000278 hrs 50.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.3 MB, 75% compression

 Grove file created containing:
      1 TreeNet

