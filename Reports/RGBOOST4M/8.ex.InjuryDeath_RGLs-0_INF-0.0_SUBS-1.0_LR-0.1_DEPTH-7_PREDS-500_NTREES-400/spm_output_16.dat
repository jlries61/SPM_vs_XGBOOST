
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11399      0.12105      0.02910      0.02898      1.00000 |                                               *
      2       0.10494      0.11708      0.02910      0.02898      1.00000 |                                             *
      3       0.09982      0.11478      0.02910      0.02898      1.00000 |                                             *
      4       0.09496      0.11294      0.02884      0.02898      1.00000 |                                            *
      5       0.09099      0.11101      0.02818      0.02898      1.00000 |                                           *
      6       0.08762      0.10946      0.02805      0.02898      1.00000 |                                          *
      7       0.08528      0.10834      0.02779      0.02924      1.00000 |                                          *
      8       0.08307      0.10768      0.02739      0.02924      1.00000 |                                          *
      9       0.08124      0.10702      0.02699      0.02924      1.00000 |                                         *
     10       0.07948      0.10645      0.02660      0.02924      1.00000 |                                         *
     11       0.07737      0.10637      0.02660      0.02950      1.00000 |                                         *
     12       0.07556      0.10626      0.02581      0.03003      1.00000 |                                         *
     13       0.07364      0.10588      0.02568      0.03030      1.00000 |                                         *
     14       0.07207      0.10582      0.02581      0.03030      1.00000 |                                         *
     15       0.07061      0.10564      0.02541      0.03030      1.00000 |                                         *
     16       0.06962      0.10549      0.02541      0.03030      1.00000 |                                         *
     17       0.06811      0.10570      0.02528      0.03030      1.00000 |                                         *
     18       0.06739      0.10572      0.02528      0.03003      1.00000 |                                         *
     19       0.06572      0.10565      0.02502      0.02977      1.00000 |                                         *
     20       0.06503      0.10583      0.02436      0.03003      1.00000 |                                         *
     30       0.05841      0.10576      0.02357      0.03030      1.00000 |                                         *
     40       0.05216      0.10655      0.02225      0.03030      1.00000 |                                         *
     50       0.04680      0.10712      0.02028      0.03056      1.00000 |                                         *
     60       0.04238      0.10908      0.01804      0.03056      1.00000 |                                          *
     70       0.03951      0.10982      0.01620      0.03135      1.00000 |                                           *
     80       0.03569      0.11143      0.01290      0.03109      1.00000 |                                           *
     90       0.03379      0.11249      0.01146      0.03135      1.00000 |                                            *
    100       0.03254      0.11341      0.01040      0.03188      1.00000 |                                            *
    110       0.03081      0.11483      0.00988      0.03214      1.00000 |                                             *
    120       0.02955      0.11537      0.00895      0.03214      1.00000 |                                             *
    130       0.02817      0.11628      0.00830      0.03240      1.00000 |                                             *
    140       0.02758      0.11707      0.00803      0.03293      1.00000 |                                             *
    150       0.02614      0.11852      0.00685      0.03293      1.00000 |                                              *
    160       0.02499      0.11937      0.00658      0.03214      1.00000 |                                              *
    170       0.02419      0.12033      0.00566      0.03267      1.00000 |                                               *
    180       0.02319      0.12113      0.00461      0.03240      1.00000 |                                               *
    190       0.02198      0.12251      0.00421      0.03214      1.00000 |                                               *
    200       0.02136      0.12314      0.00395      0.03240      1.00000 |                                               *
    210       0.01949      0.12555      0.00277      0.03293      1.00000 |                                               *
    220       0.01847      0.12688      0.00277      0.03346      1.00000 |                                               *
    230       0.01785      0.12788      0.00250      0.03346      1.00000 |                                               *
    240       0.01703      0.12913      0.00237      0.03346      1.00000 |                                               *
    250       0.01591      0.13097      0.00119      0.03293      1.00000 |                                               *
    260       0.01511      0.13227      0.00092      0.03293      1.00000 |                                               *
    270       0.01484      0.13277      0.00066      0.03293      1.00000 |                                               *
    280       0.01412      0.13438      0.00066      0.03319      1.00000 |                                               *
    290       0.01368      0.13533      0.00053      0.03319      1.00000 |                                               *
    300       0.01331      0.13564      0.00040      0.03346      1.00000 |                                               *
    310       0.01275      0.13646      0.00026      0.03293      1.00000 |                                               *
    320       0.01205      0.13771      0.00026      0.03267      1.00000 |                                               *
    330       0.01087      0.14067      0.00013      0.03267      1.00000 |                                               *
    340       0.01036      0.14208      0.00013      0.03240      1.00000 |                                               *
    350       0.01004      0.14292      0.00013      0.03267      1.00000 |                                               *
    360       0.00965      0.14414      0.00013      0.03267      1.00000 |                                               *
    370       0.00924      0.14511      0.00013      0.03293      1.00000 |                                               *
    380       0.00897      0.14602      0.00013      0.03319      1.00000 |                                               *
    390       0.00879      0.14646      0.00013      0.03319      1.00000 |                                               *
    400       0.00842      0.14791      0.00013      0.03346      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.29      6.72  CHILDYRS
    342      1    400      1      7      4.01      3.41  AGE
    270      1    400      1      7      4.04      2.67  INCOME
    249      1    400      2      7      4.49      2.19  AGE_MOM
    248      1    398      1      7      4.29      2.30  EDUC_MOM
    237      1    400      1      7      4.07      2.33  OTH_CHLD
    188      1    398      1      7      4.95      1.43  ILLEGIT
    163      1    400      2      7      5.29      1.10  RACE_MOM
    147      2    398      2      7      5.57      0.89  LBW
    142      2    400      1      7      5.26      0.97  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    98 terminal nodes
    Average :     33.29250 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 49 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 49 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 26234 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.10549
                  ROC           49      0.85492
                 Lift            7      5.81818
              KS-stat            7      0.61335
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11399     0.12105     0.90625     0.82238     6.47343     5.30854     0.65039     0.54536     0.02910     0.02898
      7     0.08528     0.10834     0.94933     0.85086     8.23529     5.81818     0.75328     0.61335     0.02779     0.02924
     10     0.07948     0.10645     0.95572     0.85301     8.28054     5.72727     0.77201     0.60222     0.02660     0.02924
     16     0.06962     0.10549     0.97094     0.85036     9.04977     5.45455     0.83370     0.58215     0.02541     0.03030
     20     0.06503     0.10583     0.97619     0.84863     9.09502     5.36364     0.84377     0.58092     0.02436     0.03003
     30     0.05841     0.10576     0.98621     0.85344     9.63801     5.45455     0.89752     0.60303     0.02357     0.03030
     40     0.05216     0.10655     0.99119     0.85341     9.81900     5.54545     0.93294     0.59760     0.02225     0.03030
     49     0.04836     0.10679     0.99287     0.85492     9.81900     5.45455     0.93755     0.60589     0.02067     0.03030
     50     0.04680     0.10712     0.99431     0.85386     9.95475     5.45455     0.93813     0.60574     0.02028     0.03056
     54     0.04468     0.10807     0.99555     0.85243    10.00000     5.36364     0.94696     0.60005     0.01870     0.03030
     60     0.04238     0.10908     0.99655     0.85129    10.00000     5.50909     0.95718     0.59639     0.01804     0.03056
     70     0.03951     0.10982     0.99723     0.85395    10.00000     5.50909     0.96369     0.58811     0.01620     0.03135
     80     0.03569     0.11143     0.99823     0.85246    10.00000     5.45455     0.97223     0.58919     0.01290     0.03109
     90     0.03379     0.11249     0.99860     0.85161    10.00000     5.36364     0.97739     0.58485     0.01146     0.03135
    100     0.03254     0.11341     0.99882     0.85129    10.00000     5.27273     0.97929     0.58878     0.01040     0.03188
    110     0.03081     0.11483     0.99908     0.85015    10.00000     5.27273     0.97969     0.58241     0.00988     0.03214
    120     0.02955     0.11537     0.99931     0.85079    10.00000     5.18182     0.98471     0.57957     0.00895     0.03214
    130     0.02817     0.11628     0.99951     0.85080    10.00000     5.18182     0.98747     0.57414     0.00830     0.03240
    140     0.02758     0.11707     0.99955     0.85048    10.00000     5.18182     0.98910     0.56978     0.00803     0.03293
    150     0.02614     0.11852     0.99968     0.84830    10.00000     5.27273     0.99059     0.56844     0.00685     0.03293
    160     0.02499     0.11937     0.99976     0.84671    10.00000     5.27273     0.99168     0.57602     0.00658     0.03214
    170     0.02419     0.12033     0.99980     0.84536    10.00000     5.27273     0.99195     0.57087     0.00566     0.03267
    180     0.02319     0.12113     0.99985     0.84441    10.00000     5.27273     0.99208     0.56354     0.00461     0.03240
    190     0.02198     0.12251     0.99988     0.84286    10.00000     5.27273     0.99331     0.56612     0.00421     0.03214
    200     0.02136     0.12314     0.99991     0.84218    10.00000     5.27273     0.99317     0.56504     0.00395     0.03240
    210     0.01949     0.12555     0.99996     0.84034    10.00000     5.27273     0.99525     0.56965     0.00277     0.03293
    220     0.01847     0.12688     0.99997     0.83978    10.00000     5.27273     0.99566     0.57155     0.00277     0.03346
    230     0.01785     0.12788     0.99998     0.83920    10.00000     5.27273     0.99688     0.56395     0.00250     0.03346
    240     0.01703     0.12913     0.99999     0.83811    10.00000     5.05455     0.99891     0.56775     0.00237     0.03346
    250     0.01591     0.13097     0.99999     0.83690    10.00000     4.72727     0.99932     0.56409     0.00119     0.03293
    260     0.01511     0.13227     1.00000     0.83519    10.00000     4.90909     0.99946     0.55894     0.00092     0.03293
    270     0.01484     0.13277     1.00000     0.83458    10.00000     4.72727     0.99946     0.55622     0.00066     0.03293
    280     0.01412     0.13438     1.00000     0.83442    10.00000     4.72727     0.99946     0.55215     0.00066     0.03319
    290     0.01368     0.13533     1.00000     0.83456    10.00000     4.72727     0.99959     0.54906     0.00053     0.03319
    300     0.01331     0.13564     1.00000     0.83535    10.00000     4.63636     0.99959     0.54444     0.00040     0.03346
    310     0.01275     0.13646     1.00000     0.83614    10.00000     4.72727     0.99973     0.55446     0.00026     0.03293
    318     0.01222     0.13748     1.00000     0.83520    10.00000     4.72727     1.00000     0.54767     0.00026     0.03267
    320     0.01205     0.13771     1.00000     0.83496    10.00000     4.81818     1.00000     0.54225     0.00026     0.03267
    325     0.01149     0.13923     1.00000     0.83273    10.00000     4.72727     1.00000     0.54212     0.00013     0.03319
    330     0.01087     0.14067     1.00000     0.83140    10.00000     4.60000     1.00000     0.53642     0.00013     0.03267
    340     0.01036     0.14208     1.00000     0.83152    10.00000     4.63636     1.00000     0.54022     0.00013     0.03240
    350     0.01004     0.14292     1.00000     0.83217    10.00000     4.45455     1.00000     0.54456     0.00013     0.03267
    360     0.00965     0.14414     1.00000     0.83144    10.00000     4.54545     1.00000     0.54429     0.00013     0.03267
    370     0.00924     0.14511     1.00000     0.83189    10.00000     4.45455     1.00000     0.53723     0.00013     0.03293
    380     0.00897     0.14602     1.00000     0.83101    10.00000     4.45455     1.00000     0.53506     0.00013     0.03319
    390     0.00879     0.14646     1.00000     0.83159    10.00000     4.45455     1.00000     0.53777     0.00013     0.03319
    400     0.00842     0.14791     1.00000     0.83134    10.00000     4.36364     1.00000     0.53125     0.00013     0.03346


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     35.64724   35.65 |*****      |
 AGE          29.48810   29.49 |****       |
 OTH_CHLD     28.35038   28.35 |****       |
 AGE_MOM      25.83748   25.84 |****       |
 INCOME       25.54356   25.54 |****       |
 ILLEGIT      18.76234   18.76 |***        |
 LBW          13.51015   13.51 |**         |
 RACE_MOM     11.48982   11.49 |**         |
 PNCLATE       9.30244    9.30 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7367.00         6.00       0.0008
 1                  221.00        34.00       187.00       0.8462


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3677.00         9.00       0.0024
 1                  110.00         4.00       106.00       0.9636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

