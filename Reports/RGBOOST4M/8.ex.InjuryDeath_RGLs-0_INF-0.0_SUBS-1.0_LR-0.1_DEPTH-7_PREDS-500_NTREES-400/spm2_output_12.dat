
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:01

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10891      0.11985      0.02910      0.02898      1.00000 |                                               *
      2       0.10073      0.11742      0.02792      0.02898      1.00000 |                                              *
      3       0.09366      0.11550      0.02792      0.02898      1.00000 |                                             *
      4       0.08796      0.11366      0.02792      0.02898      1.00000 |                                             *
      5       0.08385      0.11249      0.02752      0.02871      1.00000 |                                            *
      6       0.08007      0.11157      0.02713      0.02898      1.00000 |                                            *
      7       0.07725      0.11060      0.02686      0.02924      1.00000 |                                           *
      8       0.07467      0.11037      0.02634      0.02977      1.00000 |                                           *
      9       0.07222      0.10995      0.02634      0.02977      1.00000 |                                           *
     10       0.06999      0.10933      0.02581      0.03082      1.00000 |                                           *
     11       0.06767      0.10940      0.02555      0.03109      1.00000 |                                           *
     12       0.06610      0.10911      0.02541      0.03109      1.00000 |                                           *
     13       0.06451      0.10905      0.02541      0.03135      1.00000 |                                           *
     14       0.06237      0.10870      0.02502      0.03135      1.00000 |                                           *
     15       0.06132      0.10844      0.02489      0.03161      1.00000 |                                          *
     16       0.06005      0.10852      0.02462      0.03161      1.00000 |                                          *
     17       0.05817      0.10845      0.02410      0.03214      1.00000 |                                          *
     18       0.05743      0.10843      0.02357      0.03240      1.00000 |                                          *
     19       0.05630      0.10823      0.02344      0.03214      1.00000 |                                          *
     20       0.05497      0.10811      0.02291      0.03240      1.00000 |                                          *
     30       0.04765      0.10877      0.02133      0.03267      1.00000 |                                           *
     40       0.04283      0.10955      0.01804      0.03240      1.00000 |                                           *
     50       0.03936      0.11069      0.01593      0.03240      1.00000 |                                           *
     60       0.03582      0.11211      0.01396      0.03240      1.00000 |                                            *
     70       0.03417      0.11306      0.01251      0.03240      1.00000 |                                            *
     80       0.03031      0.11527      0.01027      0.03188      1.00000 |                                             *
     90       0.02886      0.11684      0.00974      0.03161      1.00000 |                                              *
    100       0.02714      0.11831      0.00816      0.03188      1.00000 |                                              *
    110       0.02487      0.12003      0.00566      0.03188      1.00000 |                                               *
    120       0.02302      0.12205      0.00474      0.03240      1.00000 |                                               *
    130       0.02178      0.12328      0.00382      0.03214      1.00000 |                                               *
    140       0.02033      0.12481      0.00342      0.03267      1.00000 |                                               *
    150       0.01902      0.12661      0.00263      0.03267      1.00000 |                                               *
    160       0.01800      0.12828      0.00237      0.03293      1.00000 |                                               *
    170       0.01693      0.12955      0.00224      0.03346      1.00000 |                                               *
    180       0.01534      0.13088      0.00132      0.03240      1.00000 |                                               *
    190       0.01428      0.13260      0.00079      0.03267      1.00000 |                                               *
    200       0.01345      0.13467      0.00066      0.03346      1.00000 |                                               *
    210       0.01211      0.13630      0.00013      0.03319      1.00000 |                                               *
    220       0.01099      0.13866      0.00026      0.03319      1.00000 |                                               *
    230       0.01052      0.13971      0.00026      0.03319      1.00000 |                                               *
    240       0.00932      0.14230      0.00000      0.03319      1.00000 |                                               *
    250       0.00840      0.14419      0.00000      0.03372      1.00000 |                                               *
    260       0.00762      0.14615      0.00000      0.03372      1.00000 |                                               *
    270       0.00678      0.14888      0.00000      0.03346      1.00000 |                                               *
    280       0.00619      0.15110      0.00000      0.03398      1.00000 |                                               *
    290       0.00589      0.15295      0.00000      0.03372      1.00000 |                                               *
    300       0.00525      0.15642      0.00000      0.03372      1.00000 |                                               *
    310       0.00489      0.15887      0.00000      0.03346      1.00000 |                                               *
    320       0.00430      0.16241      0.00000      0.03372      1.00000 |                                               *
    330       0.00384      0.16510      0.00000      0.03319      1.00000 |                                               *
    340       0.00343      0.16767      0.00000      0.03372      1.00000 |                                               *
    350       0.00307      0.17041      0.00000      0.03372      1.00000 |                                               *
    360       0.00278      0.17286      0.00000      0.03346      1.00000 |                                               *
    370       0.00253      0.17571      0.00000      0.03372      1.00000 |                                               *
    380       0.00227      0.17846      0.00000      0.03398      1.00000 |                                               *
    390       0.00207      0.18057      0.00000      0.03372      1.00000 |                                               *
    400       0.00187      0.18325      0.00000      0.03398      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.51      6.49  CHILDYRS
    371      1    400      1      7      3.72      3.97  AGE
    357      1    400      1      7      4.06      3.52  INCOME
    345      1    400      1      7      4.40      3.11  OTH_CHLD
    333      1    400      1      7      4.11      3.24  AGE_MOM
    319      1    400      1      7      4.30      2.95  EDUC_MOM
    294      1    400      1      7      5.07      2.15  ILLEGIT
    248      1    400      2      7      5.47      1.57  RACE_MOM
    239      1    400      1      7      5.33      1.60  PNCLATE
    214      1    400      2      7      5.55      1.31  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :   110 terminal nodes
    Average :     53.18250 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 40 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 40 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 20

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 42146 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           20      0.10811
                  ROC           40      0.86103
                 Lift            3      5.26212
              KS-stat           10      0.59113
          Class.Error            5      0.02871

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10891     0.11985     0.92493     0.74466     7.20712     5.03776     0.69025     0.48905     0.02910     0.02898
      3     0.09366     0.11550     0.94724     0.83851     8.23529     5.26212     0.76177     0.55516     0.02792     0.02898
      5     0.08385     0.11249     0.96752     0.84157     8.64253     5.09091     0.81726     0.55584     0.02752     0.02871
     10     0.06999     0.10933     0.97963     0.85629     9.41176     4.81818     0.86866     0.59113     0.02581     0.03082
     20     0.05497     0.10811     0.99064     0.85910     9.72851     4.81818     0.92280     0.57497     0.02291     0.03240
     25     0.05003     0.10844     0.99441     0.85908    10.00000     5.00000     0.94523     0.57795     0.02252     0.03240
     30     0.04765     0.10877     0.99502     0.85907    10.00000     5.09091     0.95283     0.57862     0.02133     0.03267
     40     0.04283     0.10955     0.99629     0.86103    10.00000     5.18182     0.95722     0.57919     0.01804     0.03240
     50     0.03936     0.11069     0.99762     0.85972    10.00000     5.09091     0.97228     0.56942     0.01593     0.03240
     60     0.03582     0.11211     0.99848     0.85699    10.00000     5.09091     0.97472     0.57077     0.01396     0.03240
     70     0.03417     0.11306     0.99873     0.85585    10.00000     5.00000     0.97472     0.57849     0.01251     0.03240
     80     0.03031     0.11527     0.99946     0.85250    10.00000     5.00000     0.98517     0.55719     0.01027     0.03188
     90     0.02886     0.11684     0.99954     0.84935    10.00000     4.90909     0.98571     0.56276     0.00974     0.03161
    100     0.02714     0.11831     0.99964     0.84835    10.00000     4.81818     0.98639     0.55545     0.00816     0.03188
    110     0.02487     0.12003     0.99980     0.84653    10.00000     4.72727     0.99091     0.55409     0.00566     0.03188
    120     0.02302     0.12205     0.99989     0.84309    10.00000     4.72727     0.99240     0.55488     0.00474     0.03240
    130     0.02178     0.12328     0.99994     0.84243    10.00000     4.72727     0.99525     0.55460     0.00382     0.03214
    140     0.02033     0.12481     0.99996     0.84110    10.00000     4.78182     0.99661     0.56491     0.00342     0.03267
    150     0.01902     0.12661     0.99998     0.83900    10.00000     4.54545     0.99729     0.56519     0.00263     0.03267
    160     0.01800     0.12828     0.99999     0.83696    10.00000     4.54545     0.99810     0.56573     0.00237     0.03293
    170     0.01693     0.12955     1.00000     0.83544    10.00000     4.81818     0.99959     0.54864     0.00224     0.03346
    180     0.01534     0.13088     1.00000     0.83531    10.00000     4.81818     0.99973     0.53846     0.00132     0.03240
    190     0.01428     0.13260     1.00000     0.83556    10.00000     4.81818     0.99986     0.53682     0.00079     0.03267
    200     0.01345     0.13467     1.00000     0.83427    10.00000     4.72727     0.99986     0.54184     0.00066     0.03346
    210     0.01211     0.13630     1.00000     0.83460    10.00000     4.72727     0.99986     0.54198     0.00013     0.03319
    212     0.01196     0.13669     1.00000     0.83427    10.00000     4.81818     1.00000     0.54225     0.00026     0.03319
    220     0.01099     0.13866     1.00000     0.83395    10.00000     4.90909     1.00000     0.53913     0.00026     0.03319
    230     0.01052     0.13971     1.00000     0.83494    10.00000     4.90909     1.00000     0.53547     0.00026     0.03319
    237     0.00976     0.14150     1.00000     0.83327    10.00000     4.81818     1.00000     0.52787     0.00000     0.03319
    240     0.00932     0.14230     1.00000     0.83290    10.00000     4.90909     1.00000     0.52950     0.00000     0.03319
    250     0.00840     0.14419     1.00000     0.83368    10.00000     4.90909     1.00000     0.53656     0.00000     0.03372
    260     0.00762     0.14615     1.00000     0.83605    10.00000     4.81818     1.00000     0.53193     0.00000     0.03372
    270     0.00678     0.14888     1.00000     0.83604    10.00000     4.81818     1.00000     0.53003     0.00000     0.03346
    280     0.00619     0.15110     1.00000     0.83526    10.00000     4.81818     1.00000     0.52502     0.00000     0.03398
    290     0.00589     0.15295     1.00000     0.83469    10.00000     4.90909     1.00000     0.52814     0.00000     0.03372
    300     0.00525     0.15642     1.00000     0.83278    10.00000     4.90909     1.00000     0.51905     0.00000     0.03372
    310     0.00489     0.15887     1.00000     0.83047    10.00000     4.54545     1.00000     0.51688     0.00000     0.03346
    320     0.00430     0.16241     1.00000     0.82779    10.00000     4.36364     1.00000     0.51037     0.00000     0.03372
    330     0.00384     0.16510     1.00000     0.82645    10.00000     4.45455     1.00000     0.51431     0.00000     0.03319
    340     0.00343     0.16767     1.00000     0.82391    10.00000     4.45455     1.00000     0.50305     0.00000     0.03372
    350     0.00307     0.17041     1.00000     0.82294    10.00000     4.45455     1.00000     0.51635     0.00000     0.03372
    360     0.00278     0.17286     1.00000     0.82324    10.00000     4.45455     1.00000     0.51404     0.00000     0.03346
    370     0.00253     0.17571     1.00000     0.82172    10.00000     4.45455     1.00000     0.51512     0.00000     0.03372
    380     0.00227     0.17846     1.00000     0.82192    10.00000     4.63636     1.00000     0.50767     0.00000     0.03398
    390     0.00207     0.18057     1.00000     0.82308    10.00000     4.54545     1.00000     0.50577     0.00000     0.03372
    400     0.00187     0.18325     1.00000     0.82175    10.00000     4.45455     1.00000     0.50604     0.00000     0.03398


 =========================================
 Variable Importance for the 20-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     37.10569   37.11 |*****      |
 AGE          33.44370   33.44 |****       |
 OTH_CHLD     27.96174   27.96 |****       |
 INCOME       27.29690   27.30 |****       |
 AGE_MOM      26.85170   26.85 |****       |
 ILLEGIT      19.03525   19.04 |***        |
 PNCLATE      14.29009   14.29 |**         |
 RACE_MOM     12.48262   12.48 |**         |
 LBW          11.56992   11.57 |**         |


 Learn Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7367.00         6.00       0.0008
 1                  221.00        53.00       168.00       0.7602


 Test Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3669.00        17.00       0.0046
 1                  110.00         4.00       106.00       0.9636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.8 MB, 75% compression

 Grove file created containing:
      1 TreeNet

