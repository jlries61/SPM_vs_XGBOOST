
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11212      0.11969      0.02910      0.02898      1.00000 |                                               *
      2       0.10418      0.11625      0.02910      0.02898      1.00000 |                                              *
      3       0.09895      0.11371      0.02910      0.02898      1.00000 |                                             *
      4       0.09451      0.11158      0.02884      0.02871      1.00000 |                                            *
      5       0.09114      0.10989      0.02831      0.02845      1.00000 |                                           *
      6       0.08763      0.10888      0.02792      0.02845      1.00000 |                                           *
      7       0.08426      0.10781      0.02779      0.02845      1.00000 |                                          *
      8       0.08158      0.10706      0.02752      0.02871      1.00000 |                                          *
      9       0.07909      0.10631      0.02739      0.02871      1.00000 |                                          *
     10       0.07679      0.10578      0.02713      0.02871      1.00000 |                                         *
     11       0.07456      0.10584      0.02699      0.02871      1.00000 |                                         *
     12       0.07282      0.10564      0.02699      0.02871      1.00000 |                                         *
     13       0.07120      0.10516      0.02699      0.02871      1.00000 |                                         *
     14       0.06962      0.10464      0.02699      0.02898      1.00000 |                                         *
     15       0.06753      0.10495      0.02634      0.02977      1.00000 |                                         *
     16       0.06639      0.10459      0.02620      0.02977      1.00000 |                                         *
     17       0.06467      0.10470      0.02620      0.02950      1.00000 |                                         *
     18       0.06379      0.10460      0.02594      0.02950      1.00000 |                                         *
     19       0.06232      0.10433      0.02568      0.02977      1.00000 |                                         *
     20       0.06132      0.10422      0.02528      0.02977      1.00000 |                                         *
     30       0.05422      0.10378      0.02449      0.02977      1.00000 |                                         *
     40       0.05014      0.10448      0.02239      0.02977      1.00000 |                                         *
     50       0.04498      0.10513      0.01988      0.02977      1.00000 |                                         *
     60       0.04275      0.10612      0.01817      0.02977      1.00000 |                                          *
     70       0.04026      0.10759      0.01712      0.03003      1.00000 |                                          *
     80       0.03843      0.10856      0.01580      0.03056      1.00000 |                                           *
     90       0.03660      0.10992      0.01462      0.03056      1.00000 |                                           *
    100       0.03538      0.11099      0.01343      0.03030      1.00000 |                                            *
    110       0.03311      0.11240      0.01198      0.02977      1.00000 |                                            *
    120       0.03223      0.11282      0.01067      0.02977      1.00000 |                                            *
    130       0.03089      0.11346      0.00974      0.02950      1.00000 |                                             *
    140       0.02875      0.11506      0.00909      0.02950      1.00000 |                                             *
    150       0.02816      0.11582      0.00869      0.02924      1.00000 |                                             *
    160       0.02659      0.11723      0.00737      0.02950      1.00000 |                                              *
    170       0.02536      0.11860      0.00658      0.02977      1.00000 |                                               *
    180       0.02373      0.11966      0.00500      0.02977      1.00000 |                                               *
    190       0.02213      0.12109      0.00382      0.02977      1.00000 |                                               *
    200       0.02088      0.12283      0.00342      0.03056      1.00000 |                                               *
    210       0.02031      0.12368      0.00316      0.03056      1.00000 |                                               *
    220       0.01933      0.12491      0.00303      0.03109      1.00000 |                                               *
    230       0.01862      0.12581      0.00224      0.03109      1.00000 |                                               *
    240       0.01757      0.12768      0.00198      0.03135      1.00000 |                                               *
    250       0.01624      0.12854      0.00158      0.03161      1.00000 |                                               *
    260       0.01555      0.12950      0.00119      0.03161      1.00000 |                                               *
    270       0.01474      0.13115      0.00105      0.03161      1.00000 |                                               *
    280       0.01403      0.13269      0.00092      0.03188      1.00000 |                                               *
    290       0.01344      0.13385      0.00079      0.03188      1.00000 |                                               *
    300       0.01273      0.13471      0.00079      0.03214      1.00000 |                                               *
    310       0.01227      0.13607      0.00079      0.03214      1.00000 |                                               *
    320       0.01181      0.13782      0.00053      0.03267      1.00000 |                                               *
    330       0.01085      0.14001      0.00013      0.03267      1.00000 |                                               *
    340       0.01016      0.14206      0.00013      0.03240      1.00000 |                                               *
    350       0.00988      0.14270      0.00000      0.03240      1.00000 |                                               *
    360       0.00927      0.14452      0.00000      0.03214      1.00000 |                                               *
    370       0.00883      0.14628      0.00000      0.03240      1.00000 |                                               *
    380       0.00848      0.14787      0.00000      0.03214      1.00000 |                                               *
    390       0.00822      0.14937      0.00000      0.03161      1.00000 |                                               *
    400       0.00794      0.15061      0.00000      0.03188      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.23      6.78  CHILDYRS
    301      1    400      1      7      4.24      2.83  INCOME
    296      1    400      1      7      3.73      3.16  AGE
    288      1    399      2      7      4.39      2.60  AGE_MOM
    279      1    400      1      7      4.36      2.54  OTH_CHLD
    262      1    400      1      7      4.50      2.29  EDUC_MOM
    201      1    400      2      7      5.23      1.39  RACE_MOM
    189      1    394      1      7      4.79      1.52  ILLEGIT
    159      1    397      3      7      5.38      1.04  PNCLATE
    152      1    394      2      7      5.45      0.97  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   100 terminal nodes
    Average :     34.87750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 43 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 43 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 29

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 27502 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           29      0.10370
                  ROC           43      0.86589
                 Lift            7      5.72727
              KS-stat           51      0.60034
          Class.Error            5      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11212     0.11969     0.92063     0.78164     7.01584     4.72727     0.68271     0.53383     0.02910     0.02898
      5     0.09114     0.10989     0.95466     0.84226     8.19169     5.63636     0.78581     0.53658     0.02831     0.02845
      7     0.08426     0.10781     0.96647     0.84114     8.86878     5.72727     0.83217     0.54877     0.02779     0.02845
     10     0.07679     0.10578     0.97369     0.85535     9.21719     5.18182     0.86143     0.56980     0.02713     0.02871
     20     0.06132     0.10422     0.98651     0.86052     9.63801     5.09091     0.90168     0.55691     0.02528     0.02977
     29     0.05485     0.10370     0.99154     0.86484     9.86425     5.18182     0.93895     0.57158     0.02449     0.02977
     30     0.05422     0.10378     0.99196     0.86446     9.90950     5.18182     0.93868     0.56820     0.02449     0.02977
     40     0.05014     0.10448     0.99361     0.86306     9.90950     5.18182     0.95035     0.57022     0.02239     0.02977
     43     0.04834     0.10416     0.99428     0.86589     9.90950     5.09091     0.95279     0.57972     0.02173     0.02977
     50     0.04498     0.10513     0.99538     0.86447     9.90950     5.09091     0.95618     0.59789     0.01988     0.02977
     51     0.04453     0.10523     0.99552     0.86440     9.90950     5.18182     0.95618     0.60034     0.01949     0.02977
     60     0.04275     0.10612     0.99610     0.86171     9.90950     5.18182     0.95849     0.58256     0.01817     0.02977
     70     0.04026     0.10759     0.99681     0.85775     9.90950     5.09091     0.95781     0.58663     0.01712     0.03003
     79     0.03860     0.10854     0.99740     0.85531    10.00000     5.18182     0.96396     0.58066     0.01580     0.03056
     80     0.03843     0.10856     0.99747     0.85536    10.00000     5.18182     0.96396     0.57592     0.01580     0.03056
     90     0.03660     0.10992     0.99792     0.85291    10.00000     5.09091     0.96477     0.56982     0.01462     0.03056
    100     0.03538     0.11099     0.99814     0.85110    10.00000     5.00000     0.96549     0.57334     0.01343     0.03030
    110     0.03311     0.11240     0.99861     0.84809    10.00000     4.90909     0.96902     0.55734     0.01198     0.02977
    120     0.03223     0.11282     0.99876     0.84751    10.00000     4.90909     0.97227     0.55788     0.01067     0.02977
    130     0.03089     0.11346     0.99896     0.84754    10.00000     5.00000     0.97268     0.55489     0.00974     0.02950
    140     0.02875     0.11506     0.99937     0.84610    10.00000     5.00000     0.98195     0.54132     0.00909     0.02950
    150     0.02816     0.11582     0.99942     0.84567    10.00000     5.00000     0.98209     0.54540     0.00869     0.02924
    160     0.02659     0.11723     0.99957     0.84527    10.00000     4.90909     0.98539     0.54838     0.00737     0.02950
    170     0.02536     0.11860     0.99967     0.84296    10.00000     4.90909     0.98620     0.54934     0.00658     0.02977
    180     0.02373     0.11966     0.99979     0.84386    10.00000     4.90909     0.98901     0.54445     0.00500     0.02977
    190     0.02213     0.12109     0.99987     0.84421    10.00000     5.00000     0.99403     0.55394     0.00382     0.02977
    200     0.02088     0.12283     0.99991     0.84331    10.00000     5.00000     0.99498     0.54404     0.00342     0.03056
    210     0.02031     0.12368     0.99993     0.84243    10.00000     5.00000     0.99539     0.54648     0.00316     0.03056
    220     0.01933     0.12491     0.99995     0.84325    10.00000     5.00000     0.99634     0.54798     0.00303     0.03109
    230     0.01862     0.12581     0.99996     0.84206    10.00000     4.90909     0.99620     0.54717     0.00224     0.03109
    240     0.01757     0.12768     0.99997     0.84225    10.00000     4.81818     0.99661     0.54364     0.00198     0.03135
    250     0.01624     0.12854     0.99999     0.84229    10.00000     5.00000     0.99878     0.54961     0.00158     0.03161
    260     0.01555     0.12950     0.99999     0.84224    10.00000     4.90909     0.99905     0.54107     0.00119     0.03161
    270     0.01474     0.13115     1.00000     0.84023    10.00000     4.87273     0.99973     0.53546     0.00105     0.03161
    280     0.01403     0.13269     1.00000     0.83780    10.00000     4.90909     0.99986     0.54088     0.00092     0.03188
    290     0.01344     0.13385     1.00000     0.83637    10.00000     4.81818     0.99986     0.53003     0.00079     0.03188
    296     0.01313     0.13448     1.00000     0.83616    10.00000     4.81818     1.00000     0.53166     0.00079     0.03188
    300     0.01273     0.13471     1.00000     0.83648    10.00000     4.81818     1.00000     0.53478     0.00079     0.03214
    310     0.01227     0.13607     1.00000     0.83543    10.00000     4.81818     1.00000     0.52569     0.00079     0.03214
    320     0.01181     0.13782     1.00000     0.83311    10.00000     4.81818     1.00000     0.51703     0.00053     0.03267
    330     0.01085     0.14001     1.00000     0.83235    10.00000     4.90909     1.00000     0.51864     0.00013     0.03267
    340     0.01016     0.14206     1.00000     0.83044    10.00000     4.90909     1.00000     0.51782     0.00013     0.03240
    348     0.00994     0.14256     1.00000     0.82967    10.00000     4.90909     1.00000     0.51579     0.00000     0.03240
    350     0.00988     0.14270     1.00000     0.83000    10.00000     4.90909     1.00000     0.51606     0.00000     0.03240
    360     0.00927     0.14452     1.00000     0.82977    10.00000     4.90909     1.00000     0.51579     0.00000     0.03214
    370     0.00883     0.14628     1.00000     0.82745    10.00000     4.81818     1.00000     0.51324     0.00000     0.03240
    380     0.00848     0.14787     1.00000     0.82541    10.00000     4.81818     1.00000     0.51498     0.00000     0.03214
    390     0.00822     0.14937     1.00000     0.82330    10.00000     4.81818     1.00000     0.51105     0.00000     0.03161
    400     0.00794     0.15061     1.00000     0.82175    10.00000     4.81818     1.00000     0.51390     0.00000     0.03188


 =========================================
 Variable Importance for the 29-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     37.69344   37.69 |*****      |
 AGE          34.42744   34.43 |****       |
 OTH_CHLD     33.01791   33.02 |****       |
 INCOME       28.47794   28.48 |****       |
 AGE_MOM      26.53500   26.54 |****       |
 ILLEGIT      18.13558   18.14 |***        |
 RACE_MOM     14.61201   14.61 |**         |
 LBW          13.96747   13.97 |**         |
 PNCLATE      12.86396   12.86 |**         |


 Learn Sample Misclassification by Target Class
 For The 29-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7368.00         5.00       0.0007
 1                  221.00        40.00       181.00       0.8190


 Test Sample Misclassification by Target Class
 For The 29-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3680.00         6.00       0.0016
 1                  110.00         3.00       107.00       0.9727

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

