
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11503      0.12141      0.02910      0.02898      1.00000 |                                               *
      2       0.10803      0.11675      0.02910      0.02898      1.00000 |                                             *
      3       0.10230      0.11348      0.02910      0.02898      1.00000 |                                            *
      4       0.09777      0.11159      0.02910      0.02898      1.00000 |                                           *
      5       0.09430      0.11019      0.02910      0.02898      1.00000 |                                           *
      6       0.09141      0.10924      0.02871      0.02898      1.00000 |                                          *
      7       0.08846      0.10847      0.02844      0.02898      1.00000 |                                          *
      8       0.08607      0.10795      0.02699      0.02950      1.00000 |                                          *
      9       0.08417      0.10730      0.02686      0.02924      1.00000 |                                         *
     10       0.08210      0.10708      0.02647      0.02924      1.00000 |                                         *
     11       0.08080      0.10685      0.02607      0.02924      1.00000 |                                         *
     12       0.07929      0.10618      0.02541      0.02924      1.00000 |                                         *
     13       0.07803      0.10603      0.02541      0.02924      1.00000 |                                         *
     14       0.07671      0.10564      0.02528      0.02950      1.00000 |                                         *
     15       0.07583      0.10573      0.02502      0.02950      1.00000 |                                         *
     16       0.07508      0.10550      0.02476      0.02977      1.00000 |                                         *
     17       0.07417      0.10547      0.02462      0.03003      1.00000 |                                         *
     18       0.07322      0.10549      0.02436      0.03003      1.00000 |                                         *
     19       0.07248      0.10558      0.02436      0.03003      1.00000 |                                         *
     20       0.07166      0.10531      0.02436      0.02977      1.00000 |                                         *
     30       0.06814      0.10489      0.02344      0.03003      1.00000 |                                        *
     40       0.06303      0.10527      0.02252      0.03030      1.00000 |                                         *
     50       0.06013      0.10574      0.02146      0.03030      1.00000 |                                         *
     60       0.05670      0.10624      0.02028      0.03056      1.00000 |                                         *
     70       0.05572      0.10657      0.02002      0.03056      1.00000 |                                         *
     80       0.05480      0.10678      0.01923      0.03082      1.00000 |                                         *
     90       0.05140      0.10816      0.01778      0.03135      1.00000 |                                          *
    100       0.04913      0.10856      0.01659      0.03109      1.00000 |                                          *
    110       0.04841      0.10902      0.01659      0.03082      1.00000 |                                          *
    120       0.04702      0.10921      0.01633      0.03082      1.00000 |                                          *
    130       0.04627      0.10954      0.01620      0.03082      1.00000 |                                          *
    140       0.04532      0.10989      0.01580      0.03109      1.00000 |                                          *
    150       0.04465      0.11027      0.01554      0.03109      1.00000 |                                           *
    160       0.04391      0.11074      0.01514      0.03109      1.00000 |                                           *
    170       0.04360      0.11093      0.01501      0.03109      1.00000 |                                           *
    180       0.04274      0.11144      0.01501      0.03109      1.00000 |                                           *
    190       0.04220      0.11176      0.01475      0.03109      1.00000 |                                           *
    200       0.04152      0.11220      0.01475      0.03109      1.00000 |                                           *
    210       0.03970      0.11370      0.01396      0.03135      1.00000 |                                            *
    220       0.03873      0.11437      0.01370      0.03109      1.00000 |                                            *
    230       0.03749      0.11582      0.01238      0.03109      1.00000 |                                             *
    240       0.03652      0.11686      0.01172      0.03109      1.00000 |                                             *
    250       0.03631      0.11716      0.01172      0.03056      1.00000 |                                             *
    260       0.03501      0.11843      0.01106      0.03109      1.00000 |                                              *
    270       0.03421      0.11890      0.01080      0.03109      1.00000 |                                              *
    280       0.03336      0.11970      0.01014      0.03109      1.00000 |                                              *
    290       0.03285      0.12060      0.01014      0.03109      1.00000 |                                               *
    300       0.03187      0.12219      0.01014      0.03214      1.00000 |                                               *
    310       0.03078      0.12270      0.00974      0.03214      1.00000 |                                               *
    320       0.02963      0.12323      0.00922      0.03240      1.00000 |                                               *
    330       0.02856      0.12430      0.00895      0.03188      1.00000 |                                               *
    340       0.02808      0.12506      0.00882      0.03188      1.00000 |                                               *
    350       0.02696      0.12623      0.00843      0.03188      1.00000 |                                               *
    360       0.02648      0.12676      0.00816      0.03188      1.00000 |                                               *
    370       0.02583      0.12728      0.00803      0.03214      1.00000 |                                               *
    380       0.02542      0.12798      0.00790      0.03214      1.00000 |                                               *
    390       0.02497      0.12836      0.00777      0.03267      1.00000 |                                               *
    400       0.02423      0.12922      0.00751      0.03214      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.06      6.94  CHILDYRS
    273      1    399      1      7      4.54      2.36  AGE
    244      1    400      1      7      4.90      1.89  INCOME
    202      1    399      2      7      5.42      1.30  AGE_MOM
    171      1    399      1      7      5.33      1.14  OTH_CHLD
    160      1    399      1      7      5.02      1.19  EDUC_MOM
    127      1    399      2      7      5.50      0.80  ILLEGIT
     63      1    396      3      7      5.63      0.37  RACE_MOM
     61      2    395      1      7      5.41      0.40  PNCLATE
     44      3    396      3      7      6.02      0.22  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    59 terminal nodes
    Average :     19.55750 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 29 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 29 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 27

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 15246 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           27      0.10478
                  ROC           29      0.86009
                 Lift            5      6.45455
              KS-stat            9      0.60251
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11503     0.12141     0.90625     0.82593     6.47343     5.30854     0.65039     0.54536     0.02910     0.02898
      5     0.09430     0.11019     0.93014     0.84634     7.73756     6.45455     0.70783     0.56379     0.02910     0.02898
      9     0.08417     0.10730     0.94099     0.85068     8.05430     5.81818     0.74257     0.60251     0.02686     0.02924
     10     0.08210     0.10708     0.94197     0.84985     8.00905     5.90909     0.74993     0.59573     0.02647     0.02924
     20     0.07166     0.10531     0.95128     0.85675     8.37104     6.00000     0.77408     0.57118     0.02436     0.02977
     27     0.06874     0.10478     0.95431     0.85989     8.46154     6.00000     0.78168     0.58363     0.02370     0.03003
     29     0.06821     0.10485     0.95496     0.86009     8.46154     5.81818     0.78661     0.58445     0.02357     0.03003
     30     0.06814     0.10489     0.95497     0.86007     8.46154     5.81818     0.78661     0.58445     0.02344     0.03003
     40     0.06303     0.10527     0.96843     0.85743     8.82353     5.45455     0.81962     0.58594     0.02252     0.03030
     50     0.06013     0.10574     0.97124     0.85879     9.04977     5.27273     0.83536     0.59597     0.02146     0.03030
     60     0.05670     0.10624     0.97812     0.85636     9.15837     5.27273     0.84641     0.57915     0.02028     0.03056
     70     0.05572     0.10657     0.97897     0.85553     9.18552     5.09091     0.84726     0.58349     0.02002     0.03056
     80     0.05480     0.10678     0.97953     0.85543     9.23077     5.14545     0.84880     0.58267     0.01923     0.03082
     90     0.05140     0.10816     0.98383     0.84861     9.27602     5.18182     0.86357     0.56585     0.01778     0.03135
    100     0.04913     0.10856     0.98596     0.84837     9.41176     5.27273     0.87218     0.56762     0.01659     0.03109
    110     0.04841     0.10902     0.98659     0.84824     9.45701     5.18182     0.87585     0.57006     0.01659     0.03082
    120     0.04702     0.10921     0.98780     0.85057     9.50226     5.27273     0.88244     0.57684     0.01633     0.03082
    130     0.04627     0.10954     0.98824     0.84938     9.50226     5.27273     0.88805     0.56843     0.01620     0.03082
    140     0.04532     0.10989     0.98907     0.84966     9.54751     5.27273     0.88967     0.56289     0.01580     0.03109
    150     0.04465     0.11027     0.98944     0.84868     9.59276     5.27273     0.88967     0.55950     0.01554     0.03109
    160     0.04391     0.11074     0.98984     0.84676     9.59276     5.14545     0.89742     0.56099     0.01514     0.03109
    170     0.04360     0.11093     0.98994     0.84642     9.59276     5.09091     0.89769     0.56072     0.01501     0.03109
    180     0.04274     0.11144     0.99115     0.84559     9.72851     5.09091     0.90612     0.56072     0.01501     0.03109
    190     0.04220     0.11176     0.99145     0.84473     9.72851     5.18182     0.90653     0.57307     0.01475     0.03109
    200     0.04152     0.11220     0.99185     0.84369     9.72851     5.18182     0.90732     0.57198     0.01475     0.03109
    210     0.03970     0.11370     0.99308     0.83962     9.77376     5.09091     0.92247     0.55123     0.01396     0.03135
    220     0.03873     0.11437     0.99351     0.83783     9.77376     5.00000     0.92342     0.54757     0.01370     0.03109
    230     0.03749     0.11582     0.99459     0.83306     9.77376     5.00000     0.92825     0.52748     0.01238     0.03109
    240     0.03652     0.11686     0.99519     0.83053     9.86425     4.90909     0.93441     0.52708     0.01172     0.03109
    250     0.03631     0.11716     0.99526     0.82980     9.86425     4.90909     0.93454     0.52205     0.01172     0.03056
    260     0.03501     0.11843     0.99606     0.82796     9.86425     4.72727     0.93613     0.52938     0.01106     0.03109
    270     0.03421     0.11890     0.99715     0.82702     9.95475     4.54545     0.94079     0.52857     0.01080     0.03109
    277     0.03359     0.11942     0.99734     0.82555    10.00000     4.60000     0.94270     0.52667     0.01053     0.03109
    280     0.03336     0.11970     0.99737     0.82503    10.00000     4.54545     0.94325     0.52179     0.01014     0.03109
    290     0.03285     0.12060     0.99753     0.82306    10.00000     4.63636     0.94623     0.51906     0.01014     0.03109
    300     0.03187     0.12219     0.99775     0.81872    10.00000     4.54545     0.94826     0.50183     0.01014     0.03214
    310     0.03078     0.12270     0.99811     0.81831    10.00000     4.54545     0.95093     0.50265     0.00974     0.03214
    320     0.02963     0.12323     0.99865     0.81982    10.00000     4.54545     0.96247     0.51146     0.00922     0.03240
    330     0.02856     0.12430     0.99895     0.81854    10.00000     4.45455     0.96789     0.50699     0.00895     0.03188
    340     0.02808     0.12506     0.99902     0.81636    10.00000     4.45455     0.96911     0.50332     0.00882     0.03188
    350     0.02696     0.12623     0.99920     0.81509    10.00000     4.54545     0.97278     0.50428     0.00843     0.03188
    360     0.02648     0.12676     0.99925     0.81428    10.00000     4.54545     0.97390     0.49302     0.00816     0.03188
    370     0.02583     0.12728     0.99937     0.81412    10.00000     4.54545     0.97856     0.49600     0.00803     0.03214
    380     0.02542     0.12798     0.99942     0.81250    10.00000     4.54545     0.97842     0.48745     0.00790     0.03214
    390     0.02497     0.12836     0.99947     0.81194    10.00000     4.45455     0.97964     0.49478     0.00777     0.03267
    396     0.02440     0.12909     0.99956     0.81083    10.00000     4.41818     0.98471     0.49152     0.00764     0.03267
    399     0.02424     0.12922     0.99957     0.81146    10.00000     4.45455     0.98458     0.49396     0.00751     0.03240
    400     0.02423     0.12922     0.99957     0.81135    10.00000     4.45455     0.98458     0.49396     0.00751     0.03214


 =========================================
 Variable Importance for the 27-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      40.92997   40.93 |*****      |
 EDUC_MOM     37.88531   37.89 |*****      |
 AGE          30.83724   30.84 |****       |
 INCOME       28.87441   28.87 |****       |
 OTH_CHLD     28.67769   28.68 |****       |
 ILLEGIT      18.27638   18.28 |***        |
 RACE_MOM     14.87822   14.88 |**         |
 PNCLATE      13.47279   13.47 |**         |
 LBW           9.73889    9.74 |**         |


 Learn Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7367.00         6.00       0.0008
 1                  221.00        47.00       174.00       0.7873


 Test Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3673.00        13.00       0.0035
 1                  110.00         9.00       101.00       0.9182

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 698 kb , 76% compression

 Grove file created containing:
      1 TreeNet

