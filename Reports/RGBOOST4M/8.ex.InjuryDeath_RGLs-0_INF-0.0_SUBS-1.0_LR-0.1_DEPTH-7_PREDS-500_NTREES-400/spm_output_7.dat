
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11072      0.11563      0.02910      0.02898      1.00000 |                                               *
      2       0.10375      0.11172      0.02910      0.02898      1.00000 |                                             *
      3       0.09850      0.10848      0.02910      0.02898      1.00000 |                                            *
      4       0.09413      0.10655      0.02910      0.02898      1.00000 |                                           *
      5       0.09038      0.10441      0.02858      0.02819      1.00000 |                                          *
      6       0.08666      0.10352      0.02805      0.02766      1.00000 |                                          *
      7       0.08383      0.10261      0.02792      0.02740      1.00000 |                                          *
      8       0.08059      0.10180      0.02765      0.02740      1.00000 |                                         *
      9       0.07806      0.10105      0.02739      0.02740      1.00000 |                                         *
     10       0.07598      0.10050      0.02713      0.02713      1.00000 |                                         *
     11       0.07343      0.10000      0.02660      0.02687      1.00000 |                                         *
     12       0.07174      0.09911      0.02634      0.02661      1.00000 |                                        *
     13       0.07032      0.09875      0.02594      0.02661      1.00000 |                                        *
     14       0.06897      0.09835      0.02541      0.02608      1.00000 |                                        *
     15       0.06767      0.09804      0.02515      0.02634      1.00000 |                                        *
     16       0.06611      0.09775      0.02502      0.02634      1.00000 |                                        *
     17       0.06450      0.09782      0.02476      0.02634      1.00000 |                                        *
     18       0.06309      0.09778      0.02423      0.02661      1.00000 |                                        *
     19       0.06187      0.09772      0.02410      0.02687      1.00000 |                                        *
     20       0.06043      0.09730      0.02397      0.02687      1.00000 |                                       *
     30       0.05199      0.09767      0.02304      0.02792      1.00000 |                                        *
     40       0.04740      0.09847      0.02107      0.02740      1.00000 |                                        *
     50       0.04494      0.09939      0.01936      0.02687      1.00000 |                                        *
     60       0.04256      0.09973      0.01751      0.02687      1.00000 |                                        *
     70       0.03941      0.10069      0.01607      0.02740      1.00000 |                                         *
     80       0.03582      0.10248      0.01356      0.02740      1.00000 |                                          *
     90       0.03358      0.10291      0.01304      0.02792      1.00000 |                                          *
    100       0.03067      0.10481      0.00974      0.02819      1.00000 |                                           *
    110       0.02899      0.10616      0.00895      0.02819      1.00000 |                                           *
    120       0.02775      0.10718      0.00790      0.02871      1.00000 |                                           *
    130       0.02638      0.10829      0.00711      0.02871      1.00000 |                                            *
    140       0.02419      0.10982      0.00566      0.02845      1.00000 |                                             *
    150       0.02277      0.11096      0.00500      0.02819      1.00000 |                                             *
    160       0.02219      0.11161      0.00461      0.02845      1.00000 |                                             *
    170       0.02160      0.11260      0.00448      0.02819      1.00000 |                                              *
    180       0.02086      0.11320      0.00369      0.02792      1.00000 |                                              *
    190       0.02044      0.11349      0.00342      0.02845      1.00000 |                                              *
    200       0.01868      0.11535      0.00211      0.02871      1.00000 |                                               *
    210       0.01800      0.11619      0.00184      0.02819      1.00000 |                                               *
    220       0.01729      0.11710      0.00158      0.02819      1.00000 |                                               *
    230       0.01700      0.11763      0.00158      0.02819      1.00000 |                                               *
    240       0.01694      0.11782      0.00158      0.02819      1.00000 |                                               *
    250       0.01609      0.11838      0.00132      0.02819      1.00000 |                                               *
    260       0.01550      0.11944      0.00079      0.02871      1.00000 |                                               *
    270       0.01473      0.12116      0.00079      0.02845      1.00000 |                                               *
    280       0.01429      0.12203      0.00066      0.02845      1.00000 |                                               *
    290       0.01384      0.12325      0.00053      0.02845      1.00000 |                                               *
    300       0.01320      0.12441      0.00013      0.02845      1.00000 |                                               *
    310       0.01251      0.12580      0.00013      0.02792      1.00000 |                                               *
    320       0.01181      0.12700      0.00013      0.02792      1.00000 |                                               *
    330       0.01104      0.12871      0.00000      0.02871      1.00000 |                                               *
    340       0.01053      0.12987      0.00000      0.02871      1.00000 |                                               *
    350       0.00991      0.13183      0.00000      0.02845      1.00000 |                                               *
    360       0.00956      0.13299      0.00000      0.02845      1.00000 |                                               *
    370       0.00879      0.13478      0.00000      0.02898      1.00000 |                                               *
    380       0.00841      0.13570      0.00000      0.02977      1.00000 |                                               *
    390       0.00783      0.13702      0.00000      0.03003      1.00000 |                                               *
    400       0.00741      0.13808      0.00000      0.03003      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.33      6.67  CHILDYRS
    293      1    400      1      7      4.01      2.93  AGE
    278      1    400      1      7      4.23      2.62  INCOME
    271      1    400      1      7      4.19      2.58  AGE_MOM
    247      1    399      1      7      4.48      2.18  OTH_CHLD
    237      1    399      1      7      3.93      2.41  EDUC_MOM
    217      1    399      1      7      4.62      1.83  ILLEGIT
    191      1    397      2      7      5.32      1.28  RACE_MOM
    148      3    399      2      7      5.17      1.05  PNCLATE
    146      3    399      1      7      5.19      1.03  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    98 terminal nodes
    Average :     35.05250 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 22 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 22 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 21

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 27642 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           21      0.09714
                  ROC           12      0.87440
                 Lift           22      6.27273
              KS-stat           57      0.62053
          Class.Error           14      0.02608

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11072     0.11563     0.91673     0.76835     7.16373     5.29761     0.67309     0.45036     0.02910     0.02898
     10     0.07598     0.10050     0.97085     0.87170     8.91403     5.90909     0.82103     0.58079     0.02713     0.02713
     12     0.07174     0.09911     0.97799     0.87440     9.36652     6.09091     0.86393     0.57642     0.02634     0.02661
     14     0.06897     0.09835     0.97979     0.87290     9.36652     6.18182     0.86731     0.57479     0.02541     0.02608
     20     0.06043     0.09730     0.98864     0.87277     9.68326     6.18182     0.91343     0.58282     0.02397     0.02687
     21     0.05958     0.09714     0.98907     0.87303     9.81900     6.18182     0.91560     0.58963     0.02410     0.02713
     22     0.05807     0.09722     0.98998     0.87261     9.86425     6.27273     0.91913     0.59096     0.02397     0.02713
     26     0.05503     0.09729     0.99201     0.87305    10.00000     6.09091     0.93490     0.59381     0.02331     0.02766
     30     0.05199     0.09767     0.99374     0.87079    10.00000     6.18182     0.95872     0.60290     0.02304     0.02792
     40     0.04740     0.09847     0.99513     0.87015    10.00000     6.18182     0.96681     0.60724     0.02107     0.02740
     50     0.04494     0.09939     0.99577     0.86861    10.00000     6.09091     0.96713     0.60914     0.01936     0.02687
     57     0.04361     0.09973     0.99619     0.86962    10.00000     6.09091     0.96848     0.62053     0.01830     0.02687
     60     0.04256     0.09973     0.99660     0.87064    10.00000     6.09091     0.96862     0.61415     0.01751     0.02687
     70     0.03941     0.10069     0.99754     0.86945    10.00000     5.90909     0.97608     0.61184     0.01607     0.02740
     80     0.03582     0.10248     0.99833     0.86617    10.00000     5.69091     0.98779     0.60750     0.01356     0.02740
     90     0.03358     0.10291     0.99871     0.86791    10.00000     5.60000     0.98834     0.60153     0.01304     0.02792
    100     0.03067     0.10481     0.99913     0.86308    10.00000     5.63636     0.99146     0.60099     0.00974     0.02819
    110     0.02899     0.10616     0.99933     0.86044    10.00000     5.72727     0.99213     0.58919     0.00895     0.02819
    120     0.02775     0.10718     0.99945     0.85916    10.00000     5.54545     0.99227     0.58851     0.00790     0.02871
    130     0.02638     0.10829     0.99959     0.85774    10.00000     5.54545     0.99295     0.58078     0.00711     0.02871
    140     0.02419     0.10982     0.99978     0.85630    10.00000     5.60000     0.99512     0.58362     0.00566     0.02845
    150     0.02277     0.11096     0.99987     0.85518    10.00000     5.63636     0.99512     0.58770     0.00500     0.02819
    160     0.02219     0.11161     0.99989     0.85502    10.00000     5.72727     0.99539     0.57983     0.00461     0.02845
    170     0.02160     0.11260     0.99991     0.85375    10.00000     5.63636     0.99647     0.57250     0.00448     0.02819
    180     0.02086     0.11320     0.99992     0.85280    10.00000     5.60000     0.99634     0.56855     0.00369     0.02792
    190     0.02044     0.11349     0.99994     0.85267    10.00000     5.54545     0.99810     0.57466     0.00342     0.02845
    200     0.01868     0.11535     0.99996     0.85225    10.00000     5.45455     0.99891     0.57249     0.00211     0.02871
    210     0.01800     0.11619     0.99997     0.85246    10.00000     5.63636     0.99905     0.57439     0.00184     0.02819
    220     0.01729     0.11710     0.99997     0.85245    10.00000     5.63636     0.99905     0.57114     0.00158     0.02819
    230     0.01700     0.11763     0.99998     0.85184    10.00000     5.72727     0.99946     0.57114     0.00158     0.02819
    240     0.01694     0.11782     0.99999     0.85152    10.00000     5.63636     0.99946     0.57141     0.00158     0.02819
    250     0.01609     0.11838     0.99999     0.85236    10.00000     5.72727     0.99973     0.57114     0.00132     0.02819
    260     0.01550     0.11944     0.99999     0.85216    10.00000     5.72727     0.99973     0.56869     0.00079     0.02871
    270     0.01473     0.12116     1.00000     0.85058    10.00000     5.54545     0.99973     0.56626     0.00079     0.02845
    280     0.01429     0.12203     1.00000     0.85069    10.00000     5.63636     0.99986     0.56680     0.00066     0.02845
    290     0.01384     0.12325     1.00000     0.84941    10.00000     5.54545     0.99986     0.57711     0.00053     0.02845
    300     0.01320     0.12441     1.00000     0.84877    10.00000     5.54545     0.99986     0.57549     0.00013     0.02845
    310     0.01251     0.12580     1.00000     0.84727    10.00000     5.45455     0.99986     0.57114     0.00013     0.02792
    314     0.01217     0.12644     1.00000     0.84668    10.00000     5.45455     1.00000     0.57982     0.00013     0.02792
    320     0.01181     0.12700     1.00000     0.84651    10.00000     5.45455     1.00000     0.58145     0.00013     0.02792
    327     0.01128     0.12798     1.00000     0.84670    10.00000     5.45455     1.00000     0.57792     0.00000     0.02871
    330     0.01104     0.12871     1.00000     0.84578    10.00000     5.54545     1.00000     0.57371     0.00000     0.02871
    340     0.01053     0.12987     1.00000     0.84447    10.00000     5.45455     1.00000     0.57575     0.00000     0.02871
    350     0.00991     0.13183     1.00000     0.84351    10.00000     5.54545     1.00000     0.56939     0.00000     0.02845
    360     0.00956     0.13299     1.00000     0.84321    10.00000     5.45455     1.00000     0.57346     0.00000     0.02845
    370     0.00879     0.13478     1.00000     0.84253    10.00000     5.36364     1.00000     0.57074     0.00000     0.02898
    380     0.00841     0.13570     1.00000     0.84114    10.00000     5.36364     1.00000     0.56530     0.00000     0.02977
    390     0.00783     0.13702     1.00000     0.84045    10.00000     5.63636     1.00000     0.56436     0.00000     0.03003
    400     0.00741     0.13808     1.00000     0.83999    10.00000     5.50909     1.00000     0.56382     0.00000     0.03003


 =========================================
 Variable Importance for the 21-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          35.65469   35.65 |*****      |
 EDUC_MOM     33.91711   33.92 |****       |
 AGE_MOM      31.91684   31.92 |****       |
 INCOME       30.54366   30.54 |****       |
 OTH_CHLD     29.23160   29.23 |****       |
 ILLEGIT      20.09272   20.09 |***        |
 RACE_MOM     16.87157   16.87 |***        |
 PNCLATE      13.02822   13.03 |**         |
 LBW           9.89905    9.90 |**         |


 Learn Sample Misclassification by Target Class
 For The 21-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7368.00         5.00       0.0007
 1                  221.00        43.00       178.00       0.8054


 Test Sample Misclassification by Target Class
 For The 21-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3678.00         8.00       0.0022
 1                  110.00        15.00        95.00       0.8636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs,  50.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  50.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000278 hrs 50.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

