
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10967      0.12255      0.02910      0.02898      1.00000 |                                               *
      2       0.10211      0.11945      0.02910      0.02898      1.00000 |                                              *
      3       0.09682      0.11759      0.02910      0.02898      1.00000 |                                             *
      4       0.09194      0.11607      0.02910      0.02898      1.00000 |                                            *
      5       0.08829      0.11562      0.02910      0.02898      1.00000 |                                            *
      6       0.08487      0.11437      0.02910      0.02898      1.00000 |                                            *
      7       0.08211      0.11372      0.02792      0.02898      1.00000 |                                            *
      8       0.07963      0.11328      0.02765      0.02977      1.00000 |                                           *
      9       0.07723      0.11310      0.02726      0.02898      1.00000 |                                           *
     10       0.07513      0.11287      0.02726      0.02898      1.00000 |                                           *
     11       0.07313      0.11289      0.02634      0.02924      1.00000 |                                           *
     12       0.07145      0.11283      0.02594      0.03030      1.00000 |                                           *
     13       0.06992      0.11279      0.02515      0.03056      1.00000 |                                           *
     14       0.06894      0.11258      0.02436      0.02977      1.00000 |                                           *
     15       0.06758      0.11251      0.02423      0.02977      1.00000 |                                           *
     16       0.06628      0.11268      0.02397      0.02950      1.00000 |                                           *
     17       0.06577      0.11269      0.02370      0.02950      1.00000 |                                           *
     18       0.06526      0.11260      0.02331      0.02950      1.00000 |                                           *
     19       0.06470      0.11269      0.02265      0.02977      1.00000 |                                           *
     20       0.06429      0.11284      0.02225      0.03030      1.00000 |                                           *
     30       0.05829      0.11405      0.02120      0.03030      1.00000 |                                            *
     40       0.05385      0.11478      0.01923      0.03030      1.00000 |                                            *
     50       0.05082      0.11619      0.01817      0.03056      1.00000 |                                             *
     60       0.04843      0.11769      0.01672      0.03056      1.00000 |                                             *
     70       0.04531      0.11881      0.01554      0.03135      1.00000 |                                              *
     80       0.04314      0.12026      0.01501      0.03214      1.00000 |                                              *
     90       0.04157      0.12234      0.01370      0.03240      1.00000 |                                               *
    100       0.04002      0.12333      0.01304      0.03214      1.00000 |                                               *
    110       0.03964      0.12398      0.01317      0.03267      1.00000 |                                               *
    120       0.03782      0.12482      0.01277      0.03319      1.00000 |                                               *
    130       0.03669      0.12541      0.01238      0.03293      1.00000 |                                               *
    140       0.03555      0.12632      0.01172      0.03293      1.00000 |                                               *
    150       0.03470      0.12679      0.01119      0.03293      1.00000 |                                               *
    160       0.03240      0.12866      0.01001      0.03293      1.00000 |                                               *
    170       0.03019      0.13006      0.00856      0.03319      1.00000 |                                               *
    180       0.02827      0.13079      0.00737      0.03293      1.00000 |                                               *
    190       0.02678      0.13203      0.00672      0.03319      1.00000 |                                               *
    200       0.02479      0.13382      0.00566      0.03293      1.00000 |                                               *
    210       0.02250      0.13583      0.00487      0.03372      1.00000 |                                               *
    220       0.02143      0.13678      0.00435      0.03346      1.00000 |                                               *
    230       0.01962      0.13863      0.00369      0.03346      1.00000 |                                               *
    240       0.01900      0.13991      0.00342      0.03346      1.00000 |                                               *
    250       0.01804      0.14164      0.00356      0.03346      1.00000 |                                               *
    260       0.01713      0.14286      0.00329      0.03293      1.00000 |                                               *
    270       0.01622      0.14442      0.00290      0.03293      1.00000 |                                               *
    280       0.01549      0.14534      0.00277      0.03346      1.00000 |                                               *
    290       0.01403      0.14764      0.00171      0.03293      1.00000 |                                               *
    300       0.01344      0.14936      0.00145      0.03346      1.00000 |                                               *
    310       0.01293      0.15047      0.00145      0.03372      1.00000 |                                               *
    320       0.01248      0.15162      0.00132      0.03346      1.00000 |                                               *
    330       0.01175      0.15320      0.00119      0.03398      1.00000 |                                               *
    340       0.01114      0.15446      0.00079      0.03398      1.00000 |                                               *
    350       0.01061      0.15578      0.00066      0.03398      1.00000 |                                               *
    360       0.01002      0.15787      0.00053      0.03451      1.00000 |                                               *
    370       0.00941      0.15930      0.00026      0.03504      1.00000 |                                               *
    380       0.00897      0.16068      0.00013      0.03477      1.00000 |                                               *
    390       0.00870      0.16152      0.00013      0.03504      1.00000 |                                               *
    400       0.00843      0.16240      0.00013      0.03556      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.40      6.60  CHILDYRS
    335      1    400      1      7      3.73      3.58  AGE
    290      1    400      1      7      4.40      2.61  INCOME
    267      1    399      1      7      4.86      2.10  EDUC_MOM
    249      1    400      1      7      4.83      1.98  OTH_CHLD
    224      1    400      1      7      4.13      2.17  AGE_MOM
    163      1    400      1      7      5.36      1.08  ILLEGIT
    127      2    400      3      7      5.54      0.78  RACE_MOM
    115      2    400      1      7      5.18      0.81  PNCLATE
     66     16    392      2      7      5.11      0.48  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    73 terminal nodes
    Average :     29.26000 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 33 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 33 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 15

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 23008 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           15      0.11251
                  ROC           33      0.83158
                 Lift           18      4.54545
              KS-stat           15      0.59260
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10967     0.12255     0.93518     0.74508     7.83348     4.00000     0.71670     0.42179     0.02910     0.02898
     10     0.07513     0.11287     0.96383     0.83036     8.77828     4.36364     0.80995     0.57985     0.02726     0.02898
     15     0.06758     0.11251     0.96973     0.83060     8.91403     4.45455     0.82097     0.59260     0.02423     0.02977
     18     0.06526     0.11260     0.97112     0.83051     8.86878     4.54545     0.82213     0.57958     0.02331     0.02950
     20     0.06429     0.11284     0.97110     0.83023     8.82353     4.45455     0.82186     0.57876     0.02225     0.03030
     30     0.05829     0.11405     0.97583     0.82829     9.00452     4.27273     0.84249     0.54919     0.02120     0.03030
     33     0.05650     0.11416     0.97799     0.83158     9.04977     4.18182     0.84827     0.54797     0.02067     0.03056
     40     0.05385     0.11478     0.98188     0.82894     9.36652     4.09091     0.86988     0.55542     0.01923     0.03030
     50     0.05082     0.11619     0.98491     0.82622     9.50226     4.18182     0.88474     0.53887     0.01817     0.03056
     60     0.04843     0.11769     0.98624     0.82366     9.54751     4.09091     0.88547     0.52843     0.01672     0.03056
     70     0.04531     0.11881     0.98945     0.82345     9.63801     3.90909     0.89792     0.52095     0.01554     0.03135
     80     0.04314     0.12026     0.99076     0.81958     9.63801     3.90909     0.89874     0.52842     0.01501     0.03214
     90     0.04157     0.12234     0.99130     0.81402     9.63801     3.63636     0.89969     0.51784     0.01370     0.03240
    100     0.04002     0.12333     0.99196     0.81255     9.68326     3.69091     0.90250     0.51363     0.01304     0.03214
    110     0.03964     0.12398     0.99207     0.81038     9.68326     3.63636     0.90195     0.51336     0.01317     0.03267
    120     0.03782     0.12482     0.99379     0.80978     9.81900     3.63636     0.91521     0.51486     0.01277     0.03319
    130     0.03669     0.12541     0.99434     0.80870     9.81900     3.63636     0.92086     0.51203     0.01238     0.03293
    140     0.03555     0.12632     0.99493     0.80710     9.86425     3.72727     0.92679     0.50782     0.01172     0.03293
    150     0.03470     0.12679     0.99511     0.80694     9.86425     3.72727     0.92796     0.50728     0.01119     0.03293
    160     0.03240     0.12866     0.99669     0.80229     9.90950     3.72727     0.94189     0.50700     0.01001     0.03293
    170     0.03019     0.13006     0.99746     0.80186     9.95475     3.63636     0.95781     0.50891     0.00856     0.03319
    180     0.02827     0.13079     0.99823     0.80077     9.95475     3.54545     0.96532     0.49925     0.00737     0.03293
    190     0.02678     0.13203     0.99857     0.79881     9.95475     3.72727     0.97033     0.49056     0.00672     0.03319
    195     0.02577     0.13312     0.99885     0.79769    10.00000     3.63636     0.97250     0.48323     0.00619     0.03319
    200     0.02479     0.13382     0.99905     0.79661    10.00000     3.63636     0.97386     0.47048     0.00566     0.03293
    210     0.02250     0.13583     0.99935     0.79391    10.00000     3.45455     0.97657     0.48731     0.00487     0.03372
    220     0.02143     0.13678     0.99948     0.79057    10.00000     3.63636     0.98168     0.47388     0.00435     0.03346
    230     0.01962     0.13863     0.99969     0.78721    10.00000     3.45455     0.98439     0.46004     0.00369     0.03346
    240     0.01900     0.13991     0.99977     0.78459    10.00000     3.50909     0.98439     0.45556     0.00342     0.03346
    250     0.01804     0.14164     0.99983     0.78013    10.00000     3.72727     0.98525     0.44769     0.00356     0.03346
    260     0.01713     0.14286     0.99991     0.77916    10.00000     3.63636     0.99113     0.44716     0.00329     0.03293
    270     0.01622     0.14442     0.99993     0.77628    10.00000     3.60000     0.99154     0.45774     0.00290     0.03293
    280     0.01549     0.14534     0.99996     0.77674    10.00000     3.54545     0.99498     0.45747     0.00277     0.03346
    290     0.01403     0.14764     0.99999     0.77658    10.00000     3.41818     0.99864     0.45081     0.00171     0.03293
    300     0.01344     0.14936     0.99999     0.77308    10.00000     3.45455     0.99878     0.45218     0.00145     0.03346
    310     0.01293     0.15047     0.99999     0.77169    10.00000     3.36364     0.99891     0.44893     0.00145     0.03372
    320     0.01248     0.15162     1.00000     0.76955    10.00000     3.54545     0.99905     0.43808     0.00132     0.03346
    323     0.01206     0.15215     1.00000     0.77035    10.00000     3.36364     1.00000     0.44323     0.00132     0.03346
    330     0.01175     0.15320     1.00000     0.76839    10.00000     3.36364     1.00000     0.43631     0.00119     0.03398
    340     0.01114     0.15446     1.00000     0.76788    10.00000     3.36364     1.00000     0.44201     0.00079     0.03398
    350     0.01061     0.15578     1.00000     0.76789    10.00000     3.50909     1.00000     0.43156     0.00066     0.03398
    360     0.01002     0.15787     1.00000     0.76542    10.00000     3.27273     1.00000     0.43007     0.00053     0.03451
    370     0.00941     0.15930     1.00000     0.76464    10.00000     3.27273     1.00000     0.42600     0.00026     0.03504
    375     0.00927     0.15979     1.00000     0.76399    10.00000     3.27273     1.00000     0.40958     0.00013     0.03530
    380     0.00897     0.16068     1.00000     0.76318    10.00000     3.27273     1.00000     0.40918     0.00013     0.03477
    390     0.00870     0.16152     1.00000     0.76253    10.00000     3.27273     1.00000     0.40700     0.00013     0.03504
    400     0.00843     0.16240     1.00000     0.76238    10.00000     3.27273     1.00000     0.41421     0.00013     0.03556


 =========================================
 Variable Importance for the 15-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          41.82108   41.82 |*****      |
 AGE_MOM      40.90134   40.90 |*****      |
 EDUC_MOM     29.15958   29.16 |****       |
 INCOME       28.78120   28.78 |****       |
 OTH_CHLD     24.75616   24.76 |***        |
 ILLEGIT      21.15085   21.15 |***        |
 RACE_MOM     13.92208   13.92 |**         |
 PNCLATE      12.00433   12.00 |**         |


 Learn Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7367.00         6.00       0.0008
 1                  221.00        43.00       178.00       0.8054


 Test Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3677.00         9.00       0.0024
 1                  110.00         6.00       104.00       0.9455

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 1 MB, 75% compression

 Grove file created containing:
      1 TreeNet

