
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:01

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11087      0.12266      0.02910      0.02898      1.00000 |                                               *
      2       0.10302      0.11929      0.02910      0.02898      1.00000 |                                              *
      3       0.09729      0.11683      0.02910      0.02898      1.00000 |                                             *
      4       0.09327      0.11552      0.02910      0.02898      1.00000 |                                            *
      5       0.08949      0.11409      0.02910      0.02898      1.00000 |                                            *
      6       0.08658      0.11338      0.02818      0.02898      1.00000 |                                           *
      7       0.08429      0.11251      0.02726      0.02898      1.00000 |                                           *
      8       0.08205      0.11180      0.02699      0.02871      1.00000 |                                           *
      9       0.08022      0.11127      0.02620      0.02898      1.00000 |                                           *
     10       0.07839      0.11103      0.02568      0.02950      1.00000 |                                          *
     11       0.07649      0.11052      0.02541      0.02977      1.00000 |                                          *
     12       0.07477      0.11016      0.02423      0.02950      1.00000 |                                          *
     13       0.07364      0.11013      0.02410      0.02950      1.00000 |                                          *
     14       0.07248      0.11014      0.02357      0.02950      1.00000 |                                          *
     15       0.07156      0.11000      0.02318      0.03030      1.00000 |                                          *
     16       0.07063      0.10981      0.02278      0.03030      1.00000 |                                          *
     17       0.06965      0.10999      0.02278      0.03030      1.00000 |                                          *
     18       0.06895      0.11016      0.02265      0.03161      1.00000 |                                          *
     19       0.06795      0.11021      0.02225      0.03135      1.00000 |                                          *
     20       0.06770      0.11034      0.02225      0.03161      1.00000 |                                          *
     30       0.06323      0.11164      0.02133      0.03161      1.00000 |                                           *
     40       0.05726      0.11260      0.01936      0.03214      1.00000 |                                           *
     50       0.05456      0.11307      0.01936      0.03293      1.00000 |                                           *
     60       0.05259      0.11420      0.01883      0.03293      1.00000 |                                            *
     70       0.04983      0.11555      0.01738      0.03267      1.00000 |                                            *
     80       0.04733      0.11616      0.01686      0.03293      1.00000 |                                            *
     90       0.04578      0.11723      0.01633      0.03293      1.00000 |                                             *
    100       0.04392      0.11850      0.01607      0.03293      1.00000 |                                             *
    110       0.04245      0.11965      0.01528      0.03346      1.00000 |                                              *
    120       0.04158      0.12069      0.01475      0.03346      1.00000 |                                              *
    130       0.04073      0.12152      0.01435      0.03346      1.00000 |                                               *
    140       0.03872      0.12289      0.01317      0.03319      1.00000 |                                               *
    150       0.03676      0.12424      0.01251      0.03372      1.00000 |                                               *
    160       0.03533      0.12510      0.01225      0.03319      1.00000 |                                               *
    170       0.03446      0.12665      0.01198      0.03346      1.00000 |                                               *
    180       0.03353      0.12762      0.01185      0.03293      1.00000 |                                               *
    190       0.03168      0.12863      0.01119      0.03293      1.00000 |                                               *
    200       0.03054      0.13003      0.01067      0.03346      1.00000 |                                               *
    210       0.02931      0.13069      0.00974      0.03267      1.00000 |                                               *
    220       0.02864      0.13121      0.00882      0.03293      1.00000 |                                               *
    230       0.02808      0.13198      0.00869      0.03372      1.00000 |                                               *
    240       0.02706      0.13344      0.00830      0.03346      1.00000 |                                               *
    250       0.02671      0.13428      0.00830      0.03293      1.00000 |                                               *
    260       0.02590      0.13484      0.00777      0.03319      1.00000 |                                               *
    270       0.02503      0.13608      0.00777      0.03372      1.00000 |                                               *
    280       0.02420      0.13732      0.00737      0.03372      1.00000 |                                               *
    290       0.02344      0.13817      0.00698      0.03346      1.00000 |                                               *
    300       0.02267      0.13921      0.00645      0.03372      1.00000 |                                               *
    310       0.02194      0.13995      0.00593      0.03346      1.00000 |                                               *
    320       0.02120      0.14061      0.00566      0.03372      1.00000 |                                               *
    330       0.02081      0.14159      0.00540      0.03346      1.00000 |                                               *
    340       0.01988      0.14288      0.00487      0.03346      1.00000 |                                               *
    350       0.01927      0.14365      0.00474      0.03372      1.00000 |                                               *
    360       0.01885      0.14401      0.00435      0.03398      1.00000 |                                               *
    370       0.01835      0.14486      0.00421      0.03372      1.00000 |                                               *
    380       0.01747      0.14566      0.00356      0.03372      1.00000 |                                               *
    390       0.01697      0.14646      0.00329      0.03398      1.00000 |                                               *
    400       0.01649      0.14717      0.00290      0.03372      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      2      1.14      6.86  CHILDYRS
    260      1    400      1      7      4.53      2.26  AGE
    250      1    400      2      7      4.58      2.14  AGE_MOM
    247      1    399      1      7      5.03      1.83  INCOME
    209      1    396      1      7      5.24      1.44  OTH_CHLD
    181      1    398      1      7      5.04      1.34  EDUC_MOM
    130      1    394      2      7      5.44      0.83  ILLEGIT
    111      1    398      3      7      5.48      0.70  RACE_MOM
     90      3    390      3      7      5.69      0.52  PNCLATE
     53      6    396      1      7      5.81      0.29  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    85 terminal nodes
    Average :     21.93500 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 23 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 23 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 16

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 17148 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           16      0.10981
                  ROC           23      0.84814
                 Lift           17      5.18182
              KS-stat           24      0.54650
          Class.Error            8      0.02871

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11087     0.12266     0.92148     0.73185     7.60070     4.34949     0.69852     0.40970     0.02910     0.02898
      8     0.08205     0.11180     0.94652     0.82377     8.31222     4.72727     0.76315     0.50115     0.02699     0.02871
     10     0.07839     0.11103     0.95114     0.82791     8.50679     5.00000     0.77770     0.50261     0.02568     0.02950
     16     0.07063     0.10981     0.95591     0.84208     8.63710     5.09091     0.78825     0.51936     0.02278     0.03030
     17     0.06965     0.10999     0.95671     0.84225     8.64253     5.18182     0.79318     0.52587     0.02278     0.03030
     20     0.06770     0.11034     0.95711     0.84407     8.64253     5.18182     0.79193     0.52070     0.02225     0.03161
     23     0.06558     0.11057     0.95967     0.84814     8.77828     5.18182     0.80841     0.54351     0.02173     0.03109
     24     0.06542     0.11068     0.95962     0.84782     8.77828     5.09091     0.80768     0.54650     0.02173     0.03109
     30     0.06323     0.11164     0.96371     0.84128     8.86878     5.09091     0.81877     0.52804     0.02133     0.03161
     40     0.05726     0.11260     0.97452     0.84194     9.14027     5.00000     0.84662     0.53700     0.01936     0.03214
     50     0.05456     0.11307     0.97882     0.84336     9.32127     4.81818     0.86503     0.53171     0.01936     0.03293
     60     0.05259     0.11420     0.98007     0.84044     9.36652     4.81818     0.87453     0.50523     0.01883     0.03293
     70     0.04983     0.11555     0.98377     0.83584     9.50226     4.81818     0.88662     0.50674     0.01738     0.03267
     80     0.04733     0.11616     0.98638     0.83495     9.59276     5.09091     0.89946     0.49399     0.01686     0.03293
     90     0.04578     0.11723     0.98740     0.83138     9.59276     4.81818     0.90403     0.50809     0.01633     0.03293
    100     0.04392     0.11850     0.98883     0.82573     9.63801     4.54545     0.91216     0.50523     0.01607     0.03293
    110     0.04245     0.11965     0.98988     0.82123     9.63801     4.54545     0.92062     0.49343     0.01528     0.03346
    120     0.04158     0.12069     0.99044     0.81710     9.68326     4.63636     0.92089     0.49439     0.01475     0.03346
    130     0.04073     0.12152     0.99090     0.81464     9.72851     4.54545     0.92388     0.48286     0.01435     0.03346
    140     0.03872     0.12289     0.99344     0.80988     9.77376     4.54545     0.93030     0.46116     0.01317     0.03319
    150     0.03676     0.12424     0.99522     0.80624     9.81900     4.54545     0.94201     0.45451     0.01251     0.03372
    160     0.03533     0.12510     0.99638     0.80495     9.90950     4.60000     0.94772     0.44943     0.01225     0.03319
    170     0.03446     0.12665     0.99667     0.79893     9.90950     4.45455     0.95003     0.44604     0.01198     0.03346
    180     0.03353     0.12762     0.99688     0.79546     9.90950     4.45455     0.95098     0.44062     0.01185     0.03293
    190     0.03168     0.12863     0.99823     0.79426    10.00000     4.09091     0.96676     0.43301     0.01119     0.03293
    200     0.03054     0.13003     0.99867     0.79082    10.00000     4.27273     0.97015     0.43084     0.01067     0.03346
    210     0.02931     0.13069     0.99890     0.78878    10.00000     4.18182     0.97029     0.42813     0.00974     0.03267
    220     0.02864     0.13121     0.99899     0.78727    10.00000     4.36364     0.97205     0.42314     0.00882     0.03293
    230     0.02808     0.13198     0.99908     0.78546    10.00000     4.45455     0.97639     0.41472     0.00869     0.03372
    240     0.02706     0.13344     0.99925     0.78244    10.00000     4.32727     0.97712     0.41337     0.00830     0.03346
    250     0.02671     0.13428     0.99928     0.77893    10.00000     4.41818     0.97924     0.41419     0.00830     0.03293
    260     0.02590     0.13484     0.99944     0.78036    10.00000     4.18182     0.98046     0.41486     0.00777     0.03319
    270     0.02503     0.13608     0.99954     0.77883    10.00000     4.00000     0.98209     0.41880     0.00777     0.03372
    280     0.02420     0.13732     0.99970     0.77652    10.00000     4.09091     0.98978     0.41352     0.00737     0.03372
    290     0.02344     0.13817     0.99975     0.77468    10.00000     4.05455     0.98978     0.40526     0.00698     0.03346
    300     0.02267     0.13921     0.99981     0.77325    10.00000     3.90909     0.99195     0.40387     0.00645     0.03372
    310     0.02194     0.13995     0.99982     0.77258    10.00000     3.90909     0.99195     0.40903     0.00593     0.03346
    320     0.02120     0.14061     0.99986     0.77204    10.00000     3.90909     0.99236     0.40985     0.00566     0.03372
    330     0.02081     0.14159     0.99987     0.77041    10.00000     3.81818     0.99249     0.42505     0.00540     0.03346
    340     0.01988     0.14288     0.99992     0.76909    10.00000     3.81818     0.99412     0.42681     0.00487     0.03346
    350     0.01927     0.14365     0.99993     0.76847    10.00000     3.90909     0.99412     0.42979     0.00474     0.03372
    360     0.01885     0.14401     0.99994     0.76790    10.00000     4.00000     0.99425     0.42287     0.00435     0.03398
    370     0.01835     0.14486     0.99995     0.76485    10.00000     3.90909     0.99425     0.42369     0.00421     0.03372
    380     0.01747     0.14566     0.99999     0.76523    10.00000     3.81818     0.99878     0.42477     0.00356     0.03372
    390     0.01697     0.14646     0.99999     0.76263    10.00000     3.90909     0.99878     0.42612     0.00329     0.03398
    396     0.01662     0.14692     0.99999     0.76215    10.00000     3.87273     0.99905     0.41921     0.00290     0.03372
    398     0.01653     0.14694     0.99999     0.76255    10.00000     4.00000     0.99932     0.41921     0.00290     0.03372
    400     0.01649     0.14717     0.99999     0.76198    10.00000     4.00000     0.99919     0.41921     0.00290     0.03372


 =========================================
 Variable Importance for the 16-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          47.78134   47.78 |******     |
 AGE_MOM      47.63019   47.63 |******     |
 EDUC_MOM     36.64511   36.65 |*****      |
 INCOME       28.50988   28.51 |****       |
 OTH_CHLD     25.70299   25.70 |****       |
 ILLEGIT      21.29227   21.29 |***        |
 RACE_MOM     18.09942   18.10 |***        |
 PNCLATE      11.89177   11.89 |**         |
 LBW           7.41232    7.41 |**         |


 Learn Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7369.00         4.00       0.0005
 1                  221.00        52.00       169.00       0.7647


 Test Sample Misclassification by Target Class
 For The 16-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3675.00        11.00       0.0030
 1                  110.00         6.00       104.00       0.9455

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 815 kb , 76% compression

 Grove file created containing:
      1 TreeNet

