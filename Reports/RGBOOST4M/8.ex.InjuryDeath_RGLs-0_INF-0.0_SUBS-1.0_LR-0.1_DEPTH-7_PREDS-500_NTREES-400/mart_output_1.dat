
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11152      0.12132      0.02910      0.02898      1.00000 |                                               *
      2       0.10357      0.11875      0.02910      0.02898      1.00000 |                                              *
      3       0.09808      0.11714      0.02910      0.02898      1.00000 |                                             *
      4       0.09428      0.11631      0.02910      0.02898      1.00000 |                                             *
      5       0.09083      0.11559      0.02844      0.02845      1.00000 |                                             *
      6       0.08719      0.11463      0.02844      0.02845      1.00000 |                                            *
      7       0.08476      0.11385      0.02726      0.02845      1.00000 |                                            *
      8       0.08239      0.11330      0.02686      0.02924      1.00000 |                                            *
      9       0.08019      0.11276      0.02594      0.02977      1.00000 |                                            *
     10       0.07743      0.11281      0.02528      0.03003      1.00000 |                                            *
     11       0.07605      0.11265      0.02502      0.03003      1.00000 |                                            *
     12       0.07395      0.11261      0.02476      0.03003      1.00000 |                                            *
     13       0.07196      0.11288      0.02449      0.03056      1.00000 |                                            *
     14       0.07057      0.11280      0.02423      0.03056      1.00000 |                                            *
     15       0.06907      0.11294      0.02357      0.03056      1.00000 |                                            *
     16       0.06806      0.11293      0.02318      0.03056      1.00000 |                                            *
     17       0.06700      0.11308      0.02318      0.03109      1.00000 |                                            *
     18       0.06624      0.11295      0.02318      0.03135      1.00000 |                                            *
     19       0.06571      0.11308      0.02304      0.03161      1.00000 |                                            *
     20       0.06503      0.11315      0.02160      0.03161      1.00000 |                                            *
     30       0.05995      0.11446      0.01949      0.03188      1.00000 |                                            *
     40       0.05558      0.11605      0.01844      0.03267      1.00000 |                                             *
     50       0.05259      0.11756      0.01751      0.03267      1.00000 |                                              *
     60       0.05050      0.11867      0.01593      0.03346      1.00000 |                                              *
     70       0.04716      0.11943      0.01514      0.03319      1.00000 |                                              *
     80       0.04536      0.12074      0.01488      0.03293      1.00000 |                                               *
     90       0.04404      0.12175      0.01462      0.03372      1.00000 |                                               *
    100       0.04241      0.12298      0.01409      0.03293      1.00000 |                                               *
    110       0.04108      0.12372      0.01370      0.03319      1.00000 |                                               *
    120       0.03918      0.12495      0.01317      0.03372      1.00000 |                                               *
    130       0.03704      0.12661      0.01211      0.03398      1.00000 |                                               *
    140       0.03616      0.12739      0.01146      0.03425      1.00000 |                                               *
    150       0.03543      0.12800      0.01080      0.03398      1.00000 |                                               *
    160       0.03441      0.12896      0.01067      0.03398      1.00000 |                                               *
    170       0.03317      0.12992      0.01027      0.03425      1.00000 |                                               *
    180       0.03135      0.13097      0.01001      0.03372      1.00000 |                                               *
    190       0.02920      0.13263      0.00935      0.03425      1.00000 |                                               *
    200       0.02818      0.13346      0.00909      0.03398      1.00000 |                                               *
    210       0.02791      0.13376      0.00909      0.03451      1.00000 |                                               *
    220       0.02640      0.13526      0.00869      0.03451      1.00000 |                                               *
    230       0.02570      0.13620      0.00816      0.03451      1.00000 |                                               *
    240       0.02474      0.13695      0.00737      0.03425      1.00000 |                                               *
    250       0.02344      0.13813      0.00685      0.03504      1.00000 |                                               *
    260       0.02242      0.13906      0.00645      0.03530      1.00000 |                                               *
    270       0.02135      0.14011      0.00632      0.03530      1.00000 |                                               *
    280       0.02013      0.14149      0.00579      0.03530      1.00000 |                                               *
    290       0.01927      0.14248      0.00527      0.03583      1.00000 |                                               *
    300       0.01845      0.14407      0.00474      0.03609      1.00000 |                                               *
    310       0.01660      0.14438      0.00356      0.03556      1.00000 |                                               *
    320       0.01595      0.14576      0.00329      0.03556      1.00000 |                                               *
    330       0.01565      0.14645      0.00303      0.03556      1.00000 |                                               *
    340       0.01517      0.14724      0.00290      0.03530      1.00000 |                                               *
    350       0.01484      0.14781      0.00277      0.03504      1.00000 |                                               *
    360       0.01403      0.14921      0.00250      0.03530      1.00000 |                                               *
    370       0.01325      0.15047      0.00171      0.03530      1.00000 |                                               *
    380       0.01251      0.15173      0.00119      0.03530      1.00000 |                                               *
    390       0.01183      0.15225      0.00092      0.03556      1.00000 |                                               *
    400       0.01165      0.15291      0.00092      0.03583      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.21      6.80  CHILDYRS
    299      1    398      1      7      3.98      3.01  AGE
    269      1    398      1      7      4.46      2.38  INCOME
    226      1    395      2      7      5.23      1.57  EDUC_MOM
    220      1    398      1      7      4.85      1.73  AGE_MOM
    202      1    393      1      7      4.81      1.61  OTH_CHLD
    118      1    396      2      7      5.25      0.81  ILLEGIT
     95      1    392      2      7      5.34      0.63  RACE_MOM
     71      1    390      1      7      5.32      0.48  PNCLATE
     59      6    396      2      7      5.36      0.39  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    86 terminal nodes
    Average :     24.52750 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 40 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 40 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 12

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 19222 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           12      0.11261
                  ROC           22      0.80997
                 Lift           40      4.54545
              KS-stat           11      0.48340
          Class.Error            5      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11152     0.12132     0.92329     0.69722     7.26575     4.13493     0.69315     0.43805     0.02910     0.02898
      5     0.09083     0.11559     0.93620     0.70717     7.77941     4.08112     0.72491     0.41567     0.02844     0.02845
     10     0.07743     0.11281     0.95684     0.78535     8.50679     4.18182     0.79199     0.45300     0.02528     0.03003
     11     0.07605     0.11265     0.95702     0.78889     8.59005     4.27273     0.79208     0.48340     0.02502     0.03003
     12     0.07395     0.11261     0.96207     0.79324     8.64253     4.36364     0.79388     0.48340     0.02476     0.03003
     20     0.06503     0.11315     0.97086     0.80813     8.82353     4.36364     0.81890     0.47662     0.02160     0.03161
     22     0.06384     0.11343     0.97129     0.80997     8.77828     4.36364     0.82444     0.45763     0.02120     0.03161
     30     0.05995     0.11446     0.97505     0.80504     9.00452     4.36364     0.83209     0.46116     0.01949     0.03188
     40     0.05558     0.11605     0.98074     0.80316     9.27602     4.54545     0.85636     0.46211     0.01844     0.03267
     50     0.05259     0.11756     0.98307     0.79978     9.27602     4.45455     0.86441     0.44728     0.01751     0.03267
     60     0.05050     0.11867     0.98576     0.79852     9.41176     4.54545     0.87953     0.45801     0.01593     0.03346
     70     0.04716     0.11943     0.99044     0.79978     9.77376     4.45455     0.90386     0.45884     0.01514     0.03319
     80     0.04536     0.12074     0.99163     0.79677     9.81900     4.27273     0.90960     0.45477     0.01488     0.03293
     90     0.04404     0.12175     0.99226     0.79409     9.81900     4.27273     0.91597     0.44743     0.01462     0.03372
    100     0.04241     0.12298     0.99316     0.79214     9.77376     4.18182     0.92465     0.45122     0.01409     0.03293
    110     0.04108     0.12372     0.99392     0.79008     9.86425     4.09091     0.92556     0.45339     0.01370     0.03319
    120     0.03918     0.12495     0.99499     0.78807     9.88235     4.00000     0.93307     0.44606     0.01317     0.03372
    130     0.03704     0.12661     0.99581     0.78346     9.86425     3.90909     0.93882     0.42641     0.01211     0.03398
    140     0.03616     0.12739     0.99611     0.78284     9.86425     3.90909     0.94216     0.42669     0.01146     0.03425
    150     0.03543     0.12800     0.99641     0.78205     9.90950     3.90909     0.94750     0.42534     0.01080     0.03398
    160     0.03441     0.12896     0.99674     0.78208     9.90950     3.90909     0.95333     0.42196     0.01067     0.03398
    170     0.03317     0.12992     0.99731     0.78026     9.95475     4.00000     0.95564     0.42751     0.01027     0.03425
    178     0.03138     0.13097     0.99818     0.77748    10.00000     4.00000     0.96545     0.41612     0.01001     0.03372
    180     0.03135     0.13097     0.99818     0.77757    10.00000     4.00000     0.96559     0.41639     0.01001     0.03372
    190     0.02920     0.13263     0.99882     0.77368    10.00000     3.90909     0.97717     0.41450     0.00935     0.03425
    200     0.02818     0.13346     0.99912     0.77281    10.00000     4.00000     0.97757     0.41014     0.00909     0.03398
    210     0.02791     0.13376     0.99916     0.77358    10.00000     3.90909     0.98237     0.41584     0.00909     0.03451
    220     0.02640     0.13526     0.99940     0.77111    10.00000     3.72727     0.98327     0.39953     0.00869     0.03451
    230     0.02570     0.13620     0.99954     0.76850    10.00000     3.69091     0.98806     0.39821     0.00816     0.03451
    240     0.02474     0.13695     0.99961     0.76760    10.00000     3.81818     0.98793     0.41028     0.00737     0.03425
    250     0.02344     0.13813     0.99973     0.76675    10.00000     4.00000     0.99091     0.39479     0.00685     0.03504
    260     0.02242     0.13906     0.99984     0.76423    10.00000     3.81818     0.99376     0.39669     0.00645     0.03530
    270     0.02135     0.14011     0.99988     0.76177    10.00000     3.81818     0.99457     0.38990     0.00632     0.03530
    280     0.02013     0.14149     0.99991     0.75815    10.00000     3.90909     0.99647     0.39491     0.00579     0.03530
    290     0.01927     0.14248     0.99993     0.75655    10.00000     3.72727     0.99674     0.40278     0.00527     0.03583
    300     0.01845     0.14407     0.99995     0.75139    10.00000     3.72727     0.99742     0.39466     0.00474     0.03609
    310     0.01660     0.14438     0.99999     0.75713    10.00000     3.63636     0.99878     0.40836     0.00356     0.03556
    320     0.01595     0.14576     0.99999     0.75304    10.00000     3.72727     0.99891     0.38790     0.00329     0.03556
    330     0.01565     0.14645     0.99999     0.75154    10.00000     3.72727     0.99891     0.39142     0.00303     0.03556
    340     0.01517     0.14724     1.00000     0.75119    10.00000     3.60000     0.99905     0.39260     0.00290     0.03530
    350     0.01484     0.14781     1.00000     0.75156    10.00000     3.54545     0.99905     0.40187     0.00277     0.03504
    360     0.01403     0.14921     1.00000     0.75123    10.00000     3.54545     0.99946     0.39671     0.00250     0.03530
    370     0.01325     0.15047     1.00000     0.75087    10.00000     3.72727     0.99959     0.39617     0.00171     0.03530
    380     0.01251     0.15173     1.00000     0.75262    10.00000     3.63636     0.99986     0.40281     0.00119     0.03530
    384     0.01220     0.15205     1.00000     0.75365    10.00000     3.63636     1.00000     0.39928     0.00105     0.03530
    385     0.01212     0.15211     1.00000     0.75487    10.00000     3.63636     1.00000     0.40566     0.00092     0.03530
    390     0.01183     0.15225     1.00000     0.75733    10.00000     3.63636     1.00000     0.41217     0.00092     0.03556
    400     0.01165     0.15291     1.00000     0.75788    10.00000     3.54545     1.00000     0.41814     0.00092     0.03583


 =========================================
 Variable Importance for the 12-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      37.76447   37.76 |*****      |
 AGE          34.38881   34.39 |****       |
 INCOME       33.46846   33.47 |****       |
 EDUC_MOM     29.98853   29.99 |****       |
 OTH_CHLD     25.08706   25.09 |***        |
 ILLEGIT      21.28196   21.28 |***        |
 PNCLATE      14.21289   14.21 |**         |
 RACE_MOM     12.30250   12.30 |**         |
 LBW           5.10427    5.10 |*          |


 Learn Sample Misclassification by Target Class
 For The 12-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        35.00       186.00       0.8416


 Test Sample Misclassification by Target Class
 For The 12-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3676.00        10.00       0.0027
 1                  110.00         6.00       104.00       0.9455

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 909 kb , 75% compression

 Grove file created containing:
      1 TreeNet

