
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10811      0.12007      0.02910      0.02898      1.00000 |                                               *
      2       0.10014      0.11583      0.02831      0.02950      1.00000 |                                             *
      3       0.09421      0.11310      0.02831      0.02950      1.00000 |                                            *
      4       0.08985      0.11108      0.02831      0.02950      1.00000 |                                           *
      5       0.08611      0.10970      0.02831      0.02950      1.00000 |                                           *
      6       0.08273      0.10856      0.02792      0.02950      1.00000 |                                          *
      7       0.07990      0.10757      0.02673      0.02950      1.00000 |                                          *
      8       0.07606      0.10748      0.02660      0.02950      1.00000 |                                          *
      9       0.07358      0.10685      0.02634      0.02950      1.00000 |                                          *
     10       0.07182      0.10625      0.02634      0.02977      1.00000 |                                         *
     11       0.07032      0.10568      0.02594      0.02977      1.00000 |                                         *
     12       0.06819      0.10520      0.02541      0.02950      1.00000 |                                         *
     13       0.06589      0.10471      0.02423      0.02977      1.00000 |                                         *
     14       0.06329      0.10443      0.02370      0.03003      1.00000 |                                         *
     15       0.06165      0.10446      0.02370      0.03003      1.00000 |                                         *
     16       0.06021      0.10436      0.02357      0.03003      1.00000 |                                         *
     17       0.05879      0.10454      0.02331      0.03003      1.00000 |                                         *
     18       0.05656      0.10440      0.02331      0.03003      1.00000 |                                         *
     19       0.05535      0.10448      0.02291      0.03003      1.00000 |                                         *
     20       0.05409      0.10436      0.02278      0.03030      1.00000 |                                         *
     30       0.04417      0.10511      0.01909      0.02924      1.00000 |                                         *
     40       0.03937      0.10567      0.01620      0.02977      1.00000 |                                         *
     50       0.03475      0.10788      0.01290      0.02924      1.00000 |                                          *
     60       0.03013      0.11094      0.00974      0.02950      1.00000 |                                           *
     70       0.02705      0.11325      0.00764      0.02924      1.00000 |                                            *
     80       0.02437      0.11536      0.00540      0.02924      1.00000 |                                             *
     90       0.02282      0.11693      0.00448      0.02950      1.00000 |                                              *
    100       0.02062      0.11857      0.00382      0.02977      1.00000 |                                              *
    110       0.01862      0.12073      0.00224      0.03003      1.00000 |                                               *
    120       0.01705      0.12225      0.00184      0.03003      1.00000 |                                               *
    130       0.01580      0.12400      0.00132      0.03030      1.00000 |                                               *
    140       0.01465      0.12538      0.00092      0.03056      1.00000 |                                               *
    150       0.01351      0.12699      0.00040      0.03082      1.00000 |                                               *
    160       0.01273      0.12841      0.00040      0.03030      1.00000 |                                               *
    170       0.01190      0.12985      0.00026      0.03056      1.00000 |                                               *
    180       0.01059      0.13127      0.00000      0.03030      1.00000 |                                               *
    190       0.00950      0.13382      0.00000      0.03003      1.00000 |                                               *
    200       0.00888      0.13601      0.00000      0.03003      1.00000 |                                               *
    210       0.00802      0.13782      0.00000      0.03030      1.00000 |                                               *
    220       0.00748      0.13934      0.00000      0.03056      1.00000 |                                               *
    230       0.00694      0.14109      0.00000      0.03056      1.00000 |                                               *
    240       0.00621      0.14347      0.00000      0.03056      1.00000 |                                               *
    250       0.00570      0.14580      0.00000      0.03003      1.00000 |                                               *
    260       0.00508      0.14898      0.00000      0.03003      1.00000 |                                               *
    270       0.00460      0.15139      0.00000      0.03030      1.00000 |                                               *
    280       0.00424      0.15355      0.00000      0.03003      1.00000 |                                               *
    290       0.00389      0.15622      0.00000      0.03082      1.00000 |                                               *
    300       0.00367      0.15821      0.00000      0.03082      1.00000 |                                               *
    310       0.00337      0.16080      0.00000      0.03135      1.00000 |                                               *
    320       0.00306      0.16341      0.00000      0.03135      1.00000 |                                               *
    330       0.00286      0.16501      0.00000      0.03214      1.00000 |                                               *
    340       0.00257      0.16769      0.00000      0.03214      1.00000 |                                               *
    350       0.00237      0.16954      0.00000      0.03214      1.00000 |                                               *
    360       0.00217      0.17194      0.00000      0.03214      1.00000 |                                               *
    370       0.00201      0.17478      0.00000      0.03267      1.00000 |                                               *
    380       0.00181      0.17728      0.00000      0.03267      1.00000 |                                               *
    390       0.00167      0.17964      0.00000      0.03267      1.00000 |                                               *
    400       0.00149      0.18187      0.00000      0.03267      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.50      6.50  CHILDYRS
    380      1    400      1      7      3.82      3.97  AGE
    380      1    400      1      7      3.84      3.95  INCOME
    367      1    400      1      7      4.22      3.47  AGE_MOM
    350      1    400      1      7      4.24      3.29  OTH_CHLD
    337      1    400      1      7      4.44      3.00  EDUC_MOM
    297      1    400      1      7      4.63      2.51  ILLEGIT
    270      3    400      1      7      5.04      2.00  RACE_MOM
    242      1    400      2      7      5.43      1.56  PNCLATE
    227      1    400      2      7      5.23      1.57  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    10 terminal nodes
    Largest :   111 terminal nodes
    Average :     55.15250 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 45 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 45 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 20

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 43722 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           20      0.10436
                  ROC           45      0.85668
                 Lift            6      5.63636
              KS-stat           12      0.58906
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10811     0.12007     0.92417     0.76723     7.48772     4.92321     0.67896     0.47210     0.02910     0.02898
      6     0.08273     0.10856     0.95546     0.84394     8.46154     5.63636     0.77881     0.52922     0.02792     0.02950
     10     0.07182     0.10625     0.96948     0.84621     8.91403     5.37455     0.81581     0.57224     0.02634     0.02977
     12     0.06819     0.10520     0.97301     0.84935     9.00452     5.45455     0.82698     0.58906     0.02541     0.02950
     20     0.05409     0.10436     0.99138     0.84963     9.77376     5.36364     0.92084     0.56927     0.02278     0.03030
     28     0.04522     0.10495     0.99660     0.85110    10.00000     5.45455     0.96613     0.57115     0.01936     0.02898
     30     0.04417     0.10511     0.99687     0.85142    10.00000     5.45455     0.97093     0.57022     0.01909     0.02924
     40     0.03937     0.10567     0.99807     0.85577    10.00000     5.54545     0.97871     0.58893     0.01620     0.02977
     45     0.03708     0.10650     0.99849     0.85668    10.00000     5.54545     0.98142     0.58215     0.01422     0.02924
     50     0.03475     0.10788     0.99892     0.85464    10.00000     5.45455     0.99023     0.57767     0.01290     0.02924
     60     0.03013     0.11094     0.99950     0.85051    10.00000     5.45455     0.99295     0.56926     0.00974     0.02950
     70     0.02705     0.11325     0.99978     0.84677    10.00000     5.27273     0.99674     0.56275     0.00764     0.02924
     80     0.02437     0.11536     0.99990     0.84557    10.00000     5.00000     0.99783     0.56533     0.00540     0.02924
     90     0.02282     0.11693     0.99995     0.84395    10.00000     5.27273     0.99878     0.55448     0.00448     0.02950
    100     0.02062     0.11857     0.99998     0.84320    10.00000     5.00000     0.99919     0.56490     0.00382     0.02977
    110     0.01862     0.12073     1.00000     0.84022    10.00000     4.96364     0.99973     0.55215     0.00224     0.03003
    112     0.01787     0.12146     1.00000     0.83888    10.00000     5.00000     1.00000     0.55378     0.00211     0.03003
    120     0.01705     0.12225     1.00000     0.84098    10.00000     5.05455     1.00000     0.55432     0.00184     0.03003
    130     0.01580     0.12400     1.00000     0.83952    10.00000     5.00000     1.00000     0.54932     0.00132     0.03030
    140     0.01465     0.12538     1.00000     0.83950    10.00000     4.90909     1.00000     0.56004     0.00092     0.03056
    150     0.01351     0.12699     1.00000     0.83981    10.00000     4.72727     1.00000     0.55773     0.00040     0.03082
    160     0.01273     0.12841     1.00000     0.83877    10.00000     4.63636     1.00000     0.55568     0.00040     0.03030
    170     0.01190     0.12985     1.00000     0.83969    10.00000     4.63636     1.00000     0.55703     0.00026     0.03056
    173     0.01141     0.13034     1.00000     0.83975    10.00000     4.63636     1.00000     0.55947     0.00000     0.03056
    180     0.01059     0.13127     1.00000     0.84230    10.00000     4.63636     1.00000     0.56370     0.00000     0.03030
    190     0.00950     0.13382     1.00000     0.83966    10.00000     4.72727     1.00000     0.55608     0.00000     0.03003
    200     0.00888     0.13601     1.00000     0.83873    10.00000     4.63636     1.00000     0.55716     0.00000     0.03003
    210     0.00802     0.13782     1.00000     0.83838    10.00000     4.63636     1.00000     0.55770     0.00000     0.03030
    220     0.00748     0.13934     1.00000     0.84004    10.00000     4.81818     1.00000     0.55216     0.00000     0.03056
    230     0.00694     0.14109     1.00000     0.83941    10.00000     4.90909     1.00000     0.54985     0.00000     0.03056
    240     0.00621     0.14347     1.00000     0.83808    10.00000     4.81818     1.00000     0.55500     0.00000     0.03056
    250     0.00570     0.14580     1.00000     0.83564    10.00000     4.90909     1.00000     0.55189     0.00000     0.03003
    260     0.00508     0.14898     1.00000     0.83542    10.00000     4.72727     1.00000     0.55582     0.00000     0.03003
    270     0.00460     0.15139     1.00000     0.83551    10.00000     4.63636     1.00000     0.56396     0.00000     0.03030
    280     0.00424     0.15355     1.00000     0.83499    10.00000     4.72727     1.00000     0.55826     0.00000     0.03003
    290     0.00389     0.15622     1.00000     0.83401    10.00000     4.81818     1.00000     0.56043     0.00000     0.03082
    300     0.00367     0.15821     1.00000     0.83375    10.00000     4.81818     1.00000     0.56627     0.00000     0.03082
    310     0.00337     0.16080     1.00000     0.83355    10.00000     4.78182     1.00000     0.55758     0.00000     0.03135
    320     0.00306     0.16341     1.00000     0.83255    10.00000     4.81818     1.00000     0.54851     0.00000     0.03135
    330     0.00286     0.16501     1.00000     0.83241    10.00000     4.63636     1.00000     0.55122     0.00000     0.03214
    340     0.00257     0.16769     1.00000     0.83299    10.00000     4.69091     1.00000     0.55433     0.00000     0.03214
    350     0.00237     0.16954     1.00000     0.83292    10.00000     4.69091     1.00000     0.54633     0.00000     0.03214
    360     0.00217     0.17194     1.00000     0.83298    10.00000     4.54545     1.00000     0.55080     0.00000     0.03214
    370     0.00201     0.17478     1.00000     0.83166    10.00000     4.54545     1.00000     0.54185     0.00000     0.03267
    380     0.00181     0.17728     1.00000     0.83231    10.00000     4.63636     1.00000     0.54172     0.00000     0.03267
    390     0.00167     0.17964     1.00000     0.83145    10.00000     4.54545     1.00000     0.54349     0.00000     0.03267
    400     0.00149     0.18187     1.00000     0.83187    10.00000     4.45455     1.00000     0.54349     0.00000     0.03267


 =========================================
 Variable Importance for the 20-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      32.81390   32.81 |****       |
 AGE          31.25804   31.26 |****       |
 OTH_CHLD     27.28639   27.29 |****       |
 INCOME       26.79627   26.80 |****       |
 EDUC_MOM     26.10689   26.11 |****       |
 ILLEGIT      20.91092   20.91 |***        |
 PNCLATE      16.11727   16.12 |***        |
 LBW          13.95142   13.95 |**         |
 RACE_MOM      9.69114    9.69 |**         |


 Learn Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7370.00         3.00       0.0004
 1                  221.00        51.00       170.00       0.7692


 Test Sample Misclassification by Target Class
 For The 20-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3677.00         9.00       0.0024
 1                  110.00         4.00       106.00       0.9636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.9 MB, 75% compression

 Grove file created containing:
      1 TreeNet

