
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11431      0.12176      0.02910      0.02898      1.00000 |                                               *
      2       0.10578      0.11844      0.02910      0.02898      1.00000 |                                              *
      3       0.10072      0.11658      0.02910      0.02898      1.00000 |                                             *
      4       0.09720      0.11470      0.02910      0.02898      1.00000 |                                            *
      5       0.09378      0.11353      0.02831      0.02871      1.00000 |                                            *
      6       0.09073      0.11306      0.02792      0.02845      1.00000 |                                            *
      7       0.08751      0.11229      0.02779      0.02871      1.00000 |                                           *
      8       0.08531      0.11158      0.02739      0.02871      1.00000 |                                           *
      9       0.08272      0.11098      0.02686      0.02845      1.00000 |                                           *
     10       0.08020      0.11070      0.02660      0.02871      1.00000 |                                           *
     11       0.07815      0.11062      0.02607      0.02924      1.00000 |                                           *
     12       0.07680      0.11045      0.02594      0.02924      1.00000 |                                           *
     13       0.07540      0.11008      0.02568      0.02924      1.00000 |                                          *
     14       0.07344      0.10995      0.02528      0.02977      1.00000 |                                          *
     15       0.07269      0.10993      0.02515      0.02950      1.00000 |                                          *
     16       0.07172      0.10980      0.02462      0.02950      1.00000 |                                          *
     17       0.07039      0.10971      0.02436      0.02950      1.00000 |                                          *
     18       0.06972      0.10964      0.02397      0.02950      1.00000 |                                          *
     19       0.06904      0.10947      0.02397      0.02950      1.00000 |                                          *
     20       0.06805      0.10959      0.02397      0.03056      1.00000 |                                          *
     30       0.06397      0.11031      0.02212      0.03135      1.00000 |                                          *
     40       0.06124      0.11112      0.02133      0.03135      1.00000 |                                           *
     50       0.05729      0.11214      0.02067      0.03109      1.00000 |                                           *
     60       0.05300      0.11314      0.01975      0.03161      1.00000 |                                            *
     70       0.05138      0.11375      0.01896      0.03188      1.00000 |                                            *
     80       0.04944      0.11473      0.01857      0.03240      1.00000 |                                            *
     90       0.04759      0.11520      0.01844      0.03267      1.00000 |                                            *
    100       0.04622      0.11617      0.01712      0.03293      1.00000 |                                             *
    110       0.04531      0.11714      0.01620      0.03293      1.00000 |                                             *
    120       0.04424      0.11803      0.01580      0.03267      1.00000 |                                              *
    130       0.04177      0.11926      0.01528      0.03240      1.00000 |                                              *
    140       0.04099      0.12030      0.01514      0.03293      1.00000 |                                              *
    150       0.03865      0.12082      0.01488      0.03319      1.00000 |                                               *
    160       0.03666      0.12203      0.01317      0.03293      1.00000 |                                               *
    170       0.03463      0.12333      0.01211      0.03346      1.00000 |                                               *
    180       0.03259      0.12453      0.01093      0.03319      1.00000 |                                               *
    190       0.03151      0.12552      0.01027      0.03372      1.00000 |                                               *
    200       0.02971      0.12647      0.00935      0.03372      1.00000 |                                               *
    210       0.02862      0.12723      0.00909      0.03372      1.00000 |                                               *
    220       0.02738      0.12827      0.00843      0.03372      1.00000 |                                               *
    230       0.02609      0.12932      0.00737      0.03346      1.00000 |                                               *
    240       0.02338      0.13104      0.00487      0.03372      1.00000 |                                               *
    250       0.02256      0.13211      0.00487      0.03372      1.00000 |                                               *
    260       0.02165      0.13339      0.00448      0.03346      1.00000 |                                               *
    270       0.02090      0.13457      0.00369      0.03372      1.00000 |                                               *
    280       0.02000      0.13594      0.00356      0.03346      1.00000 |                                               *
    290       0.01962      0.13696      0.00356      0.03372      1.00000 |                                               *
    300       0.01810      0.13737      0.00316      0.03346      1.00000 |                                               *
    310       0.01695      0.13848      0.00237      0.03398      1.00000 |                                               *
    320       0.01575      0.13970      0.00184      0.03346      1.00000 |                                               *
    330       0.01490      0.14117      0.00145      0.03346      1.00000 |                                               *
    340       0.01432      0.14259      0.00145      0.03293      1.00000 |                                               *
    350       0.01365      0.14309      0.00132      0.03346      1.00000 |                                               *
    360       0.01287      0.14480      0.00132      0.03346      1.00000 |                                               *
    370       0.01247      0.14565      0.00132      0.03293      1.00000 |                                               *
    380       0.01196      0.14643      0.00119      0.03293      1.00000 |                                               *
    390       0.01152      0.14744      0.00105      0.03293      1.00000 |                                               *
    400       0.01093      0.14871      0.00079      0.03293      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.28      6.72  CHILDYRS
    306      1    400      1      7      4.31      2.83  AGE
    258      1    400      1      7      4.66      2.16  AGE_MOM
    254      1    399      1      7      4.39      2.30  INCOME
    253      1    400      1      7      4.38      2.29  EDUC_MOM
    229      1    400      1      7      4.84      1.81  OTH_CHLD
    159      1    398      1      7      4.97      1.21  ILLEGIT
    114      1    400      2      7      5.35      0.76  RACE_MOM
     87      1    399      1      7      5.40      0.57  LBW
     87      2    399      1      7      5.38      0.57  PNCLATE

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    87 terminal nodes
    Average :     27.90000 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 39 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 39 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 19

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 21920 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           19      0.10947
                  ROC           39      0.83910
                 Lift            1      5.42539
              KS-stat           67      0.56181
          Class.Error            6      0.02845

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11431     0.12176     0.90581     0.78961     6.70548     5.42539     0.64484     0.48958     0.02910     0.02898
      6     0.09073     0.11306     0.93684     0.82043     7.96380     4.72727     0.74936     0.51349     0.02792     0.02845
     10     0.08020     0.11070     0.95731     0.83351     8.59729     4.41818     0.79792     0.53210     0.02660     0.02871
     19     0.06904     0.10947     0.96954     0.83887     8.95928     4.72727     0.83271     0.54336     0.02397     0.02950
     20     0.06805     0.10959     0.97039     0.83839     9.06787     4.54545     0.83685     0.54675     0.02397     0.03056
     30     0.06397     0.11031     0.97216     0.83836     9.18552     4.90909     0.84658     0.54769     0.02212     0.03135
     39     0.06128     0.11106     0.97612     0.83910     9.18552     4.72727     0.84853     0.55557     0.02146     0.03109
     40     0.06124     0.11112     0.97612     0.83905     9.18552     4.72727     0.84867     0.55557     0.02133     0.03135
     50     0.05729     0.11214     0.98235     0.83666     9.45701     4.69091     0.87969     0.55719     0.02067     0.03109
     60     0.05300     0.11314     0.98697     0.83531     9.59276     4.54545     0.89299     0.55937     0.01975     0.03161
     67     0.05201     0.11349     0.98751     0.83468     9.59276     4.54545     0.89697     0.56181     0.01923     0.03188
     70     0.05138     0.11375     0.98846     0.83423     9.72851     4.54545     0.90150     0.55570     0.01896     0.03188
     80     0.04944     0.11473     0.98996     0.83255     9.77376     4.54545     0.91343     0.54810     0.01857     0.03240
     90     0.04759     0.11520     0.99142     0.83167     9.77376     4.63636     0.92221     0.55367     0.01844     0.03267
    100     0.04622     0.11617     0.99201     0.82985     9.77376     4.54545     0.92402     0.54525     0.01712     0.03293
    110     0.04531     0.11714     0.99250     0.82670     9.77376     4.63636     0.92592     0.55367     0.01620     0.03293
    120     0.04424     0.11803     0.99290     0.82528     9.77376     4.54545     0.92701     0.55353     0.01580     0.03267
    130     0.04177     0.11926     0.99435     0.82253     9.81900     4.54545     0.93374     0.53441     0.01528     0.03240
    140     0.04099     0.12030     0.99472     0.82061     9.81900     4.45455     0.93637     0.52165     0.01514     0.03293
    150     0.03865     0.12082     0.99576     0.82001     9.81900     4.45455     0.94840     0.51514     0.01488     0.03319
    160     0.03666     0.12203     0.99640     0.81524     9.81900     4.45455     0.95015     0.50091     0.01317     0.03293
    170     0.03463     0.12333     0.99697     0.81138     9.81900     4.45455     0.95567     0.49440     0.01211     0.03346
    180     0.03259     0.12453     0.99751     0.80976     9.81900     4.36364     0.95879     0.49549     0.01093     0.03319
    190     0.03151     0.12552     0.99792     0.80855     9.86425     4.36364     0.95907     0.48884     0.01027     0.03372
    200     0.02971     0.12647     0.99873     0.80783     9.95475     4.45455     0.96844     0.48166     0.00935     0.03372
    210     0.02862     0.12723     0.99897     0.80684     9.95475     4.54545     0.97590     0.48071     0.00909     0.03372
    220     0.02738     0.12827     0.99917     0.80465     9.95475     4.36364     0.97644     0.47868     0.00843     0.03372
    230     0.02609     0.12932     0.99934     0.80372     9.95475     4.18182     0.97937     0.47908     0.00737     0.03346
    233     0.02487     0.12990     0.99949     0.80306    10.00000     4.27273     0.98276     0.47027     0.00579     0.03372
    240     0.02338     0.13104     0.99966     0.80192    10.00000     4.36364     0.98368     0.46552     0.00487     0.03372
    250     0.02256     0.13211     0.99969     0.79871    10.00000     4.18182     0.98493     0.45955     0.00487     0.03372
    260     0.02165     0.13339     0.99975     0.79742    10.00000     4.27273     0.99032     0.45301     0.00448     0.03346
    270     0.02090     0.13457     0.99978     0.79507    10.00000     4.27273     0.99249     0.45028     0.00369     0.03372
    280     0.02000     0.13594     0.99988     0.79341    10.00000     4.27273     0.99371     0.45939     0.00356     0.03346
    290     0.01962     0.13696     0.99989     0.79064    10.00000     4.14545     0.99371     0.44501     0.00356     0.03372
    300     0.01810     0.13737     0.99994     0.79278    10.00000     4.27273     0.99466     0.46210     0.00316     0.03346
    310     0.01695     0.13848     0.99996     0.79325    10.00000     4.32727     0.99466     0.45545     0.00237     0.03398
    320     0.01575     0.13970     0.99998     0.79304    10.00000     4.45455     0.99634     0.45449     0.00184     0.03346
    330     0.01490     0.14117     0.99999     0.79327    10.00000     4.27273     0.99851     0.45126     0.00145     0.03346
    336     0.01457     0.14192     1.00000     0.79149    10.00000     3.96364     1.00000     0.44433     0.00145     0.03319
    340     0.01432     0.14259     1.00000     0.79014    10.00000     4.00000     1.00000     0.44703     0.00145     0.03293
    350     0.01365     0.14309     1.00000     0.79181    10.00000     4.09091     1.00000     0.44622     0.00132     0.03346
    360     0.01287     0.14480     1.00000     0.79098    10.00000     3.90909     1.00000     0.44990     0.00132     0.03346
    370     0.01247     0.14565     1.00000     0.79029    10.00000     3.90909     1.00000     0.44922     0.00132     0.03293
    380     0.01196     0.14643     1.00000     0.78968    10.00000     4.00000     1.00000     0.45137     0.00119     0.03293
    390     0.01152     0.14744     1.00000     0.78768    10.00000     4.00000     1.00000     0.44500     0.00105     0.03293
    397     0.01106     0.14845     1.00000     0.78953    10.00000     4.09091     1.00000     0.45354     0.00079     0.03319
    400     0.01093     0.14871     1.00000     0.78902    10.00000     4.00000     1.00000     0.44025     0.00079     0.03293


 =========================================
 Variable Importance for the 19-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      36.41809   36.42 |*****      |
 INCOME       32.18961   32.19 |****       |
 AGE          31.71416   31.71 |****       |
 EDUC_MOM     30.88773   30.89 |****       |
 OTH_CHLD     27.13589   27.14 |****       |
 ILLEGIT      15.27636   15.28 |**         |
 PNCLATE      13.00369   13.00 |**         |
 RACE_MOM      9.79830    9.80 |**         |
 LBW           7.20879    7.21 |**         |


 Learn Sample Misclassification by Target Class
 For The 19-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7369.00         4.00       0.0005
 1                  221.00        43.00       178.00       0.8054


 Test Sample Misclassification by Target Class
 For The 19-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3676.00        10.00       0.0027
 1                  110.00         8.00       102.00       0.9273

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                1.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 1009 kb , 75% compression

 Grove file created containing:
      1 TreeNet

