
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11100      0.12189      0.02910      0.02898      1.00000 |                                               *
      2       0.10071      0.11906      0.02765      0.02871      1.00000 |                                              *
      3       0.09397      0.11678      0.02765      0.02871      1.00000 |                                             *
      4       0.08950      0.11544      0.02699      0.02898      1.00000 |                                            *
      5       0.08595      0.11422      0.02699      0.02977      1.00000 |                                            *
      6       0.08096      0.11361      0.02581      0.02950      1.00000 |                                            *
      7       0.07833      0.11261      0.02541      0.03056      1.00000 |                                           *
      8       0.07495      0.11209      0.02489      0.03056      1.00000 |                                           *
      9       0.07301      0.11149      0.02436      0.03056      1.00000 |                                           *
     10       0.07105      0.11092      0.02397      0.03056      1.00000 |                                           *
     11       0.06933      0.11036      0.02370      0.03056      1.00000 |                                          *
     12       0.06723      0.11046      0.02304      0.03056      1.00000 |                                          *
     13       0.06506      0.11000      0.02304      0.03056      1.00000 |                                          *
     14       0.06380      0.10967      0.02304      0.03056      1.00000 |                                          *
     15       0.06275      0.10936      0.02265      0.03056      1.00000 |                                          *
     16       0.06085      0.10978      0.02239      0.03056      1.00000 |                                          *
     17       0.05896      0.10970      0.02186      0.03135      1.00000 |                                          *
     18       0.05793      0.10967      0.02133      0.03109      1.00000 |                                          *
     19       0.05633      0.10978      0.02094      0.03082      1.00000 |                                          *
     20       0.05541      0.10986      0.02081      0.03082      1.00000 |                                          *
     30       0.04800      0.11068      0.01923      0.03135      1.00000 |                                           *
     40       0.04323      0.11171      0.01699      0.03135      1.00000 |                                           *
     50       0.03939      0.11305      0.01528      0.03188      1.00000 |                                            *
     60       0.03405      0.11466      0.01172      0.03161      1.00000 |                                            *
     70       0.03068      0.11679      0.01001      0.03267      1.00000 |                                             *
     80       0.02744      0.12001      0.00843      0.03240      1.00000 |                                              *
     90       0.02471      0.12179      0.00645      0.03240      1.00000 |                                               *
    100       0.02209      0.12500      0.00553      0.03214      1.00000 |                                               *
    110       0.02003      0.12758      0.00461      0.03240      1.00000 |                                               *
    120       0.01892      0.12937      0.00408      0.03267      1.00000 |                                               *
    130       0.01711      0.13124      0.00303      0.03267      1.00000 |                                               *
    140       0.01594      0.13314      0.00237      0.03293      1.00000 |                                               *
    150       0.01417      0.13551      0.00158      0.03267      1.00000 |                                               *
    160       0.01347      0.13702      0.00092      0.03293      1.00000 |                                               *
    170       0.01322      0.13741      0.00092      0.03293      1.00000 |                                               *
    180       0.01176      0.14017      0.00053      0.03346      1.00000 |                                               *
    190       0.01080      0.14260      0.00026      0.03346      1.00000 |                                               *
    200       0.01023      0.14393      0.00026      0.03346      1.00000 |                                               *
    210       0.00951      0.14509      0.00026      0.03346      1.00000 |                                               *
    220       0.00889      0.14692      0.00013      0.03425      1.00000 |                                               *
    230       0.00847      0.14842      0.00013      0.03425      1.00000 |                                               *
    240       0.00776      0.15057      0.00000      0.03372      1.00000 |                                               *
    250       0.00717      0.15278      0.00000      0.03372      1.00000 |                                               *
    260       0.00676      0.15436      0.00000      0.03425      1.00000 |                                               *
    270       0.00598      0.15709      0.00000      0.03398      1.00000 |                                               *
    280       0.00558      0.15898      0.00000      0.03372      1.00000 |                                               *
    290       0.00497      0.16202      0.00000      0.03372      1.00000 |                                               *
    300       0.00447      0.16513      0.00000      0.03372      1.00000 |                                               *
    310       0.00408      0.16765      0.00000      0.03372      1.00000 |                                               *
    320       0.00380      0.16978      0.00000      0.03372      1.00000 |                                               *
    330       0.00356      0.17175      0.00000      0.03372      1.00000 |                                               *
    340       0.00340      0.17347      0.00000      0.03346      1.00000 |                                               *
    350       0.00316      0.17604      0.00000      0.03346      1.00000 |                                               *
    360       0.00282      0.17888      0.00000      0.03372      1.00000 |                                               *
    370       0.00267      0.18037      0.00000      0.03398      1.00000 |                                               *
    380       0.00250      0.18237      0.00000      0.03372      1.00000 |                                               *
    390       0.00231      0.18431      0.00000      0.03398      1.00000 |                                               *
    400       0.00217      0.18570      0.00000      0.03425      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.57      6.44  CHILDYRS
    368      1    400      1      7      3.46      4.18  AGE
    347      1    399      1      7      3.90      3.56  AGE_MOM
    329      1    400      1      7      4.18      3.14  INCOME
    325      1    399      1      7      4.72      2.66  EDUC_MOM
    314      1    398      1      7      3.91      3.21  OTH_CHLD
    288      1    399      1      7      5.22      2.00  ILLEGIT
    250      3    399      2      7      4.99      1.88  RACE_MOM
    240      1    399      2      7      5.29      1.63  PNCLATE
    223      1    397      2      7      5.41      1.45  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   113 terminal nodes
    Average :     51.35250 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 15 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 15 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 15

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 40682 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           15      0.10936
                  ROC            4      0.84923
                 Lift            4      5.45455
              KS-stat           10      0.62556
          Class.Error            2      0.02871

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11100     0.12189     0.90176     0.80851     6.71895     5.42679     0.62223     0.53085     0.02910     0.02898
      2     0.10071     0.11906     0.92706     0.83739     7.37557     5.29524     0.70146     0.60126     0.02765     0.02871
      4     0.08950     0.11544     0.94147     0.84923     8.19005     5.45455     0.74902     0.60194     0.02699     0.02898
     10     0.07105     0.11092     0.96869     0.84783     9.04977     5.18182     0.84091     0.62556     0.02397     0.03056
     15     0.06275     0.10936     0.97758     0.84766     9.27602     5.01818     0.86202     0.60303     0.02265     0.03056
     20     0.05541     0.10986     0.98555     0.84367     9.54751     4.90909     0.90487     0.58757     0.02081     0.03082
     30     0.04800     0.11068     0.99365     0.84366     9.81900     4.81818     0.93568     0.57536     0.01923     0.03135
     40     0.04323     0.11171     0.99605     0.84493     9.86425     5.09091     0.94835     0.57657     0.01699     0.03135
     50     0.03939     0.11305     0.99703     0.84621     9.86425     5.27273     0.95454     0.57387     0.01528     0.03188
     56     0.03604     0.11423     0.99825     0.84583    10.00000     5.18182     0.96852     0.57943     0.01396     0.03161
     60     0.03405     0.11466     0.99857     0.84531    10.00000     5.00000     0.97205     0.57143     0.01172     0.03161
     70     0.03068     0.11679     0.99910     0.84414    10.00000     5.00000     0.98118     0.56966     0.01001     0.03267
     80     0.02744     0.12001     0.99948     0.84084    10.00000     5.00000     0.98652     0.56695     0.00843     0.03240
     90     0.02471     0.12179     0.99976     0.83992    10.00000     5.18182     0.99019     0.57373     0.00645     0.03240
    100     0.02209     0.12500     0.99988     0.83524    10.00000     4.90909     0.99263     0.56817     0.00553     0.03214
    110     0.02003     0.12758     0.99990     0.83409    10.00000     5.00000     0.99303     0.55718     0.00461     0.03240
    120     0.01892     0.12937     0.99994     0.83285    10.00000     5.00000     0.99371     0.56071     0.00408     0.03267
    130     0.01711     0.13124     0.99997     0.83253    10.00000     5.00000     0.99507     0.55814     0.00303     0.03267
    140     0.01594     0.13314     0.99997     0.83167    10.00000     4.90909     0.99520     0.56275     0.00237     0.03293
    150     0.01417     0.13551     0.99999     0.83233    10.00000     4.81818     0.99824     0.55800     0.00158     0.03267
    160     0.01347     0.13702     1.00000     0.83236    10.00000     4.81818     0.99946     0.54783     0.00092     0.03293
    170     0.01322     0.13741     1.00000     0.83193    10.00000     4.81818     0.99973     0.54783     0.00092     0.03293
    176     0.01252     0.13863     1.00000     0.83108    10.00000     4.72727     1.00000     0.54579     0.00066     0.03346
    180     0.01176     0.14017     1.00000     0.82950    10.00000     4.90909     1.00000     0.54253     0.00053     0.03346
    190     0.01080     0.14260     1.00000     0.82714    10.00000     4.72727     1.00000     0.53768     0.00026     0.03346
    200     0.01023     0.14393     1.00000     0.82624    10.00000     4.78182     1.00000     0.53279     0.00026     0.03346
    210     0.00951     0.14509     1.00000     0.82656    10.00000     4.72727     1.00000     0.53209     0.00026     0.03346
    220     0.00889     0.14692     1.00000     0.82709    10.00000     4.69091     1.00000     0.53412     0.00013     0.03425
    230     0.00847     0.14842     1.00000     0.82647    10.00000     4.63636     1.00000     0.53385     0.00013     0.03425
    238     0.00793     0.15027     1.00000     0.82462    10.00000     4.72727     1.00000     0.52775     0.00000     0.03425
    240     0.00776     0.15057     1.00000     0.82488    10.00000     4.72727     1.00000     0.52708     0.00000     0.03372
    250     0.00717     0.15278     1.00000     0.82384    10.00000     4.54545     1.00000     0.52274     0.00000     0.03372
    260     0.00676     0.15436     1.00000     0.82355    10.00000     4.45455     1.00000     0.53156     0.00000     0.03425
    270     0.00598     0.15709     1.00000     0.82257    10.00000     4.54545     1.00000     0.52790     0.00000     0.03398
    280     0.00558     0.15898     1.00000     0.82096    10.00000     4.45455     1.00000     0.52017     0.00000     0.03372
    290     0.00497     0.16202     1.00000     0.82007    10.00000     4.45455     1.00000     0.52015     0.00000     0.03372
    300     0.00447     0.16513     1.00000     0.81897    10.00000     4.45455     1.00000     0.52314     0.00000     0.03372
    310     0.00408     0.16765     1.00000     0.81818    10.00000     4.54545     1.00000     0.51907     0.00000     0.03372
    320     0.00380     0.16978     1.00000     0.81737    10.00000     4.36364     1.00000     0.51636     0.00000     0.03372
    330     0.00356     0.17175     1.00000     0.81574    10.00000     4.45455     1.00000     0.51147     0.00000     0.03372
    340     0.00340     0.17347     1.00000     0.81398    10.00000     4.36364     1.00000     0.51433     0.00000     0.03346
    350     0.00316     0.17604     1.00000     0.81227    10.00000     4.27273     1.00000     0.51609     0.00000     0.03346
    360     0.00282     0.17888     1.00000     0.81204    10.00000     4.36364     1.00000     0.51649     0.00000     0.03372
    370     0.00267     0.18037     1.00000     0.81096    10.00000     4.45455     1.00000     0.51134     0.00000     0.03398
    380     0.00250     0.18237     1.00000     0.81096    10.00000     4.45455     1.00000     0.50836     0.00000     0.03372
    390     0.00231     0.18431     1.00000     0.81143    10.00000     4.36364     1.00000     0.50564     0.00000     0.03398
    400     0.00217     0.18570     1.00000     0.81133    10.00000     4.27273     1.00000     0.51092     0.00000     0.03425


 =========================================
 Variable Importance for the 15-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 EDUC_MOM     35.36770   35.37 |****       |
 AGE          30.15106   30.15 |****       |
 AGE_MOM      24.54279   24.54 |***        |
 INCOME       24.00403   24.00 |***        |
 OTH_CHLD     22.34092   22.34 |***        |
 ILLEGIT      17.96018   17.96 |***        |
 PNCLATE      14.16773   14.17 |**         |
 LBW          13.71880   13.72 |**         |
 RACE_MOM     10.37244   10.37 |**         |


 Learn Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7370.00         3.00       0.0004
 1                  221.00        52.00       169.00       0.7647


 Test Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3674.00        12.00       0.0033
 1                  110.00         6.00       104.00       0.9455

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         1.000 sec ( 0.00 hrs,  50.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.7 MB, 75% compression

 Grove file created containing:
      1 TreeNet

