
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11219      0.12308      0.02910      0.02898      1.00000 |                                               *
      2       0.10471      0.11975      0.02910      0.02898      1.00000 |                                              *
      3       0.09983      0.11703      0.02910      0.02898      1.00000 |                                             *
      4       0.09542      0.11518      0.02910      0.02898      1.00000 |                                            *
      5       0.09182      0.11395      0.02910      0.02898      1.00000 |                                           *
      6       0.08855      0.11320      0.02871      0.02898      1.00000 |                                           *
      7       0.08587      0.11288      0.02699      0.02950      1.00000 |                                           *
      8       0.08334      0.11253      0.02673      0.03003      1.00000 |                                           *
      9       0.08146      0.11240      0.02660      0.03003      1.00000 |                                           *
     10       0.07982      0.11226      0.02620      0.03030      1.00000 |                                           *
     11       0.07830      0.11229      0.02594      0.03082      1.00000 |                                           *
     12       0.07621      0.11217      0.02528      0.03135      1.00000 |                                           *
     13       0.07478      0.11194      0.02476      0.03161      1.00000 |                                           *
     14       0.07389      0.11216      0.02436      0.03214      1.00000 |                                           *
     15       0.07286      0.11202      0.02423      0.03188      1.00000 |                                           *
     16       0.07156      0.11215      0.02410      0.03214      1.00000 |                                           *
     17       0.07014      0.11222      0.02370      0.03188      1.00000 |                                           *
     18       0.06958      0.11247      0.02357      0.03240      1.00000 |                                           *
     19       0.06855      0.11296      0.02331      0.03267      1.00000 |                                           *
     20       0.06779      0.11301      0.02331      0.03267      1.00000 |                                           *
     30       0.06391      0.11477      0.02278      0.03293      1.00000 |                                            *
     40       0.05985      0.11649      0.02160      0.03398      1.00000 |                                            *
     50       0.05749      0.11666      0.02081      0.03319      1.00000 |                                            *
     60       0.05480      0.11785      0.01962      0.03372      1.00000 |                                             *
     70       0.05328      0.11863      0.01883      0.03425      1.00000 |                                             *
     80       0.05149      0.11960      0.01778      0.03425      1.00000 |                                              *
     90       0.05058      0.11981      0.01751      0.03398      1.00000 |                                              *
    100       0.04999      0.12018      0.01738      0.03372      1.00000 |                                              *
    110       0.04900      0.12095      0.01725      0.03398      1.00000 |                                              *
    120       0.04799      0.12163      0.01646      0.03398      1.00000 |                                              *
    130       0.04654      0.12239      0.01607      0.03425      1.00000 |                                               *
    140       0.04601      0.12290      0.01567      0.03425      1.00000 |                                               *
    150       0.04555      0.12352      0.01541      0.03372      1.00000 |                                               *
    160       0.04478      0.12444      0.01528      0.03319      1.00000 |                                               *
    170       0.04383      0.12530      0.01514      0.03346      1.00000 |                                               *
    180       0.04220      0.12621      0.01422      0.03451      1.00000 |                                               *
    190       0.04101      0.12709      0.01370      0.03425      1.00000 |                                               *
    200       0.03912      0.12779      0.01304      0.03451      1.00000 |                                               *
    210       0.03816      0.12848      0.01225      0.03425      1.00000 |                                               *
    220       0.03622      0.12987      0.01106      0.03425      1.00000 |                                               *
    230       0.03555      0.13058      0.01080      0.03398      1.00000 |                                               *
    240       0.03453      0.13146      0.01040      0.03425      1.00000 |                                               *
    250       0.03386      0.13219      0.01040      0.03477      1.00000 |                                               *
    260       0.03359      0.13251      0.01014      0.03477      1.00000 |                                               *
    270       0.03302      0.13328      0.00988      0.03451      1.00000 |                                               *
    280       0.03222      0.13454      0.00909      0.03477      1.00000 |                                               *
    290       0.03113      0.13579      0.00882      0.03504      1.00000 |                                               *
    300       0.03032      0.13667      0.00856      0.03477      1.00000 |                                               *
    310       0.02899      0.13770      0.00843      0.03451      1.00000 |                                               *
    320       0.02770      0.13830      0.00777      0.03477      1.00000 |                                               *
    330       0.02689      0.13875      0.00751      0.03504      1.00000 |                                               *
    340       0.02604      0.13972      0.00724      0.03477      1.00000 |                                               *
    350       0.02498      0.14102      0.00698      0.03477      1.00000 |                                               *
    360       0.02435      0.14184      0.00645      0.03477      1.00000 |                                               *
    370       0.02300      0.14270      0.00553      0.03451      1.00000 |                                               *
    380       0.02278      0.14309      0.00540      0.03451      1.00000 |                                               *
    390       0.02225      0.14346      0.00527      0.03425      1.00000 |                                               *
    400       0.02175      0.14441      0.00527      0.03425      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      3      1.14      6.86  CHILDYRS
    232      1    398      1      7      4.83      1.84  AGE
    221      1    398      2      7      5.33      1.48  INCOME
    213      1    399      2      7      5.00      1.60  AGE_MOM
    178      1    398      1      7      4.80      1.43  OTH_CHLD
    160      1    398      1      7      5.24      1.10  EDUC_MOM
    106      1    398      1      7      5.32      0.71  ILLEGIT
     72      2    393      3      7      5.79      0.40  RACE_MOM
     62      1    397      2      7      5.98      0.31  PNCLATE
     57      8    393      3      7      5.89      0.30  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    74 terminal nodes
    Average :     20.31000 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 17 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 17 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 13

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 15848 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           13      0.11194
                  ROC           17      0.83233
                 Lift            7      5.00606
              KS-stat            5      0.55976
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11219     0.12308     0.90143     0.75673     7.06199     4.72727     0.63369     0.44496     0.02910     0.02898
      5     0.09182     0.11395     0.94116     0.81820     8.00905     4.81818     0.74288     0.55976     0.02910     0.02898
      7     0.08587     0.11288     0.94336     0.82052     8.14480     5.00606     0.76236     0.53181     0.02699     0.02950
     10     0.07982     0.11226     0.94977     0.82214     8.41629     4.81818     0.77597     0.53847     0.02620     0.03030
     13     0.07478     0.11194     0.95545     0.82638     8.55204     4.96364     0.79022     0.54769     0.02476     0.03161
     17     0.07014     0.11222     0.96174     0.83233     8.64253     4.81818     0.81470     0.54795     0.02370     0.03188
     20     0.06779     0.11301     0.96387     0.82742     8.73303     4.90909     0.81158     0.52937     0.02331     0.03267
     30     0.06391     0.11477     0.96628     0.82622     8.82353     4.63636     0.81507     0.52096     0.02278     0.03293
     40     0.05985     0.11649     0.97490     0.82132     8.95928     4.63636     0.83457     0.49709     0.02160     0.03398
     50     0.05749     0.11666     0.97860     0.82502     9.04977     4.54545     0.85095     0.50617     0.02081     0.03319
     60     0.05480     0.11785     0.98171     0.82446     9.23077     4.45455     0.86049     0.51064     0.01962     0.03372
     70     0.05328     0.11863     0.98287     0.82429     9.36652     4.36364     0.86423     0.50874     0.01883     0.03425
     80     0.05149     0.11960     0.98478     0.82248     9.41176     4.36364     0.87038     0.51026     0.01778     0.03425
     90     0.05058     0.11981     0.98547     0.82296     9.45701     4.36364     0.87599     0.50728     0.01751     0.03398
    100     0.04999     0.12018     0.98593     0.82228     9.45701     4.36364     0.87721     0.51081     0.01738     0.03372
    110     0.04900     0.12095     0.98649     0.82089     9.45701     4.09091     0.87924     0.51311     0.01725     0.03398
    120     0.04799     0.12163     0.98738     0.81864     9.50226     4.09091     0.88377     0.51976     0.01646     0.03398
    130     0.04654     0.12239     0.98828     0.81759     9.54751     4.18182     0.88965     0.50715     0.01607     0.03425
    140     0.04601     0.12290     0.98865     0.81549     9.54751     4.09091     0.89141     0.49951     0.01567     0.03425
    150     0.04555     0.12352     0.98882     0.81359     9.54751     4.09091     0.89087     0.50032     0.01541     0.03372
    160     0.04478     0.12444     0.98917     0.81106     9.54751     4.18182     0.89155     0.49440     0.01528     0.03319
    170     0.04383     0.12530     0.98977     0.80766     9.54751     4.00000     0.89331     0.48640     0.01514     0.03346
    180     0.04220     0.12621     0.99078     0.80697     9.59276     4.00000     0.89891     0.49832     0.01422     0.03451
    190     0.04101     0.12709     0.99186     0.80501     9.63801     4.00000     0.90452     0.49045     0.01370     0.03425
    200     0.03912     0.12779     0.99298     0.80317     9.63801     4.00000     0.90737     0.47593     0.01304     0.03451
    210     0.03816     0.12848     0.99365     0.80188     9.68326     4.09091     0.91035     0.47486     0.01225     0.03425
    220     0.03622     0.12987     0.99504     0.79990     9.77376     4.18182     0.92352     0.47283     0.01106     0.03425
    230     0.03555     0.13058     0.99540     0.79733     9.81900     4.00000     0.92669     0.48178     0.01080     0.03398
    240     0.03453     0.13146     0.99588     0.79464     9.86425     4.00000     0.93143     0.46753     0.01040     0.03425
    250     0.03386     0.13219     0.99619     0.79311     9.90950     4.09091     0.93157     0.46007     0.01040     0.03477
    260     0.03359     0.13251     0.99626     0.79274     9.90950     4.09091     0.93211     0.45655     0.01014     0.03477
    270     0.03302     0.13328     0.99643     0.79078     9.90950     4.00000     0.93651     0.44150     0.00988     0.03451
    280     0.03222     0.13454     0.99674     0.78784     9.95475     4.09091     0.94248     0.44989     0.00909     0.03477
    290     0.03113     0.13579     0.99729     0.78582     9.95475     4.00000     0.95053     0.44270     0.00882     0.03504
    300     0.03032     0.13667     0.99752     0.78333     9.95475     3.81818     0.95587     0.44121     0.00856     0.03477
    303     0.02996     0.13707     0.99773     0.78223    10.00000     3.81818     0.95587     0.44392     0.00856     0.03451
    310     0.02899     0.13770     0.99812     0.78101    10.00000     3.90909     0.95723     0.43077     0.00843     0.03451
    320     0.02770     0.13830     0.99848     0.78214    10.00000     3.90909     0.95857     0.43851     0.00777     0.03477
    330     0.02689     0.13875     0.99877     0.78177    10.00000     3.81818     0.96178     0.43457     0.00751     0.03504
    340     0.02604     0.13972     0.99897     0.78049    10.00000     3.90909     0.96725     0.44108     0.00724     0.03477
    350     0.02498     0.14102     0.99925     0.77839    10.00000     3.72727     0.97151     0.43499     0.00698     0.03477
    360     0.02435     0.14184     0.99936     0.77735    10.00000     3.72727     0.97369     0.43214     0.00645     0.03477
    370     0.02300     0.14270     0.99962     0.77784    10.00000     3.87273     0.98169     0.43281     0.00553     0.03451
    380     0.02278     0.14309     0.99964     0.77708    10.00000     3.81818     0.98169     0.43023     0.00540     0.03451
    383     0.02263     0.14325     0.99964     0.77672    10.00000     3.81818     0.98183     0.42844     0.00527     0.03451
    390     0.02225     0.14346     0.99972     0.77707    10.00000     3.87273     0.98462     0.43155     0.00527     0.03425
    399     0.02177     0.14430     0.99974     0.77614    10.00000     3.63636     0.98557     0.43522     0.00527     0.03425
    400     0.02175     0.14441     0.99975     0.77585    10.00000     3.63636     0.98544     0.43522     0.00527     0.03425


 =========================================
 Variable Importance for the 13-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE_MOM      51.45737   51.46 |******     |
 AGE          39.96504   39.97 |*****      |
 OTH_CHLD     29.48567   29.49 |****       |
 INCOME       27.90939   27.91 |****       |
 ILLEGIT      22.37667   22.38 |***        |
 EDUC_MOM     20.75737   20.76 |***        |
 RACE_MOM     16.41908   16.42 |***        |
 LBW           7.18059    7.18 |**         |
 PNCLATE       6.85109    6.85 |**         |


 Learn Sample Misclassification by Target Class
 For The 13-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        35.00       186.00       0.8416


 Test Sample Misclassification by Target Class
 For The 13-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3672.00        14.00       0.0038
 1                  110.00         4.00       106.00       0.9636

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 735 kb , 76% compression

 Grove file created containing:
      1 TreeNet

