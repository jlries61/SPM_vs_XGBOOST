
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:00

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.11058      0.12100      0.02910      0.02898      1.00000 |                                               *
      2       0.10261      0.11776      0.02910      0.02898      1.00000 |                                              *
      3       0.09662      0.11620      0.02910      0.02898      1.00000 |                                             *
      4       0.09203      0.11528      0.02884      0.02924      1.00000 |                                             *
      5       0.08862      0.11475      0.02858      0.02924      1.00000 |                                             *
      6       0.08498      0.11363      0.02779      0.02924      1.00000 |                                            *
      7       0.08179      0.11320      0.02752      0.02898      1.00000 |                                            *
      8       0.07928      0.11337      0.02739      0.02924      1.00000 |                                            *
      9       0.07684      0.11320      0.02699      0.02950      1.00000 |                                            *
     10       0.07504      0.11288      0.02660      0.02977      1.00000 |                                            *
     11       0.07279      0.11274      0.02568      0.02950      1.00000 |                                            *
     12       0.07110      0.11317      0.02568      0.03030      1.00000 |                                            *
     13       0.06991      0.11322      0.02568      0.03030      1.00000 |                                            *
     14       0.06855      0.11316      0.02555      0.03003      1.00000 |                                            *
     15       0.06699      0.11267      0.02541      0.02977      1.00000 |                                            *
     16       0.06599      0.11275      0.02515      0.02977      1.00000 |                                            *
     17       0.06502      0.11295      0.02489      0.02977      1.00000 |                                            *
     18       0.06359      0.11308      0.02449      0.03003      1.00000 |                                            *
     19       0.06233      0.11286      0.02410      0.03082      1.00000 |                                            *
     20       0.06129      0.11289      0.02410      0.03109      1.00000 |                                            *
     30       0.05163      0.11444      0.02212      0.03135      1.00000 |                                            *
     40       0.04648      0.11611      0.02041      0.03082      1.00000 |                                             *
     50       0.04265      0.11833      0.01817      0.03135      1.00000 |                                              *
     60       0.03992      0.12039      0.01659      0.03135      1.00000 |                                               *
     70       0.03747      0.12217      0.01462      0.03188      1.00000 |                                               *
     80       0.03470      0.12314      0.01225      0.03240      1.00000 |                                               *
     90       0.03253      0.12465      0.01172      0.03267      1.00000 |                                               *
    100       0.03152      0.12553      0.01119      0.03293      1.00000 |                                               *
    110       0.02894      0.12706      0.00843      0.03293      1.00000 |                                               *
    120       0.02731      0.12882      0.00737      0.03267      1.00000 |                                               *
    130       0.02614      0.13037      0.00685      0.03240      1.00000 |                                               *
    140       0.02424      0.13164      0.00553      0.03293      1.00000 |                                               *
    150       0.02312      0.13267      0.00448      0.03346      1.00000 |                                               *
    160       0.02265      0.13345      0.00421      0.03346      1.00000 |                                               *
    170       0.02168      0.13472      0.00395      0.03451      1.00000 |                                               *
    180       0.02088      0.13628      0.00356      0.03477      1.00000 |                                               *
    190       0.01979      0.13828      0.00316      0.03504      1.00000 |                                               *
    200       0.01918      0.13940      0.00263      0.03504      1.00000 |                                               *
    210       0.01831      0.14078      0.00224      0.03504      1.00000 |                                               *
    220       0.01706      0.14297      0.00198      0.03504      1.00000 |                                               *
    230       0.01630      0.14455      0.00184      0.03477      1.00000 |                                               *
    240       0.01560      0.14658      0.00171      0.03477      1.00000 |                                               *
    250       0.01408      0.14885      0.00105      0.03583      1.00000 |                                               *
    260       0.01273      0.15103      0.00066      0.03556      1.00000 |                                               *
    270       0.01199      0.15353      0.00053      0.03635      1.00000 |                                               *
    280       0.01137      0.15486      0.00053      0.03609      1.00000 |                                               *
    290       0.01054      0.15717      0.00040      0.03688      1.00000 |                                               *
    300       0.01001      0.15877      0.00000      0.03688      1.00000 |                                               *
    310       0.00944      0.16040      0.00000      0.03662      1.00000 |                                               *
    320       0.00901      0.16199      0.00000      0.03662      1.00000 |                                               *
    330       0.00843      0.16377      0.00000      0.03635      1.00000 |                                               *
    340       0.00827      0.16451      0.00000      0.03635      1.00000 |                                               *
    350       0.00803      0.16530      0.00000      0.03609      1.00000 |                                               *
    360       0.00743      0.16730      0.00000      0.03583      1.00000 |                                               *
    370       0.00725      0.16796      0.00000      0.03609      1.00000 |                                               *
    380       0.00706      0.16880      0.00000      0.03583      1.00000 |                                               *
    390       0.00677      0.17019      0.00000      0.03609      1.00000 |                                               *
    400       0.00636      0.17168      0.00000      0.03635      1.00000 |                                               *

 Core TN model building:          1.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.32      6.68  CHILDYRS
    333      1    400      1      7      3.55      3.71  AGE
    316      1    400      1      7      4.00      3.16  INCOME
    267      1    400      1      7      4.81      2.13  AGE_MOM
    262      1    400      1      7      4.37      2.38  OTH_CHLD
    247      1    400      1      7      4.08      2.42  EDUC_MOM
    182      1    400      2      7      5.02      1.36  ILLEGIT
    172      1    400      2      7      5.43      1.11  RACE_MOM
    143      1    400      1      7      5.58      0.87  PNCLATE
    140      2    400      2      7      5.53      0.87  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    88 terminal nodes
    Average :     34.28750 terminal nodes

 Reconciling 7594 Learn sample scores across 4 selected models,
 the largest having 40 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 4 selected models,
 the largest having 40 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 15

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 27030 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           15      0.11267
                  ROC           40      0.81610
                 Lift            6      4.90909
              KS-stat          148      0.50185
          Class.Error            1      0.02898

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.11058     0.12100     0.92330     0.72191     7.26575     4.13493     0.69315     0.43805     0.02910     0.02898
      6     0.08498     0.11363     0.95869     0.77215     8.59729     4.90909     0.78853     0.40843     0.02779     0.02924
     10     0.07504     0.11288     0.97073     0.79226     8.91403     4.59394     0.82249     0.42442     0.02660     0.02977
     15     0.06699     0.11267     0.97866     0.79650     9.32127     4.60000     0.86676     0.42289     0.02541     0.02977
     20     0.06129     0.11289     0.98470     0.80568     9.68326     4.63636     0.89671     0.44341     0.02410     0.03109
     28     0.05320     0.11409     0.99205     0.81084    10.00000     4.45455     0.94407     0.44892     0.02239     0.03135
     30     0.05163     0.11444     0.99305     0.81203    10.00000     4.45455     0.94588     0.44946     0.02212     0.03135
     40     0.04648     0.11611     0.99514     0.81610    10.00000     4.36364     0.95523     0.45830     0.02041     0.03082
     50     0.04265     0.11833     0.99635     0.81513    10.00000     4.45455     0.96315     0.46180     0.01817     0.03135
     60     0.03992     0.12039     0.99708     0.81089    10.00000     4.36364     0.96776     0.45827     0.01659     0.03135
     70     0.03747     0.12217     0.99773     0.80793    10.00000     4.27273     0.96957     0.45433     0.01462     0.03188
     80     0.03470     0.12314     0.99837     0.81061    10.00000     4.36364     0.97811     0.46549     0.01225     0.03240
     90     0.03253     0.12465     0.99885     0.80973    10.00000     4.41818     0.97947     0.46807     0.01172     0.03267
    100     0.03152     0.12553     0.99901     0.80692    10.00000     4.27273     0.97947     0.46685     0.01119     0.03293
    110     0.02894     0.12706     0.99938     0.81062    10.00000     4.36364     0.98372     0.48462     0.00843     0.03293
    120     0.02731     0.12882     0.99956     0.80793    10.00000     4.27273     0.98495     0.48544     0.00737     0.03267
    130     0.02614     0.13037     0.99964     0.80694    10.00000     4.27273     0.98793     0.48122     0.00685     0.03240
    140     0.02424     0.13164     0.99978     0.80966    10.00000     4.36364     0.99078     0.49181     0.00553     0.03293
    148     0.02344     0.13211     0.99981     0.81265    10.00000     4.36364     0.99064     0.50185     0.00474     0.03319
    150     0.02312     0.13267     0.99983     0.81105    10.00000     4.36364     0.99268     0.49317     0.00448     0.03346
    160     0.02265     0.13345     0.99984     0.81142    10.00000     4.36364     0.99254     0.50050     0.00421     0.03346
    170     0.02168     0.13472     0.99987     0.80978    10.00000     4.36364     0.99349     0.49100     0.00395     0.03451
    180     0.02088     0.13628     0.99988     0.80750    10.00000     4.27273     0.99349     0.49887     0.00356     0.03477
    190     0.01979     0.13828     0.99989     0.80717    10.00000     4.27273     0.99390     0.48068     0.00316     0.03504
    200     0.01918     0.13940     0.99991     0.80511    10.00000     4.36364     0.99376     0.48299     0.00263     0.03504
    210     0.01831     0.14078     0.99993     0.80355    10.00000     4.36364     0.99457     0.48570     0.00224     0.03504
    220     0.01706     0.14297     0.99995     0.80160    10.00000     4.32727     0.99552     0.46834     0.00198     0.03504
    230     0.01630     0.14455     0.99998     0.79810    10.00000     4.36364     0.99837     0.46400     0.00184     0.03477
    240     0.01560     0.14658     0.99999     0.79661    10.00000     4.36364     0.99864     0.46968     0.00171     0.03477
    250     0.01408     0.14885     1.00000     0.79588    10.00000     4.36364     0.99986     0.46046     0.00105     0.03583
    258     0.01287     0.15094     1.00000     0.79577    10.00000     4.36364     1.00000     0.45586     0.00092     0.03556
    260     0.01273     0.15103     1.00000     0.79571    10.00000     4.36364     1.00000     0.45640     0.00066     0.03556
    270     0.01199     0.15353     1.00000     0.79291    10.00000     4.36364     1.00000     0.45490     0.00053     0.03635
    280     0.01137     0.15486     1.00000     0.79334    10.00000     4.45455     1.00000     0.46128     0.00053     0.03609
    290     0.01054     0.15717     1.00000     0.79132    10.00000     4.45455     1.00000     0.45503     0.00040     0.03688
    296     0.01012     0.15823     1.00000     0.79105    10.00000     4.45455     1.00000     0.44580     0.00000     0.03688
    300     0.01001     0.15877     1.00000     0.79220    10.00000     4.45455     1.00000     0.45286     0.00000     0.03688
    310     0.00944     0.16040     1.00000     0.79066    10.00000     4.45455     1.00000     0.45259     0.00000     0.03662
    320     0.00901     0.16199     1.00000     0.78860    10.00000     4.45455     1.00000     0.44485     0.00000     0.03662
    330     0.00843     0.16377     1.00000     0.78996    10.00000     4.45455     1.00000     0.43631     0.00000     0.03635
    340     0.00827     0.16451     1.00000     0.78956    10.00000     4.36364     1.00000     0.43483     0.00000     0.03635
    350     0.00803     0.16530     1.00000     0.78931    10.00000     4.45455     1.00000     0.43784     0.00000     0.03609
    360     0.00743     0.16730     1.00000     0.78982    10.00000     4.36364     1.00000     0.43727     0.00000     0.03583
    370     0.00725     0.16796     1.00000     0.79037    10.00000     4.36364     1.00000     0.44107     0.00000     0.03609
    380     0.00706     0.16880     1.00000     0.79026    10.00000     4.36364     1.00000     0.44256     0.00000     0.03583
    390     0.00677     0.17019     1.00000     0.78926    10.00000     4.36364     1.00000     0.44066     0.00000     0.03609
    400     0.00636     0.17168     1.00000     0.79034    10.00000     4.27273     1.00000     0.44758     0.00000     0.03635


 =========================================
 Variable Importance for the 15-tree Model
 =========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          33.83222   33.83 |****       |
 INCOME       33.74815   33.75 |****       |
 OTH_CHLD     30.97383   30.97 |****       |
 AGE_MOM      30.52549   30.53 |****       |
 EDUC_MOM     25.72162   25.72 |****       |
 ILLEGIT      20.20643   20.21 |***        |
 PNCLATE      17.82224   17.82 |***        |
 RACE_MOM     14.13315   14.13 |**         |
 LBW          10.84814   10.85 |**         |


 Learn Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        30.00       191.00       0.8643


 Test Sample Misclassification by Target Class
 For The 15-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3675.00        11.00       0.0030
 1                  110.00         8.00       102.00       0.9273

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               1.000 sec ( 0.00 hrs,  50.00%)
    Core model:         1.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             1.000 sec ( 0.00 hrs,  50.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 1.2 MB, 75% compression

 Grove file created containing:
      1 TreeNet

