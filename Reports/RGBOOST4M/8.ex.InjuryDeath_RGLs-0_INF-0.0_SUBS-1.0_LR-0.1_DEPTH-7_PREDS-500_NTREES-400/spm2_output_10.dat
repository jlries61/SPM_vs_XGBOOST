
 The "USE "../Data/Classification/8.ex.InjuryDeath/SAMPL" command: 00:00:01

 Model (target and predictors) reset: ANY_INJ_DTH

 The KEEP list has 10 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 7594
 Records Kept in Learning sample: 7594

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 3796
 Records Kept in Test sample: 3796

 Discrete         N Levels
 Variable         in Model
 -------------------------
 ANY_INJ_DTH             2

 ======================
 Target Frequency Table
 ======================

 Variable: ANY_INJ_DTH
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L         7373  97.09              7373.00  97.09
                 T        (3686  97.10)            (3686.00  97.10)
 1               L          221   2.91               221.00   2.91
                 T         (110   2.90)             (110.00   2.90)
 -----------------------------------------------------------------
 Totals
 0                        11059  97.09             11059.00  97.09
 1                          331   2.91               331.00   2.91
 -----------------------------------------------------------------
 Total                    11390                    11390.00
 Total Learn               7594                     7594.00
 Total Test                3796                     3796.00


 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.10712      0.12055      0.02910      0.02898      1.00000 |                                               *
      2       0.09574      0.11817      0.02831      0.02845      1.00000 |                                              *
      3       0.08865      0.11735      0.02805      0.02792      1.00000 |                                              *
      4       0.08329      0.11599      0.02739      0.02819      1.00000 |                                             *
      5       0.07886      0.11539      0.02739      0.02819      1.00000 |                                             *
      6       0.07532      0.11475      0.02713      0.02740      1.00000 |                                             *
      7       0.07245      0.11423      0.02647      0.02766      1.00000 |                                            *
      8       0.06968      0.11378      0.02594      0.02792      1.00000 |                                            *
      9       0.06698      0.11385      0.02541      0.02871      1.00000 |                                            *
     10       0.06499      0.11393      0.02449      0.02871      1.00000 |                                            *
     11       0.06326      0.11401      0.02383      0.02898      1.00000 |                                            *
     12       0.06074      0.11418      0.02357      0.02950      1.00000 |                                            *
     13       0.05901      0.11438      0.02278      0.03030      1.00000 |                                             *
     14       0.05712      0.11430      0.02252      0.03030      1.00000 |                                             *
     15       0.05554      0.11411      0.02199      0.03109      1.00000 |                                            *
     16       0.05373      0.11444      0.02120      0.03109      1.00000 |                                             *
     17       0.05233      0.11459      0.02054      0.03109      1.00000 |                                             *
     18       0.05152      0.11479      0.02002      0.03109      1.00000 |                                             *
     19       0.05064      0.11500      0.02002      0.03135      1.00000 |                                             *
     20       0.04996      0.11517      0.01975      0.03109      1.00000 |                                             *
     30       0.04261      0.11856      0.01725      0.03161      1.00000 |                                              *
     40       0.03941      0.12131      0.01580      0.03240      1.00000 |                                               *
     50       0.03489      0.12378      0.01211      0.03161      1.00000 |                                               *
     60       0.03077      0.12693      0.00974      0.03188      1.00000 |                                               *
     70       0.02841      0.12999      0.00869      0.03240      1.00000 |                                               *
     80       0.02711      0.13138      0.00777      0.03267      1.00000 |                                               *
     90       0.02590      0.13235      0.00698      0.03214      1.00000 |                                               *
    100       0.02325      0.13418      0.00514      0.03188      1.00000 |                                               *
    110       0.02144      0.13592      0.00421      0.03240      1.00000 |                                               *
    120       0.01928      0.13845      0.00263      0.03240      1.00000 |                                               *
    130       0.01786      0.14120      0.00224      0.03214      1.00000 |                                               *
    140       0.01597      0.14387      0.00119      0.03188      1.00000 |                                               *
    150       0.01458      0.14710      0.00079      0.03188      1.00000 |                                               *
    160       0.01354      0.14873      0.00053      0.03161      1.00000 |                                               *
    170       0.01255      0.15133      0.00040      0.03240      1.00000 |                                               *
    180       0.01138      0.15349      0.00026      0.03240      1.00000 |                                               *
    190       0.01033      0.15651      0.00013      0.03188      1.00000 |                                               *
    200       0.00938      0.15887      0.00013      0.03240      1.00000 |                                               *
    210       0.00850      0.16083      0.00000      0.03267      1.00000 |                                               *
    220       0.00778      0.16301      0.00000      0.03267      1.00000 |                                               *
    230       0.00718      0.16517      0.00000      0.03240      1.00000 |                                               *
    240       0.00668      0.16694      0.00000      0.03240      1.00000 |                                               *
    250       0.00636      0.16813      0.00000      0.03319      1.00000 |                                               *
    260       0.00590      0.17030      0.00000      0.03267      1.00000 |                                               *
    270       0.00561      0.17209      0.00000      0.03293      1.00000 |                                               *
    280       0.00518      0.17463      0.00000      0.03346      1.00000 |                                               *
    290       0.00488      0.17644      0.00000      0.03319      1.00000 |                                               *
    300       0.00464      0.17851      0.00000      0.03346      1.00000 |                                               *
    310       0.00438      0.18009      0.00000      0.03319      1.00000 |                                               *
    320       0.00417      0.18164      0.00000      0.03319      1.00000 |                                               *
    330       0.00379      0.18439      0.00000      0.03346      1.00000 |                                               *
    340       0.00350      0.18668      0.00000      0.03346      1.00000 |                                               *
    350       0.00315      0.19048      0.00000      0.03293      1.00000 |                                               *
    360       0.00283      0.19398      0.00000      0.03319      1.00000 |                                               *
    370       0.00266      0.19581      0.00000      0.03293      1.00000 |                                               *
    380       0.00247      0.19756      0.00000      0.03293      1.00000 |                                               *
    390       0.00235      0.19971      0.00000      0.03293      1.00000 |                                               *
    400       0.00220      0.20155      0.00000      0.03346      1.00000 |                                               *

 Core TN model building:          2.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    400      1    400      1      4      1.35      6.65  CHILDYRS
    372      1    400      1      7      3.60      4.09  AGE
    354      1    400      1      7      4.09      3.46  INCOME
    335      1    400      1      7      4.12      3.25  OTH_CHLD
    328      1    399      2      7      4.46      2.90  AGE_MOM
    327      1    400      1      7      4.36      2.97  EDUC_MOM
    291      1    400      1      7      4.93      2.23  ILLEGIT
    251      1    399      1      7      5.15      1.79  RACE_MOM
    236      1    399      2      7      5.44      1.51  PNCLATE
    192      1    397      2      7      5.14      1.37  LBW

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :   112 terminal nodes
    Average :     50.36000 terminal nodes

 Reconciling 7594 Learn sample scores across 5 selected models,
 the largest having 27 trees, to compute gains and PS tables.

 Reconciling 3796 Test sample scores across 5 selected models,
 the largest having 27 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 8

 Target: ANY_INJ_DTH
 Focus Class: 1

                     N     Weighted
 N Learn Obs:     7594      7594.00
 N Test  Obs:     3796      3796.00
 Learn Rate :    0.1000000

 Storage requirements: 39888 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL            8      0.11378
                  ROC           15      0.81411
                 Lift           27      4.54545
              KS-stat           17      0.51717
          Class.Error            6      0.02740

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.10712     0.12055     0.93098     0.71509     7.52192     4.04148     0.70378     0.41308     0.02910     0.02898
      6     0.07532     0.11475     0.97630     0.80173     9.32127     4.00000     0.86630     0.49857     0.02713     0.02740
      8     0.06968     0.11378     0.98138     0.80740     9.59276     4.20000     0.89458     0.50484     0.02594     0.02792
     10     0.06499     0.11393     0.98342     0.81083     9.63801     4.18182     0.90186     0.50249     0.02449     0.02871
     15     0.05554     0.11411     0.98896     0.81411     9.81900     4.18182     0.92923     0.51214     0.02199     0.03109
     17     0.05233     0.11459     0.99131     0.81045     9.81900     4.18182     0.93294     0.51717     0.02054     0.03109
     20     0.04996     0.11517     0.99248     0.80936     9.86425     4.36364     0.93669     0.50129     0.01975     0.03109
     27     0.04404     0.11752     0.99656     0.80684     9.95475     4.54545     0.96233     0.50929     0.01791     0.03161
     30     0.04261     0.11856     0.99697     0.80183     9.95475     4.45455     0.96767     0.49545     0.01725     0.03161
     40     0.03941     0.12131     0.99747     0.79915     9.95475     4.45455     0.96862     0.50592     0.01580     0.03240
     50     0.03489     0.12378     0.99836     0.79929     9.95475     4.54545     0.97255     0.50008     0.01211     0.03161
     57     0.03132     0.12644     0.99929     0.79574    10.00000     4.45455     0.98237     0.49235     0.01040     0.03188
     60     0.03077     0.12693     0.99937     0.79546    10.00000     4.45455     0.98305     0.49046     0.00974     0.03188
     70     0.02841     0.12999     0.99961     0.79134    10.00000     4.14545     0.98589     0.47971     0.00869     0.03240
     80     0.02711     0.13138     0.99973     0.79305    10.00000     4.36364     0.98969     0.48015     0.00777     0.03267
     90     0.02590     0.13235     0.99979     0.79455    10.00000     4.32727     0.99430     0.48313     0.00698     0.03214
    100     0.02325     0.13418     0.99995     0.79443    10.00000     4.27273     0.99688     0.48340     0.00514     0.03188
    110     0.02144     0.13592     0.99998     0.79390    10.00000     4.18182     0.99919     0.49358     0.00421     0.03240
    120     0.01928     0.13845     0.99999     0.79123    10.00000     4.00000     0.99959     0.49208     0.00263     0.03240
    130     0.01786     0.14120     1.00000     0.78997    10.00000     4.00000     0.99973     0.48598     0.00224     0.03214
    140     0.01597     0.14387     1.00000     0.78807    10.00000     3.90909     0.99973     0.45858     0.00119     0.03188
    150     0.01458     0.14710     1.00000     0.78381    10.00000     3.81818     0.99986     0.44715     0.00079     0.03188
    160     0.01354     0.14873     1.00000     0.78329    10.00000     3.63636     0.99986     0.44786     0.00053     0.03161
    170     0.01255     0.15133     1.00000     0.78139    10.00000     3.72727     1.00000     0.45274     0.00040     0.03240
    180     0.01138     0.15349     1.00000     0.78062    10.00000     3.72727     1.00000     0.45721     0.00026     0.03240
    190     0.01033     0.15651     1.00000     0.78078    10.00000     3.81818     1.00000     0.46006     0.00013     0.03188
    200     0.00938     0.15887     1.00000     0.77971    10.00000     3.81818     1.00000     0.44623     0.00013     0.03240
    204     0.00906     0.15942     1.00000     0.77977    10.00000     3.81818     1.00000     0.44811     0.00000     0.03267
    210     0.00850     0.16083     1.00000     0.77975    10.00000     4.00000     1.00000     0.44174     0.00000     0.03267
    220     0.00778     0.16301     1.00000     0.78004    10.00000     3.90909     1.00000     0.45707     0.00000     0.03267
    230     0.00718     0.16517     1.00000     0.77977    10.00000     3.90909     1.00000     0.44675     0.00000     0.03240
    240     0.00668     0.16694     1.00000     0.77924    10.00000     4.09091     1.00000     0.44093     0.00000     0.03240
    250     0.00636     0.16813     1.00000     0.77892    10.00000     3.90909     1.00000     0.44620     0.00000     0.03319
    260     0.00590     0.17030     1.00000     0.77828    10.00000     4.00000     1.00000     0.45244     0.00000     0.03267
    270     0.00561     0.17209     1.00000     0.77744    10.00000     3.90909     1.00000     0.45814     0.00000     0.03293
    280     0.00518     0.17463     1.00000     0.77676    10.00000     3.81818     1.00000     0.45896     0.00000     0.03346
    290     0.00488     0.17644     1.00000     0.77673    10.00000     3.90909     1.00000     0.45706     0.00000     0.03319
    300     0.00464     0.17851     1.00000     0.77656    10.00000     3.81818     1.00000     0.45081     0.00000     0.03346
    310     0.00438     0.18009     1.00000     0.77592    10.00000     3.90909     1.00000     0.45380     0.00000     0.03319
    320     0.00417     0.18164     1.00000     0.77475    10.00000     3.81818     1.00000     0.45542     0.00000     0.03319
    330     0.00379     0.18439     1.00000     0.77097    10.00000     3.81818     1.00000     0.44443     0.00000     0.03346
    340     0.00350     0.18668     1.00000     0.77187    10.00000     3.81818     1.00000     0.44118     0.00000     0.03346
    350     0.00315     0.19048     1.00000     0.77077    10.00000     3.63636     1.00000     0.43887     0.00000     0.03293
    360     0.00283     0.19398     1.00000     0.76943    10.00000     3.63636     1.00000     0.43495     0.00000     0.03319
    370     0.00266     0.19581     1.00000     0.76951    10.00000     3.63636     1.00000     0.44065     0.00000     0.03293
    380     0.00247     0.19756     1.00000     0.76898    10.00000     3.54545     1.00000     0.43592     0.00000     0.03293
    390     0.00235     0.19971     1.00000     0.76695    10.00000     3.50909     1.00000     0.42261     0.00000     0.03293
    400     0.00220     0.20155     1.00000     0.76690    10.00000     3.45455     1.00000     0.42532     0.00000     0.03346


 ========================================
 Variable Importance for the 8-tree Model
 ========================================

                   Abs     Rel

 CHILDYRS    100.00000  100.00 |***********|
 AGE          37.04313   37.04 |*****      |
 EDUC_MOM     32.41664   32.42 |****       |
 AGE_MOM      32.27939   32.28 |****       |
 OTH_CHLD     29.70458   29.70 |****       |
 INCOME       25.85123   25.85 |****       |
 ILLEGIT      19.78101   19.78 |***        |
 RACE_MOM     18.96113   18.96 |***        |
 PNCLATE      15.40261   15.40 |**         |
 LBW          14.56473   14.56 |**         |


 Learn Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 7373.00      7371.00         2.00       0.0003
 1                  221.00        26.00       195.00       0.8824


 Test Sample Misclassification by Target Class
 For The 8-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                 3686.00      3681.00         5.00       0.0014
 1                  110.00         9.00       101.00       0.9182

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                2.000 sec ( 0.00 hrs)
  LOADDATA 1:           0.000 sec ( 0.00 hrs,   0.00%)
  MARTGO:               2.000 sec ( 0.00 hrs, 100.00%)
    Core model:         2.000 sec ( 0.00 hrs, 100.00%)
  MARTPRED:             0.000 sec ( 0.00 hrs,   0.00%)
  PLOTS/INTER:          0.000 sec ( 0.00 hrs,   0.00%)

  Reconciling (LEARN):       0.000000 hrs  0.00%

  Reconciling (TEST ):       0.000000 hrs  0.00%


 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet2_model.grv: 1.7 MB, 75% compression

 Grove file created containing:
      1 TreeNet

