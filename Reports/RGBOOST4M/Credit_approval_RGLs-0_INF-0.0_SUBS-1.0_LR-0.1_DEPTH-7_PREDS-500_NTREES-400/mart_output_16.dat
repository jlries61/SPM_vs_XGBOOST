
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 51 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A2        0.0202
 A14       0.0173

             Test
 ----------------
 A2        0.0174
 A14       0.0116

 No learn sample variance for: A7_O.
 No test sample variance for: A4_L.
 No test sample variance for: A7_N.
 No test sample variance for: A5_GG.



 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.62051      0.62454      0.23699      0.25581      1.00000 |                                               *
      2       0.56612      0.57663      0.13584      0.14535      1.00000 |                                           *
      3       0.52022      0.53620      0.11561      0.15698      1.00000 |                                        *
      4       0.48059      0.50341      0.08671      0.12791      1.00000 |                                      *
      5       0.44535      0.47013      0.08092      0.11628      1.00000 |                                   *
      6       0.41447      0.44342      0.08092      0.12209      1.00000 |                                 *
      7       0.38885      0.42326      0.07514      0.11628      1.00000 |                                *
      8       0.36594      0.40202      0.07803      0.11047      1.00000 |                              *
      9       0.34522      0.38864      0.07514      0.11628      1.00000 |                             *
     10       0.32708      0.37121      0.07514      0.11628      1.00000 |                            *
     11       0.30982      0.36097      0.07803      0.11047      1.00000 |                           *
     12       0.29320      0.35326      0.07514      0.11047      1.00000 |                          *
     13       0.27907      0.34340      0.07514      0.10465      1.00000 |                         *
     14       0.26586      0.33589      0.06936      0.10465      1.00000 |                         *
     15       0.25473      0.32557      0.06936      0.11047      1.00000 |                        *
     16       0.24360      0.32240      0.07225      0.09884      1.00000 |                        *
     17       0.23314      0.31846      0.07225      0.11047      1.00000 |                       *
     18       0.22468      0.31391      0.06358      0.12209      1.00000 |                       *
     19       0.21316      0.30928      0.06358      0.11047      1.00000 |                       *
     20       0.20528      0.30536      0.06069      0.11047      1.00000 |                      *
     30       0.13614      0.29165      0.02601      0.10465      1.00000 |                     *
     40       0.10094      0.29308      0.01734      0.09884      1.00000 |                      *
     50       0.07469      0.29289      0.00289      0.09302      1.00000 |                      *
     60       0.05865      0.29701      0.00000      0.11047      1.00000 |                      *
     70       0.04066      0.31239      0.00000      0.11628      1.00000 |                       *
     80       0.02987      0.32966      0.00000      0.11628      1.00000 |                        *
     90       0.02213      0.34486      0.00000      0.11628      1.00000 |                          *
    100       0.01710      0.35586      0.00000      0.11628      1.00000 |                          *
    110       0.01245      0.36589      0.00000      0.11047      1.00000 |                           *
    120       0.00931      0.38305      0.00000      0.11628      1.00000 |                            *
    130       0.00705      0.40023      0.00000      0.12791      1.00000 |                              *
    140       0.00518      0.40805      0.00000      0.11047      1.00000 |                              *
    150       0.00396      0.42037      0.00000      0.11047      1.00000 |                               *
    160       0.00296      0.43350      0.00000      0.11047      1.00000 |                                *
    170       0.00224      0.45233      0.00000      0.10465      1.00000 |                                  *
    180       0.00165      0.47403      0.00000      0.12209      1.00000 |                                   *
    190       0.00127      0.49333      0.00000      0.12791      1.00000 |                                     *
    200       0.00094      0.51104      0.00000      0.12209      1.00000 |                                      *
    210       0.00071      0.52519      0.00000      0.12791      1.00000 |                                       *
    220       0.00055      0.54759      0.00000      0.12791      1.00000 |                                         *
    230       0.00043      0.56461      0.00000      0.12209      1.00000 |                                          *
    240       0.00032      0.58108      0.00000      0.12209      1.00000 |                                            *
    250       0.00024      0.59939      0.00000      0.12791      1.00000 |                                             *
    260       0.00019      0.61543      0.00000      0.12209      1.00000 |                                              *
    270       0.00015      0.63271      0.00000      0.12209      1.00000 |                                               *
    280       0.00011      0.65030      0.00000      0.12791      1.00000 |                                               *
    290       0.00008      0.67384      0.00000      0.12209      1.00000 |                                               *
    300       0.00006      0.69594      0.00000      0.12209      1.00000 |                                               *
    310       0.00004      0.71325      0.00000      0.12209      1.00000 |                                               *
    320       0.00003      0.73731      0.00000      0.12209      1.00000 |                                               *
    330       0.00003      0.75883      0.00000      0.12209      1.00000 |                                               *
    340       0.00002      0.77038      0.00000      0.12209      1.00000 |                                               *
    350       0.00002      0.79089      0.00000      0.12209      1.00000 |                                               *
    360       0.00001      0.80682      0.00000      0.11628      1.00000 |                                               *
    370       0.00001      0.82656      0.00000      0.12209      1.00000 |                                               *
    380       0.00001      0.84641      0.00000      0.12209      1.00000 |                                               *
    390       0.00001      0.86131      0.00000      0.12209      1.00000 |                                               *
    400       0.00000      0.88105      0.00000      0.11628      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    392      1    400      1      7      3.00      4.90  A14
    385      1    400      2      7      3.75      4.09  A2
    369      1    400      1      7      3.42      4.22  A3
    347      1    400      1      7      3.87      3.58  A8
    329      1    399      1      7      3.77      3.48  A15
    243      1    400      1      7      2.05      3.62  A9_T
    237      2    399      1      7      3.83      2.47  A11
     88     18    400      1      7      3.81      0.92  A4_Y
     69     15    397      3      7      5.46      0.44  A12_F
     65      3    399      2      7      4.74      0.53  A6_Q
     64      9    397      3      7      5.52      0.40  A7_V
     59      4    395      1      6      2.58      0.80  A7_H
     54      2    387      2      7      5.00      0.41  A1_A
     51      1    395      2      7      3.04      0.63  A10_F
     49     15    392      3      7      5.06      0.36  A4_U
     44     37    398      1      7      3.48      0.50  A6_CC
     39     14    376      2      7      4.90      0.30  A6_C
     37     50    400      2      7      4.24      0.35  A6_W
     31     18    400      3      7      5.23      0.22  A12_T
     27     62    362      2      4      2.41      0.38  A6_AA
     23      6    384      3      7      4.09      0.23  A6_K
     22     13    393      2      4      3.00      0.28  A6_X
     20      6    387      3      7      5.40      0.13  A1_B
     18    116    396      2      7      4.61      0.15  A13_S
     18     52    377      1      7      5.44      0.12  A9_F
     14     67    379      2      7      4.00      0.14  A7_BB
     11     28    195      2      2      2.00      0.17  A6_M
     10     70    242      5      7      6.00      0.05  A6_D
      4    184    384      1      6      3.25      0.05  A6_FF
      3     95    235      4      7      5.67      0.02  A13_G
      0      0      0      0      0      0.00      0.00  A4_L
      0      0      0      0      0      0.00      0.00  A4_MISS
      0      0      0      0      0      0.00      0.00  A1_MISS
      0      0      0      0      0      0.00      0.00  A6_R
      0      0      0      0      0      0.00      0.00  A5_MISS
      0      0      0      0      0      0.00      0.00  A5_P
      0      0      0      0      0      0.00      0.00  A5_G
      0      0      0      0      0      0.00      0.00  A10_T
      0      0      0      0      0      0.00      0.00  A7_N
      0      0      0      0      0      0.00      0.00  A7_DD
      0      0      0      0      0      0.00      0.00  A7_O
      0      0      0      0      0      0.00      0.00  A7_MISS
      0      0      0      0      0      0.00      0.00  A7_Z
      0      0      0      0      0      0.00      0.00  A6_I
      0      0      0      0      0      0.00      0.00  A5_GG
      0      0      0      0      0      0.00      0.00  A6_J
      0      0      0      0      0      0.00      0.00  A6_MISS
      0      0      0      0      0      0.00      0.00  A13_P
      0      0      0      0      0      0.00      0.00  A7_J
      0      0      0      0      0      0.00      0.00  A7_FF
      0      0      0      0      0      0.00      0.00  A6_E

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    10 terminal nodes
    Largest :    29 terminal nodes
    Average :     19.85000 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 42 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 42 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 34

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 15480 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           34      0.28868
                  ROC            8      0.94894
                 Lift            6      2.26316
              KS-stat            6      0.83279
          Class.Error           42      0.09302

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.62051     0.62454     0.96571     0.94052     2.24675     2.16029     0.79322     0.79002     0.23699     0.25581
      6     0.41447     0.44342     0.97998     0.94538     2.24675     2.26316     0.84652     0.83279     0.08092     0.12209
      8     0.36594     0.40202     0.98052     0.94894     2.24675     2.26316     0.85045     0.83279     0.07803     0.11047
     10     0.32708     0.37121     0.98253     0.94730     2.24675     2.13158     0.84916     0.81963     0.07514     0.11628
     20     0.20528     0.30536     0.99073     0.94367     2.24675     2.13158     0.90517     0.80866     0.06069     0.11047
     30     0.13614     0.29165     0.99679     0.94038     2.24675     2.13158     0.95583     0.81140     0.02601     0.10465
     34     0.11862     0.28868     0.99848     0.94010     2.24675     2.13158     0.96489     0.82182     0.02023     0.09884
     40     0.10094     0.29308     0.99953     0.93805     2.24675     2.13158     0.98438     0.82182     0.01734     0.09884
     42     0.09362     0.29083     0.99976     0.94134     2.24675     2.13158     0.99479     0.82950     0.01156     0.09302
     50     0.07469     0.29289     1.00000     0.94120     2.24675     2.13158     1.00000     0.82950     0.00289     0.09302
     58     0.06186     0.29424     1.00000     0.94353     2.24675     2.13158     1.00000     0.82950     0.00000     0.11628
     60     0.05865     0.29701     1.00000     0.94298     2.24675     2.13158     1.00000     0.81908     0.00000     0.11047
     70     0.04066     0.31239     1.00000     0.94010     2.24675     2.13158     1.00000     0.81634     0.00000     0.11628
     80     0.02987     0.32966     1.00000     0.93887     2.24675     2.26316     1.00000     0.79825     0.00000     0.11628
     90     0.02213     0.34486     1.00000     0.93668     2.24675     2.26316     1.00000     0.79057     0.00000     0.11628
    100     0.01710     0.35586     1.00000     0.93736     2.24675     2.26316     1.00000     0.80373     0.00000     0.11628
    110     0.01245     0.36589     1.00000     0.93640     2.24675     2.26316     1.00000     0.80373     0.00000     0.11047
    120     0.00931     0.38305     1.00000     0.93517     2.24675     2.26316     1.00000     0.80373     0.00000     0.11628
    130     0.00705     0.40023     1.00000     0.93544     2.24675     2.26316     1.00000     0.80373     0.00000     0.12791
    140     0.00518     0.40805     1.00000     0.93490     2.24675     2.26316     1.00000     0.78564     0.00000     0.11047
    150     0.00396     0.42037     1.00000     0.93421     2.24675     2.26316     1.00000     0.78564     0.00000     0.11047
    160     0.00296     0.43350     1.00000     0.93517     2.24675     2.26316     1.00000     0.78564     0.00000     0.11047
    170     0.00224     0.45233     1.00000     0.93572     2.24675     2.26316     1.00000     0.79605     0.00000     0.10465
    180     0.00165     0.47403     1.00000     0.93517     2.24675     2.26316     1.00000     0.78564     0.00000     0.12209
    190     0.00127     0.49333     1.00000     0.93476     2.24675     2.26316     1.00000     0.77522     0.00000     0.12791
    200     0.00094     0.51104     1.00000     0.93298     2.24675     2.26316     1.00000     0.76974     0.00000     0.12209
    210     0.00071     0.52519     1.00000     0.93284     2.24675     2.26316     1.00000     0.77522     0.00000     0.12791
    220     0.00055     0.54759     1.00000     0.93298     2.24675     2.26316     1.00000     0.77522     0.00000     0.12791
    230     0.00043     0.56461     1.00000     0.93257     2.24675     2.26316     1.00000     0.76974     0.00000     0.12209
    240     0.00032     0.58108     1.00000     0.93161     2.24675     2.26316     1.00000     0.77522     0.00000     0.12209
    250     0.00024     0.59939     1.00000     0.93243     2.24675     2.26316     1.00000     0.77522     0.00000     0.12791
    260     0.00019     0.61543     1.00000     0.93202     2.24675     2.26316     1.00000     0.77522     0.00000     0.12209
    270     0.00015     0.63271     1.00000     0.93078     2.24675     2.26316     1.00000     0.77522     0.00000     0.12209
    280     0.00011     0.65030     1.00000     0.93092     2.24675     2.26316     1.00000     0.77522     0.00000     0.12791
    290     0.00008     0.67384     1.00000     0.92928     2.24675     2.26316     1.00000     0.77522     0.00000     0.12209
    300     0.00006     0.69594     1.00000     0.92859     2.24675     2.26316     1.00000     0.77248     0.00000     0.12209
    310     0.00004     0.71325     1.00000     0.92791     2.24675     2.26316     1.00000     0.77248     0.00000     0.12209
    320     0.00003     0.73731     1.00000     0.92640     2.24675     2.26316     1.00000     0.77248     0.00000     0.12209
    330     0.00003     0.75883     1.00000     0.92516     2.24675     2.26316     1.00000     0.77248     0.00000     0.12209
    340     0.00002     0.77038     1.00000     0.92558     2.24675     2.26316     1.00000     0.77248     0.00000     0.12209
    350     0.00002     0.79089     1.00000     0.92489     2.24675     2.26316     1.00000     0.76974     0.00000     0.12209
    360     0.00001     0.80682     1.00000     0.92475     2.24675     2.26316     1.00000     0.77248     0.00000     0.11628
    370     0.00001     0.82656     1.00000     0.92393     2.24675     2.26316     1.00000     0.76974     0.00000     0.12209
    380     0.00001     0.84641     1.00000     0.92421     2.24675     2.26316     1.00000     0.76974     0.00000     0.12209
    390     0.00001     0.86131     1.00000     0.92516     2.24675     2.26316     1.00000     0.76974     0.00000     0.12209
    400     0.00000     0.88105     1.00000     0.92379     2.24675     2.26316     1.00000     0.76974     0.00000     0.11628


 =========================================
 Variable Importance for the 34-tree Model
 =========================================

                  Abs     Rel

 A9_T       100.00000  100.00 |***********|
 A14         31.92624   31.93 |****       |
 A15         28.94645   28.95 |****       |
 A3          28.31014   28.31 |****       |
 A8          25.67805   25.68 |****       |
 A11         24.76156   24.76 |***        |
 A2          23.42143   23.42 |***        |
 A10_F       20.48380   20.48 |***        |
 A7_H        12.43438   12.43 |**         |
 A4_Y         6.83933    6.84 |**         |
 A7_V         6.07413    6.07 |**         |
 A1_A         5.28791    5.29 |*          |
 A6_C         4.67067    4.67 |*          |
 A4_U         4.07282    4.07 |*          |
 A12_F        3.72695    3.73 |*          |
 A6_Q         3.12169    3.12 |*          |
 A6_K         3.05780    3.06 |*          |
 A6_M         2.24640    2.25 |*          |
 A12_T        2.15257    2.15 |*          |
 A6_X         2.02125    2.02 |*          |
 A1_B         0.05399    0.05 |*          |


 Learn Sample Misclassification by Target Class
 For The 34-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       190.00         2.00       0.0104
 1                  154.00       149.00         5.00       0.0325


 Test Sample Misclassification by Target Class
 For The 34-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        86.00        10.00       0.1042
 1                   76.00        69.00         7.00       0.0921

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 649 kb , 78% compression

 Grove file created containing:
      1 TreeNet

