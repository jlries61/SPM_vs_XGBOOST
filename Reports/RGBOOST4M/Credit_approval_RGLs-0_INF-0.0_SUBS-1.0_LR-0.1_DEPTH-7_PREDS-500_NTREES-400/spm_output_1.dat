
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 51 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A2        0.0260
 A14       0.0173

             Test
 ----------------
 A14       0.0174
 A2        0.0058

 No learn sample variance for: A4_L.
 No learn sample variance for: A6_R.
 No learn sample variance for: A5_GG.
 No test sample variance for: A7_Z.



 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.62016      0.63167      0.17919      0.23837      1.00000 |                                               *
      2       0.56435      0.58613      0.13873      0.20349      1.00000 |                                            *
      3       0.51886      0.55161      0.11561      0.18023      1.00000 |                                         *
      4       0.47970      0.51898      0.09249      0.16860      1.00000 |                                      *
      5       0.44627      0.49150      0.08960      0.15698      1.00000 |                                    *
      6       0.41771      0.47152      0.09249      0.15698      1.00000 |                                   *
      7       0.39203      0.45127      0.09249      0.15116      1.00000 |                                 *
      8       0.36940      0.43354      0.08960      0.16860      1.00000 |                                *
      9       0.34951      0.41880      0.09538      0.15698      1.00000 |                               *
     10       0.33204      0.40419      0.08960      0.15698      1.00000 |                              *
     11       0.31623      0.39622      0.08960      0.16279      1.00000 |                             *
     12       0.30248      0.38555      0.08960      0.16279      1.00000 |                            *
     13       0.28926      0.37811      0.08671      0.15116      1.00000 |                            *
     14       0.27830      0.36957      0.08382      0.15116      1.00000 |                           *
     15       0.26814      0.36625      0.07514      0.15116      1.00000 |                           *
     16       0.25928      0.36085      0.07514      0.15116      1.00000 |                          *
     17       0.24918      0.35728      0.08092      0.15116      1.00000 |                          *
     18       0.24001      0.35299      0.08092      0.14535      1.00000 |                          *
     19       0.23253      0.35178      0.07803      0.13953      1.00000 |                          *
     20       0.22522      0.35090      0.07514      0.13953      1.00000 |                          *
     30       0.16213      0.34707      0.06069      0.14535      1.00000 |                         *
     40       0.12312      0.36443      0.02023      0.13953      1.00000 |                           *
     50       0.08880      0.38174      0.00867      0.15698      1.00000 |                            *
     60       0.06796      0.39159      0.00000      0.14535      1.00000 |                             *
     70       0.05196      0.40540      0.00000      0.13953      1.00000 |                              *
     80       0.04039      0.42255      0.00000      0.13953      1.00000 |                               *
     90       0.02948      0.44597      0.00000      0.14535      1.00000 |                                 *
    100       0.02184      0.46814      0.00000      0.16279      1.00000 |                                   *
    110       0.01737      0.48370      0.00000      0.15116      1.00000 |                                    *
    120       0.01297      0.50563      0.00000      0.15116      1.00000 |                                     *
    130       0.00933      0.52603      0.00000      0.15116      1.00000 |                                       *
    140       0.00687      0.54873      0.00000      0.15116      1.00000 |                                         *
    150       0.00522      0.57180      0.00000      0.15116      1.00000 |                                          *
    160       0.00410      0.59610      0.00000      0.15116      1.00000 |                                            *
    170       0.00320      0.61370      0.00000      0.15698      1.00000 |                                              *
    180       0.00247      0.63122      0.00000      0.15698      1.00000 |                                               *
    190       0.00184      0.64670      0.00000      0.15698      1.00000 |                                               *
    200       0.00139      0.66504      0.00000      0.15698      1.00000 |                                               *
    210       0.00102      0.69837      0.00000      0.15698      1.00000 |                                               *
    220       0.00082      0.72136      0.00000      0.15698      1.00000 |                                               *
    230       0.00061      0.74657      0.00000      0.16279      1.00000 |                                               *
    240       0.00050      0.76594      0.00000      0.16860      1.00000 |                                               *
    250       0.00038      0.78902      0.00000      0.16860      1.00000 |                                               *
    260       0.00029      0.81446      0.00000      0.16860      1.00000 |                                               *
    270       0.00022      0.82900      0.00000      0.16279      1.00000 |                                               *
    280       0.00017      0.85189      0.00000      0.15698      1.00000 |                                               *
    290       0.00014      0.86983      0.00000      0.16279      1.00000 |                                               *
    300       0.00011      0.88461      0.00000      0.16279      1.00000 |                                               *
    310       0.00008      0.91010      0.00000      0.16279      1.00000 |                                               *
    320       0.00006      0.92707      0.00000      0.15698      1.00000 |                                               *
    330       0.00005      0.94826      0.00000      0.15698      1.00000 |                                               *
    340       0.00004      0.97106      0.00000      0.15698      1.00000 |                                               *
    350       0.00003      1.00003      0.00000      0.15698      1.00000 |                                               *
    360       0.00002      1.02256      0.00000      0.15698      1.00000 |                                               *
    370       0.00002      1.04120      0.00000      0.15698      1.00000 |                                               *
    380       0.00001      1.06673      0.00000      0.15698      1.00000 |                                               *
    390       0.00001      1.09297      0.00000      0.15698      1.00000 |                                               *
    400       0.00001      1.12352      0.00000      0.15698      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    387      1    400      1      7      3.71      4.15  A2
    381      1    400      1      7      3.46      4.33  A3
    357      1    400      1      7      3.51      4.01  A14
    345      1    400      1      7      4.32      3.18  A8
    305      1    400      1      7      3.90      3.12  A15
    242      1    400      1      7      3.95      2.45  A11
    131      1    398      1      7      2.91      1.67  A9_F
    121      2    400      1      7      3.03      1.50  A9_T
     90      8    394      1      7      4.71      0.74  A4_U
     89     28    392      2      7      3.89      0.92  A1_A
     72     10    400      1      7      3.76      0.76  A4_Y
     72     20    397      3      7      5.42      0.47  A7_V
     68     37    399      2      7      4.97      0.52  A1_B
     68     23    400      3      7      4.91      0.53  A6_C
     66     23    393      1      5      1.36      1.10  A6_X
     54     33    392      1      6      2.54      0.74  A6_AA
     53      5    400      3      7      5.21      0.37  A6_Q
     49     29    389      1      7      3.06      0.61  A7_FF
     48     29    385      1      6      2.33      0.68  A6_K
     46     13    396      3      7      5.43      0.30  A12_T
     42     18    397      3      7      5.67      0.25  A12_F
     42      7    395      3      7      5.33      0.28  A10_F
     41     37    388      3      7      5.90      0.22  A13_G
     41      1    385      2      6      4.22      0.39  A6_W
     40     15    398      3      7      5.20      0.28  A7_H
     33     51    379      1      7      3.76      0.35  A6_I
     30     42    394      1      2      1.07      0.52  A6_E
     29     32    393      2      7      3.93      0.30  A13_S
     26     63    397      4      7      5.46      0.17  A7_BB
     10    162    357      1      5      3.60      0.11  A6_CC
      4     87    251      5      5      5.00      0.03  A6_M
      1    295    295      1      1      1.00      0.02  A6_D
      0      0      0      0      0      0.00      0.00  A5_G
      0      0      0      0      0      0.00      0.00  A10_T
      0      0      0      0      0      0.00      0.00  A5_P
      0      0      0      0      0      0.00      0.00  A7_N
      0      0      0      0      0      0.00      0.00  A5_MISS
      0      0      0      0      0      0.00      0.00  A7_DD
      0      0      0      0      0      0.00      0.00  A7_O
      0      0      0      0      0      0.00      0.00  A1_MISS
      0      0      0      0      0      0.00      0.00  A7_MISS
      0      0      0      0      0      0.00      0.00  A7_Z
      0      0      0      0      0      0.00      0.00  A6_FF
      0      0      0      0      0      0.00      0.00  A6_J
      0      0      0      0      0      0.00      0.00  A6_MISS
      0      0      0      0      0      0.00      0.00  A6_R
      0      0      0      0      0      0.00      0.00  A13_P
      0      0      0      0      0      0.00      0.00  A4_MISS
      0      0      0      0      0      0.00      0.00  A4_L
      0      0      0      0      0      0.00      0.00  A7_J
      0      0      0      0      0      0.00      0.00  A5_GG

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     8 terminal nodes
    Largest :    30 terminal nodes
    Average :     19.10000 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 28 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 27

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 14880 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           27      0.34571
                  ROC           28      0.92133
                 Lift            3      2.25658
              KS-stat           18      0.75439
          Class.Error           24      0.12791

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.62016     0.63167     0.96610     0.87685     2.24675     1.82668     0.77760     0.67544     0.17919     0.23837
      3     0.51886     0.55161     0.97174     0.90604     2.24675     2.25658     0.80756     0.69627     0.11561     0.18023
     10     0.33204     0.40419     0.97697     0.91598     2.24675     2.23684     0.82576     0.72094     0.08960     0.15698
     18     0.24001     0.35299     0.98128     0.91845     2.24675     2.13158     0.84930     0.75439     0.08092     0.14535
     20     0.22522     0.35090     0.98238     0.91379     2.24675     2.00000     0.85450     0.72807     0.07514     0.13953
     24     0.19878     0.34680     0.98624     0.91721     2.24675     2.10526     0.86093     0.74890     0.06936     0.12791
     27     0.17841     0.34571     0.98913     0.91982     2.24675     2.00000     0.88805     0.73794     0.06358     0.13372
     28     0.17324     0.34633     0.98994     0.92133     2.24675     2.00000     0.89847     0.73794     0.06069     0.13953
     30     0.16213     0.34707     0.99198     0.91982     2.24675     2.00000     0.90889     0.73794     0.06069     0.14535
     40     0.12312     0.36443     0.99817     0.91434     2.24675     2.00000     0.96361     0.74068     0.02023     0.13953
     50     0.08880     0.38174     0.99986     0.91214     2.24675     1.97368     0.98830     0.72807     0.00867     0.15698
     52     0.08423     0.38470     1.00000     0.91228     2.24675     1.97368     1.00000     0.72971     0.00289     0.15698
     53     0.08125     0.38690     1.00000     0.91160     2.24675     2.00000     1.00000     0.71930     0.00000     0.15116
     60     0.06796     0.39159     1.00000     0.91146     2.24675     2.00000     1.00000     0.74287     0.00000     0.14535
     70     0.05196     0.40540     1.00000     0.91146     2.24675     2.00000     1.00000     0.75329     0.00000     0.13953
     80     0.04039     0.42255     1.00000     0.91064     2.24675     2.00000     1.00000     0.73575     0.00000     0.13953
     90     0.02948     0.44597     1.00000     0.90927     2.24675     2.00000     1.00000     0.73575     0.00000     0.14535
    100     0.02184     0.46814     1.00000     0.90872     2.24675     2.00000     1.00000     0.74123     0.00000     0.16279
    110     0.01737     0.48370     1.00000     0.90844     2.24675     2.00000     1.00000     0.73575     0.00000     0.15116
    120     0.01297     0.50563     1.00000     0.90872     2.24675     2.00000     1.00000     0.73575     0.00000     0.15116
    130     0.00933     0.52603     1.00000     0.90995     2.24675     2.00000     1.00000     0.73849     0.00000     0.15116
    140     0.00687     0.54873     1.00000     0.90995     2.24675     2.00000     1.00000     0.73849     0.00000     0.15116
    150     0.00522     0.57180     1.00000     0.91036     2.24675     2.00000     1.00000     0.73849     0.00000     0.15116
    160     0.00410     0.59610     1.00000     0.90954     2.24675     2.00000     1.00000     0.72807     0.00000     0.15116
    170     0.00320     0.61370     1.00000     0.90913     2.24675     2.00000     1.00000     0.72807     0.00000     0.15698
    180     0.00247     0.63122     1.00000     0.91022     2.24675     2.00000     1.00000     0.72807     0.00000     0.15698
    190     0.00184     0.64670     1.00000     0.91077     2.24675     2.00000     1.00000     0.72807     0.00000     0.15698
    200     0.00139     0.66504     1.00000     0.91091     2.24675     2.00000     1.00000     0.72807     0.00000     0.15698
    210     0.00102     0.69837     1.00000     0.90913     2.24675     2.00000     1.00000     0.72807     0.00000     0.15698
    220     0.00082     0.72136     1.00000     0.90803     2.24675     2.00000     1.00000     0.71765     0.00000     0.15698
    230     0.00061     0.74657     1.00000     0.90831     2.24675     2.00000     1.00000     0.71765     0.00000     0.16279
    240     0.00050     0.76594     1.00000     0.90735     2.24675     2.00000     1.00000     0.72533     0.00000     0.16860
    250     0.00038     0.78902     1.00000     0.90762     2.24675     2.00000     1.00000     0.72807     0.00000     0.16860
    260     0.00029     0.81446     1.00000     0.90694     2.24675     2.00000     1.00000     0.72533     0.00000     0.16860
    270     0.00022     0.82900     1.00000     0.90858     2.24675     2.00000     1.00000     0.72807     0.00000     0.16279
    280     0.00017     0.85189     1.00000     0.90817     2.24675     2.00000     1.00000     0.72533     0.00000     0.15698
    290     0.00014     0.86983     1.00000     0.90789     2.24675     2.00000     1.00000     0.72533     0.00000     0.16279
    300     0.00011     0.88461     1.00000     0.90817     2.24675     2.00000     1.00000     0.72533     0.00000     0.16279
    310     0.00008     0.91010     1.00000     0.90789     2.24675     2.00000     1.00000     0.72533     0.00000     0.16279
    320     0.00006     0.92707     1.00000     0.90844     2.24675     2.00000     1.00000     0.72533     0.00000     0.15698
    330     0.00005     0.94826     1.00000     0.90858     2.24675     2.00000     1.00000     0.72533     0.00000     0.15698
    340     0.00004     0.97106     1.00000     0.90885     2.24675     2.00000     1.00000     0.71765     0.00000     0.15698
    350     0.00003     1.00003     1.00000     0.90831     2.24675     2.00000     1.00000     0.71765     0.00000     0.15698
    360     0.00002     1.02256     1.00000     0.90858     2.24675     2.13158     1.00000     0.72039     0.00000     0.15698
    370     0.00002     1.04120     1.00000     0.90803     2.24675     2.13158     1.00000     0.72039     0.00000     0.15698
    380     0.00001     1.06673     1.00000     0.90748     2.24675     2.10526     1.00000     0.72039     0.00000     0.15698
    390     0.00001     1.09297     1.00000     0.90748     2.24675     2.13158     1.00000     0.72039     0.00000     0.15698
    400     0.00001     1.12352     1.00000     0.90639     2.24675     2.13158     1.00000     0.72039     0.00000     0.15698


 =========================================
 Variable Importance for the 27-tree Model
 =========================================

                  Abs     Rel

 A9_F       100.00000  100.00 |***********|
 A9_T        62.34801   62.35 |*******    |
 A15         45.24726   45.25 |*****      |
 A11         41.72195   41.72 |*****      |
 A3          40.94215   40.94 |*****      |
 A8          31.44829   31.45 |****       |
 A14         31.00841   31.01 |****       |
 A2          26.52071   26.52 |****       |
 A6_X        15.50889   15.51 |***        |
 A6_W        12.13159   12.13 |**         |
 A4_Y        12.13046   12.13 |**         |
 A4_U        10.16550   10.17 |**         |
 A6_C         8.25634    8.26 |**         |
 A10_F        6.67759    6.68 |**         |
 A12_T        6.66776    6.67 |**         |
 A12_F        6.51575    6.52 |**         |
 A7_V         3.55384    3.55 |*          |
 A7_H         3.30961    3.31 |*          |
 A6_Q         1.75403    1.75 |*          |


 Learn Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       185.00         7.00       0.0365
 1                  154.00       139.00        15.00       0.0974


 Test Sample Misclassification by Target Class
 For The 27-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        85.00        11.00       0.1146
 1                   76.00        64.00        12.00       0.1579

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 624 kb , 78% compression

 Grove file created containing:
      1 TreeNet

