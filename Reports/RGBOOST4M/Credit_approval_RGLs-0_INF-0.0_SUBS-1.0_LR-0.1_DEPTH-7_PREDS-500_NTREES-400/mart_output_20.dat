
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 51 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A2        0.0202
 A14       0.0145

             Test
 ----------------
 A14       0.0291
 A2        0.0174

 No learn sample variance for: A4_L.
 No learn sample variance for: A7_O.
 No learn sample variance for: A5_GG.
 No test sample variance for: A1_MISS.
 No test sample variance for: A6_R.
 No test sample variance for: A7_O.
 No test sample variance for: A7_N.



 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.61486      0.61999      0.16474      0.18023      1.00000 |                                               *
      2       0.55586      0.56668      0.11850      0.12791      1.00000 |                                           *
      3       0.50639      0.52223      0.10694      0.12209      1.00000 |                                       *
      4       0.46430      0.48512      0.08671      0.10465      1.00000 |                                     *
      5       0.42865      0.45561      0.08960      0.09884      1.00000 |                                  *
      6       0.39785      0.43022      0.08382      0.09302      1.00000 |                                *
      7       0.37049      0.41143      0.08382      0.09302      1.00000 |                               *
      8       0.34601      0.39330      0.08382      0.09884      1.00000 |                             *
      9       0.32595      0.37882      0.08671      0.09302      1.00000 |                            *
     10       0.30653      0.36181      0.07514      0.12209      1.00000 |                           *
     11       0.29015      0.35129      0.07803      0.12209      1.00000 |                          *
     12       0.27308      0.33796      0.07514      0.12791      1.00000 |                         *
     13       0.25807      0.32940      0.06936      0.12791      1.00000 |                         *
     14       0.24458      0.31881      0.05491      0.11628      1.00000 |                        *
     15       0.23282      0.31011      0.05491      0.11628      1.00000 |                       *
     16       0.22315      0.30363      0.05202      0.11628      1.00000 |                       *
     17       0.21251      0.29471      0.04624      0.11628      1.00000 |                      *
     18       0.20324      0.29081      0.04335      0.11628      1.00000 |                      *
     19       0.19429      0.28913      0.04046      0.11628      1.00000 |                     *
     20       0.18517      0.28531      0.03179      0.12209      1.00000 |                     *
     30       0.12214      0.25639      0.01156      0.11628      1.00000 |                   *
     40       0.08338      0.25116      0.00289      0.11047      1.00000 |                  *
     50       0.05929      0.25148      0.00000      0.10465      1.00000 |                  *
     60       0.04206      0.25963      0.00000      0.10465      1.00000 |                   *
     70       0.03142      0.27154      0.00000      0.10465      1.00000 |                    *
     80       0.02196      0.28040      0.00000      0.11047      1.00000 |                     *
     90       0.01585      0.28725      0.00000      0.10465      1.00000 |                     *
    100       0.01169      0.29812      0.00000      0.11047      1.00000 |                      *
    110       0.00883      0.30975      0.00000      0.11047      1.00000 |                       *
    120       0.00681      0.32606      0.00000      0.11047      1.00000 |                        *
    130       0.00521      0.33551      0.00000      0.11047      1.00000 |                         *
    140       0.00375      0.34898      0.00000      0.10465      1.00000 |                          *
    150       0.00272      0.36662      0.00000      0.11628      1.00000 |                           *
    160       0.00194      0.38273      0.00000      0.11628      1.00000 |                             *
    170       0.00142      0.39550      0.00000      0.11628      1.00000 |                              *
    180       0.00108      0.41457      0.00000      0.11628      1.00000 |                               *
    190       0.00078      0.43387      0.00000      0.11628      1.00000 |                                 *
    200       0.00059      0.44739      0.00000      0.11047      1.00000 |                                  *
    210       0.00043      0.46571      0.00000      0.11628      1.00000 |                                   *
    220       0.00032      0.47506      0.00000      0.11047      1.00000 |                                    *
    230       0.00025      0.49184      0.00000      0.11047      1.00000 |                                     *
    240       0.00019      0.50996      0.00000      0.11047      1.00000 |                                      *
    250       0.00014      0.51865      0.00000      0.11047      1.00000 |                                       *
    260       0.00011      0.52823      0.00000      0.11047      1.00000 |                                        *
    270       0.00008      0.54355      0.00000      0.11047      1.00000 |                                         *
    280       0.00006      0.54773      0.00000      0.11047      1.00000 |                                         *
    290       0.00004      0.56108      0.00000      0.11047      1.00000 |                                          *
    300       0.00003      0.57750      0.00000      0.11047      1.00000 |                                            *
    310       0.00002      0.59147      0.00000      0.11047      1.00000 |                                             *
    320       0.00002      0.60724      0.00000      0.11047      1.00000 |                                              *
    330       0.00001      0.61842      0.00000      0.10465      1.00000 |                                               *
    340       0.00001      0.63159      0.00000      0.10465      1.00000 |                                               *
    350       0.00001      0.65038      0.00000      0.10465      1.00000 |                                               *
    360       0.00001      0.66567      0.00000      0.10465      1.00000 |                                               *
    370       0.00000      0.68383      0.00000      0.10465      1.00000 |                                               *
    380       0.00000      0.69770      0.00000      0.11047      1.00000 |                                               *
    390       0.00000      0.71024      0.00000      0.11047      1.00000 |                                               *
    400       0.00000      0.73460      0.00000      0.11047      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    374      1    400      1      7      2.99      4.68  A3
    371      3    400      1      7      2.84      4.78  A14
    368      1    400      1      7      4.26      3.45  A2
    363      1    400      1      7      3.99      3.64  A8
    318      1    400      1      7      4.53      2.76  A15
    266      1    400      1      7      4.58      2.27  A11
    239      1    400      1      7      2.95      3.02  A9_T
    127      1    396      2      7      4.94      0.97  A7_V
     89      7    398      1      7      3.52      1.00  A6_W
     81      1    395      2      7      5.00      0.61  A7_H
     74     17    397      4      7      5.11      0.54  A6_C
     74     10    398      3      7      4.95      0.57  A4_U
     69     26    391      3      7      5.26      0.47  A1_B
     54     26    397      2      7      5.33      0.36  A9_F
     53      8    398      3      7      4.81      0.42  A1_A
     49     28    386      1      7      2.29      0.70  A6_FF
     42     31    395      3      7      5.07      0.31  A12_F
     40     12    399      1      7      4.15      0.39  A4_Y
     40      2    382      2      7      4.63      0.34  A10_F
     38     51    398      2      7      4.61      0.32  A6_M
     31      4    360      3      7      5.00      0.23  A6_Q
     29     39    370      1      6      3.69      0.31  A6_I
     24     30    373      1      5      2.63      0.32  A6_X
     22     19    380      3      7      6.09      0.11  A13_G
     17     68    397      2      7      4.71      0.14  A7_FF
     17     24    322      3      7      5.82      0.09  A6_K
     15     74    398      3      6      3.87      0.16  A7_BB
     12     61    379      1      7      4.17      0.12  A6_CC
     12     21    343      3      7      5.67      0.07  A12_T
     11     51    392      3      7      5.45      0.07  A13_S
      4    222    383      5      5      5.00      0.03  A6_D
      4    308    395      3      6      4.25      0.04  A6_AA
      0      0      0      0      0      0.00      0.00  A4_MISS
      0      0      0      0      0      0.00      0.00  A1_MISS
      0      0      0      0      0      0.00      0.00  A4_L
      0      0      0      0      0      0.00      0.00  A6_R
      0      0      0      0      0      0.00      0.00  A5_MISS
      0      0      0      0      0      0.00      0.00  A5_P
      0      0      0      0      0      0.00      0.00  A5_G
      0      0      0      0      0      0.00      0.00  A10_T
      0      0      0      0      0      0.00      0.00  A7_N
      0      0      0      0      0      0.00      0.00  A7_DD
      0      0      0      0      0      0.00      0.00  A7_O
      0      0      0      0      0      0.00      0.00  A7_MISS
      0      0      0      0      0      0.00      0.00  A5_GG
      0      0      0      0      0      0.00      0.00  A6_J
      0      0      0      0      0      0.00      0.00  A6_MISS
      0      0      0      0      0      0.00      0.00  A13_P
      0      0      0      0      0      0.00      0.00  A7_Z
      0      0      0      0      0      0.00      0.00  A7_J
      0      0      0      0      0      0.00      0.00  A6_E

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:     9 terminal nodes
    Largest :    27 terminal nodes
    Average :     18.43000 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 46 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 46 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 46

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 14344 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           46      0.24591
                  ROC           36      0.96443
                 Lift            9      2.26316
              KS-stat           61      0.82511
          Class.Error            6      0.09302

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.61486     0.61999     0.97709     0.92235     2.24675     1.96115     0.83212     0.77741     0.16474     0.18023
      6     0.39785     0.43022     0.98204     0.93702     2.24675     2.07393     0.84118     0.80866     0.08382     0.09302
      9     0.32595     0.37882     0.98446     0.94305     2.24675     2.26316     0.84794     0.80866     0.08671     0.09302
     10     0.30653     0.36181     0.98737     0.94655     2.24675     2.26316     0.86614     0.80866     0.07514     0.12209
     20     0.18517     0.28531     0.99503     0.95772     2.24675     2.26316     0.93628     0.80592     0.03179     0.12209
     30     0.12214     0.25639     0.99871     0.96053     2.24675     2.26316     0.98180     0.80154     0.01156     0.11628
     36     0.09570     0.24689     0.99983     0.96443     2.24675     2.26316     0.99479     0.80702     0.00578     0.11047
     40     0.08338     0.25116     0.99997     0.96251     2.24675     2.26316     0.99479     0.80702     0.00289     0.11047
     42     0.07774     0.24960     1.00000     0.96142     2.24675     2.26316     1.00000     0.80702     0.00289     0.11047
     43     0.07571     0.24788     1.00000     0.96279     2.24675     2.26316     1.00000     0.80921     0.00000     0.11047
     46     0.06872     0.24591     1.00000     0.96361     2.24675     2.26316     1.00000     0.81963     0.00000     0.11047
     50     0.05929     0.25148     1.00000     0.96128     2.24675     2.26316     1.00000     0.81743     0.00000     0.10465
     60     0.04206     0.25963     1.00000     0.95936     2.24675     2.26316     1.00000     0.82237     0.00000     0.10465
     61     0.04067     0.26117     1.00000     0.95922     2.24675     2.26316     1.00000     0.82511     0.00000     0.10465
     70     0.03142     0.27154     1.00000     0.95950     2.24675     2.26316     1.00000     0.82511     0.00000     0.10465
     80     0.02196     0.28040     1.00000     0.95881     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
     90     0.01585     0.28725     1.00000     0.95881     2.24675     2.26316     1.00000     0.82511     0.00000     0.10465
    100     0.01169     0.29812     1.00000     0.95772     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    110     0.00883     0.30975     1.00000     0.95868     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    120     0.00681     0.32606     1.00000     0.95895     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    130     0.00521     0.33551     1.00000     0.96005     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    140     0.00375     0.34898     1.00000     0.95964     2.24675     2.26316     1.00000     0.82511     0.00000     0.10465
    150     0.00272     0.36662     1.00000     0.95881     2.24675     2.26316     1.00000     0.82511     0.00000     0.11628
    160     0.00194     0.38273     1.00000     0.95964     2.24675     2.26316     1.00000     0.82511     0.00000     0.11628
    170     0.00142     0.39550     1.00000     0.95881     2.24675     2.26316     1.00000     0.82511     0.00000     0.11628
    180     0.00108     0.41457     1.00000     0.95868     2.24675     2.26316     1.00000     0.82511     0.00000     0.11628
    190     0.00078     0.43387     1.00000     0.95854     2.24675     2.26316     1.00000     0.82511     0.00000     0.11628
    200     0.00059     0.44739     1.00000     0.95758     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    210     0.00043     0.46571     1.00000     0.95785     2.24675     2.26316     1.00000     0.82511     0.00000     0.11628
    220     0.00032     0.47506     1.00000     0.95731     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    230     0.00025     0.49184     1.00000     0.95689     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    240     0.00019     0.50996     1.00000     0.95566     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    250     0.00014     0.51865     1.00000     0.95662     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    260     0.00011     0.52823     1.00000     0.95607     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    270     0.00008     0.54355     1.00000     0.95621     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    280     0.00006     0.54773     1.00000     0.95662     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    290     0.00004     0.56108     1.00000     0.95662     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    300     0.00003     0.57750     1.00000     0.95676     2.24675     2.26316     1.00000     0.81469     0.00000     0.11047
    310     0.00002     0.59147     1.00000     0.95689     2.24675     2.26316     1.00000     0.81469     0.00000     0.11047
    320     0.00002     0.60724     1.00000     0.95676     2.24675     2.26316     1.00000     0.82511     0.00000     0.11047
    330     0.00001     0.61842     1.00000     0.95662     2.24675     2.26316     1.00000     0.82511     0.00000     0.10465
    340     0.00001     0.63159     1.00000     0.95648     2.24675     2.26316     1.00000     0.82511     0.00000     0.10465
    350     0.00001     0.65038     1.00000     0.95580     2.24675     2.23684     1.00000     0.82511     0.00000     0.10465
    360     0.00001     0.66567     1.00000     0.95580     2.24675     2.26316     1.00000     0.81469     0.00000     0.10465
    370     0.00000     0.68383     1.00000     0.95552     2.24675     2.26316     1.00000     0.81469     0.00000     0.10465
    380     0.00000     0.69770     1.00000     0.95498     2.24675     2.26316     1.00000     0.81469     0.00000     0.11047
    390     0.00000     0.71024     1.00000     0.95470     2.24675     2.26316     1.00000     0.81469     0.00000     0.11047
    400     0.00000     0.73460     1.00000     0.95360     2.24675     2.13158     1.00000     0.81469     0.00000     0.11047


 =========================================
 Variable Importance for the 46-tree Model
 =========================================

                  Abs     Rel

 A9_T       100.00000  100.00 |***********|
 A3          41.20314   41.20 |*****      |
 A15         35.18324   35.18 |****       |
 A11         31.21416   31.21 |****       |
 A8          29.40783   29.41 |****       |
 A2          28.20995   28.21 |****       |
 A7_H        23.41322   23.41 |***        |
 A10_F       22.75428   22.75 |***        |
 A14         22.57866   22.58 |***        |
 A6_Q         9.63114    9.63 |**         |
 A6_W         8.19442    8.19 |**         |
 A7_V         7.38847    7.39 |**         |
 A4_U         6.21197    6.21 |**         |
 A6_FF        5.26334    5.26 |*          |
 A4_Y         5.09257    5.09 |*          |
 A1_B         4.82631    4.83 |*          |
 A1_A         4.45845    4.46 |*          |
 A9_F         4.09310    4.09 |*          |
 A6_X         3.89371    3.89 |*          |
 A13_G        3.10647    3.11 |*          |
 A6_C         2.65905    2.66 |*          |
 A6_I         2.51223    2.51 |*          |
 A12_F        1.55774    1.56 |*          |
 A6_K         0.98664    0.99 |*          |
 A12_T        0.17741    0.18 |*          |


 Learn Sample Misclassification by Target Class
 For The 46-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       192.00         0.00       0.0000
 1                  154.00       154.00         0.00       0.0000


 Test Sample Misclassification by Target Class
 For The 46-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        85.00        11.00       0.1146
 1                   76.00        68.00         8.00       0.1053

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/mart_model.grv: 599 kb , 79% compression

 Grove file created containing:
      1 TreeNet

