
 The "USE "../Data/Classification/Credit_approval/SAMPLE" command: 00:00:00

 Model (target and predictors) reset: CLASS

 The KEEP list has 51 variables.

 Salford Predictive Modeler(R) software suite: TreeNet(R) version 8.3.0.002

 The data cache will be established with this analysis.


 USE file Records Read: 346
 Records Kept in Learning sample: 346

 Note: data partitioning may differ from expected due to
 missing data, particularly in the target.


 Error file Records Read: 172
 Records Kept in Test sample: 172

 Discrete         N Levels
 Variable         in Model
 -------------------------
 CLASS                   2

 ======================
 Target Frequency Table
 ======================

 Variable: CLASS
 N Classes: 2
 Data Value                   N      %            Wgt Count      %
 -----------------------------------------------------------------
 0               L          192  55.49               192.00  55.49
                 T          (96  55.81)              (96.00  55.81)
 1               L          154  44.51               154.00  44.51
                 T          (76  44.19)              (76.00  44.19)
 -----------------------------------------------------------------
 Totals
 0                          288  55.60               288.00  55.60
 1                          230  44.40               230.00  44.40
 -----------------------------------------------------------------
 Total                      518                      518.00
 Total Learn                346                      346.00
 Total Test                 172                      172.00


 ========================
 Missing Value Prevalence
 ========================

            Learn
 ----------------
 A14       0.0145
 A2        0.0116

             Test
 ----------------
 A2        0.0174
 A14       0.0174

 No test sample variance for: A4_L.
 No test sample variance for: A6_R.
 No test sample variance for: A7_O.
 No test sample variance for: A7_N.
 No test sample variance for: A5_GG.



 ===============
 TreeNet Results
 ===============


 Unit Class Weights

 TreeNet is using CXE optimality criterion.

 Loss Function: LOGIT

           ---------AveLL---------   ---------CLASS---------
 N Trees        Learn         Test        Learn         Test        Fract    Test Profile
 ----------------------------------------------------------------------------------------
      1       0.62450      0.62483      0.25434      0.23837      1.00000 |                                               *
      2       0.57288      0.57628      0.14740      0.15116      1.00000 |                                           *
      3       0.52992      0.53379      0.10694      0.12791      1.00000 |                                        *
      4       0.49142      0.49685      0.09827      0.10465      1.00000 |                                     *
      5       0.45776      0.46835      0.10116      0.11047      1.00000 |                                   *
      6       0.42957      0.44136      0.09538      0.11628      1.00000 |                                 *
      7       0.40572      0.41991      0.09827      0.10465      1.00000 |                               *
      8       0.38316      0.40206      0.10405      0.12209      1.00000 |                              *
      9       0.36411      0.38626      0.10116      0.12209      1.00000 |                             *
     10       0.34649      0.37279      0.09538      0.12209      1.00000 |                            *
     11       0.33108      0.36008      0.08382      0.13372      1.00000 |                           *
     12       0.31711      0.34976      0.08382      0.12791      1.00000 |                          *
     13       0.30475      0.34121      0.08092      0.13372      1.00000 |                         *
     14       0.29219      0.32945      0.07803      0.12791      1.00000 |                        *
     15       0.27917      0.32053      0.07225      0.12791      1.00000 |                        *
     16       0.26938      0.31429      0.07514      0.12791      1.00000 |                       *
     17       0.26037      0.30767      0.07225      0.12791      1.00000 |                       *
     18       0.24986      0.30030      0.06647      0.12791      1.00000 |                      *
     19       0.24172      0.29473      0.06358      0.11628      1.00000 |                      *
     20       0.23394      0.28904      0.06358      0.12209      1.00000 |                     *
     30       0.16499      0.25521      0.03757      0.09302      1.00000 |                   *
     40       0.12005      0.25884      0.01445      0.09884      1.00000 |                   *
     50       0.08862      0.26430      0.00289      0.10465      1.00000 |                   *
     60       0.06768      0.27148      0.00289      0.10465      1.00000 |                    *
     70       0.05139      0.27637      0.00000      0.11628      1.00000 |                    *
     80       0.03952      0.29463      0.00000      0.12209      1.00000 |                      *
     90       0.03123      0.30772      0.00000      0.12791      1.00000 |                       *
    100       0.02400      0.31953      0.00000      0.12791      1.00000 |                        *
    110       0.01869      0.32510      0.00000      0.12209      1.00000 |                        *
    120       0.01483      0.33871      0.00000      0.12209      1.00000 |                         *
    130       0.01151      0.35126      0.00000      0.11628      1.00000 |                          *
    140       0.00867      0.36357      0.00000      0.11047      1.00000 |                           *
    150       0.00686      0.37435      0.00000      0.11047      1.00000 |                            *
    160       0.00544      0.38742      0.00000      0.11047      1.00000 |                             *
    170       0.00433      0.39676      0.00000      0.11047      1.00000 |                             *
    180       0.00338      0.40264      0.00000      0.11047      1.00000 |                              *
    190       0.00258      0.41879      0.00000      0.11628      1.00000 |                               *
    200       0.00202      0.42591      0.00000      0.11628      1.00000 |                                *
    210       0.00162      0.43825      0.00000      0.11047      1.00000 |                                 *
    220       0.00132      0.45360      0.00000      0.11628      1.00000 |                                  *
    230       0.00103      0.46897      0.00000      0.12209      1.00000 |                                   *
    240       0.00082      0.48079      0.00000      0.12209      1.00000 |                                    *
    250       0.00064      0.48768      0.00000      0.12209      1.00000 |                                    *
    260       0.00050      0.49622      0.00000      0.12209      1.00000 |                                     *
    270       0.00040      0.50915      0.00000      0.12209      1.00000 |                                      *
    280       0.00033      0.52161      0.00000      0.12209      1.00000 |                                       *
    290       0.00026      0.53800      0.00000      0.12209      1.00000 |                                        *
    300       0.00020      0.55716      0.00000      0.12209      1.00000 |                                          *
    310       0.00016      0.56783      0.00000      0.12209      1.00000 |                                           *
    320       0.00012      0.58461      0.00000      0.12209      1.00000 |                                            *
    330       0.00009      0.59427      0.00000      0.12791      1.00000 |                                             *
    340       0.00007      0.60812      0.00000      0.12209      1.00000 |                                              *
    350       0.00005      0.61815      0.00000      0.12209      1.00000 |                                              *
    360       0.00004      0.63024      0.00000      0.12209      1.00000 |                                               *
    370       0.00003      0.64270      0.00000      0.11628      1.00000 |                                               *
    380       0.00003      0.65256      0.00000      0.11628      1.00000 |                                               *
    390       0.00002      0.67042      0.00000      0.12209      1.00000 |                                               *
    400       0.00002      0.68867      0.00000      0.12209      1.00000 |                                               *

 Core TN model building:          0.000 sec ( 0.00 hrs)



 ----- Presence -----    ---- Top Depth -----     Depth
 NTrees  First   Last    Min    Max       Avg     Score  Predictor
 ------------------------------------------------------------------
    381      1    400      1      7      3.59      4.20  A2
    366      1    400      2      7      3.40      4.21  A3
    360      1    400      1      7      4.12      3.49  A14
    330      1    400      1      7      4.62      2.79  A8
    320      1    399      1      7      3.82      3.35  A15
    209      1    399      1      7      3.99      2.10  A11
    117      1    390      1      7      2.46      1.62  A9_F
    117      4    399      1      7      2.38      1.65  A9_T
    115      9    400      3      7      5.58      0.70  A7_V
     94     21    400      1      5      1.29      1.58  A6_X
     76     11    396      3      7      3.88      0.78  A6_C
     72     46    397      1      6      1.42      1.19  A6_M
     70     25    396      1      7      2.47      0.97  A6_I
     69      4    400      1      7      3.93      0.70  A4_Y
     57     11    398      2      7      3.82      0.60  A1_A
     50     32    389      2      7      3.14      0.61  A6_FF
     45      7    375      3      7      5.53      0.28  A10_F
     43      4    366      3      7      5.91      0.23  A12_T
     42     32    388      1      7      4.81      0.34  A6_K
     40     11    389      3      7      5.50      0.25  A12_F
     39     24    398      1      3      1.33      0.65  A6_CC
     38     34    400      3      7      5.76      0.21  A1_B
     29      2    400      3      7      5.10      0.21  A6_W
     25     17    398      4      7      4.96      0.19  A4_U
     19     39    388      2      7      5.63      0.11  A13_S
     18     66    399      2      7      4.17      0.17  A6_Q
     17      2    394      4      7      5.41      0.11  A7_H
     15      2    383      2      5      3.20      0.18  A13_G
     14     31    397      2      5      2.79      0.18  A7_FF
     13     52    295      2      6      3.23      0.16  A7_BB
      9    128    285      1      2      1.44      0.15  A6_E
      3    202    334      4      7      5.00      0.02  A6_AA
      1     59     59      4      4      4.00      0.01  A6_D
      0      0      0      0      0      0.00      0.00  A5_MISS
      0      0      0      0      0      0.00      0.00  A5_P
      0      0      0      0      0      0.00      0.00  A5_G
      0      0      0      0      0      0.00      0.00  A10_T
      0      0      0      0      0      0.00      0.00  A7_N
      0      0      0      0      0      0.00      0.00  A7_DD
      0      0      0      0      0      0.00      0.00  A7_O
      0      0      0      0      0      0.00      0.00  A1_MISS
      0      0      0      0      0      0.00      0.00  A7_MISS
      0      0      0      0      0      0.00      0.00  A7_Z
      0      0      0      0      0      0.00      0.00  A6_R
      0      0      0      0      0      0.00      0.00  A6_J
      0      0      0      0      0      0.00      0.00  A6_MISS
      0      0      0      0      0      0.00      0.00  A13_P
      0      0      0      0      0      0.00      0.00  A7_J
      0      0      0      0      0      0.00      0.00  A4_MISS
      0      0      0      0      0      0.00      0.00  A4_L
      0      0      0      0      0      0.00      0.00  A5_GG

 Note: Top Depth is conditional on predictor appearing in tree.
       Depth Score == 0.0 for a predictor not appearing in tree.
       Depth == 1 for the root node.

 Characterization of TN tree dimensionality:
    Smallest:    10 terminal nodes
    Largest :    27 terminal nodes
    Average :     18.17750 terminal nodes

 Reconciling 346 Learn sample scores across 5 selected models,
 the largest having 32 trees, to compute gains and PS tables.

 Reconciling 172 Test sample scores across 5 selected models,
 the largest having 32 trees, to compute gains and PS tables.


 ========================
 TreeNet Model Dimensions
 ========================

 N Trees
       Total: 400
     Optimal: 32

 Target: CLASS
 Focus Class: 1

                     N     Weighted
 N Learn Obs:      346       346.00
 N Test  Obs:      172       172.00
 Learn Rate :    0.1000000

 Storage requirements: 14142 tree / 1 categorical splits

 Mean time per tree: 00:00:00.00
 Logistic Model.


 ==========================
 Learn and Test Performance
 ==========================

 Optimality Criterion      N-trees      Test/CV
 ----------------------------------------------
                AveLL           32      0.25425
                  ROC           29      0.96258
                 Lift            4      2.26316
              KS-stat           32      0.84539
          Class.Error           28      0.09302

              AveLL       AveLL         ROC         ROC        Lift        Lift     KS-stat     KS-stat Class.Error Class.Error
  Trees       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV       Learn     Test/CV
 ------------------------------------------------------------------------------------------------------------------------------
      1     0.62450     0.62483     0.95564     0.94189     2.24675     2.18772     0.75812     0.76480     0.25434     0.23837
      4     0.49142     0.49685     0.96763     0.95347     2.24675     2.26316     0.81284     0.79550     0.09827     0.10465
     10     0.34649     0.37279     0.97507     0.95230     2.24675     2.26316     0.81683     0.80099     0.09538     0.12209
     20     0.23394     0.28904     0.98446     0.95710     2.24675     2.26316     0.88305     0.80866     0.06358     0.12209
     28     0.17739     0.25707     0.99278     0.96176     2.24675     2.26316     0.90902     0.83772     0.04335     0.09302
     29     0.17278     0.25551     0.99329     0.96258     2.24675     2.26316     0.91423     0.83772     0.04335     0.09302
     30     0.16499     0.25521     0.99488     0.96121     2.24675     2.26316     0.93107     0.83772     0.03757     0.09302
     32     0.15441     0.25425     0.99626     0.96217     2.24675     2.26316     0.94670     0.84539     0.02601     0.09302
     40     0.12005     0.25884     0.99958     0.95998     2.24675     2.26316     0.97917     0.83498     0.01445     0.09884
     50     0.08862     0.26430     0.99995     0.95765     2.24675     2.26316     0.99479     0.81469     0.00289     0.10465
     60     0.06768     0.27148     0.99998     0.95641     2.24675     2.26316     0.99479     0.80921     0.00289     0.10465
     66     0.05710     0.27591     1.00000     0.95491     2.24675     2.26316     1.00000     0.80647     0.00000     0.11047
     70     0.05139     0.27637     1.00000     0.95518     2.24675     2.26316     1.00000     0.79605     0.00000     0.11628
     80     0.03952     0.29463     1.00000     0.95134     2.24675     2.13158     1.00000     0.79112     0.00000     0.12209
     90     0.03123     0.30772     1.00000     0.94901     2.24675     2.13158     1.00000     0.77248     0.00000     0.12791
    100     0.02400     0.31953     1.00000     0.94833     2.24675     2.13158     1.00000     0.79825     0.00000     0.12791
    110     0.01869     0.32510     1.00000     0.94805     2.24675     2.13158     1.00000     0.80866     0.00000     0.12209
    120     0.01483     0.33871     1.00000     0.94696     2.24675     2.13158     1.00000     0.79825     0.00000     0.12209
    130     0.01151     0.35126     1.00000     0.94490     2.24675     2.13158     1.00000     0.77741     0.00000     0.11628
    140     0.00867     0.36357     1.00000     0.94380     2.24675     2.13158     1.00000     0.77741     0.00000     0.11047
    150     0.00686     0.37435     1.00000     0.94476     2.24675     2.13158     1.00000     0.77741     0.00000     0.11047
    160     0.00544     0.38742     1.00000     0.94367     2.24675     2.13158     1.00000     0.77741     0.00000     0.11047
    170     0.00433     0.39676     1.00000     0.94367     2.24675     2.23684     1.00000     0.77741     0.00000     0.11047
    180     0.00338     0.40264     1.00000     0.94422     2.24675     2.26316     1.00000     0.77741     0.00000     0.11047
    190     0.00258     0.41879     1.00000     0.94257     2.24675     2.26316     1.00000     0.77741     0.00000     0.11628
    200     0.00202     0.42591     1.00000     0.94271     2.24675     2.26316     1.00000     0.78783     0.00000     0.11628
    210     0.00162     0.43825     1.00000     0.94230     2.24675     2.13158     1.00000     0.78783     0.00000     0.11047
    220     0.00132     0.45360     1.00000     0.94271     2.24675     2.13158     1.00000     0.77741     0.00000     0.11628
    230     0.00103     0.46897     1.00000     0.94257     2.24675     2.23684     1.00000     0.77741     0.00000     0.12209
    240     0.00082     0.48079     1.00000     0.94202     2.24675     2.13158     1.00000     0.77741     0.00000     0.12209
    250     0.00064     0.48768     1.00000     0.94175     2.24675     2.13158     1.00000     0.77741     0.00000     0.12209
    260     0.00050     0.49622     1.00000     0.94161     2.24675     2.13158     1.00000     0.77467     0.00000     0.12209
    270     0.00040     0.50915     1.00000     0.94216     2.24675     2.13158     1.00000     0.78783     0.00000     0.12209
    280     0.00033     0.52161     1.00000     0.94285     2.24675     2.13158     1.00000     0.79825     0.00000     0.12209
    290     0.00026     0.53800     1.00000     0.94093     2.24675     2.13158     1.00000     0.78783     0.00000     0.12209
    300     0.00020     0.55716     1.00000     0.94010     2.24675     2.13158     1.00000     0.78235     0.00000     0.12209
    310     0.00016     0.56783     1.00000     0.94010     2.24675     2.13158     1.00000     0.78235     0.00000     0.12209
    320     0.00012     0.58461     1.00000     0.93969     2.24675     2.13158     1.00000     0.78235     0.00000     0.12209
    330     0.00009     0.59427     1.00000     0.93969     2.24675     2.13158     1.00000     0.78235     0.00000     0.12791
    340     0.00007     0.60812     1.00000     0.94010     2.24675     2.13158     1.00000     0.78235     0.00000     0.12209
    350     0.00005     0.61815     1.00000     0.94038     2.24675     2.13158     1.00000     0.77741     0.00000     0.12209
    360     0.00004     0.63024     1.00000     0.94024     2.24675     2.13158     1.00000     0.77741     0.00000     0.12209
    370     0.00003     0.64270     1.00000     0.94010     2.24675     2.13158     1.00000     0.78015     0.00000     0.11628
    380     0.00003     0.65256     1.00000     0.94024     2.24675     2.13158     1.00000     0.77741     0.00000     0.11628
    390     0.00002     0.67042     1.00000     0.93942     2.24675     2.13158     1.00000     0.77741     0.00000     0.12209
    400     0.00002     0.68867     1.00000     0.93819     2.24675     2.13158     1.00000     0.77741     0.00000     0.12209


 =========================================
 Variable Importance for the 32-tree Model
 =========================================

                  Abs     Rel

 A9_F       100.00000  100.00 |***********|
 A9_T        96.02716   96.03 |***********|
 A15         55.15904   55.16 |******     |
 A3          52.45544   52.46 |******     |
 A14         42.64533   42.65 |*****      |
 A2          40.65361   40.65 |*****      |
 A11         39.14765   39.15 |*****      |
 A8          38.54110   38.54 |*****      |
 A6_X        24.24356   24.24 |***        |
 A6_W        19.29135   19.29 |***        |
 A13_G       17.88679   17.89 |***        |
 A4_Y        16.82223   16.82 |***        |
 A6_CC       15.42256   15.42 |**         |
 A7_H        14.57171   14.57 |**         |
 A4_U        12.41132   12.41 |**         |
 A1_A        11.43370   11.43 |**         |
 A12_T       10.87686   10.88 |**         |
 A10_F        9.37289    9.37 |**         |
 A12_F        6.93133    6.93 |**         |
 A7_FF        5.88975    5.89 |**         |
 A6_FF        5.78152    5.78 |**         |
 A6_K         5.43604    5.44 |*          |
 A7_V         4.29793    4.30 |*          |
 A6_I         0.08683    0.09 |*          |
 A6_C         0.02913    0.03 |*          |


 Learn Sample Misclassification by Target Class
 For The 32-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                  192.00       189.00         3.00       0.0156
 1                  154.00       148.00         6.00       0.0390


 Test Sample Misclassification by Target Class
 For The 32-Tree Model
 Accumulation: True Class by Predicted Class
 All Counts are Weighted

 Class             N Total    N Correct   N Misclass  Prop Misclass
 0                   96.00        86.00        10.00       0.1042
 1                   76.00        70.00         6.00       0.0789

 Plot queue is empty.

 Smoothed plots queue is empty.

 MARTDO:                0.000 sec ( 0.00 hrs)

 Grove file created: /home/jries/projects/SPM_vs_XGBOOST/Scripts/treenet_model.grv: 598 kb , 78% compression

 Grove file created containing:
      1 TreeNet

